{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def normalize(arr):\n",
    "    norm = np.linalg.norm(arr)\n",
    "    if norm == 0.0:\n",
    "        return arr\n",
    "    return np.divide(arr, norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title             405\n",
       "TitleAgiVector    405\n",
       "JoinKey           405\n",
       "dtype: int64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_agi_vector_list = []\n",
    "title_set = set()\n",
    "title_agi_vector_file = open(\"title_agi_vector_json.tsv\", \"r\", encoding = \"cp1252\")\n",
    "for line in title_agi_vector_file:\n",
    "    try:\n",
    "        parsed_result = json.loads(line.strip())[0]\n",
    "        title = parsed_result['query']\n",
    "        vector = normalize(parsed_result['vector'])\n",
    "        if title not in title_set:\n",
    "            title_agi_vector_list.append((title, vector))\n",
    "            title_set.add(parsed_result['query'])\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "title_agi_vector_file.close()\n",
    "\n",
    "title_df = pd.DataFrame(title_agi_vector_list, columns = ['Title', 'TitleAgiVector'])\n",
    "title_df[\"JoinKey\"] = 1\n",
    "title_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Snippet             386\n",
       "SnippetAgiVector    386\n",
       "JoinKey             386\n",
       "dtype: int64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snippet_agi_vector_list = []\n",
    "snippet_set = set()\n",
    "snippet_agi_vector_file = open(\"snippet_agi_vector_json.tsv\", \"r\", encoding = 'cp1252')\n",
    "for line in snippet_agi_vector_file:\n",
    "    try:\n",
    "        parsed_result = json.loads(line.strip())[0]\n",
    "        snippet = parsed_result['query']\n",
    "        vector = normalize(parsed_result['vector'])\n",
    "        if snippet not in snippet_set:\n",
    "            snippet_agi_vector_list.append((snippet, vector))\n",
    "            snippet_set.add(snippet)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "snippet_agi_vector_file.close()\n",
    "\n",
    "snippet_df = pd.DataFrame(snippet_agi_vector_list, columns = [\"Snippet\", \"SnippetAgiVector\"])\n",
    "snippet_df[\"JoinKey\"] = 1\n",
    "snippet_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title_x             164025\n",
       "TitleAgiVector_x    164025\n",
       "Title_y             164025\n",
       "TitleAgiVector_y    164025\n",
       "dtype: int64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_title_df = pd.merge(title_df, title_df, on = [\"JoinKey\"])\n",
    "title_title_df = title_title_df.drop(\"JoinKey\", axis=1)\n",
    "title_title_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title_x</th>\n",
       "      <th>TitleAgiVector_x</th>\n",
       "      <th>Title_y</th>\n",
       "      <th>TitleAgiVector_y</th>\n",
       "      <th>Similarity</th>\n",
       "      <th>Similarity1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30856</th>\n",
       "      <td>阿里浏览器DNS解析加速</td>\n",
       "      <td>[-0.03440448356489144, -0.12447976191659889, -...</td>\n",
       "      <td>阿里浏览器DNS解析加速</td>\n",
       "      <td>[-0.03440448356489144, -0.12447976191659889, -...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30894</th>\n",
       "      <td>阿里浏览器DNS解析加速</td>\n",
       "      <td>[-0.03440448356489144, -0.12447976191659889, -...</td>\n",
       "      <td>淘宝海量数据库的设计和实现</td>\n",
       "      <td>[-0.05795493055917471, -0.10417753143380089, -...</td>\n",
       "      <td>0.979902</td>\n",
       "      <td>0.979902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30973</th>\n",
       "      <td>阿里浏览器DNS解析加速</td>\n",
       "      <td>[-0.03440448356489144, -0.12447976191659889, -...</td>\n",
       "      <td>刘佳_出生证明公证办理委托书</td>\n",
       "      <td>[-0.05795493055917471, -0.10417753143380089, -...</td>\n",
       "      <td>0.979902</td>\n",
       "      <td>0.979902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30835</th>\n",
       "      <td>阿里浏览器DNS解析加速</td>\n",
       "      <td>[-0.03440448356489144, -0.12447976191659889, -...</td>\n",
       "      <td>贴吧大数据存储解决方案</td>\n",
       "      <td>[-0.05553168131325587, -0.09946641756622951, -...</td>\n",
       "      <td>0.979322</td>\n",
       "      <td>0.979322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30843</th>\n",
       "      <td>阿里浏览器DNS解析加速</td>\n",
       "      <td>[-0.03440448356489144, -0.12447976191659889, -...</td>\n",
       "      <td>工作6周年5个月小记</td>\n",
       "      <td>[-0.053652287028072544, -0.09610203085849282, ...</td>\n",
       "      <td>0.977716</td>\n",
       "      <td>0.977716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Title_x                                   TitleAgiVector_x  \\\n",
       "30856  阿里浏览器DNS解析加速  [-0.03440448356489144, -0.12447976191659889, -...   \n",
       "30894  阿里浏览器DNS解析加速  [-0.03440448356489144, -0.12447976191659889, -...   \n",
       "30973  阿里浏览器DNS解析加速  [-0.03440448356489144, -0.12447976191659889, -...   \n",
       "30835  阿里浏览器DNS解析加速  [-0.03440448356489144, -0.12447976191659889, -...   \n",
       "30843  阿里浏览器DNS解析加速  [-0.03440448356489144, -0.12447976191659889, -...   \n",
       "\n",
       "              Title_y                                   TitleAgiVector_y  \\\n",
       "30856    阿里浏览器DNS解析加速  [-0.03440448356489144, -0.12447976191659889, -...   \n",
       "30894   淘宝海量数据库的设计和实现  [-0.05795493055917471, -0.10417753143380089, -...   \n",
       "30973  刘佳_出生证明公证办理委托书  [-0.05795493055917471, -0.10417753143380089, -...   \n",
       "30835     贴吧大数据存储解决方案  [-0.05553168131325587, -0.09946641756622951, -...   \n",
       "30843      工作6周年5个月小记  [-0.053652287028072544, -0.09610203085849282, ...   \n",
       "\n",
       "       Similarity  Similarity1  \n",
       "30856    1.000000     1.000000  \n",
       "30894    0.979902     0.979902  \n",
       "30973    0.979902     0.979902  \n",
       "30835    0.979322     0.979322  \n",
       "30843    0.977716     0.977716  "
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# axis=0 or axis=\"index\", apply functions to each column\n",
    "# axis=1 or axis=\"column\", apply functions to each row\n",
    "title_title_df['Similarity1'] = title_title_df.apply(lambda r: np.dot(r['TitleAgiVector_x'], r['TitleAgiVector_y']), axis=\"columns\")\n",
    "title_title_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in title_title_df.iterrows():\n",
    "    #print(np.dot(list(map,float(row['TitleAgiVector_x'])), list(map(float(row['TitleAgiVector_y'])))))\n",
    "    title_title_df.loc[i,\"Similarity\"] = np.dot(row['TitleAgiVector_x'], row['TitleAgiVector_y'])\n",
    "    if i%10000==0:\n",
    "        print(i)\n",
    "title_title_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87000\n",
      "54000\n",
      "96000\n",
      "114000\n",
      "0\n",
      "1000\n",
      "81000\n",
      "143000\n",
      "95000\n",
      "405 titles got 10 similar titles\n"
     ]
    }
   ],
   "source": [
    "title_measurement_file = codecs.open(\"title_measurement.tsv\", \"w\", encoding=\"utf-8\")\n",
    "\n",
    "title_title_df= title_title_df.sort_values(by = ['Title_x','Similarity'], ascending = [False,False])\n",
    "title_title_df_top10 = title_title_df.groupby('Title_x')[\"Title_x\", \"Title_y\", \"Similarity\"].head(10)\n",
    "\n",
    "title_set = set()\n",
    "for index, row in title_title_df_top10.iterrows():\n",
    "    if row['Title_x'] not in title_set:\n",
    "        title_set.add(row['Title_x'])\n",
    "        title_measurement_file.write(\"\\n{0}\\t{1}\\t{2}\\n\".format(row['Title_x'], row['Title_y'], row['Similarity']))\n",
    "    else:\n",
    "        title_measurement_file.write(\"{0}\\t{1}\\t{2}\\n\".format(row['Title_x'], row['Title_y'], row['Similarity']))\n",
    "    if index%1000 == 0:\n",
    "        print(index)\n",
    "\n",
    "print(\"{0} titles got 10 similar titles\".format(len(title_set)))\n",
    "title_measurement_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_recall_file = codecs.open(\"title_recall_file.tsv\", \"w\", encoding = \"utf-8\")\n",
    "title_set = set()\n",
    "for index, row in title_title_df_top10.iterrows():\n",
    "    if float(row['Similarity']) >= 0.5 and row['Title_x'] != row['Title_y']:\n",
    "        if row['Title_x'] not in title_set:\n",
    "            title_set.add(row['Title_x'])\n",
    "            title_recall_file.write(\"\\n{0}\\t{1}\\t{2}\\n\".format(row['Title_x'], row['Title_y'], row['Similarity']))\n",
    "        else:\n",
    "            title_recall_file.write(\"{0}\\t{1}\\t{2}\\n\".format(row['Title_x'], row['Title_y'], row['Similarity']))\n",
    "    if index % 10000:\n",
    "        print(index)\n",
    "\n",
    "print(\"{0} titles got titles with similarity >= 0.5\".format(len(title_set)))\n",
    "title_recall_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title               156330\n",
       "TitleAgiVector      156330\n",
       "Snippet             156330\n",
       "SnippetAgiVector    156330\n",
       "dtype: int64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_snippet_df = pd.merge(title_df, snippet_df, on = [\"JoinKey\"])\n",
    "title_snippet_df = title_snippet_df.drop(\"JoinKey\", axis=1)\n",
    "title_snippet_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in title_snippet_df.iterrows():\n",
    "    title_snippet_df.loc[i, \"Similarity\"] = np.dot(row[\"TitleAgiVector\"], row[\"SnippetAgiVector\"])\n",
    "    if i % 10000 == 0:\n",
    "        print(i)\n",
    "title_snippet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29000\n",
      "95000\n",
      "0\n",
      "405 titles have similarity scores with snippets\n"
     ]
    }
   ],
   "source": [
    "snippet_measurement_file = codecs.open(\"snippet_measurement.tsv\", \"w\", encoding=\"utf-8\")\n",
    "\n",
    "title_snippet_df= title_snippet_df.sort_values(by = ['Title','Similarity'], ascending = [False,False])\n",
    "title_snippet_df_top10 = title_snippet_df.groupby('Title')[\"Title\", \"Snippet\", \"Similarity\"].head(10)\n",
    "\n",
    "snippet_set = set()\n",
    "for index, row in title_snippet_df_top10.iterrows():\n",
    "    if row['Title'] not in snippet_set:\n",
    "        snippet_set.add(row['Title'])\n",
    "        snippet_measurement_file.write(\"\\n{0}\\t{1}\\t{2}\\n\".format(row['Title'], row['Snippet'], row['Similarity']))\n",
    "    else:\n",
    "        snippet_measurement_file.write(\"{0}\\t{1}\\t{2}\\n\".format(row['Title'], row['Snippet'], row['Similarity']))\n",
    "    if index%1000 == 0:\n",
    "        print(index)\n",
    "\n",
    "print(\"{0} titles have similarity scores with snippets\".format(len(snippet_set)))\n",
    "snippet_measurement_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29000\n",
      "95000\n",
      "0\n",
      "219 titles have similarity >= 0.5 with other documents\n"
     ]
    }
   ],
   "source": [
    "snippet_recall_file = codecs.open(\"snippet_recall.tsv\", \"w\", encoding = \"utf-8\")\n",
    "\n",
    "snippet_set = set()\n",
    "for index, row in title_snippet_df_top10.iterrows():\n",
    "    if float(row['Similarity']) >= 0.5 and float(row['Similarity']) < 1:\n",
    "        if row['Title'] not in snippet_set:\n",
    "            snippet_set.add(row['Title'])\n",
    "            snippet_recall_file.write(\"\\n{0}\\t{1}\\t{2}\\n\".format(row['Title'], row['Snippet'], row['Similarity']))\n",
    "        else:\n",
    "            snippet_recall_file.write(\"{0}\\t{1}\\t{2}\\n\".format(row['Title'], row['Snippet'], row['Similarity']))\n",
    "    if index%1000 == 0:\n",
    "        print(index)\n",
    "    \n",
    "print(\"{0} titles have similarity >= 0.5 with other documents\".format(len(snippet_set)))\n",
    "snippet_recall_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
