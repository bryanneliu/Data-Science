
阿里浏览器DNS解析加速	BS代码阅读：BS基本功能：索引相关性切词成分分析offset调权query解析 （where+what）多路归并 综合调权类聚（偏离点）query分类空间调权数据来源点击调权BS代码阅读：bs_cache:map库的term cachemap库term cache操作锁where库term cachewhere库term cache操作锁init_map_term_cache: 初始化map库term cachein	0.9221752936295954
阿里浏览器DNS解析加速	贝叶斯分类模型：基础知识：假设	X：是数据元组，由n个属性描述；	H：是某种假设，如数据元组属于某特定类C	P(H|X)：表示给定X的属性描述，找出元组X属于类C的概率举例：X：一位35岁的顾客，收入为4w美元；H：顾客将购买计算机P(H|X)：在X的条件下，H的后验概率。当我们知道顾客的年龄和收入时，顾客X将购买计算机的概率。P(H)：H的先验概率。任意给定顾客将购买计算机的概率，独立与X。P(X|H)：在条件H下，X的后验概率。已知顾客购买了计算机，顾客是一位3	0.9219524723346816
阿里浏览器DNS解析加速	K最近邻分类模型：原理：训练元组用n个属性描述，每个元组代表n维空间中的一个点，所有的训练元组存放在n维的模式空间。当给定一个未知元组时，KNN搜索该模式空间，找出最接近未知元组的k个训练元组。未知元组指派到它的k个最近邻中的多数类。“邻近性”用距离度量，如欧几里德距离。欧几里德距离：	设元组X1=(X11,X12,…X1n)，X2=(X21,X22,…X2n)，	Dist(X1,X2)=√ ∑ k= 1 n (X1i-X2i) 2 	使用上式之前，对每个属性的值规范化，以防止具有	0.9191686648038612
阿里浏览器DNS解析加速	排序及扩展：插入排序，选择排序（冒泡排序），使用二分思想求第k大数，快速排序，非递归的快速排序，使用快排思想求第k大数，归并排序，求逆序数，自然排序算法，堆排序，最小优先级队列，计数排序，桶排序，鸽巢排序（分块排序），基数排序，外部排序：二路归并，K路归并，胜者树，败者树。  算法一：使用插入或者选择排序，得到最大的K个数，时间复杂度为：O(N*k)。 冒泡排序： void swap(int * a,int * b){            //注意	0.9186142755226615
阿里浏览器DNS解析加速	克拉玛依公证处:本人因生活在国外，不能亲自到贵单位办理出生证明公证事项，兹授权委托雷春香女士全权代表我办理相关事项。对委托人在办理上述事项过程中所签署的有关文件，我均予以认可，并承担相应的法律责任。委托人：刘佳			委托人身份证号码：654301198608243929被委托人：雷春香		被委托人身份证号码：6526196207113926委托人：刘佳2018年5月24日	0.9186142755226615
阿里浏览器DNS解析加速	性能升级性能升级的几个层面：系统结构：模块分解，模块交互，系统构建中的粗略估算。算法和数据结构：获得快速模块的关键：表示数据的结构，操作数据的算法：索引结构及拉链归并。代码调优：分支预测等。循环：将循环体中不改变的变量移动到循环体外；多重循环嵌套顺序。函数调用：inline函数节省函数调用开销：若makefile中不指定至少-O优化，即使声明为inline函数，编译器也不会进行函数内联。内存寻址：避免重复内存寻址。Cpu流水线的分支预测：将满足概率最高的条件放在靠前的位置。	0.9186142755226615
阿里浏览器DNS解析加速	业务生成平台用户指南总体说明开发背景下一代网络是业务驱动的网络，在融合的下一代网络上高效、灵活地开发和部署各种丰富多彩的业务，从而提高网络使用率、增加收益的目标，是下一代网络的关键环节。下一代网络的发展要求呼叫与承载相分离、呼叫控制与业务相分离，使业务真正独立于网络，业务开发者不必关心与业务承载相关的底层网络知识以及具体的通信协议，只需利用业务生成平台提供的业务开发工具，就可以开发出灵活丰富且极具个性化的业务。 为了适合多种技术水平的业务开发人员的需要，现在主要有四种业务开发方式：	0.9186142755226615
阿里浏览器DNS解析加速	Svm分类模型：基本原理：将所有待分类的点映射到“高维空间”，然后在高维空间中找到一个能将这些点分开的“超平面”，这在理论上是被完全证明了是成立的，而且在实际计算中也是可行的。满足条件的“超平面”的个数不是唯一的。SVM需要的是利用这些超平面，找到这两类点之间的“最大间隔”。并非所有的数据都线性可分，将非线性映射到更高维的特征空间变成线性可分。（低维空间向量集通常难于划分，解决的方法是将它们映射到高维空间。）但这个办法带来的困难就是计算复杂度的增加，而核函数正好巧妙地解决了这个问题。也就是说，只要选用	0.9175959477868517
阿里浏览器DNS解析加速	工作6周年5个月小记今天是中国时间8/24/2018，也就是我32岁的生日，这是一个不老也不再年轻的年纪。最近总是因为工作而郁郁寡欢，心中不快，所以决定记录总结一下，希望自己能有所释怀、转变、确立新的目标。从2012年3月31到现在，我已在微软Bing工作6年5个月。在此之前，我在百度实习9个月，在阿里巴巴实习2个月，在搜狗实习1个月。在微软北京CJK relevance组勤恳的工作2年6个月，从级别59升到61，做了1年半的DU, 1年的relevance。总体来说，老板们的风格是相关性主导基础	0.9166918806631864
阿里浏览器DNS解析加速	神经网络原理及应用介绍Anti RD：王伟琼、张爱华主要内容特点及应用场景神经网络原理我们的经验和教训多线程训练下一步的工作应用场景分类预测时间允许的场合使用并行化等方法加速测试过程很快，且可以方便的使用hadoop平台环境比较固定的场合数据的统计特性变化不大需要定量预测的场合给出未知数据的定量预测神经网络特点优点对噪音数据有较好的适应能力对未知数据具有较好的预测分类能力拟合各种函数得出定量值缺点学习时间较长	0.9164615063819938

资源区confilter词表匹配算法升级	资源区confilter升级之词表匹配算法调研分析词表匹配贴吧confilter词表匹配算法介绍贴吧confilter词表匹配算法的分析trie树介绍trie树进行词表匹配的分析ac自动机介绍ac自动机进行词表匹配的分析改进内存的ac自动机介绍tst（ternary-search- tree）介绍tst（ternary-search- tree）进行词表匹配的分析资源confilter词表统计分析总结词表匹配confilter为内容过滤模块，词表匹配	0.943640302226239
资源区confilter词表匹配算法升级	资源confilter升级之词表匹配算法详细设计及对比贴吧词表算法抽取ac自动机改进内存的ac自动机测试环境的搭建测试数据与对比分析贴吧词表匹配算法抽取bitmap原理：将词表中的一行字符串的前3个字节（可以小于3）在bitmap中标识。用于在匹配输入串时，快速定位词表中是否有当前指针指向的字符串前3个字节为首的过滤词，若有继续匹配，否则指针后移。具体实现：3个字节的二进制数，即表示：0-256^3。动态分配2^24bit的空间，即（2^24bit）/((8bi	0.9339283107935193
资源区confilter词表匹配算法升级	贝叶斯分类模型：基础知识：假设	X：是数据元组，由n个属性描述；	H：是某种假设，如数据元组属于某特定类C	P(H|X)：表示给定X的属性描述，找出元组X属于类C的概率举例：X：一位35岁的顾客，收入为4w美元；H：顾客将购买计算机P(H|X)：在X的条件下，H的后验概率。当我们知道顾客的年龄和收入时，顾客X将购买计算机的概率。P(H)：H的先验概率。任意给定顾客将购买计算机的概率，独立与X。P(X|H)：在条件H下，X的后验概率。已知顾客购买了计算机，顾客是一位3	0.9166929205772043
资源区confilter词表匹配算法升级	BS代码阅读：BS基本功能：索引相关性切词成分分析offset调权query解析 （where+what）多路归并 综合调权类聚（偏离点）query分类空间调权数据来源点击调权BS代码阅读：bs_cache:map库的term cachemap库term cache操作锁where库term cachewhere库term cache操作锁init_map_term_cache: 初始化map库term cachein	0.9166472116819638
资源区confilter词表匹配算法升级	K最近邻分类模型：原理：训练元组用n个属性描述，每个元组代表n维空间中的一个点，所有的训练元组存放在n维的模式空间。当给定一个未知元组时，KNN搜索该模式空间，找出最接近未知元组的k个训练元组。未知元组指派到它的k个最近邻中的多数类。“邻近性”用距离度量，如欧几里德距离。欧几里德距离：	设元组X1=(X11,X12,…X1n)，X2=(X21,X22,…X2n)，	Dist(X1,X2)=√ ∑ k= 1 n (X1i-X2i) 2 	使用上式之前，对每个属性的值规范化，以防止具有	0.9153283267117739
资源区confilter词表匹配算法升级	海量数据库的设计和实现淘宝海量数据库之一：来自业务的挑战(2010-11-24 11:34:38) 作为一个电子商务企业，从一开始，数据库及其事务能力在淘宝一直扮演着十分关键的角色，淘宝积累了丰富的数据库的架构和规划等方面的经验，产生了众多优秀的DBA。 淘宝是一家迅速发展的公司。全球网站排名公司Alexa提供的数据显示，2010年4月27日，Amazon、Ebay的用户占全球互联网用户的百分比分别为3.47%和2.68%，而淘宝的用户占全球互联网用户的百分比则达到了4.1%，淘宝网日	0.915270647556357
资源区confilter词表匹配算法升级	排序及扩展：插入排序，选择排序（冒泡排序），使用二分思想求第k大数，快速排序，非递归的快速排序，使用快排思想求第k大数，归并排序，求逆序数，自然排序算法，堆排序，最小优先级队列，计数排序，桶排序，鸽巢排序（分块排序），基数排序，外部排序：二路归并，K路归并，胜者树，败者树。  算法一：使用插入或者选择排序，得到最大的K个数，时间复杂度为：O(N*k)。 冒泡排序： void swap(int * a,int * b){            //注意	0.9151716477125761
资源区confilter词表匹配算法升级	克拉玛依公证处:本人因生活在国外，不能亲自到贵单位办理出生证明公证事项，兹授权委托雷春香女士全权代表我办理相关事项。对委托人在办理上述事项过程中所签署的有关文件，我均予以认可，并承担相应的法律责任。委托人：刘佳			委托人身份证号码：654301198608243929被委托人：雷春香		被委托人身份证号码：6526196207113926委托人：刘佳2018年5月24日	0.9151716477125761
资源区confilter词表匹配算法升级	性能升级性能升级的几个层面：系统结构：模块分解，模块交互，系统构建中的粗略估算。算法和数据结构：获得快速模块的关键：表示数据的结构，操作数据的算法：索引结构及拉链归并。代码调优：分支预测等。循环：将循环体中不改变的变量移动到循环体外；多重循环嵌套顺序。函数调用：inline函数节省函数调用开销：若makefile中不指定至少-O优化，即使声明为inline函数，编译器也不会进行函数内联。内存寻址：避免重复内存寻址。Cpu流水线的分支预测：将满足概率最高的条件放在靠前的位置。	0.9151716477125761
资源区confilter词表匹配算法升级	业务生成平台用户指南总体说明开发背景下一代网络是业务驱动的网络，在融合的下一代网络上高效、灵活地开发和部署各种丰富多彩的业务，从而提高网络使用率、增加收益的目标，是下一代网络的关键环节。下一代网络的发展要求呼叫与承载相分离、呼叫控制与业务相分离，使业务真正独立于网络，业务开发者不必关心与业务承载相关的底层网络知识以及具体的通信协议，只需利用业务生成平台提供的业务开发工具，就可以开发出灵活丰富且极具个性化的业务。 为了适合多种技术水平的业务开发人员的需要，现在主要有四种业务开发方式：	0.9151716477125761

资源confilter升级之词表匹配算法详细设计及对比	资源区confilter升级之词表匹配算法调研分析词表匹配贴吧confilter词表匹配算法介绍贴吧confilter词表匹配算法的分析trie树介绍trie树进行词表匹配的分析ac自动机介绍ac自动机进行词表匹配的分析改进内存的ac自动机介绍tst（ternary-search- tree）介绍tst（ternary-search- tree）进行词表匹配的分析资源confilter词表统计分析总结词表匹配confilter为内容过滤模块，词表匹配	0.9667643905429235
资源confilter升级之词表匹配算法详细设计及对比	资源confilter升级之词表匹配算法详细设计及对比贴吧词表算法抽取ac自动机改进内存的ac自动机测试环境的搭建测试数据与对比分析贴吧词表匹配算法抽取bitmap原理：将词表中的一行字符串的前3个字节（可以小于3）在bitmap中标识。用于在匹配输入串时，快速定位词表中是否有当前指针指向的字符串前3个字节为首的过滤词，若有继续匹配，否则指针后移。具体实现：3个字节的二进制数，即表示：0-256^3。动态分配2^24bit的空间，即（2^24bit）/((8bi	0.9625230067781944
资源confilter升级之词表匹配算法详细设计及对比	贝叶斯分类模型：基础知识：假设	X：是数据元组，由n个属性描述；	H：是某种假设，如数据元组属于某特定类C	P(H|X)：表示给定X的属性描述，找出元组X属于类C的概率举例：X：一位35岁的顾客，收入为4w美元；H：顾客将购买计算机P(H|X)：在X的条件下，H的后验概率。当我们知道顾客的年龄和收入时，顾客X将购买计算机的概率。P(H)：H的先验概率。任意给定顾客将购买计算机的概率，独立与X。P(X|H)：在条件H下，X的后验概率。已知顾客购买了计算机，顾客是一位3	0.9483198149864677
资源confilter升级之词表匹配算法详细设计及对比	K最近邻分类模型：原理：训练元组用n个属性描述，每个元组代表n维空间中的一个点，所有的训练元组存放在n维的模式空间。当给定一个未知元组时，KNN搜索该模式空间，找出最接近未知元组的k个训练元组。未知元组指派到它的k个最近邻中的多数类。“邻近性”用距离度量，如欧几里德距离。欧几里德距离：	设元组X1=(X11,X12,…X1n)，X2=(X21,X22,…X2n)，	Dist(X1,X2)=√ ∑ k= 1 n (X1i-X2i) 2 	使用上式之前，对每个属性的值规范化，以防止具有	0.9477937399551446
资源confilter升级之词表匹配算法详细设计及对比	排序及扩展：插入排序，选择排序（冒泡排序），使用二分思想求第k大数，快速排序，非递归的快速排序，使用快排思想求第k大数，归并排序，求逆序数，自然排序算法，堆排序，最小优先级队列，计数排序，桶排序，鸽巢排序（分块排序），基数排序，外部排序：二路归并，K路归并，胜者树，败者树。  算法一：使用插入或者选择排序，得到最大的K个数，时间复杂度为：O(N*k)。 冒泡排序： void swap(int * a,int * b){            //注意	0.9476228820535951
资源confilter升级之词表匹配算法详细设计及对比	克拉玛依公证处:本人因生活在国外，不能亲自到贵单位办理出生证明公证事项，兹授权委托雷春香女士全权代表我办理相关事项。对委托人在办理上述事项过程中所签署的有关文件，我均予以认可，并承担相应的法律责任。委托人：刘佳			委托人身份证号码：654301198608243929被委托人：雷春香		被委托人身份证号码：6526196207113926委托人：刘佳2018年5月24日	0.9476228820535951
资源confilter升级之词表匹配算法详细设计及对比	性能升级性能升级的几个层面：系统结构：模块分解，模块交互，系统构建中的粗略估算。算法和数据结构：获得快速模块的关键：表示数据的结构，操作数据的算法：索引结构及拉链归并。代码调优：分支预测等。循环：将循环体中不改变的变量移动到循环体外；多重循环嵌套顺序。函数调用：inline函数节省函数调用开销：若makefile中不指定至少-O优化，即使声明为inline函数，编译器也不会进行函数内联。内存寻址：避免重复内存寻址。Cpu流水线的分支预测：将满足概率最高的条件放在靠前的位置。	0.9476228820535951
资源confilter升级之词表匹配算法详细设计及对比	业务生成平台用户指南总体说明开发背景下一代网络是业务驱动的网络，在融合的下一代网络上高效、灵活地开发和部署各种丰富多彩的业务，从而提高网络使用率、增加收益的目标，是下一代网络的关键环节。下一代网络的发展要求呼叫与承载相分离、呼叫控制与业务相分离，使业务真正独立于网络，业务开发者不必关心与业务承载相关的底层网络知识以及具体的通信协议，只需利用业务生成平台提供的业务开发工具，就可以开发出灵活丰富且极具个性化的业务。 为了适合多种技术水平的业务开发人员的需要，现在主要有四种业务开发方式：	0.9476228820535951
资源confilter升级之词表匹配算法详细设计及对比	工作6周年5个月小记今天是中国时间8/24/2018，也就是我32岁的生日，这是一个不老也不再年轻的年纪。最近总是因为工作而郁郁寡欢，心中不快，所以决定记录总结一下，希望自己能有所释怀、转变、确立新的目标。从2012年3月31到现在，我已在微软Bing工作6年5个月。在此之前，我在百度实习9个月，在阿里巴巴实习2个月，在搜狗实习1个月。在微软北京CJK relevance组勤恳的工作2年6个月，从级别59升到61，做了1年半的DU, 1年的relevance。总体来说，老板们的风格是相关性主导基础	0.9471801399183513
资源confilter升级之词表匹配算法详细设计及对比	BS代码阅读：BS基本功能：索引相关性切词成分分析offset调权query解析 （where+what）多路归并 综合调权类聚（偏离点）query分类空间调权数据来源点击调权BS代码阅读：bs_cache:map库的term cachemap库term cache操作锁where库term cachewhere库term cache操作锁init_map_term_cache: 初始化map库term cachein	0.9471652614023791

贴吧大数据存储解决方案	贝叶斯分类模型：基础知识：假设	X：是数据元组，由n个属性描述；	H：是某种假设，如数据元组属于某特定类C	P(H|X)：表示给定X的属性描述，找出元组X属于类C的概率举例：X：一位35岁的顾客，收入为4w美元；H：顾客将购买计算机P(H|X)：在X的条件下，H的后验概率。当我们知道顾客的年龄和收入时，顾客X将购买计算机的概率。P(H)：H的先验概率。任意给定顾客将购买计算机的概率，独立与X。P(X|H)：在条件H下，X的后验概率。已知顾客购买了计算机，顾客是一位3	0.9332373263989363
贴吧大数据存储解决方案	K最近邻分类模型：原理：训练元组用n个属性描述，每个元组代表n维空间中的一个点，所有的训练元组存放在n维的模式空间。当给定一个未知元组时，KNN搜索该模式空间，找出最接近未知元组的k个训练元组。未知元组指派到它的k个最近邻中的多数类。“邻近性”用距离度量，如欧几里德距离。欧几里德距离：	设元组X1=(X11,X12,…X1n)，X2=(X21,X22,…X2n)，	Dist(X1,X2)=√ ∑ k= 1 n (X1i-X2i) 2 	使用上式之前，对每个属性的值规范化，以防止具有	0.9293009368694836
贴吧大数据存储解决方案	排序及扩展：插入排序，选择排序（冒泡排序），使用二分思想求第k大数，快速排序，非递归的快速排序，使用快排思想求第k大数，归并排序，求逆序数，自然排序算法，堆排序，最小优先级队列，计数排序，桶排序，鸽巢排序（分块排序），基数排序，外部排序：二路归并，K路归并，胜者树，败者树。  算法一：使用插入或者选择排序，得到最大的K个数，时间复杂度为：O(N*k)。 冒泡排序： void swap(int * a,int * b){            //注意	0.9292623676878005
贴吧大数据存储解决方案	克拉玛依公证处:本人因生活在国外，不能亲自到贵单位办理出生证明公证事项，兹授权委托雷春香女士全权代表我办理相关事项。对委托人在办理上述事项过程中所签署的有关文件，我均予以认可，并承担相应的法律责任。委托人：刘佳			委托人身份证号码：654301198608243929被委托人：雷春香		被委托人身份证号码：6526196207113926委托人：刘佳2018年5月24日	0.9292623676878005
贴吧大数据存储解决方案	性能升级性能升级的几个层面：系统结构：模块分解，模块交互，系统构建中的粗略估算。算法和数据结构：获得快速模块的关键：表示数据的结构，操作数据的算法：索引结构及拉链归并。代码调优：分支预测等。循环：将循环体中不改变的变量移动到循环体外；多重循环嵌套顺序。函数调用：inline函数节省函数调用开销：若makefile中不指定至少-O优化，即使声明为inline函数，编译器也不会进行函数内联。内存寻址：避免重复内存寻址。Cpu流水线的分支预测：将满足概率最高的条件放在靠前的位置。	0.9292623676878005
贴吧大数据存储解决方案	业务生成平台用户指南总体说明开发背景下一代网络是业务驱动的网络，在融合的下一代网络上高效、灵活地开发和部署各种丰富多彩的业务，从而提高网络使用率、增加收益的目标，是下一代网络的关键环节。下一代网络的发展要求呼叫与承载相分离、呼叫控制与业务相分离，使业务真正独立于网络，业务开发者不必关心与业务承载相关的底层网络知识以及具体的通信协议，只需利用业务生成平台提供的业务开发工具，就可以开发出灵活丰富且极具个性化的业务。 为了适合多种技术水平的业务开发人员的需要，现在主要有四种业务开发方式：	0.9292623676878005
贴吧大数据存储解决方案	工作6周年5个月小记今天是中国时间8/24/2018，也就是我32岁的生日，这是一个不老也不再年轻的年纪。最近总是因为工作而郁郁寡欢，心中不快，所以决定记录总结一下，希望自己能有所释怀、转变、确立新的目标。从2012年3月31到现在，我已在微软Bing工作6年5个月。在此之前，我在百度实习9个月，在阿里巴巴实习2个月，在搜狗实习1个月。在微软北京CJK relevance组勤恳的工作2年6个月，从级别59升到61，做了1年半的DU, 1年的relevance。总体来说，老板们的风格是相关性主导基础	0.9283737160834299
贴吧大数据存储解决方案	海量数据库的设计和实现淘宝海量数据库之一：来自业务的挑战(2010-11-24 11:34:38) 作为一个电子商务企业，从一开始，数据库及其事务能力在淘宝一直扮演着十分关键的角色，淘宝积累了丰富的数据库的架构和规划等方面的经验，产生了众多优秀的DBA。 淘宝是一家迅速发展的公司。全球网站排名公司Alexa提供的数据显示，2010年4月27日，Amazon、Ebay的用户占全球互联网用户的百分比分别为3.47%和2.68%，而淘宝的用户占全球互联网用户的百分比则达到了4.1%，淘宝网日	0.9273279471127776
贴吧大数据存储解决方案	BS代码阅读：BS基本功能：索引相关性切词成分分析offset调权query解析 （where+what）多路归并 综合调权类聚（偏离点）query分类空间调权数据来源点击调权BS代码阅读：bs_cache:map库的term cachemap库term cache操作锁where库term cachewhere库term cache操作锁init_map_term_cache: 初始化map库term cachein	0.9269329622678811
贴吧大数据存储解决方案	C专家编程读书笔记难点关键字的用法：关键字用法extern在函数名前，表示该函数全局可见，一般缺省。即一个文件的全局变量和函数对其他文件，具有可见性。在变量或者函数前，表示对象的定义在别处进行。由于重载，在c++中调用以C方式编译的函数时，需要加extern “c”。static隐藏：修饰的对象对其他文件不可见，防止多个文件命名冲突。持久性：修饰的对象，存储在数据段或者bss段，和程序有相同的生命周期。只有一次初始化。3、修饰的变量未初始化时，默认为“0	0.9263883097158293

贴吧PHP	贴吧PHP交互层演进历程&CAMEL简介zhouren@baidu.com演进历程	随交互层演化划分出四个阶段思考	交互层需要解决那些问题？	怎样解决这些问题？CAMEL介绍	CAMEL也就是贴吧PHP中间层，用于解决交互层方面的问题；	CAMEL，骆驼（沙漠之舟），寓意：中间层在无论多么恶劣的环境下，也要提供良好的运输能力；SUMMERY背景LAMP架构的初次尝试；PHP系统的流量在100万～1000万；跨系统交互少；产出：随club项	0.6538348532454509
贴吧PHP	BS代码阅读：BS基本功能：索引相关性切词成分分析offset调权query解析 （where+what）多路归并 综合调权类聚（偏离点）query分类空间调权数据来源点击调权BS代码阅读：bs_cache:map库的term cachemap库term cache操作锁where库term cachewhere库term cache操作锁init_map_term_cache: 初始化map库term cachein	0.6454771320665929
贴吧PHP	Svm分类模型：基本原理：将所有待分类的点映射到“高维空间”，然后在高维空间中找到一个能将这些点分开的“超平面”，这在理论上是被完全证明了是成立的，而且在实际计算中也是可行的。满足条件的“超平面”的个数不是唯一的。SVM需要的是利用这些超平面，找到这两类点之间的“最大间隔”。并非所有的数据都线性可分，将非线性映射到更高维的特征空间变成线性可分。（低维空间向量集通常难于划分，解决的方法是将它们映射到高维空间。）但这个办法带来的困难就是计算复杂度的增加，而核函数正好巧妙地解决了这个问题。也就是说，只要选用	0.6447250722021767
贴吧PHP	K最近邻分类模型：原理：训练元组用n个属性描述，每个元组代表n维空间中的一个点，所有的训练元组存放在n维的模式空间。当给定一个未知元组时，KNN搜索该模式空间，找出最接近未知元组的k个训练元组。未知元组指派到它的k个最近邻中的多数类。“邻近性”用距离度量，如欧几里德距离。欧几里德距离：	设元组X1=(X11,X12,…X1n)，X2=(X21,X22,…X2n)，	Dist(X1,X2)=√ ∑ k= 1 n (X1i-X2i) 2 	使用上式之前，对每个属性的值规范化，以防止具有	0.6432822125470767
贴吧PHP	排序及扩展：插入排序，选择排序（冒泡排序），使用二分思想求第k大数，快速排序，非递归的快速排序，使用快排思想求第k大数，归并排序，求逆序数，自然排序算法，堆排序，最小优先级队列，计数排序，桶排序，鸽巢排序（分块排序），基数排序，外部排序：二路归并，K路归并，胜者树，败者树。  算法一：使用插入或者选择排序，得到最大的K个数，时间复杂度为：O(N*k)。 冒泡排序： void swap(int * a,int * b){            //注意	0.6432115609549578
贴吧PHP	克拉玛依公证处:本人因生活在国外，不能亲自到贵单位办理出生证明公证事项，兹授权委托雷春香女士全权代表我办理相关事项。对委托人在办理上述事项过程中所签署的有关文件，我均予以认可，并承担相应的法律责任。委托人：刘佳			委托人身份证号码：654301198608243929被委托人：雷春香		被委托人身份证号码：6526196207113926委托人：刘佳2018年5月24日	0.6432115609549578
贴吧PHP	性能升级性能升级的几个层面：系统结构：模块分解，模块交互，系统构建中的粗略估算。算法和数据结构：获得快速模块的关键：表示数据的结构，操作数据的算法：索引结构及拉链归并。代码调优：分支预测等。循环：将循环体中不改变的变量移动到循环体外；多重循环嵌套顺序。函数调用：inline函数节省函数调用开销：若makefile中不指定至少-O优化，即使声明为inline函数，编译器也不会进行函数内联。内存寻址：避免重复内存寻址。Cpu流水线的分支预测：将满足概率最高的条件放在靠前的位置。	0.6432115609549578
贴吧PHP	业务生成平台用户指南总体说明开发背景下一代网络是业务驱动的网络，在融合的下一代网络上高效、灵活地开发和部署各种丰富多彩的业务，从而提高网络使用率、增加收益的目标，是下一代网络的关键环节。下一代网络的发展要求呼叫与承载相分离、呼叫控制与业务相分离，使业务真正独立于网络，业务开发者不必关心与业务承载相关的底层网络知识以及具体的通信协议，只需利用业务生成平台提供的业务开发工具，就可以开发出灵活丰富且极具个性化的业务。 为了适合多种技术水平的业务开发人员的需要，现在主要有四种业务开发方式：	0.6432115609549578
贴吧PHP	资源confilter升级之词表匹配算法详细设计及对比贴吧词表算法抽取ac自动机改进内存的ac自动机测试环境的搭建测试数据与对比分析贴吧词表匹配算法抽取bitmap原理：将词表中的一行字符串的前3个字节（可以小于3）在bitmap中标识。用于在匹配输入串时，快速定位词表中是否有当前指针指向的字符串前3个字节为首的过滤词，若有继续匹配，否则指针后移。具体实现：3个字节的二进制数，即表示：0-256^3。动态分配2^24bit的空间，即（2^24bit）/((8bi	0.6422102330563129
贴吧PHP	贝叶斯分类模型：基础知识：假设	X：是数据元组，由n个属性描述；	H：是某种假设，如数据元组属于某特定类C	P(H|X)：表示给定X的属性描述，找出元组X属于类C的概率举例：X：一位35岁的顾客，收入为4w美元；H：顾客将购买计算机P(H|X)：在X的条件下，H的后验概率。当我们知道顾客的年龄和收入时，顾客X将购买计算机的概率。P(H)：H的先验概率。任意给定顾客将购买计算机的概率，独立与X。P(X|H)：在条件H下，X的后验概率。已知顾客购买了计算机，顾客是一位3	0.6421144096744652

贴吧FRS重构介绍	贝叶斯分类模型：基础知识：假设	X：是数据元组，由n个属性描述；	H：是某种假设，如数据元组属于某特定类C	P(H|X)：表示给定X的属性描述，找出元组X属于类C的概率举例：X：一位35岁的顾客，收入为4w美元；H：顾客将购买计算机P(H|X)：在X的条件下，H的后验概率。当我们知道顾客的年龄和收入时，顾客X将购买计算机的概率。P(H)：H的先验概率。任意给定顾客将购买计算机的概率，独立与X。P(X|H)：在条件H下，X的后验概率。已知顾客购买了计算机，顾客是一位3	0.9037361998109544
贴吧FRS重构介绍	K最近邻分类模型：原理：训练元组用n个属性描述，每个元组代表n维空间中的一个点，所有的训练元组存放在n维的模式空间。当给定一个未知元组时，KNN搜索该模式空间，找出最接近未知元组的k个训练元组。未知元组指派到它的k个最近邻中的多数类。“邻近性”用距离度量，如欧几里德距离。欧几里德距离：	设元组X1=(X11,X12,…X1n)，X2=(X21,X22,…X2n)，	Dist(X1,X2)=√ ∑ k= 1 n (X1i-X2i) 2 	使用上式之前，对每个属性的值规范化，以防止具有	0.898833689698973
贴吧FRS重构介绍	排序及扩展：插入排序，选择排序（冒泡排序），使用二分思想求第k大数，快速排序，非递归的快速排序，使用快排思想求第k大数，归并排序，求逆序数，自然排序算法，堆排序，最小优先级队列，计数排序，桶排序，鸽巢排序（分块排序），基数排序，外部排序：二路归并，K路归并，胜者树，败者树。  算法一：使用插入或者选择排序，得到最大的K个数，时间复杂度为：O(N*k)。 冒泡排序： void swap(int * a,int * b){            //注意	0.8987845322648453
贴吧FRS重构介绍	克拉玛依公证处:本人因生活在国外，不能亲自到贵单位办理出生证明公证事项，兹授权委托雷春香女士全权代表我办理相关事项。对委托人在办理上述事项过程中所签署的有关文件，我均予以认可，并承担相应的法律责任。委托人：刘佳			委托人身份证号码：654301198608243929被委托人：雷春香		被委托人身份证号码：6526196207113926委托人：刘佳2018年5月24日	0.8987845322648453
贴吧FRS重构介绍	性能升级性能升级的几个层面：系统结构：模块分解，模块交互，系统构建中的粗略估算。算法和数据结构：获得快速模块的关键：表示数据的结构，操作数据的算法：索引结构及拉链归并。代码调优：分支预测等。循环：将循环体中不改变的变量移动到循环体外；多重循环嵌套顺序。函数调用：inline函数节省函数调用开销：若makefile中不指定至少-O优化，即使声明为inline函数，编译器也不会进行函数内联。内存寻址：避免重复内存寻址。Cpu流水线的分支预测：将满足概率最高的条件放在靠前的位置。	0.8987845322648453
贴吧FRS重构介绍	业务生成平台用户指南总体说明开发背景下一代网络是业务驱动的网络，在融合的下一代网络上高效、灵活地开发和部署各种丰富多彩的业务，从而提高网络使用率、增加收益的目标，是下一代网络的关键环节。下一代网络的发展要求呼叫与承载相分离、呼叫控制与业务相分离，使业务真正独立于网络，业务开发者不必关心与业务承载相关的底层网络知识以及具体的通信协议，只需利用业务生成平台提供的业务开发工具，就可以开发出灵活丰富且极具个性化的业务。 为了适合多种技术水平的业务开发人员的需要，现在主要有四种业务开发方式：	0.8987845322648453
贴吧FRS重构介绍	海量数据库的设计和实现淘宝海量数据库之一：来自业务的挑战(2010-11-24 11:34:38) 作为一个电子商务企业，从一开始，数据库及其事务能力在淘宝一直扮演着十分关键的角色，淘宝积累了丰富的数据库的架构和规划等方面的经验，产生了众多优秀的DBA。 淘宝是一家迅速发展的公司。全球网站排名公司Alexa提供的数据显示，2010年4月27日，Amazon、Ebay的用户占全球互联网用户的百分比分别为3.47%和2.68%，而淘宝的用户占全球互联网用户的百分比则达到了4.1%，淘宝网日	0.8984861440875543
贴吧FRS重构介绍	BS代码阅读：BS基本功能：索引相关性切词成分分析offset调权query解析 （where+what）多路归并 综合调权类聚（偏离点）query分类空间调权数据来源点击调权BS代码阅读：bs_cache:map库的term cachemap库term cache操作锁where库term cachewhere库term cache操作锁init_map_term_cache: 初始化map库term cachein	0.8983792480725098
贴吧FRS重构介绍	工作6周年5个月小记今天是中国时间8/24/2018，也就是我32岁的生日，这是一个不老也不再年轻的年纪。最近总是因为工作而郁郁寡欢，心中不快，所以决定记录总结一下，希望自己能有所释怀、转变、确立新的目标。从2012年3月31到现在，我已在微软Bing工作6年5个月。在此之前，我在百度实习9个月，在阿里巴巴实习2个月，在搜狗实习1个月。在微软北京CJK relevance组勤恳的工作2年6个月，从级别59升到61，做了1年半的DU, 1年的relevance。总体来说，老板们的风格是相关性主导基础	0.8979413481115495
贴吧FRS重构介绍	Svm分类模型：基本原理：将所有待分类的点映射到“高维空间”，然后在高维空间中找到一个能将这些点分开的“超平面”，这在理论上是被完全证明了是成立的，而且在实际计算中也是可行的。满足条件的“超平面”的个数不是唯一的。SVM需要的是利用这些超平面，找到这两类点之间的“最大间隔”。并非所有的数据都线性可分，将非线性映射到更高维的特征空间变成线性可分。（低维空间向量集通常难于划分，解决的方法是将它们映射到高维空间。）但这个办法带来的困难就是计算复杂度的增加，而核函数正好巧妙地解决了这个问题。也就是说，只要选用	0.8965191062985596

贝叶斯分类模型	贝叶斯分类模型：基础知识：假设	X：是数据元组，由n个属性描述；	H：是某种假设，如数据元组属于某特定类C	P(H|X)：表示给定X的属性描述，找出元组X属于类C的概率举例：X：一位35岁的顾客，收入为4w美元；H：顾客将购买计算机P(H|X)：在X的条件下，H的后验概率。当我们知道顾客的年龄和收入时，顾客X将购买计算机的概率。P(H)：H的先验概率。任意给定顾客将购买计算机的概率，独立与X。P(X|H)：在条件H下，X的后验概率。已知顾客购买了计算机，顾客是一位3	0.8864039560808478
贝叶斯分类模型	排序及扩展：插入排序，选择排序（冒泡排序），使用二分思想求第k大数，快速排序，非递归的快速排序，使用快排思想求第k大数，归并排序，求逆序数，自然排序算法，堆排序，最小优先级队列，计数排序，桶排序，鸽巢排序（分块排序），基数排序，外部排序：二路归并，K路归并，胜者树，败者树。  算法一：使用插入或者选择排序，得到最大的K个数，时间复杂度为：O(N*k)。 冒泡排序： void swap(int * a,int * b){            //注意	0.8821330099102237
贝叶斯分类模型	克拉玛依公证处:本人因生活在国外，不能亲自到贵单位办理出生证明公证事项，兹授权委托雷春香女士全权代表我办理相关事项。对委托人在办理上述事项过程中所签署的有关文件，我均予以认可，并承担相应的法律责任。委托人：刘佳			委托人身份证号码：654301198608243929被委托人：雷春香		被委托人身份证号码：6526196207113926委托人：刘佳2018年5月24日	0.8821330099102237
贝叶斯分类模型	性能升级性能升级的几个层面：系统结构：模块分解，模块交互，系统构建中的粗略估算。算法和数据结构：获得快速模块的关键：表示数据的结构，操作数据的算法：索引结构及拉链归并。代码调优：分支预测等。循环：将循环体中不改变的变量移动到循环体外；多重循环嵌套顺序。函数调用：inline函数节省函数调用开销：若makefile中不指定至少-O优化，即使声明为inline函数，编译器也不会进行函数内联。内存寻址：避免重复内存寻址。Cpu流水线的分支预测：将满足概率最高的条件放在靠前的位置。	0.8821330099102237
贝叶斯分类模型	业务生成平台用户指南总体说明开发背景下一代网络是业务驱动的网络，在融合的下一代网络上高效、灵活地开发和部署各种丰富多彩的业务，从而提高网络使用率、增加收益的目标，是下一代网络的关键环节。下一代网络的发展要求呼叫与承载相分离、呼叫控制与业务相分离，使业务真正独立于网络，业务开发者不必关心与业务承载相关的底层网络知识以及具体的通信协议，只需利用业务生成平台提供的业务开发工具，就可以开发出灵活丰富且极具个性化的业务。 为了适合多种技术水平的业务开发人员的需要，现在主要有四种业务开发方式：	0.8821330099102237
贝叶斯分类模型	K最近邻分类模型：原理：训练元组用n个属性描述，每个元组代表n维空间中的一个点，所有的训练元组存放在n维的模式空间。当给定一个未知元组时，KNN搜索该模式空间，找出最接近未知元组的k个训练元组。未知元组指派到它的k个最近邻中的多数类。“邻近性”用距离度量，如欧几里德距离。欧几里德距离：	设元组X1=(X11,X12,…X1n)，X2=(X21,X22,…X2n)，	Dist(X1,X2)=√ ∑ k= 1 n (X1i-X2i) 2 	使用上式之前，对每个属性的值规范化，以防止具有	0.8820342544536837
贝叶斯分类模型	工作6周年5个月小记今天是中国时间8/24/2018，也就是我32岁的生日，这是一个不老也不再年轻的年纪。最近总是因为工作而郁郁寡欢，心中不快，所以决定记录总结一下，希望自己能有所释怀、转变、确立新的目标。从2012年3月31到现在，我已在微软Bing工作6年5个月。在此之前，我在百度实习9个月，在阿里巴巴实习2个月，在搜狗实习1个月。在微软北京CJK relevance组勤恳的工作2年6个月，从级别59升到61，做了1年半的DU, 1年的relevance。总体来说，老板们的风格是相关性主导基础	0.8812594621458792
贝叶斯分类模型	海量数据库的设计和实现淘宝海量数据库之一：来自业务的挑战(2010-11-24 11:34:38) 作为一个电子商务企业，从一开始，数据库及其事务能力在淘宝一直扮演着十分关键的角色，淘宝积累了丰富的数据库的架构和规划等方面的经验，产生了众多优秀的DBA。 淘宝是一家迅速发展的公司。全球网站排名公司Alexa提供的数据显示，2010年4月27日，Amazon、Ebay的用户占全球互联网用户的百分比分别为3.47%和2.68%，而淘宝的用户占全球互联网用户的百分比则达到了4.1%，淘宝网日	0.8811772096231059
贝叶斯分类模型	C专家编程读书笔记难点关键字的用法：关键字用法extern在函数名前，表示该函数全局可见，一般缺省。即一个文件的全局变量和函数对其他文件，具有可见性。在变量或者函数前，表示对象的定义在别处进行。由于重载，在c++中调用以C方式编译的函数时，需要加extern “c”。static隐藏：修饰的对象对其他文件不可见，防止多个文件命名冲突。持久性：修饰的对象，存储在数据段或者bss段，和程序有相同的生命周期。只有一次初始化。3、修饰的变量未初始化时，默认为“0	0.8797317404615757
贝叶斯分类模型	BS代码阅读：BS基本功能：索引相关性切词成分分析offset调权query解析 （where+what）多路归并 综合调权类聚（偏离点）query分类空间调权数据来源点击调权BS代码阅读：bs_cache:map库的term cachemap库term cache操作锁where库term cachewhere库term cache操作锁init_map_term_cache: 初始化map库term cachein	0.8769633296994391

空检索优化	贝叶斯分类模型：基础知识：假设	X：是数据元组，由n个属性描述；	H：是某种假设，如数据元组属于某特定类C	P(H|X)：表示给定X的属性描述，找出元组X属于类C的概率举例：X：一位35岁的顾客，收入为4w美元；H：顾客将购买计算机P(H|X)：在X的条件下，H的后验概率。当我们知道顾客的年龄和收入时，顾客X将购买计算机的概率。P(H)：H的先验概率。任意给定顾客将购买计算机的概率，独立与X。P(X|H)：在条件H下，X的后验概率。已知顾客购买了计算机，顾客是一位3	0.8413743188327613
空检索优化	排序及扩展：插入排序，选择排序（冒泡排序），使用二分思想求第k大数，快速排序，非递归的快速排序，使用快排思想求第k大数，归并排序，求逆序数，自然排序算法，堆排序，最小优先级队列，计数排序，桶排序，鸽巢排序（分块排序），基数排序，外部排序：二路归并，K路归并，胜者树，败者树。  算法一：使用插入或者选择排序，得到最大的K个数，时间复杂度为：O(N*k)。 冒泡排序： void swap(int * a,int * b){            //注意	0.8372777254672282
空检索优化	克拉玛依公证处:本人因生活在国外，不能亲自到贵单位办理出生证明公证事项，兹授权委托雷春香女士全权代表我办理相关事项。对委托人在办理上述事项过程中所签署的有关文件，我均予以认可，并承担相应的法律责任。委托人：刘佳			委托人身份证号码：654301198608243929被委托人：雷春香		被委托人身份证号码：6526196207113926委托人：刘佳2018年5月24日	0.8372777254672282
空检索优化	性能升级性能升级的几个层面：系统结构：模块分解，模块交互，系统构建中的粗略估算。算法和数据结构：获得快速模块的关键：表示数据的结构，操作数据的算法：索引结构及拉链归并。代码调优：分支预测等。循环：将循环体中不改变的变量移动到循环体外；多重循环嵌套顺序。函数调用：inline函数节省函数调用开销：若makefile中不指定至少-O优化，即使声明为inline函数，编译器也不会进行函数内联。内存寻址：避免重复内存寻址。Cpu流水线的分支预测：将满足概率最高的条件放在靠前的位置。	0.8372777254672282
空检索优化	业务生成平台用户指南总体说明开发背景下一代网络是业务驱动的网络，在融合的下一代网络上高效、灵活地开发和部署各种丰富多彩的业务，从而提高网络使用率、增加收益的目标，是下一代网络的关键环节。下一代网络的发展要求呼叫与承载相分离、呼叫控制与业务相分离，使业务真正独立于网络，业务开发者不必关心与业务承载相关的底层网络知识以及具体的通信协议，只需利用业务生成平台提供的业务开发工具，就可以开发出灵活丰富且极具个性化的业务。 为了适合多种技术水平的业务开发人员的需要，现在主要有四种业务开发方式：	0.8372777254672282
空检索优化	K最近邻分类模型：原理：训练元组用n个属性描述，每个元组代表n维空间中的一个点，所有的训练元组存放在n维的模式空间。当给定一个未知元组时，KNN搜索该模式空间，找出最接近未知元组的k个训练元组。未知元组指派到它的k个最近邻中的多数类。“邻近性”用距离度量，如欧几里德距离。欧几里德距离：	设元组X1=(X11,X12,…X1n)，X2=(X21,X22,…X2n)，	Dist(X1,X2)=√ ∑ k= 1 n (X1i-X2i) 2 	使用上式之前，对每个属性的值规范化，以防止具有	0.8370170829843641
空检索优化	工作6周年5个月小记今天是中国时间8/24/2018，也就是我32岁的生日，这是一个不老也不再年轻的年纪。最近总是因为工作而郁郁寡欢，心中不快，所以决定记录总结一下，希望自己能有所释怀、转变、确立新的目标。从2012年3月31到现在，我已在微软Bing工作6年5个月。在此之前，我在百度实习9个月，在阿里巴巴实习2个月，在搜狗实习1个月。在微软北京CJK relevance组勤恳的工作2年6个月，从级别59升到61，做了1年半的DU, 1年的relevance。总体来说，老板们的风格是相关性主导基础	0.836922313442188
空检索优化	海量数据库的设计和实现淘宝海量数据库之一：来自业务的挑战(2010-11-24 11:34:38) 作为一个电子商务企业，从一开始，数据库及其事务能力在淘宝一直扮演着十分关键的角色，淘宝积累了丰富的数据库的架构和规划等方面的经验，产生了众多优秀的DBA。 淘宝是一家迅速发展的公司。全球网站排名公司Alexa提供的数据显示，2010年4月27日，Amazon、Ebay的用户占全球互联网用户的百分比分别为3.47%和2.68%，而淘宝的用户占全球互联网用户的百分比则达到了4.1%，淘宝网日	0.8366941298405453
空检索优化	C专家编程读书笔记难点关键字的用法：关键字用法extern在函数名前，表示该函数全局可见，一般缺省。即一个文件的全局变量和函数对其他文件，具有可见性。在变量或者函数前，表示对象的定义在别处进行。由于重载，在c++中调用以C方式编译的函数时，需要加extern “c”。static隐藏：修饰的对象对其他文件不可见，防止多个文件命名冲突。持久性：修饰的对象，存储在数据段或者bss段，和程序有相同的生命周期。只有一次初始化。3、修饰的变量未初始化时，默认为“0	0.8353689134887607
空检索优化	神经网络原理及应用介绍Anti RD：王伟琼、张爱华主要内容特点及应用场景神经网络原理我们的经验和教训多线程训练下一步的工作应用场景分类预测时间允许的场合使用并行化等方法加速测试过程很快，且可以方便的使用hadoop平台环境比较固定的场合数据的统计特性变化不大需要定量预测的场合给出未知数据的定量预测神经网络特点优点对噪音数据有较好的适应能力对未知数据具有较好的预测分类能力拟合各种函数得出定量值缺点学习时间较长	0.8312103889559255

神经网络原理及应用	贝叶斯分类模型：基础知识：假设	X：是数据元组，由n个属性描述；	H：是某种假设，如数据元组属于某特定类C	P(H|X)：表示给定X的属性描述，找出元组X属于类C的概率举例：X：一位35岁的顾客，收入为4w美元；H：顾客将购买计算机P(H|X)：在X的条件下，H的后验概率。当我们知道顾客的年龄和收入时，顾客X将购买计算机的概率。P(H)：H的先验概率。任意给定顾客将购买计算机的概率，独立与X。P(X|H)：在条件H下，X的后验概率。已知顾客购买了计算机，顾客是一位3	0.9147268687314584
神经网络原理及应用	排序及扩展：插入排序，选择排序（冒泡排序），使用二分思想求第k大数，快速排序，非递归的快速排序，使用快排思想求第k大数，归并排序，求逆序数，自然排序算法，堆排序，最小优先级队列，计数排序，桶排序，鸽巢排序（分块排序），基数排序，外部排序：二路归并，K路归并，胜者树，败者树。  算法一：使用插入或者选择排序，得到最大的K个数，时间复杂度为：O(N*k)。 冒泡排序： void swap(int * a,int * b){            //注意	0.9105450918363406
神经网络原理及应用	克拉玛依公证处:本人因生活在国外，不能亲自到贵单位办理出生证明公证事项，兹授权委托雷春香女士全权代表我办理相关事项。对委托人在办理上述事项过程中所签署的有关文件，我均予以认可，并承担相应的法律责任。委托人：刘佳			委托人身份证号码：654301198608243929被委托人：雷春香		被委托人身份证号码：6526196207113926委托人：刘佳2018年5月24日	0.9105450918363406
神经网络原理及应用	性能升级性能升级的几个层面：系统结构：模块分解，模块交互，系统构建中的粗略估算。算法和数据结构：获得快速模块的关键：表示数据的结构，操作数据的算法：索引结构及拉链归并。代码调优：分支预测等。循环：将循环体中不改变的变量移动到循环体外；多重循环嵌套顺序。函数调用：inline函数节省函数调用开销：若makefile中不指定至少-O优化，即使声明为inline函数，编译器也不会进行函数内联。内存寻址：避免重复内存寻址。Cpu流水线的分支预测：将满足概率最高的条件放在靠前的位置。	0.9105450918363406
神经网络原理及应用	业务生成平台用户指南总体说明开发背景下一代网络是业务驱动的网络，在融合的下一代网络上高效、灵活地开发和部署各种丰富多彩的业务，从而提高网络使用率、增加收益的目标，是下一代网络的关键环节。下一代网络的发展要求呼叫与承载相分离、呼叫控制与业务相分离，使业务真正独立于网络，业务开发者不必关心与业务承载相关的底层网络知识以及具体的通信协议，只需利用业务生成平台提供的业务开发工具，就可以开发出灵活丰富且极具个性化的业务。 为了适合多种技术水平的业务开发人员的需要，现在主要有四种业务开发方式：	0.9105450918363406
神经网络原理及应用	K最近邻分类模型：原理：训练元组用n个属性描述，每个元组代表n维空间中的一个点，所有的训练元组存放在n维的模式空间。当给定一个未知元组时，KNN搜索该模式空间，找出最接近未知元组的k个训练元组。未知元组指派到它的k个最近邻中的多数类。“邻近性”用距离度量，如欧几里德距离。欧几里德距离：	设元组X1=(X11,X12,…X1n)，X2=(X21,X22,…X2n)，	Dist(X1,X2)=√ ∑ k= 1 n (X1i-X2i) 2 	使用上式之前，对每个属性的值规范化，以防止具有	0.9105324249901643
神经网络原理及应用	工作6周年5个月小记今天是中国时间8/24/2018，也就是我32岁的生日，这是一个不老也不再年轻的年纪。最近总是因为工作而郁郁寡欢，心中不快，所以决定记录总结一下，希望自己能有所释怀、转变、确立新的目标。从2012年3月31到现在，我已在微软Bing工作6年5个月。在此之前，我在百度实习9个月，在阿里巴巴实习2个月，在搜狗实习1个月。在微软北京CJK relevance组勤恳的工作2年6个月，从级别59升到61，做了1年半的DU, 1年的relevance。总体来说，老板们的风格是相关性主导基础	0.9096211845632957
神经网络原理及应用	海量数据库的设计和实现淘宝海量数据库之一：来自业务的挑战(2010-11-24 11:34:38) 作为一个电子商务企业，从一开始，数据库及其事务能力在淘宝一直扮演着十分关键的角色，淘宝积累了丰富的数据库的架构和规划等方面的经验，产生了众多优秀的DBA。 淘宝是一家迅速发展的公司。全球网站排名公司Alexa提供的数据显示，2010年4月27日，Amazon、Ebay的用户占全球互联网用户的百分比分别为3.47%和2.68%，而淘宝的用户占全球互联网用户的百分比则达到了4.1%，淘宝网日	0.9091479607007864
神经网络原理及应用	C专家编程读书笔记难点关键字的用法：关键字用法extern在函数名前，表示该函数全局可见，一般缺省。即一个文件的全局变量和函数对其他文件，具有可见性。在变量或者函数前，表示对象的定义在别处进行。由于重载，在c++中调用以C方式编译的函数时，需要加extern “c”。static隐藏：修饰的对象对其他文件不可见，防止多个文件命名冲突。持久性：修饰的对象，存储在数据段或者bss段，和程序有相同的生命周期。只有一次初始化。3、修饰的变量未初始化时，默认为“0	0.9078401235624469
神经网络原理及应用	BS代码阅读：BS基本功能：索引相关性切词成分分析offset调权query解析 （where+what）多路归并 综合调权类聚（偏离点）query分类空间调权数据来源点击调权BS代码阅读：bs_cache:map库的term cachemap库term cache操作锁where库term cachewhere库term cache操作锁init_map_term_cache: 初始化map库term cachein	0.907141040353761

淘宝海量数据库的设计和实现	贝叶斯分类模型：基础知识：假设	X：是数据元组，由n个属性描述；	H：是某种假设，如数据元组属于某特定类C	P(H|X)：表示给定X的属性描述，找出元组X属于类C的概率举例：X：一位35岁的顾客，收入为4w美元；H：顾客将购买计算机P(H|X)：在X的条件下，H的后验概率。当我们知道顾客的年龄和收入时，顾客X将购买计算机的概率。P(H)：H的先验概率。任意给定顾客将购买计算机的概率，独立与X。P(X|H)：在条件H下，X的后验概率。已知顾客购买了计算机，顾客是一位3	0.9457012447497645
淘宝海量数据库的设计和实现	K最近邻分类模型：原理：训练元组用n个属性描述，每个元组代表n维空间中的一个点，所有的训练元组存放在n维的模式空间。当给定一个未知元组时，KNN搜索该模式空间，找出最接近未知元组的k个训练元组。未知元组指派到它的k个最近邻中的多数类。“邻近性”用距离度量，如欧几里德距离。欧几里德距离：	设元组X1=(X11,X12,…X1n)，X2=(X21,X22,…X2n)，	Dist(X1,X2)=√ ∑ k= 1 n (X1i-X2i) 2 	使用上式之前，对每个属性的值规范化，以防止具有	0.9420538806566909
淘宝海量数据库的设计和实现	排序及扩展：插入排序，选择排序（冒泡排序），使用二分思想求第k大数，快速排序，非递归的快速排序，使用快排思想求第k大数，归并排序，求逆序数，自然排序算法，堆排序，最小优先级队列，计数排序，桶排序，鸽巢排序（分块排序），基数排序，外部排序：二路归并，K路归并，胜者树，败者树。  算法一：使用插入或者选择排序，得到最大的K个数，时间复杂度为：O(N*k)。 冒泡排序： void swap(int * a,int * b){            //注意	0.9419812412383604
淘宝海量数据库的设计和实现	克拉玛依公证处:本人因生活在国外，不能亲自到贵单位办理出生证明公证事项，兹授权委托雷春香女士全权代表我办理相关事项。对委托人在办理上述事项过程中所签署的有关文件，我均予以认可，并承担相应的法律责任。委托人：刘佳			委托人身份证号码：654301198608243929被委托人：雷春香		被委托人身份证号码：6526196207113926委托人：刘佳2018年5月24日	0.9419812412383604
淘宝海量数据库的设计和实现	性能升级性能升级的几个层面：系统结构：模块分解，模块交互，系统构建中的粗略估算。算法和数据结构：获得快速模块的关键：表示数据的结构，操作数据的算法：索引结构及拉链归并。代码调优：分支预测等。循环：将循环体中不改变的变量移动到循环体外；多重循环嵌套顺序。函数调用：inline函数节省函数调用开销：若makefile中不指定至少-O优化，即使声明为inline函数，编译器也不会进行函数内联。内存寻址：避免重复内存寻址。Cpu流水线的分支预测：将满足概率最高的条件放在靠前的位置。	0.9419812412383604
淘宝海量数据库的设计和实现	业务生成平台用户指南总体说明开发背景下一代网络是业务驱动的网络，在融合的下一代网络上高效、灵活地开发和部署各种丰富多彩的业务，从而提高网络使用率、增加收益的目标，是下一代网络的关键环节。下一代网络的发展要求呼叫与承载相分离、呼叫控制与业务相分离，使业务真正独立于网络，业务开发者不必关心与业务承载相关的底层网络知识以及具体的通信协议，只需利用业务生成平台提供的业务开发工具，就可以开发出灵活丰富且极具个性化的业务。 为了适合多种技术水平的业务开发人员的需要，现在主要有四种业务开发方式：	0.9419812412383604
淘宝海量数据库的设计和实现	工作6周年5个月小记今天是中国时间8/24/2018，也就是我32岁的生日，这是一个不老也不再年轻的年纪。最近总是因为工作而郁郁寡欢，心中不快，所以决定记录总结一下，希望自己能有所释怀、转变、确立新的目标。从2012年3月31到现在，我已在微软Bing工作6年5个月。在此之前，我在百度实习9个月，在阿里巴巴实习2个月，在搜狗实习1个月。在微软北京CJK relevance组勤恳的工作2年6个月，从级别59升到61，做了1年半的DU, 1年的relevance。总体来说，老板们的风格是相关性主导基础	0.9411223697874557
淘宝海量数据库的设计和实现	BS代码阅读：BS基本功能：索引相关性切词成分分析offset调权query解析 （where+what）多路归并 综合调权类聚（偏离点）query分类空间调权数据来源点击调权BS代码阅读：bs_cache:map库的term cachemap库term cache操作锁where库term cachewhere库term cache操作锁init_map_term_cache: 初始化map库term cachein	0.9401922518490348
淘宝海量数据库的设计和实现	海量数据库的设计和实现淘宝海量数据库之一：来自业务的挑战(2010-11-24 11:34:38) 作为一个电子商务企业，从一开始，数据库及其事务能力在淘宝一直扮演着十分关键的角色，淘宝积累了丰富的数据库的架构和规划等方面的经验，产生了众多优秀的DBA。 淘宝是一家迅速发展的公司。全球网站排名公司Alexa提供的数据显示，2010年4月27日，Amazon、Ebay的用户占全球互联网用户的百分比分别为3.47%和2.68%，而淘宝的用户占全球互联网用户的百分比则达到了4.1%，淘宝网日	0.9394779764017819
淘宝海量数据库的设计和实现	Svm分类模型：基本原理：将所有待分类的点映射到“高维空间”，然后在高维空间中找到一个能将这些点分开的“超平面”，这在理论上是被完全证明了是成立的，而且在实际计算中也是可行的。满足条件的“超平面”的个数不是唯一的。SVM需要的是利用这些超平面，找到这两类点之间的“最大间隔”。并非所有的数据都线性可分，将非线性映射到更高维的特征空间变成线性可分。（低维空间向量集通常难于划分，解决的方法是将它们映射到高维空间。）但这个办法带来的困难就是计算复杂度的增加，而核函数正好巧妙地解决了这个问题。也就是说，只要选用	0.9390975397582952

根据clientip和wideip获取最佳访问pool的设计和实现	BS代码阅读：BS基本功能：索引相关性切词成分分析offset调权query解析 （where+what）多路归并 综合调权类聚（偏离点）query分类空间调权数据来源点击调权BS代码阅读：bs_cache:map库的term cachemap库term cache操作锁where库term cachewhere库term cache操作锁init_map_term_cache: 初始化map库term cachein	0.9516370711564355
根据clientip和wideip获取最佳访问pool的设计和实现	根据clientip和wideip获得最佳访问pool设计和实现架构设计数据库操作相关数据表结构region2cidrs(5283)：说明：将region2cidrs表中的所有记录select出来，得到[region,cidr]，将cidr使用 perl中的Net::CIDR ::cidr2range($cidr)将$cidr转化为[low_ip,high_ip]的形式，再利用ip到unsigned int的转换函数，最终转化为[low_uint,high_uint	0.9495819379544195
根据clientip和wideip获取最佳访问pool的设计和实现	神经网络原理及应用介绍Anti RD：王伟琼、张爱华主要内容特点及应用场景神经网络原理我们的经验和教训多线程训练下一步的工作应用场景分类预测时间允许的场合使用并行化等方法加速测试过程很快，且可以方便的使用hadoop平台环境比较固定的场合数据的统计特性变化不大需要定量预测的场合给出未知数据的定量预测神经网络特点优点对噪音数据有较好的适应能力对未知数据具有较好的预测分类能力拟合各种函数得出定量值缺点学习时间较长	0.9468167497672667
根据clientip和wideip获取最佳访问pool的设计和实现	贝叶斯分类模型：基础知识：假设	X：是数据元组，由n个属性描述；	H：是某种假设，如数据元组属于某特定类C	P(H|X)：表示给定X的属性描述，找出元组X属于类C的概率举例：X：一位35岁的顾客，收入为4w美元；H：顾客将购买计算机P(H|X)：在X的条件下，H的后验概率。当我们知道顾客的年龄和收入时，顾客X将购买计算机的概率。P(H)：H的先验概率。任意给定顾客将购买计算机的概率，独立与X。P(X|H)：在条件H下，X的后验概率。已知顾客购买了计算机，顾客是一位3	0.9437190359504339
根据clientip和wideip获取最佳访问pool的设计和实现	K最近邻分类模型：原理：训练元组用n个属性描述，每个元组代表n维空间中的一个点，所有的训练元组存放在n维的模式空间。当给定一个未知元组时，KNN搜索该模式空间，找出最接近未知元组的k个训练元组。未知元组指派到它的k个最近邻中的多数类。“邻近性”用距离度量，如欧几里德距离。欧几里德距离：	设元组X1=(X11,X12,…X1n)，X2=(X21,X22,…X2n)，	Dist(X1,X2)=√ ∑ k= 1 n (X1i-X2i) 2 	使用上式之前，对每个属性的值规范化，以防止具有	0.9428508213561678
根据clientip和wideip获取最佳访问pool的设计和实现	排序及扩展：插入排序，选择排序（冒泡排序），使用二分思想求第k大数，快速排序，非递归的快速排序，使用快排思想求第k大数，归并排序，求逆序数，自然排序算法，堆排序，最小优先级队列，计数排序，桶排序，鸽巢排序（分块排序），基数排序，外部排序：二路归并，K路归并，胜者树，败者树。  算法一：使用插入或者选择排序，得到最大的K个数，时间复杂度为：O(N*k)。 冒泡排序： void swap(int * a,int * b){            //注意	0.9425919538871845
根据clientip和wideip获取最佳访问pool的设计和实现	克拉玛依公证处:本人因生活在国外，不能亲自到贵单位办理出生证明公证事项，兹授权委托雷春香女士全权代表我办理相关事项。对委托人在办理上述事项过程中所签署的有关文件，我均予以认可，并承担相应的法律责任。委托人：刘佳			委托人身份证号码：654301198608243929被委托人：雷春香		被委托人身份证号码：6526196207113926委托人：刘佳2018年5月24日	0.9425919538871845
根据clientip和wideip获取最佳访问pool的设计和实现	性能升级性能升级的几个层面：系统结构：模块分解，模块交互，系统构建中的粗略估算。算法和数据结构：获得快速模块的关键：表示数据的结构，操作数据的算法：索引结构及拉链归并。代码调优：分支预测等。循环：将循环体中不改变的变量移动到循环体外；多重循环嵌套顺序。函数调用：inline函数节省函数调用开销：若makefile中不指定至少-O优化，即使声明为inline函数，编译器也不会进行函数内联。内存寻址：避免重复内存寻址。Cpu流水线的分支预测：将满足概率最高的条件放在靠前的位置。	0.9425919538871845
根据clientip和wideip获取最佳访问pool的设计和实现	业务生成平台用户指南总体说明开发背景下一代网络是业务驱动的网络，在融合的下一代网络上高效、灵活地开发和部署各种丰富多彩的业务，从而提高网络使用率、增加收益的目标，是下一代网络的关键环节。下一代网络的发展要求呼叫与承载相分离、呼叫控制与业务相分离，使业务真正独立于网络，业务开发者不必关心与业务承载相关的底层网络知识以及具体的通信协议，只需利用业务生成平台提供的业务开发工具，就可以开发出灵活丰富且极具个性化的业务。 为了适合多种技术水平的业务开发人员的需要，现在主要有四种业务开发方式：	0.9425919538871845
根据clientip和wideip获取最佳访问pool的设计和实现	工作6周年5个月小记今天是中国时间8/24/2018，也就是我32岁的生日，这是一个不老也不再年轻的年纪。最近总是因为工作而郁郁寡欢，心中不快，所以决定记录总结一下，希望自己能有所释怀、转变、确立新的目标。从2012年3月31到现在，我已在微软Bing工作6年5个月。在此之前，我在百度实习9个月，在阿里巴巴实习2个月，在搜狗实习1个月。在微软北京CJK relevance组勤恳的工作2年6个月，从级别59升到61，做了1年半的DU, 1年的relevance。总体来说，老板们的风格是相关性主导基础	0.941987296311142

本科学位证明_刘佳	贝叶斯分类模型：基础知识：假设	X：是数据元组，由n个属性描述；	H：是某种假设，如数据元组属于某特定类C	P(H|X)：表示给定X的属性描述，找出元组X属于类C的概率举例：X：一位35岁的顾客，收入为4w美元；H：顾客将购买计算机P(H|X)：在X的条件下，H的后验概率。当我们知道顾客的年龄和收入时，顾客X将购买计算机的概率。P(H)：H的先验概率。任意给定顾客将购买计算机的概率，独立与X。P(X|H)：在条件H下，X的后验概率。已知顾客购买了计算机，顾客是一位3	0.9020860628137524
本科学位证明_刘佳	排序及扩展：插入排序，选择排序（冒泡排序），使用二分思想求第k大数，快速排序，非递归的快速排序，使用快排思想求第k大数，归并排序，求逆序数，自然排序算法，堆排序，最小优先级队列，计数排序，桶排序，鸽巢排序（分块排序），基数排序，外部排序：二路归并，K路归并，胜者树，败者树。  算法一：使用插入或者选择排序，得到最大的K个数，时间复杂度为：O(N*k)。 冒泡排序： void swap(int * a,int * b){            //注意	0.8978399594857066
本科学位证明_刘佳	克拉玛依公证处:本人因生活在国外，不能亲自到贵单位办理出生证明公证事项，兹授权委托雷春香女士全权代表我办理相关事项。对委托人在办理上述事项过程中所签署的有关文件，我均予以认可，并承担相应的法律责任。委托人：刘佳			委托人身份证号码：654301198608243929被委托人：雷春香		被委托人身份证号码：6526196207113926委托人：刘佳2018年5月24日	0.8978399594857066
本科学位证明_刘佳	性能升级性能升级的几个层面：系统结构：模块分解，模块交互，系统构建中的粗略估算。算法和数据结构：获得快速模块的关键：表示数据的结构，操作数据的算法：索引结构及拉链归并。代码调优：分支预测等。循环：将循环体中不改变的变量移动到循环体外；多重循环嵌套顺序。函数调用：inline函数节省函数调用开销：若makefile中不指定至少-O优化，即使声明为inline函数，编译器也不会进行函数内联。内存寻址：避免重复内存寻址。Cpu流水线的分支预测：将满足概率最高的条件放在靠前的位置。	0.8978399594857066
本科学位证明_刘佳	业务生成平台用户指南总体说明开发背景下一代网络是业务驱动的网络，在融合的下一代网络上高效、灵活地开发和部署各种丰富多彩的业务，从而提高网络使用率、增加收益的目标，是下一代网络的关键环节。下一代网络的发展要求呼叫与承载相分离、呼叫控制与业务相分离，使业务真正独立于网络，业务开发者不必关心与业务承载相关的底层网络知识以及具体的通信协议，只需利用业务生成平台提供的业务开发工具，就可以开发出灵活丰富且极具个性化的业务。 为了适合多种技术水平的业务开发人员的需要，现在主要有四种业务开发方式：	0.8978399594857066
本科学位证明_刘佳	K最近邻分类模型：原理：训练元组用n个属性描述，每个元组代表n维空间中的一个点，所有的训练元组存放在n维的模式空间。当给定一个未知元组时，KNN搜索该模式空间，找出最接近未知元组的k个训练元组。未知元组指派到它的k个最近邻中的多数类。“邻近性”用距离度量，如欧几里德距离。欧几里德距离：	设元组X1=(X11,X12,…X1n)，X2=(X21,X22,…X2n)，	Dist(X1,X2)=√ ∑ k= 1 n (X1i-X2i) 2 	使用上式之前，对每个属性的值规范化，以防止具有	0.8977903140602628
本科学位证明_刘佳	工作6周年5个月小记今天是中国时间8/24/2018，也就是我32岁的生日，这是一个不老也不再年轻的年纪。最近总是因为工作而郁郁寡欢，心中不快，所以决定记录总结一下，希望自己能有所释怀、转变、确立新的目标。从2012年3月31到现在，我已在微软Bing工作6年5个月。在此之前，我在百度实习9个月，在阿里巴巴实习2个月，在搜狗实习1个月。在微软北京CJK relevance组勤恳的工作2年6个月，从级别59升到61，做了1年半的DU, 1年的relevance。总体来说，老板们的风格是相关性主导基础	0.8969169015172169
本科学位证明_刘佳	海量数据库的设计和实现淘宝海量数据库之一：来自业务的挑战(2010-11-24 11:34:38) 作为一个电子商务企业，从一开始，数据库及其事务能力在淘宝一直扮演着十分关键的角色，淘宝积累了丰富的数据库的架构和规划等方面的经验，产生了众多优秀的DBA。 淘宝是一家迅速发展的公司。全球网站排名公司Alexa提供的数据显示，2010年4月27日，Amazon、Ebay的用户占全球互联网用户的百分比分别为3.47%和2.68%，而淘宝的用户占全球互联网用户的百分比则达到了4.1%，淘宝网日	0.8966745463613783
本科学位证明_刘佳	C专家编程读书笔记难点关键字的用法：关键字用法extern在函数名前，表示该函数全局可见，一般缺省。即一个文件的全局变量和函数对其他文件，具有可见性。在变量或者函数前，表示对象的定义在别处进行。由于重载，在c++中调用以C方式编译的函数时，需要加extern “c”。static隐藏：修饰的对象对其他文件不可见，防止多个文件命名冲突。持久性：修饰的对象，存储在数据段或者bss段，和程序有相同的生命周期。只有一次初始化。3、修饰的变量未初始化时，默认为“0	0.8952665597776505
本科学位证明_刘佳	BS代码阅读：BS基本功能：索引相关性切词成分分析offset调权query解析 （where+what）多路归并 综合调权类聚（偏离点）query分类空间调权数据来源点击调权BS代码阅读：bs_cache:map库的term cachemap库term cache操作锁where库term cachewhere库term cache操作锁init_map_term_cache: 初始化map库term cachein	0.8936426286735205

文本自动分类介绍	贝叶斯分类模型：基础知识：假设	X：是数据元组，由n个属性描述；	H：是某种假设，如数据元组属于某特定类C	P(H|X)：表示给定X的属性描述，找出元组X属于类C的概率举例：X：一位35岁的顾客，收入为4w美元；H：顾客将购买计算机P(H|X)：在X的条件下，H的后验概率。当我们知道顾客的年龄和收入时，顾客X将购买计算机的概率。P(H)：H的先验概率。任意给定顾客将购买计算机的概率，独立与X。P(X|H)：在条件H下，X的后验概率。已知顾客购买了计算机，顾客是一位3	0.9020860628137524
文本自动分类介绍	排序及扩展：插入排序，选择排序（冒泡排序），使用二分思想求第k大数，快速排序，非递归的快速排序，使用快排思想求第k大数，归并排序，求逆序数，自然排序算法，堆排序，最小优先级队列，计数排序，桶排序，鸽巢排序（分块排序），基数排序，外部排序：二路归并，K路归并，胜者树，败者树。  算法一：使用插入或者选择排序，得到最大的K个数，时间复杂度为：O(N*k)。 冒泡排序： void swap(int * a,int * b){            //注意	0.8978399594857066
文本自动分类介绍	克拉玛依公证处:本人因生活在国外，不能亲自到贵单位办理出生证明公证事项，兹授权委托雷春香女士全权代表我办理相关事项。对委托人在办理上述事项过程中所签署的有关文件，我均予以认可，并承担相应的法律责任。委托人：刘佳			委托人身份证号码：654301198608243929被委托人：雷春香		被委托人身份证号码：6526196207113926委托人：刘佳2018年5月24日	0.8978399594857066
文本自动分类介绍	性能升级性能升级的几个层面：系统结构：模块分解，模块交互，系统构建中的粗略估算。算法和数据结构：获得快速模块的关键：表示数据的结构，操作数据的算法：索引结构及拉链归并。代码调优：分支预测等。循环：将循环体中不改变的变量移动到循环体外；多重循环嵌套顺序。函数调用：inline函数节省函数调用开销：若makefile中不指定至少-O优化，即使声明为inline函数，编译器也不会进行函数内联。内存寻址：避免重复内存寻址。Cpu流水线的分支预测：将满足概率最高的条件放在靠前的位置。	0.8978399594857066
文本自动分类介绍	业务生成平台用户指南总体说明开发背景下一代网络是业务驱动的网络，在融合的下一代网络上高效、灵活地开发和部署各种丰富多彩的业务，从而提高网络使用率、增加收益的目标，是下一代网络的关键环节。下一代网络的发展要求呼叫与承载相分离、呼叫控制与业务相分离，使业务真正独立于网络，业务开发者不必关心与业务承载相关的底层网络知识以及具体的通信协议，只需利用业务生成平台提供的业务开发工具，就可以开发出灵活丰富且极具个性化的业务。 为了适合多种技术水平的业务开发人员的需要，现在主要有四种业务开发方式：	0.8978399594857066
文本自动分类介绍	K最近邻分类模型：原理：训练元组用n个属性描述，每个元组代表n维空间中的一个点，所有的训练元组存放在n维的模式空间。当给定一个未知元组时，KNN搜索该模式空间，找出最接近未知元组的k个训练元组。未知元组指派到它的k个最近邻中的多数类。“邻近性”用距离度量，如欧几里德距离。欧几里德距离：	设元组X1=(X11,X12,…X1n)，X2=(X21,X22,…X2n)，	Dist(X1,X2)=√ ∑ k= 1 n (X1i-X2i) 2 	使用上式之前，对每个属性的值规范化，以防止具有	0.8977903140602628
文本自动分类介绍	工作6周年5个月小记今天是中国时间8/24/2018，也就是我32岁的生日，这是一个不老也不再年轻的年纪。最近总是因为工作而郁郁寡欢，心中不快，所以决定记录总结一下，希望自己能有所释怀、转变、确立新的目标。从2012年3月31到现在，我已在微软Bing工作6年5个月。在此之前，我在百度实习9个月，在阿里巴巴实习2个月，在搜狗实习1个月。在微软北京CJK relevance组勤恳的工作2年6个月，从级别59升到61，做了1年半的DU, 1年的relevance。总体来说，老板们的风格是相关性主导基础	0.8969169015172169
文本自动分类介绍	海量数据库的设计和实现淘宝海量数据库之一：来自业务的挑战(2010-11-24 11:34:38) 作为一个电子商务企业，从一开始，数据库及其事务能力在淘宝一直扮演着十分关键的角色，淘宝积累了丰富的数据库的架构和规划等方面的经验，产生了众多优秀的DBA。 淘宝是一家迅速发展的公司。全球网站排名公司Alexa提供的数据显示，2010年4月27日，Amazon、Ebay的用户占全球互联网用户的百分比分别为3.47%和2.68%，而淘宝的用户占全球互联网用户的百分比则达到了4.1%，淘宝网日	0.8966745463613783
文本自动分类介绍	C专家编程读书笔记难点关键字的用法：关键字用法extern在函数名前，表示该函数全局可见，一般缺省。即一个文件的全局变量和函数对其他文件，具有可见性。在变量或者函数前，表示对象的定义在别处进行。由于重载，在c++中调用以C方式编译的函数时，需要加extern “c”。static隐藏：修饰的对象对其他文件不可见，防止多个文件命名冲突。持久性：修饰的对象，存储在数据段或者bss段，和程序有相同的生命周期。只有一次初始化。3、修饰的变量未初始化时，默认为“0	0.8952665597776505
文本自动分类介绍	BS代码阅读：BS基本功能：索引相关性切词成分分析offset调权query解析 （where+what）多路归并 综合调权类聚（偏离点）query分类空间调权数据来源点击调权BS代码阅读：bs_cache:map库的term cachemap库term cache操作锁where库term cachewhere库term cache操作锁init_map_term_cache: 初始化map库term cachein	0.8936426286735205

排序及扩展	贝叶斯分类模型：基础知识：假设	X：是数据元组，由n个属性描述；	H：是某种假设，如数据元组属于某特定类C	P(H|X)：表示给定X的属性描述，找出元组X属于类C的概率举例：X：一位35岁的顾客，收入为4w美元；H：顾客将购买计算机P(H|X)：在X的条件下，H的后验概率。当我们知道顾客的年龄和收入时，顾客X将购买计算机的概率。P(H)：H的先验概率。任意给定顾客将购买计算机的概率，独立与X。P(X|H)：在条件H下，X的后验概率。已知顾客购买了计算机，顾客是一位3	0.8413743188327613
排序及扩展	排序及扩展：插入排序，选择排序（冒泡排序），使用二分思想求第k大数，快速排序，非递归的快速排序，使用快排思想求第k大数，归并排序，求逆序数，自然排序算法，堆排序，最小优先级队列，计数排序，桶排序，鸽巢排序（分块排序），基数排序，外部排序：二路归并，K路归并，胜者树，败者树。  算法一：使用插入或者选择排序，得到最大的K个数，时间复杂度为：O(N*k)。 冒泡排序： void swap(int * a,int * b){            //注意	0.8372777254672282
排序及扩展	克拉玛依公证处:本人因生活在国外，不能亲自到贵单位办理出生证明公证事项，兹授权委托雷春香女士全权代表我办理相关事项。对委托人在办理上述事项过程中所签署的有关文件，我均予以认可，并承担相应的法律责任。委托人：刘佳			委托人身份证号码：654301198608243929被委托人：雷春香		被委托人身份证号码：6526196207113926委托人：刘佳2018年5月24日	0.8372777254672282
排序及扩展	性能升级性能升级的几个层面：系统结构：模块分解，模块交互，系统构建中的粗略估算。算法和数据结构：获得快速模块的关键：表示数据的结构，操作数据的算法：索引结构及拉链归并。代码调优：分支预测等。循环：将循环体中不改变的变量移动到循环体外；多重循环嵌套顺序。函数调用：inline函数节省函数调用开销：若makefile中不指定至少-O优化，即使声明为inline函数，编译器也不会进行函数内联。内存寻址：避免重复内存寻址。Cpu流水线的分支预测：将满足概率最高的条件放在靠前的位置。	0.8372777254672282
排序及扩展	业务生成平台用户指南总体说明开发背景下一代网络是业务驱动的网络，在融合的下一代网络上高效、灵活地开发和部署各种丰富多彩的业务，从而提高网络使用率、增加收益的目标，是下一代网络的关键环节。下一代网络的发展要求呼叫与承载相分离、呼叫控制与业务相分离，使业务真正独立于网络，业务开发者不必关心与业务承载相关的底层网络知识以及具体的通信协议，只需利用业务生成平台提供的业务开发工具，就可以开发出灵活丰富且极具个性化的业务。 为了适合多种技术水平的业务开发人员的需要，现在主要有四种业务开发方式：	0.8372777254672282
排序及扩展	K最近邻分类模型：原理：训练元组用n个属性描述，每个元组代表n维空间中的一个点，所有的训练元组存放在n维的模式空间。当给定一个未知元组时，KNN搜索该模式空间，找出最接近未知元组的k个训练元组。未知元组指派到它的k个最近邻中的多数类。“邻近性”用距离度量，如欧几里德距离。欧几里德距离：	设元组X1=(X11,X12,…X1n)，X2=(X21,X22,…X2n)，	Dist(X1,X2)=√ ∑ k= 1 n (X1i-X2i) 2 	使用上式之前，对每个属性的值规范化，以防止具有	0.8370170829843641
排序及扩展	工作6周年5个月小记今天是中国时间8/24/2018，也就是我32岁的生日，这是一个不老也不再年轻的年纪。最近总是因为工作而郁郁寡欢，心中不快，所以决定记录总结一下，希望自己能有所释怀、转变、确立新的目标。从2012年3月31到现在，我已在微软Bing工作6年5个月。在此之前，我在百度实习9个月，在阿里巴巴实习2个月，在搜狗实习1个月。在微软北京CJK relevance组勤恳的工作2年6个月，从级别59升到61，做了1年半的DU, 1年的relevance。总体来说，老板们的风格是相关性主导基础	0.836922313442188
排序及扩展	海量数据库的设计和实现淘宝海量数据库之一：来自业务的挑战(2010-11-24 11:34:38) 作为一个电子商务企业，从一开始，数据库及其事务能力在淘宝一直扮演着十分关键的角色，淘宝积累了丰富的数据库的架构和规划等方面的经验，产生了众多优秀的DBA。 淘宝是一家迅速发展的公司。全球网站排名公司Alexa提供的数据显示，2010年4月27日，Amazon、Ebay的用户占全球互联网用户的百分比分别为3.47%和2.68%，而淘宝的用户占全球互联网用户的百分比则达到了4.1%，淘宝网日	0.8366941298405453
排序及扩展	C专家编程读书笔记难点关键字的用法：关键字用法extern在函数名前，表示该函数全局可见，一般缺省。即一个文件的全局变量和函数对其他文件，具有可见性。在变量或者函数前，表示对象的定义在别处进行。由于重载，在c++中调用以C方式编译的函数时，需要加extern “c”。static隐藏：修饰的对象对其他文件不可见，防止多个文件命名冲突。持久性：修饰的对象，存储在数据段或者bss段，和程序有相同的生命周期。只有一次初始化。3、修饰的变量未初始化时，默认为“0	0.8353689134887607
排序及扩展	神经网络原理及应用介绍Anti RD：王伟琼、张爱华主要内容特点及应用场景神经网络原理我们的经验和教训多线程训练下一步的工作应用场景分类预测时间允许的场合使用并行化等方法加速测试过程很快，且可以方便的使用hadoop平台环境比较固定的场合数据的统计特性变化不大需要定量预测的场合给出未知数据的定量预测神经网络特点优点对噪音数据有较好的适应能力对未知数据具有较好的预测分类能力拟合各种函数得出定量值缺点学习时间较长	0.8312103889559255

拉链归并算法探讨	贝叶斯分类模型：基础知识：假设	X：是数据元组，由n个属性描述；	H：是某种假设，如数据元组属于某特定类C	P(H|X)：表示给定X的属性描述，找出元组X属于类C的概率举例：X：一位35岁的顾客，收入为4w美元；H：顾客将购买计算机P(H|X)：在X的条件下，H的后验概率。当我们知道顾客的年龄和收入时，顾客X将购买计算机的概率。P(H)：H的先验概率。任意给定顾客将购买计算机的概率，独立与X。P(X|H)：在条件H下，X的后验概率。已知顾客购买了计算机，顾客是一位3	0.9020860628137524
拉链归并算法探讨	排序及扩展：插入排序，选择排序（冒泡排序），使用二分思想求第k大数，快速排序，非递归的快速排序，使用快排思想求第k大数，归并排序，求逆序数，自然排序算法，堆排序，最小优先级队列，计数排序，桶排序，鸽巢排序（分块排序），基数排序，外部排序：二路归并，K路归并，胜者树，败者树。  算法一：使用插入或者选择排序，得到最大的K个数，时间复杂度为：O(N*k)。 冒泡排序： void swap(int * a,int * b){            //注意	0.8978399594857066
拉链归并算法探讨	克拉玛依公证处:本人因生活在国外，不能亲自到贵单位办理出生证明公证事项，兹授权委托雷春香女士全权代表我办理相关事项。对委托人在办理上述事项过程中所签署的有关文件，我均予以认可，并承担相应的法律责任。委托人：刘佳			委托人身份证号码：654301198608243929被委托人：雷春香		被委托人身份证号码：6526196207113926委托人：刘佳2018年5月24日	0.8978399594857066
拉链归并算法探讨	性能升级性能升级的几个层面：系统结构：模块分解，模块交互，系统构建中的粗略估算。算法和数据结构：获得快速模块的关键：表示数据的结构，操作数据的算法：索引结构及拉链归并。代码调优：分支预测等。循环：将循环体中不改变的变量移动到循环体外；多重循环嵌套顺序。函数调用：inline函数节省函数调用开销：若makefile中不指定至少-O优化，即使声明为inline函数，编译器也不会进行函数内联。内存寻址：避免重复内存寻址。Cpu流水线的分支预测：将满足概率最高的条件放在靠前的位置。	0.8978399594857066
拉链归并算法探讨	业务生成平台用户指南总体说明开发背景下一代网络是业务驱动的网络，在融合的下一代网络上高效、灵活地开发和部署各种丰富多彩的业务，从而提高网络使用率、增加收益的目标，是下一代网络的关键环节。下一代网络的发展要求呼叫与承载相分离、呼叫控制与业务相分离，使业务真正独立于网络，业务开发者不必关心与业务承载相关的底层网络知识以及具体的通信协议，只需利用业务生成平台提供的业务开发工具，就可以开发出灵活丰富且极具个性化的业务。 为了适合多种技术水平的业务开发人员的需要，现在主要有四种业务开发方式：	0.8978399594857066
拉链归并算法探讨	K最近邻分类模型：原理：训练元组用n个属性描述，每个元组代表n维空间中的一个点，所有的训练元组存放在n维的模式空间。当给定一个未知元组时，KNN搜索该模式空间，找出最接近未知元组的k个训练元组。未知元组指派到它的k个最近邻中的多数类。“邻近性”用距离度量，如欧几里德距离。欧几里德距离：	设元组X1=(X11,X12,…X1n)，X2=(X21,X22,…X2n)，	Dist(X1,X2)=√ ∑ k= 1 n (X1i-X2i) 2 	使用上式之前，对每个属性的值规范化，以防止具有	0.8977903140602628
拉链归并算法探讨	工作6周年5个月小记今天是中国时间8/24/2018，也就是我32岁的生日，这是一个不老也不再年轻的年纪。最近总是因为工作而郁郁寡欢，心中不快，所以决定记录总结一下，希望自己能有所释怀、转变、确立新的目标。从2012年3月31到现在，我已在微软Bing工作6年5个月。在此之前，我在百度实习9个月，在阿里巴巴实习2个月，在搜狗实习1个月。在微软北京CJK relevance组勤恳的工作2年6个月，从级别59升到61，做了1年半的DU, 1年的relevance。总体来说，老板们的风格是相关性主导基础	0.8969169015172169
拉链归并算法探讨	海量数据库的设计和实现淘宝海量数据库之一：来自业务的挑战(2010-11-24 11:34:38) 作为一个电子商务企业，从一开始，数据库及其事务能力在淘宝一直扮演着十分关键的角色，淘宝积累了丰富的数据库的架构和规划等方面的经验，产生了众多优秀的DBA。 淘宝是一家迅速发展的公司。全球网站排名公司Alexa提供的数据显示，2010年4月27日，Amazon、Ebay的用户占全球互联网用户的百分比分别为3.47%和2.68%，而淘宝的用户占全球互联网用户的百分比则达到了4.1%，淘宝网日	0.8966745463613783
拉链归并算法探讨	C专家编程读书笔记难点关键字的用法：关键字用法extern在函数名前，表示该函数全局可见，一般缺省。即一个文件的全局变量和函数对其他文件，具有可见性。在变量或者函数前，表示对象的定义在别处进行。由于重载，在c++中调用以C方式编译的函数时，需要加extern “c”。static隐藏：修饰的对象对其他文件不可见，防止多个文件命名冲突。持久性：修饰的对象，存储在数据段或者bss段，和程序有相同的生命周期。只有一次初始化。3、修饰的变量未初始化时，默认为“0	0.8952665597776505
拉链归并算法探讨	BS代码阅读：BS基本功能：索引相关性切词成分分析offset调权query解析 （where+what）多路归并 综合调权类聚（偏离点）query分类空间调权数据来源点击调权BS代码阅读：bs_cache:map库的term cachemap库term cache操作锁where库term cachewhere库term cache操作锁init_map_term_cache: 初始化map库term cachein	0.8936426286735205

常用Linux命令	常用Linux命令：统计当前目录下所有.h文件的个数：find . -name "*.h" | wc -l统计当前目录下所有.h文件的总代码行数：find . -name "*.h" | xargs wc -l传输大文件时rz -be解压tar.gz文件tar zxvf x.tar.gz	0.8219872122169076
常用Linux命令	BS代码阅读：BS基本功能：索引相关性切词成分分析offset调权query解析 （where+what）多路归并 综合调权类聚（偏离点）query分类空间调权数据来源点击调权BS代码阅读：bs_cache:map库的term cachemap库term cache操作锁where库term cachewhere库term cache操作锁init_map_term_cache: 初始化map库term cachein	0.8198435070577815
常用Linux命令	贝叶斯分类模型：基础知识：假设	X：是数据元组，由n个属性描述；	H：是某种假设，如数据元组属于某特定类C	P(H|X)：表示给定X的属性描述，找出元组X属于类C的概率举例：X：一位35岁的顾客，收入为4w美元；H：顾客将购买计算机P(H|X)：在X的条件下，H的后验概率。当我们知道顾客的年龄和收入时，顾客X将购买计算机的概率。P(H)：H的先验概率。任意给定顾客将购买计算机的概率，独立与X。P(X|H)：在条件H下，X的后验概率。已知顾客购买了计算机，顾客是一位3	0.8188138487156359
常用Linux命令	K最近邻分类模型：原理：训练元组用n个属性描述，每个元组代表n维空间中的一个点，所有的训练元组存放在n维的模式空间。当给定一个未知元组时，KNN搜索该模式空间，找出最接近未知元组的k个训练元组。未知元组指派到它的k个最近邻中的多数类。“邻近性”用距离度量，如欧几里德距离。欧几里德距离：	设元组X1=(X11,X12,…X1n)，X2=(X21,X22,…X2n)，	Dist(X1,X2)=√ ∑ k= 1 n (X1i-X2i) 2 	使用上式之前，对每个属性的值规范化，以防止具有	0.8183421941245145
常用Linux命令	排序及扩展：插入排序，选择排序（冒泡排序），使用二分思想求第k大数，快速排序，非递归的快速排序，使用快排思想求第k大数，归并排序，求逆序数，自然排序算法，堆排序，最小优先级队列，计数排序，桶排序，鸽巢排序（分块排序），基数排序，外部排序：二路归并，K路归并，胜者树，败者树。  算法一：使用插入或者选择排序，得到最大的K个数，时间复杂度为：O(N*k)。 冒泡排序： void swap(int * a,int * b){            //注意	0.8177208151444194
常用Linux命令	克拉玛依公证处:本人因生活在国外，不能亲自到贵单位办理出生证明公证事项，兹授权委托雷春香女士全权代表我办理相关事项。对委托人在办理上述事项过程中所签署的有关文件，我均予以认可，并承担相应的法律责任。委托人：刘佳			委托人身份证号码：654301198608243929被委托人：雷春香		被委托人身份证号码：6526196207113926委托人：刘佳2018年5月24日	0.8177208151444194
常用Linux命令	性能升级性能升级的几个层面：系统结构：模块分解，模块交互，系统构建中的粗略估算。算法和数据结构：获得快速模块的关键：表示数据的结构，操作数据的算法：索引结构及拉链归并。代码调优：分支预测等。循环：将循环体中不改变的变量移动到循环体外；多重循环嵌套顺序。函数调用：inline函数节省函数调用开销：若makefile中不指定至少-O优化，即使声明为inline函数，编译器也不会进行函数内联。内存寻址：避免重复内存寻址。Cpu流水线的分支预测：将满足概率最高的条件放在靠前的位置。	0.8177208151444194
常用Linux命令	业务生成平台用户指南总体说明开发背景下一代网络是业务驱动的网络，在融合的下一代网络上高效、灵活地开发和部署各种丰富多彩的业务，从而提高网络使用率、增加收益的目标，是下一代网络的关键环节。下一代网络的发展要求呼叫与承载相分离、呼叫控制与业务相分离，使业务真正独立于网络，业务开发者不必关心与业务承载相关的底层网络知识以及具体的通信协议，只需利用业务生成平台提供的业务开发工具，就可以开发出灵活丰富且极具个性化的业务。 为了适合多种技术水平的业务开发人员的需要，现在主要有四种业务开发方式：	0.8177208151444194
常用Linux命令	C专家编程读书笔记难点关键字的用法：关键字用法extern在函数名前，表示该函数全局可见，一般缺省。即一个文件的全局变量和函数对其他文件，具有可见性。在变量或者函数前，表示对象的定义在别处进行。由于重载，在c++中调用以C方式编译的函数时，需要加extern “c”。static隐藏：修饰的对象对其他文件不可见，防止多个文件命名冲突。持久性：修饰的对象，存储在数据段或者bss段，和程序有相同的生命周期。只有一次初始化。3、修饰的变量未初始化时，默认为“0	0.8158747824415575
常用Linux命令	工作6周年5个月小记今天是中国时间8/24/2018，也就是我32岁的生日，这是一个不老也不再年轻的年纪。最近总是因为工作而郁郁寡欢，心中不快，所以决定记录总结一下，希望自己能有所释怀、转变、确立新的目标。从2012年3月31到现在，我已在微软Bing工作6年5个月。在此之前，我在百度实习9个月，在阿里巴巴实习2个月，在搜狗实习1个月。在微软北京CJK relevance组勤恳的工作2年6个月，从级别59升到61，做了1年半的DU, 1年的relevance。总体来说，老板们的风格是相关性主导基础	0.8128419837219975

工作6周年5个月小记	贝叶斯分类模型：基础知识：假设	X：是数据元组，由n个属性描述；	H：是某种假设，如数据元组属于某特定类C	P(H|X)：表示给定X的属性描述，找出元组X属于类C的概率举例：X：一位35岁的顾客，收入为4w美元；H：顾客将购买计算机P(H|X)：在X的条件下，H的后验概率。当我们知道顾客的年龄和收入时，顾客X将购买计算机的概率。P(H)：H的先验概率。任意给定顾客将购买计算机的概率，独立与X。P(X|H)：在条件H下，X的后验概率。已知顾客购买了计算机，顾客是一位3	0.9249398517795397
工作6周年5个月小记	K最近邻分类模型：原理：训练元组用n个属性描述，每个元组代表n维空间中的一个点，所有的训练元组存放在n维的模式空间。当给定一个未知元组时，KNN搜索该模式空间，找出最接近未知元组的k个训练元组。未知元组指派到它的k个最近邻中的多数类。“邻近性”用距离度量，如欧几里德距离。欧几里德距离：	设元组X1=(X11,X12,…X1n)，X2=(X21,X22,…X2n)，	Dist(X1,X2)=√ ∑ k= 1 n (X1i-X2i) 2 	使用上式之前，对每个属性的值规范化，以防止具有	0.9208674692387612
工作6周年5个月小记	排序及扩展：插入排序，选择排序（冒泡排序），使用二分思想求第k大数，快速排序，非递归的快速排序，使用快排思想求第k大数，归并排序，求逆序数，自然排序算法，堆排序，最小优先级队列，计数排序，桶排序，鸽巢排序（分块排序），基数排序，外部排序：二路归并，K路归并，胜者树，败者树。  算法一：使用插入或者选择排序，得到最大的K个数，时间复杂度为：O(N*k)。 冒泡排序： void swap(int * a,int * b){            //注意	0.9208515798798043
工作6周年5个月小记	克拉玛依公证处:本人因生活在国外，不能亲自到贵单位办理出生证明公证事项，兹授权委托雷春香女士全权代表我办理相关事项。对委托人在办理上述事项过程中所签署的有关文件，我均予以认可，并承担相应的法律责任。委托人：刘佳			委托人身份证号码：654301198608243929被委托人：雷春香		被委托人身份证号码：6526196207113926委托人：刘佳2018年5月24日	0.9208515798798043
工作6周年5个月小记	性能升级性能升级的几个层面：系统结构：模块分解，模块交互，系统构建中的粗略估算。算法和数据结构：获得快速模块的关键：表示数据的结构，操作数据的算法：索引结构及拉链归并。代码调优：分支预测等。循环：将循环体中不改变的变量移动到循环体外；多重循环嵌套顺序。函数调用：inline函数节省函数调用开销：若makefile中不指定至少-O优化，即使声明为inline函数，编译器也不会进行函数内联。内存寻址：避免重复内存寻址。Cpu流水线的分支预测：将满足概率最高的条件放在靠前的位置。	0.9208515798798043
工作6周年5个月小记	业务生成平台用户指南总体说明开发背景下一代网络是业务驱动的网络，在融合的下一代网络上高效、灵活地开发和部署各种丰富多彩的业务，从而提高网络使用率、增加收益的目标，是下一代网络的关键环节。下一代网络的发展要求呼叫与承载相分离、呼叫控制与业务相分离，使业务真正独立于网络，业务开发者不必关心与业务承载相关的底层网络知识以及具体的通信协议，只需利用业务生成平台提供的业务开发工具，就可以开发出灵活丰富且极具个性化的业务。 为了适合多种技术水平的业务开发人员的需要，现在主要有四种业务开发方式：	0.9208515798798043
工作6周年5个月小记	工作6周年5个月小记今天是中国时间8/24/2018，也就是我32岁的生日，这是一个不老也不再年轻的年纪。最近总是因为工作而郁郁寡欢，心中不快，所以决定记录总结一下，希望自己能有所释怀、转变、确立新的目标。从2012年3月31到现在，我已在微软Bing工作6年5个月。在此之前，我在百度实习9个月，在阿里巴巴实习2个月，在搜狗实习1个月。在微软北京CJK relevance组勤恳的工作2年6个月，从级别59升到61，做了1年半的DU, 1年的relevance。总体来说，老板们的风格是相关性主导基础	0.9199439550197025
工作6周年5个月小记	海量数据库的设计和实现淘宝海量数据库之一：来自业务的挑战(2010-11-24 11:34:38) 作为一个电子商务企业，从一开始，数据库及其事务能力在淘宝一直扮演着十分关键的角色，淘宝积累了丰富的数据库的架构和规划等方面的经验，产生了众多优秀的DBA。 淘宝是一家迅速发展的公司。全球网站排名公司Alexa提供的数据显示，2010年4月27日，Amazon、Ebay的用户占全球互联网用户的百分比分别为3.47%和2.68%，而淘宝的用户占全球互联网用户的百分比则达到了4.1%，淘宝网日	0.9191956061289238
工作6周年5个月小记	BS代码阅读：BS基本功能：索引相关性切词成分分析offset调权query解析 （where+what）多路归并 综合调权类聚（偏离点）query分类空间调权数据来源点击调权BS代码阅读：bs_cache:map库的term cachemap库term cache操作锁where库term cachewhere库term cache操作锁init_map_term_cache: 初始化map库term cachein	0.9180643711633901
工作6周年5个月小记	C专家编程读书笔记难点关键字的用法：关键字用法extern在函数名前，表示该函数全局可见，一般缺省。即一个文件的全局变量和函数对其他文件，具有可见性。在变量或者函数前，表示对象的定义在别处进行。由于重载，在c++中调用以C方式编译的函数时，需要加extern “c”。static隐藏：修饰的对象对其他文件不可见，防止多个文件命名冲突。持久性：修饰的对象，存储在数据段或者bss段，和程序有相同的生命周期。只有一次初始化。3、修饰的变量未初始化时，默认为“0	0.9180486264613177

客户价值模型	贝叶斯分类模型：基础知识：假设	X：是数据元组，由n个属性描述；	H：是某种假设，如数据元组属于某特定类C	P(H|X)：表示给定X的属性描述，找出元组X属于类C的概率举例：X：一位35岁的顾客，收入为4w美元；H：顾客将购买计算机P(H|X)：在X的条件下，H的后验概率。当我们知道顾客的年龄和收入时，顾客X将购买计算机的概率。P(H)：H的先验概率。任意给定顾客将购买计算机的概率，独立与X。P(X|H)：在条件H下，X的后验概率。已知顾客购买了计算机，顾客是一位3	0.8668015900487511
客户价值模型	排序及扩展：插入排序，选择排序（冒泡排序），使用二分思想求第k大数，快速排序，非递归的快速排序，使用快排思想求第k大数，归并排序，求逆序数，自然排序算法，堆排序，最小优先级队列，计数排序，桶排序，鸽巢排序（分块排序），基数排序，外部排序：二路归并，K路归并，胜者树，败者树。  算法一：使用插入或者选择排序，得到最大的K个数，时间复杂度为：O(N*k)。 冒泡排序： void swap(int * a,int * b){            //注意	0.8625627796303993
客户价值模型	克拉玛依公证处:本人因生活在国外，不能亲自到贵单位办理出生证明公证事项，兹授权委托雷春香女士全权代表我办理相关事项。对委托人在办理上述事项过程中所签署的有关文件，我均予以认可，并承担相应的法律责任。委托人：刘佳			委托人身份证号码：654301198608243929被委托人：雷春香		被委托人身份证号码：6526196207113926委托人：刘佳2018年5月24日	0.8625627796303993
客户价值模型	性能升级性能升级的几个层面：系统结构：模块分解，模块交互，系统构建中的粗略估算。算法和数据结构：获得快速模块的关键：表示数据的结构，操作数据的算法：索引结构及拉链归并。代码调优：分支预测等。循环：将循环体中不改变的变量移动到循环体外；多重循环嵌套顺序。函数调用：inline函数节省函数调用开销：若makefile中不指定至少-O优化，即使声明为inline函数，编译器也不会进行函数内联。内存寻址：避免重复内存寻址。Cpu流水线的分支预测：将满足概率最高的条件放在靠前的位置。	0.8625627796303993
客户价值模型	业务生成平台用户指南总体说明开发背景下一代网络是业务驱动的网络，在融合的下一代网络上高效、灵活地开发和部署各种丰富多彩的业务，从而提高网络使用率、增加收益的目标，是下一代网络的关键环节。下一代网络的发展要求呼叫与承载相分离、呼叫控制与业务相分离，使业务真正独立于网络，业务开发者不必关心与业务承载相关的底层网络知识以及具体的通信协议，只需利用业务生成平台提供的业务开发工具，就可以开发出灵活丰富且极具个性化的业务。 为了适合多种技术水平的业务开发人员的需要，现在主要有四种业务开发方式：	0.8625627796303993
客户价值模型	K最近邻分类模型：原理：训练元组用n个属性描述，每个元组代表n维空间中的一个点，所有的训练元组存放在n维的模式空间。当给定一个未知元组时，KNN搜索该模式空间，找出最接近未知元组的k个训练元组。未知元组指派到它的k个最近邻中的多数类。“邻近性”用距离度量，如欧几里德距离。欧几里德距离：	设元组X1=(X11,X12,…X1n)，X2=(X21,X22,…X2n)，	Dist(X1,X2)=√ ∑ k= 1 n (X1i-X2i) 2 	使用上式之前，对每个属性的值规范化，以防止具有	0.8623970213866929
客户价值模型	工作6周年5个月小记今天是中国时间8/24/2018，也就是我32岁的生日，这是一个不老也不再年轻的年纪。最近总是因为工作而郁郁寡欢，心中不快，所以决定记录总结一下，希望自己能有所释怀、转变、确立新的目标。从2012年3月31到现在，我已在微软Bing工作6年5个月。在此之前，我在百度实习9个月，在阿里巴巴实习2个月，在搜狗实习1个月。在微软北京CJK relevance组勤恳的工作2年6个月，从级别59升到61，做了1年半的DU, 1年的relevance。总体来说，老板们的风格是相关性主导基础	0.861846046363835
客户价值模型	海量数据库的设计和实现淘宝海量数据库之一：来自业务的挑战(2010-11-24 11:34:38) 作为一个电子商务企业，从一开始，数据库及其事务能力在淘宝一直扮演着十分关键的角色，淘宝积累了丰富的数据库的架构和规划等方面的经验，产生了众多优秀的DBA。 淘宝是一家迅速发展的公司。全球网站排名公司Alexa提供的数据显示，2010年4月27日，Amazon、Ebay的用户占全球互联网用户的百分比分别为3.47%和2.68%，而淘宝的用户占全球互联网用户的百分比则达到了4.1%，淘宝网日	0.8618091825291979
客户价值模型	C专家编程读书笔记难点关键字的用法：关键字用法extern在函数名前，表示该函数全局可见，一般缺省。即一个文件的全局变量和函数对其他文件，具有可见性。在变量或者函数前，表示对象的定义在别处进行。由于重载，在c++中调用以C方式编译的函数时，需要加extern “c”。static隐藏：修饰的对象对其他文件不可见，防止多个文件命名冲突。持久性：修饰的对象，存储在数据段或者bss段，和程序有相同的生命周期。只有一次初始化。3、修饰的变量未初始化时，默认为“0	0.8603809632153069
客户价值模型	Svm分类模型：基本原理：将所有待分类的点映射到“高维空间”，然后在高维空间中找到一个能将这些点分开的“超平面”，这在理论上是被完全证明了是成立的，而且在实际计算中也是可行的。满足条件的“超平面”的个数不是唯一的。SVM需要的是利用这些超平面，找到这两类点之间的“最大间隔”。并非所有的数据都线性可分，将非线性映射到更高维的特征空间变成线性可分。（低维空间向量集通常难于划分，解决的方法是将它们映射到高维空间。）但这个办法带来的困难就是计算复杂度的增加，而核函数正好巧妙地解决了这个问题。也就是说，只要选用	0.8568623346304849

刘佳_出生证明公证办理委托书	贝叶斯分类模型：基础知识：假设	X：是数据元组，由n个属性描述；	H：是某种假设，如数据元组属于某特定类C	P(H|X)：表示给定X的属性描述，找出元组X属于类C的概率举例：X：一位35岁的顾客，收入为4w美元；H：顾客将购买计算机P(H|X)：在X的条件下，H的后验概率。当我们知道顾客的年龄和收入时，顾客X将购买计算机的概率。P(H)：H的先验概率。任意给定顾客将购买计算机的概率，独立与X。P(X|H)：在条件H下，X的后验概率。已知顾客购买了计算机，顾客是一位3	0.9457012447497645
刘佳_出生证明公证办理委托书	K最近邻分类模型：原理：训练元组用n个属性描述，每个元组代表n维空间中的一个点，所有的训练元组存放在n维的模式空间。当给定一个未知元组时，KNN搜索该模式空间，找出最接近未知元组的k个训练元组。未知元组指派到它的k个最近邻中的多数类。“邻近性”用距离度量，如欧几里德距离。欧几里德距离：	设元组X1=(X11,X12,…X1n)，X2=(X21,X22,…X2n)，	Dist(X1,X2)=√ ∑ k= 1 n (X1i-X2i) 2 	使用上式之前，对每个属性的值规范化，以防止具有	0.9420538806566909
刘佳_出生证明公证办理委托书	排序及扩展：插入排序，选择排序（冒泡排序），使用二分思想求第k大数，快速排序，非递归的快速排序，使用快排思想求第k大数，归并排序，求逆序数，自然排序算法，堆排序，最小优先级队列，计数排序，桶排序，鸽巢排序（分块排序），基数排序，外部排序：二路归并，K路归并，胜者树，败者树。  算法一：使用插入或者选择排序，得到最大的K个数，时间复杂度为：O(N*k)。 冒泡排序： void swap(int * a,int * b){            //注意	0.9419812412383604
刘佳_出生证明公证办理委托书	克拉玛依公证处:本人因生活在国外，不能亲自到贵单位办理出生证明公证事项，兹授权委托雷春香女士全权代表我办理相关事项。对委托人在办理上述事项过程中所签署的有关文件，我均予以认可，并承担相应的法律责任。委托人：刘佳			委托人身份证号码：654301198608243929被委托人：雷春香		被委托人身份证号码：6526196207113926委托人：刘佳2018年5月24日	0.9419812412383604
刘佳_出生证明公证办理委托书	性能升级性能升级的几个层面：系统结构：模块分解，模块交互，系统构建中的粗略估算。算法和数据结构：获得快速模块的关键：表示数据的结构，操作数据的算法：索引结构及拉链归并。代码调优：分支预测等。循环：将循环体中不改变的变量移动到循环体外；多重循环嵌套顺序。函数调用：inline函数节省函数调用开销：若makefile中不指定至少-O优化，即使声明为inline函数，编译器也不会进行函数内联。内存寻址：避免重复内存寻址。Cpu流水线的分支预测：将满足概率最高的条件放在靠前的位置。	0.9419812412383604
刘佳_出生证明公证办理委托书	业务生成平台用户指南总体说明开发背景下一代网络是业务驱动的网络，在融合的下一代网络上高效、灵活地开发和部署各种丰富多彩的业务，从而提高网络使用率、增加收益的目标，是下一代网络的关键环节。下一代网络的发展要求呼叫与承载相分离、呼叫控制与业务相分离，使业务真正独立于网络，业务开发者不必关心与业务承载相关的底层网络知识以及具体的通信协议，只需利用业务生成平台提供的业务开发工具，就可以开发出灵活丰富且极具个性化的业务。 为了适合多种技术水平的业务开发人员的需要，现在主要有四种业务开发方式：	0.9419812412383604
刘佳_出生证明公证办理委托书	工作6周年5个月小记今天是中国时间8/24/2018，也就是我32岁的生日，这是一个不老也不再年轻的年纪。最近总是因为工作而郁郁寡欢，心中不快，所以决定记录总结一下，希望自己能有所释怀、转变、确立新的目标。从2012年3月31到现在，我已在微软Bing工作6年5个月。在此之前，我在百度实习9个月，在阿里巴巴实习2个月，在搜狗实习1个月。在微软北京CJK relevance组勤恳的工作2年6个月，从级别59升到61，做了1年半的DU, 1年的relevance。总体来说，老板们的风格是相关性主导基础	0.9411223697874557
刘佳_出生证明公证办理委托书	BS代码阅读：BS基本功能：索引相关性切词成分分析offset调权query解析 （where+what）多路归并 综合调权类聚（偏离点）query分类空间调权数据来源点击调权BS代码阅读：bs_cache:map库的term cachemap库term cache操作锁where库term cachewhere库term cache操作锁init_map_term_cache: 初始化map库term cachein	0.9401922518490348
刘佳_出生证明公证办理委托书	海量数据库的设计和实现淘宝海量数据库之一：来自业务的挑战(2010-11-24 11:34:38) 作为一个电子商务企业，从一开始，数据库及其事务能力在淘宝一直扮演着十分关键的角色，淘宝积累了丰富的数据库的架构和规划等方面的经验，产生了众多优秀的DBA。 淘宝是一家迅速发展的公司。全球网站排名公司Alexa提供的数据显示，2010年4月27日，Amazon、Ebay的用户占全球互联网用户的百分比分别为3.47%和2.68%，而淘宝的用户占全球互联网用户的百分比则达到了4.1%，淘宝网日	0.9394779764017819
刘佳_出生证明公证办理委托书	Svm分类模型：基本原理：将所有待分类的点映射到“高维空间”，然后在高维空间中找到一个能将这些点分开的“超平面”，这在理论上是被完全证明了是成立的，而且在实际计算中也是可行的。满足条件的“超平面”的个数不是唯一的。SVM需要的是利用这些超平面，找到这两类点之间的“最大间隔”。并非所有的数据都线性可分，将非线性映射到更高维的特征空间变成线性可分。（低维空间向量集通常难于划分，解决的方法是将它们映射到高维空间。）但这个办法带来的困难就是计算复杂度的增加，而核函数正好巧妙地解决了这个问题。也就是说，只要选用	0.9390975397582952

使用gprof分析bs性能	BS代码阅读：BS基本功能：索引相关性切词成分分析offset调权query解析 （where+what）多路归并 综合调权类聚（偏离点）query分类空间调权数据来源点击调权BS代码阅读：bs_cache:map库的term cachemap库term cache操作锁where库term cachewhere库term cache操作锁init_map_term_cache: 初始化map库term cachein	0.914629789728348
使用gprof分析bs性能	排序及扩展：插入排序，选择排序（冒泡排序），使用二分思想求第k大数，快速排序，非递归的快速排序，使用快排思想求第k大数，归并排序，求逆序数，自然排序算法，堆排序，最小优先级队列，计数排序，桶排序，鸽巢排序（分块排序），基数排序，外部排序：二路归并，K路归并，胜者树，败者树。  算法一：使用插入或者选择排序，得到最大的K个数，时间复杂度为：O(N*k)。 冒泡排序： void swap(int * a,int * b){            //注意	0.9094656747785517
使用gprof分析bs性能	克拉玛依公证处:本人因生活在国外，不能亲自到贵单位办理出生证明公证事项，兹授权委托雷春香女士全权代表我办理相关事项。对委托人在办理上述事项过程中所签署的有关文件，我均予以认可，并承担相应的法律责任。委托人：刘佳			委托人身份证号码：654301198608243929被委托人：雷春香		被委托人身份证号码：6526196207113926委托人：刘佳2018年5月24日	0.9094656747785517
使用gprof分析bs性能	性能升级性能升级的几个层面：系统结构：模块分解，模块交互，系统构建中的粗略估算。算法和数据结构：获得快速模块的关键：表示数据的结构，操作数据的算法：索引结构及拉链归并。代码调优：分支预测等。循环：将循环体中不改变的变量移动到循环体外；多重循环嵌套顺序。函数调用：inline函数节省函数调用开销：若makefile中不指定至少-O优化，即使声明为inline函数，编译器也不会进行函数内联。内存寻址：避免重复内存寻址。Cpu流水线的分支预测：将满足概率最高的条件放在靠前的位置。	0.9094656747785517
使用gprof分析bs性能	业务生成平台用户指南总体说明开发背景下一代网络是业务驱动的网络，在融合的下一代网络上高效、灵活地开发和部署各种丰富多彩的业务，从而提高网络使用率、增加收益的目标，是下一代网络的关键环节。下一代网络的发展要求呼叫与承载相分离、呼叫控制与业务相分离，使业务真正独立于网络，业务开发者不必关心与业务承载相关的底层网络知识以及具体的通信协议，只需利用业务生成平台提供的业务开发工具，就可以开发出灵活丰富且极具个性化的业务。 为了适合多种技术水平的业务开发人员的需要，现在主要有四种业务开发方式：	0.9094656747785517
使用gprof分析bs性能	K最近邻分类模型：原理：训练元组用n个属性描述，每个元组代表n维空间中的一个点，所有的训练元组存放在n维的模式空间。当给定一个未知元组时，KNN搜索该模式空间，找出最接近未知元组的k个训练元组。未知元组指派到它的k个最近邻中的多数类。“邻近性”用距离度量，如欧几里德距离。欧几里德距离：	设元组X1=(X11,X12,…X1n)，X2=(X21,X22,…X2n)，	Dist(X1,X2)=√ ∑ k= 1 n (X1i-X2i) 2 	使用上式之前，对每个属性的值规范化，以防止具有	0.9093042426759755
使用gprof分析bs性能	贝叶斯分类模型：基础知识：假设	X：是数据元组，由n个属性描述；	H：是某种假设，如数据元组属于某特定类C	P(H|X)：表示给定X的属性描述，找出元组X属于类C的概率举例：X：一位35岁的顾客，收入为4w美元；H：顾客将购买计算机P(H|X)：在X的条件下，H的后验概率。当我们知道顾客的年龄和收入时，顾客X将购买计算机的概率。P(H)：H的先验概率。任意给定顾客将购买计算机的概率，独立与X。P(X|H)：在条件H下，X的后验概率。已知顾客购买了计算机，顾客是一位3	0.9092518174155828
使用gprof分析bs性能	C专家编程读书笔记难点关键字的用法：关键字用法extern在函数名前，表示该函数全局可见，一般缺省。即一个文件的全局变量和函数对其他文件，具有可见性。在变量或者函数前，表示对象的定义在别处进行。由于重载，在c++中调用以C方式编译的函数时，需要加extern “c”。static隐藏：修饰的对象对其他文件不可见，防止多个文件命名冲突。持久性：修饰的对象，存储在数据段或者bss段，和程序有相同的生命周期。只有一次初始化。3、修饰的变量未初始化时，默认为“0	0.90803968330911
使用gprof分析bs性能	工作6周年5个月小记今天是中国时间8/24/2018，也就是我32岁的生日，这是一个不老也不再年轻的年纪。最近总是因为工作而郁郁寡欢，心中不快，所以决定记录总结一下，希望自己能有所释怀、转变、确立新的目标。从2012年3月31到现在，我已在微软Bing工作6年5个月。在此之前，我在百度实习9个月，在阿里巴巴实习2个月，在搜狗实习1个月。在微软北京CJK relevance组勤恳的工作2年6个月，从级别59升到61，做了1年半的DU, 1年的relevance。总体来说，老板们的风格是相关性主导基础	0.9078373498796513
使用gprof分析bs性能	神经网络原理及应用介绍Anti RD：王伟琼、张爱华主要内容特点及应用场景神经网络原理我们的经验和教训多线程训练下一步的工作应用场景分类预测时间允许的场合使用并行化等方法加速测试过程很快，且可以方便的使用hadoop平台环境比较固定的场合数据的统计特性变化不大需要定量预测的场合给出未知数据的定量预测神经网络特点优点对噪音数据有较好的适应能力对未知数据具有较好的预测分类能力拟合各种函数得出定量值缺点学习时间较长	0.9051121413186299

互信息	贝叶斯分类模型：基础知识：假设	X：是数据元组，由n个属性描述；	H：是某种假设，如数据元组属于某特定类C	P(H|X)：表示给定X的属性描述，找出元组X属于类C的概率举例：X：一位35岁的顾客，收入为4w美元；H：顾客将购买计算机P(H|X)：在X的条件下，H的后验概率。当我们知道顾客的年龄和收入时，顾客X将购买计算机的概率。P(H)：H的先验概率。任意给定顾客将购买计算机的概率，独立与X。P(X|H)：在条件H下，X的后验概率。已知顾客购买了计算机，顾客是一位3	0.7342630923298361
互信息	工作6周年5个月小记今天是中国时间8/24/2018，也就是我32岁的生日，这是一个不老也不再年轻的年纪。最近总是因为工作而郁郁寡欢，心中不快，所以决定记录总结一下，希望自己能有所释怀、转变、确立新的目标。从2012年3月31到现在，我已在微软Bing工作6年5个月。在此之前，我在百度实习9个月，在阿里巴巴实习2个月，在搜狗实习1个月。在微软北京CJK relevance组勤恳的工作2年6个月，从级别59升到61，做了1年半的DU, 1年的relevance。总体来说，老板们的风格是相关性主导基础	0.7332287924148556
互信息	排序及扩展：插入排序，选择排序（冒泡排序），使用二分思想求第k大数，快速排序，非递归的快速排序，使用快排思想求第k大数，归并排序，求逆序数，自然排序算法，堆排序，最小优先级队列，计数排序，桶排序，鸽巢排序（分块排序），基数排序，外部排序：二路归并，K路归并，胜者树，败者树。  算法一：使用插入或者选择排序，得到最大的K个数，时间复杂度为：O(N*k)。 冒泡排序： void swap(int * a,int * b){            //注意	0.7317925714047007
互信息	克拉玛依公证处:本人因生活在国外，不能亲自到贵单位办理出生证明公证事项，兹授权委托雷春香女士全权代表我办理相关事项。对委托人在办理上述事项过程中所签署的有关文件，我均予以认可，并承担相应的法律责任。委托人：刘佳			委托人身份证号码：654301198608243929被委托人：雷春香		被委托人身份证号码：6526196207113926委托人：刘佳2018年5月24日	0.7317925714047007
互信息	性能升级性能升级的几个层面：系统结构：模块分解，模块交互，系统构建中的粗略估算。算法和数据结构：获得快速模块的关键：表示数据的结构，操作数据的算法：索引结构及拉链归并。代码调优：分支预测等。循环：将循环体中不改变的变量移动到循环体外；多重循环嵌套顺序。函数调用：inline函数节省函数调用开销：若makefile中不指定至少-O优化，即使声明为inline函数，编译器也不会进行函数内联。内存寻址：避免重复内存寻址。Cpu流水线的分支预测：将满足概率最高的条件放在靠前的位置。	0.7317925714047007
互信息	业务生成平台用户指南总体说明开发背景下一代网络是业务驱动的网络，在融合的下一代网络上高效、灵活地开发和部署各种丰富多彩的业务，从而提高网络使用率、增加收益的目标，是下一代网络的关键环节。下一代网络的发展要求呼叫与承载相分离、呼叫控制与业务相分离，使业务真正独立于网络，业务开发者不必关心与业务承载相关的底层网络知识以及具体的通信协议，只需利用业务生成平台提供的业务开发工具，就可以开发出灵活丰富且极具个性化的业务。 为了适合多种技术水平的业务开发人员的需要，现在主要有四种业务开发方式：	0.7317925714047007
互信息	K最近邻分类模型：原理：训练元组用n个属性描述，每个元组代表n维空间中的一个点，所有的训练元组存放在n维的模式空间。当给定一个未知元组时，KNN搜索该模式空间，找出最接近未知元组的k个训练元组。未知元组指派到它的k个最近邻中的多数类。“邻近性”用距离度量，如欧几里德距离。欧几里德距离：	设元组X1=(X11,X12,…X1n)，X2=(X21,X22,…X2n)，	Dist(X1,X2)=√ ∑ k= 1 n (X1i-X2i) 2 	使用上式之前，对每个属性的值规范化，以防止具有	0.7311973101173963
互信息	C专家编程读书笔记难点关键字的用法：关键字用法extern在函数名前，表示该函数全局可见，一般缺省。即一个文件的全局变量和函数对其他文件，具有可见性。在变量或者函数前，表示对象的定义在别处进行。由于重载，在c++中调用以C方式编译的函数时，需要加extern “c”。static隐藏：修饰的对象对其他文件不可见，防止多个文件命名冲突。持久性：修饰的对象，存储在数据段或者bss段，和程序有相同的生命周期。只有一次初始化。3、修饰的变量未初始化时，默认为“0	0.7306041510443153
互信息	海量数据库的设计和实现淘宝海量数据库之一：来自业务的挑战(2010-11-24 11:34:38) 作为一个电子商务企业，从一开始，数据库及其事务能力在淘宝一直扮演着十分关键的角色，淘宝积累了丰富的数据库的架构和规划等方面的经验，产生了众多优秀的DBA。 淘宝是一家迅速发展的公司。全球网站排名公司Alexa提供的数据显示，2010年4月27日，Amazon、Ebay的用户占全球互联网用户的百分比分别为3.47%和2.68%，而淘宝的用户占全球互联网用户的百分比则达到了4.1%，淘宝网日	0.729895688682515
互信息	神经网络原理及应用介绍Anti RD：王伟琼、张爱华主要内容特点及应用场景神经网络原理我们的经验和教训多线程训练下一步的工作应用场景分类预测时间允许的场合使用并行化等方法加速测试过程很快，且可以方便的使用hadoop平台环境比较固定的场合数据的统计特性变化不大需要定量预测的场合给出未知数据的定量预测神经网络特点优点对噪音数据有较好的适应能力对未知数据具有较好的预测分类能力拟合各种函数得出定量值缺点学习时间较长	0.7274880816653436

个人简历_唐蕾	贝叶斯分类模型：基础知识：假设	X：是数据元组，由n个属性描述；	H：是某种假设，如数据元组属于某特定类C	P(H|X)：表示给定X的属性描述，找出元组X属于类C的概率举例：X：一位35岁的顾客，收入为4w美元；H：顾客将购买计算机P(H|X)：在X的条件下，H的后验概率。当我们知道顾客的年龄和收入时，顾客X将购买计算机的概率。P(H)：H的先验概率。任意给定顾客将购买计算机的概率，独立与X。P(X|H)：在条件H下，X的后验概率。已知顾客购买了计算机，顾客是一位3	0.8668015900487511
个人简历_唐蕾	排序及扩展：插入排序，选择排序（冒泡排序），使用二分思想求第k大数，快速排序，非递归的快速排序，使用快排思想求第k大数，归并排序，求逆序数，自然排序算法，堆排序，最小优先级队列，计数排序，桶排序，鸽巢排序（分块排序），基数排序，外部排序：二路归并，K路归并，胜者树，败者树。  算法一：使用插入或者选择排序，得到最大的K个数，时间复杂度为：O(N*k)。 冒泡排序： void swap(int * a,int * b){            //注意	0.8625627796303993
个人简历_唐蕾	克拉玛依公证处:本人因生活在国外，不能亲自到贵单位办理出生证明公证事项，兹授权委托雷春香女士全权代表我办理相关事项。对委托人在办理上述事项过程中所签署的有关文件，我均予以认可，并承担相应的法律责任。委托人：刘佳			委托人身份证号码：654301198608243929被委托人：雷春香		被委托人身份证号码：6526196207113926委托人：刘佳2018年5月24日	0.8625627796303993
个人简历_唐蕾	性能升级性能升级的几个层面：系统结构：模块分解，模块交互，系统构建中的粗略估算。算法和数据结构：获得快速模块的关键：表示数据的结构，操作数据的算法：索引结构及拉链归并。代码调优：分支预测等。循环：将循环体中不改变的变量移动到循环体外；多重循环嵌套顺序。函数调用：inline函数节省函数调用开销：若makefile中不指定至少-O优化，即使声明为inline函数，编译器也不会进行函数内联。内存寻址：避免重复内存寻址。Cpu流水线的分支预测：将满足概率最高的条件放在靠前的位置。	0.8625627796303993
个人简历_唐蕾	业务生成平台用户指南总体说明开发背景下一代网络是业务驱动的网络，在融合的下一代网络上高效、灵活地开发和部署各种丰富多彩的业务，从而提高网络使用率、增加收益的目标，是下一代网络的关键环节。下一代网络的发展要求呼叫与承载相分离、呼叫控制与业务相分离，使业务真正独立于网络，业务开发者不必关心与业务承载相关的底层网络知识以及具体的通信协议，只需利用业务生成平台提供的业务开发工具，就可以开发出灵活丰富且极具个性化的业务。 为了适合多种技术水平的业务开发人员的需要，现在主要有四种业务开发方式：	0.8625627796303993
个人简历_唐蕾	K最近邻分类模型：原理：训练元组用n个属性描述，每个元组代表n维空间中的一个点，所有的训练元组存放在n维的模式空间。当给定一个未知元组时，KNN搜索该模式空间，找出最接近未知元组的k个训练元组。未知元组指派到它的k个最近邻中的多数类。“邻近性”用距离度量，如欧几里德距离。欧几里德距离：	设元组X1=(X11,X12,…X1n)，X2=(X21,X22,…X2n)，	Dist(X1,X2)=√ ∑ k= 1 n (X1i-X2i) 2 	使用上式之前，对每个属性的值规范化，以防止具有	0.8623970213866929
个人简历_唐蕾	工作6周年5个月小记今天是中国时间8/24/2018，也就是我32岁的生日，这是一个不老也不再年轻的年纪。最近总是因为工作而郁郁寡欢，心中不快，所以决定记录总结一下，希望自己能有所释怀、转变、确立新的目标。从2012年3月31到现在，我已在微软Bing工作6年5个月。在此之前，我在百度实习9个月，在阿里巴巴实习2个月，在搜狗实习1个月。在微软北京CJK relevance组勤恳的工作2年6个月，从级别59升到61，做了1年半的DU, 1年的relevance。总体来说，老板们的风格是相关性主导基础	0.861846046363835
个人简历_唐蕾	海量数据库的设计和实现淘宝海量数据库之一：来自业务的挑战(2010-11-24 11:34:38) 作为一个电子商务企业，从一开始，数据库及其事务能力在淘宝一直扮演着十分关键的角色，淘宝积累了丰富的数据库的架构和规划等方面的经验，产生了众多优秀的DBA。 淘宝是一家迅速发展的公司。全球网站排名公司Alexa提供的数据显示，2010年4月27日，Amazon、Ebay的用户占全球互联网用户的百分比分别为3.47%和2.68%，而淘宝的用户占全球互联网用户的百分比则达到了4.1%，淘宝网日	0.8618091825291979
个人简历_唐蕾	C专家编程读书笔记难点关键字的用法：关键字用法extern在函数名前，表示该函数全局可见，一般缺省。即一个文件的全局变量和函数对其他文件，具有可见性。在变量或者函数前，表示对象的定义在别处进行。由于重载，在c++中调用以C方式编译的函数时，需要加extern “c”。static隐藏：修饰的对象对其他文件不可见，防止多个文件命名冲突。持久性：修饰的对象，存储在数据段或者bss段，和程序有相同的生命周期。只有一次初始化。3、修饰的变量未初始化时，默认为“0	0.8603809632153069
个人简历_唐蕾	Svm分类模型：基本原理：将所有待分类的点映射到“高维空间”，然后在高维空间中找到一个能将这些点分开的“超平面”，这在理论上是被完全证明了是成立的，而且在实际计算中也是可行的。满足条件的“超平面”的个数不是唯一的。SVM需要的是利用这些超平面，找到这两类点之间的“最大间隔”。并非所有的数据都线性可分，将非线性映射到更高维的特征空间变成线性可分。（低维空间向量集通常难于划分，解决的方法是将它们映射到高维空间。）但这个办法带来的困难就是计算复杂度的增加，而核函数正好巧妙地解决了这个问题。也就是说，只要选用	0.8568623346304849

业务生成平台-user guide	海量数据库的设计和实现淘宝海量数据库之一：来自业务的挑战(2010-11-24 11:34:38) 作为一个电子商务企业，从一开始，数据库及其事务能力在淘宝一直扮演着十分关键的角色，淘宝积累了丰富的数据库的架构和规划等方面的经验，产生了众多优秀的DBA。 淘宝是一家迅速发展的公司。全球网站排名公司Alexa提供的数据显示，2010年4月27日，Amazon、Ebay的用户占全球互联网用户的百分比分别为3.47%和2.68%，而淘宝的用户占全球互联网用户的百分比则达到了4.1%，淘宝网日	0.8501828399187302
业务生成平台-user guide	贝叶斯分类模型：基础知识：假设	X：是数据元组，由n个属性描述；	H：是某种假设，如数据元组属于某特定类C	P(H|X)：表示给定X的属性描述，找出元组X属于类C的概率举例：X：一位35岁的顾客，收入为4w美元；H：顾客将购买计算机P(H|X)：在X的条件下，H的后验概率。当我们知道顾客的年龄和收入时，顾客X将购买计算机的概率。P(H)：H的先验概率。任意给定顾客将购买计算机的概率，独立与X。P(X|H)：在条件H下，X的后验概率。已知顾客购买了计算机，顾客是一位3	0.8481149559028166
业务生成平台-user guide	工作6周年5个月小记今天是中国时间8/24/2018，也就是我32岁的生日，这是一个不老也不再年轻的年纪。最近总是因为工作而郁郁寡欢，心中不快，所以决定记录总结一下，希望自己能有所释怀、转变、确立新的目标。从2012年3月31到现在，我已在微软Bing工作6年5个月。在此之前，我在百度实习9个月，在阿里巴巴实习2个月，在搜狗实习1个月。在微软北京CJK relevance组勤恳的工作2年6个月，从级别59升到61，做了1年半的DU, 1年的relevance。总体来说，老板们的风格是相关性主导基础	0.843838779335186
业务生成平台-user guide	拉链归并算法探讨忻舟2008-8-18背景与基础知识在新产品的各个产品线中，检索作为一个必不可少的核心服务，其性能、结果相关性一直受到我们的普遍关注。检索的实现采用倒排拉链，而倒排拉链归并的效率直接影响了检索的性能。本文就拉链的归并算法展开探讨，分析各种拉链归并算法的利弊，并结合iknow的tbs升级项目讲述算法实现上的各种优化。首先简单的回顾一下拉链归并的基础知识。倒排拉链也称作拉链，是index模块对文档集合处理后的产物，每一个term都有一个拉链，记录这个term所出现的	0.8436761288908176
业务生成平台-user guide	排序及扩展：插入排序，选择排序（冒泡排序），使用二分思想求第k大数，快速排序，非递归的快速排序，使用快排思想求第k大数，归并排序，求逆序数，自然排序算法，堆排序，最小优先级队列，计数排序，桶排序，鸽巢排序（分块排序），基数排序，外部排序：二路归并，K路归并，胜者树，败者树。  算法一：使用插入或者选择排序，得到最大的K个数，时间复杂度为：O(N*k)。 冒泡排序： void swap(int * a,int * b){            //注意	0.8430670053214577
业务生成平台-user guide	克拉玛依公证处:本人因生活在国外，不能亲自到贵单位办理出生证明公证事项，兹授权委托雷春香女士全权代表我办理相关事项。对委托人在办理上述事项过程中所签署的有关文件，我均予以认可，并承担相应的法律责任。委托人：刘佳			委托人身份证号码：654301198608243929被委托人：雷春香		被委托人身份证号码：6526196207113926委托人：刘佳2018年5月24日	0.8430670053214577
业务生成平台-user guide	性能升级性能升级的几个层面：系统结构：模块分解，模块交互，系统构建中的粗略估算。算法和数据结构：获得快速模块的关键：表示数据的结构，操作数据的算法：索引结构及拉链归并。代码调优：分支预测等。循环：将循环体中不改变的变量移动到循环体外；多重循环嵌套顺序。函数调用：inline函数节省函数调用开销：若makefile中不指定至少-O优化，即使声明为inline函数，编译器也不会进行函数内联。内存寻址：避免重复内存寻址。Cpu流水线的分支预测：将满足概率最高的条件放在靠前的位置。	0.8430670053214577
业务生成平台-user guide	业务生成平台用户指南总体说明开发背景下一代网络是业务驱动的网络，在融合的下一代网络上高效、灵活地开发和部署各种丰富多彩的业务，从而提高网络使用率、增加收益的目标，是下一代网络的关键环节。下一代网络的发展要求呼叫与承载相分离、呼叫控制与业务相分离，使业务真正独立于网络，业务开发者不必关心与业务承载相关的底层网络知识以及具体的通信协议，只需利用业务生成平台提供的业务开发工具，就可以开发出灵活丰富且极具个性化的业务。 为了适合多种技术水平的业务开发人员的需要，现在主要有四种业务开发方式：	0.8430670053214577
业务生成平台-user guide	神经网络原理及应用介绍Anti RD：王伟琼、张爱华主要内容特点及应用场景神经网络原理我们的经验和教训多线程训练下一步的工作应用场景分类预测时间允许的场合使用并行化等方法加速测试过程很快，且可以方便的使用hadoop平台环境比较固定的场合数据的统计特性变化不大需要定量预测的场合给出未知数据的定量预测神经网络特点优点对噪音数据有较好的适应能力对未知数据具有较好的预测分类能力拟合各种函数得出定量值缺点学习时间较长	0.8428179635505761
业务生成平台-user guide	K最近邻分类模型：原理：训练元组用n个属性描述，每个元组代表n维空间中的一个点，所有的训练元组存放在n维的模式空间。当给定一个未知元组时，KNN搜索该模式空间，找出最接近未知元组的k个训练元组。未知元组指派到它的k个最近邻中的多数类。“邻近性”用距离度量，如欧几里德距离。欧几里德距离：	设元组X1=(X11,X12,…X1n)，X2=(X21,X22,…X2n)，	Dist(X1,X2)=√ ∑ k= 1 n (X1i-X2i) 2 	使用上式之前，对每个属性的值规范化，以防止具有	0.842810475883764

一致性哈希	贝叶斯分类模型：基础知识：假设	X：是数据元组，由n个属性描述；	H：是某种假设，如数据元组属于某特定类C	P(H|X)：表示给定X的属性描述，找出元组X属于类C的概率举例：X：一位35岁的顾客，收入为4w美元；H：顾客将购买计算机P(H|X)：在X的条件下，H的后验概率。当我们知道顾客的年龄和收入时，顾客X将购买计算机的概率。P(H)：H的先验概率。任意给定顾客将购买计算机的概率，独立与X。P(X|H)：在条件H下，X的后验概率。已知顾客购买了计算机，顾客是一位3	0.8413743188327613
一致性哈希	排序及扩展：插入排序，选择排序（冒泡排序），使用二分思想求第k大数，快速排序，非递归的快速排序，使用快排思想求第k大数，归并排序，求逆序数，自然排序算法，堆排序，最小优先级队列，计数排序，桶排序，鸽巢排序（分块排序），基数排序，外部排序：二路归并，K路归并，胜者树，败者树。  算法一：使用插入或者选择排序，得到最大的K个数，时间复杂度为：O(N*k)。 冒泡排序： void swap(int * a,int * b){            //注意	0.8372777254672282
一致性哈希	克拉玛依公证处:本人因生活在国外，不能亲自到贵单位办理出生证明公证事项，兹授权委托雷春香女士全权代表我办理相关事项。对委托人在办理上述事项过程中所签署的有关文件，我均予以认可，并承担相应的法律责任。委托人：刘佳			委托人身份证号码：654301198608243929被委托人：雷春香		被委托人身份证号码：6526196207113926委托人：刘佳2018年5月24日	0.8372777254672282
一致性哈希	性能升级性能升级的几个层面：系统结构：模块分解，模块交互，系统构建中的粗略估算。算法和数据结构：获得快速模块的关键：表示数据的结构，操作数据的算法：索引结构及拉链归并。代码调优：分支预测等。循环：将循环体中不改变的变量移动到循环体外；多重循环嵌套顺序。函数调用：inline函数节省函数调用开销：若makefile中不指定至少-O优化，即使声明为inline函数，编译器也不会进行函数内联。内存寻址：避免重复内存寻址。Cpu流水线的分支预测：将满足概率最高的条件放在靠前的位置。	0.8372777254672282
一致性哈希	业务生成平台用户指南总体说明开发背景下一代网络是业务驱动的网络，在融合的下一代网络上高效、灵活地开发和部署各种丰富多彩的业务，从而提高网络使用率、增加收益的目标，是下一代网络的关键环节。下一代网络的发展要求呼叫与承载相分离、呼叫控制与业务相分离，使业务真正独立于网络，业务开发者不必关心与业务承载相关的底层网络知识以及具体的通信协议，只需利用业务生成平台提供的业务开发工具，就可以开发出灵活丰富且极具个性化的业务。 为了适合多种技术水平的业务开发人员的需要，现在主要有四种业务开发方式：	0.8372777254672282
一致性哈希	K最近邻分类模型：原理：训练元组用n个属性描述，每个元组代表n维空间中的一个点，所有的训练元组存放在n维的模式空间。当给定一个未知元组时，KNN搜索该模式空间，找出最接近未知元组的k个训练元组。未知元组指派到它的k个最近邻中的多数类。“邻近性”用距离度量，如欧几里德距离。欧几里德距离：	设元组X1=(X11,X12,…X1n)，X2=(X21,X22,…X2n)，	Dist(X1,X2)=√ ∑ k= 1 n (X1i-X2i) 2 	使用上式之前，对每个属性的值规范化，以防止具有	0.8370170829843641
一致性哈希	工作6周年5个月小记今天是中国时间8/24/2018，也就是我32岁的生日，这是一个不老也不再年轻的年纪。最近总是因为工作而郁郁寡欢，心中不快，所以决定记录总结一下，希望自己能有所释怀、转变、确立新的目标。从2012年3月31到现在，我已在微软Bing工作6年5个月。在此之前，我在百度实习9个月，在阿里巴巴实习2个月，在搜狗实习1个月。在微软北京CJK relevance组勤恳的工作2年6个月，从级别59升到61，做了1年半的DU, 1年的relevance。总体来说，老板们的风格是相关性主导基础	0.836922313442188
一致性哈希	海量数据库的设计和实现淘宝海量数据库之一：来自业务的挑战(2010-11-24 11:34:38) 作为一个电子商务企业，从一开始，数据库及其事务能力在淘宝一直扮演着十分关键的角色，淘宝积累了丰富的数据库的架构和规划等方面的经验，产生了众多优秀的DBA。 淘宝是一家迅速发展的公司。全球网站排名公司Alexa提供的数据显示，2010年4月27日，Amazon、Ebay的用户占全球互联网用户的百分比分别为3.47%和2.68%，而淘宝的用户占全球互联网用户的百分比则达到了4.1%，淘宝网日	0.8366941298405453
一致性哈希	C专家编程读书笔记难点关键字的用法：关键字用法extern在函数名前，表示该函数全局可见，一般缺省。即一个文件的全局变量和函数对其他文件，具有可见性。在变量或者函数前，表示对象的定义在别处进行。由于重载，在c++中调用以C方式编译的函数时，需要加extern “c”。static隐藏：修饰的对象对其他文件不可见，防止多个文件命名冲突。持久性：修饰的对象，存储在数据段或者bss段，和程序有相同的生命周期。只有一次初始化。3、修饰的变量未初始化时，默认为“0	0.8353689134887607
一致性哈希	神经网络原理及应用介绍Anti RD：王伟琼、张爱华主要内容特点及应用场景神经网络原理我们的经验和教训多线程训练下一步的工作应用场景分类预测时间允许的场合使用并行化等方法加速测试过程很快，且可以方便的使用hadoop平台环境比较固定的场合数据的统计特性变化不大需要定量预测的场合给出未知数据的定量预测神经网络特点优点对噪音数据有较好的适应能力对未知数据具有较好的预测分类能力拟合各种函数得出定量值缺点学习时间较长	0.8312103889559255

zhcn general topic classifier training data distribution	Zh-cn Document classification based on topicBackgroundWe want to do zh-cn document classification for better understanding the document type and topic. It can help ranking with document and  query category matching. We defined our category system: 69 	0.5429161111666609
zhcn general topic classifier training data distribution	Zhcn document classification based on topicJia Liu2012.11.14agendarTraining data selection&crawl&cleanFeature selection&cleanClassifierRating Bad case analysisTrainning data	0.529909740940415
zhcn general topic classifier training data distribution	File Relevance Experimentation Design DocRecall AnalysisTest the search quality of external services like OLS, 3S, QF and SPO Search.Search scenarios: 0-term search, term search, 3S (Insert File and Attach File).Compare the recall: diff of returne	0.4980296178507697
zhcn general topic classifier training data distribution	Span ClassifierSpan classifier is a general infrastructure that can be used to run a fastrank based classifier on a sequence of terms from a query.  It can be used to apply rankonly or norelax to parts of the query based on the result of the model.  Fea	0.479369429921969
zhcn general topic classifier training data distribution	Restaurant segment metrics collectionObjectiveTo understand user behavior/engagement on Restaurant answers.Why this is important? The metrics will help us understand:The comparisons between different answersWhat is important to our users and w	0.47018045613948517
zhcn general topic classifier training data distribution	Auto Category Classification PipelineHanqing Cui2012/10/25OutlinePain PointsThinkingAuto Category Classification PipelineAuto Page LabelingData SamplingTrainingFeature SelectionThresholdIterative TrainingInitial Seed Model Creati	0.44164393892708537
zhcn general topic classifier training data distribution	Training data distributionContain categories as many as possible : 36 categies. The data of category in the same amountContain hudong data and  host dataPositive : negative = 1:7  ~ 1:10 categoryhudonghostpositivenegativeNegative_total	0.43134128231298097
zhcn general topic classifier training data distribution	Zh-cn Transportation Segment Optimization by Pattern EngineJia Liu/Allen WangDSATsQuery: 吉林市到查干湖Relevant result title: 吉林市到查干湖怎么走近？_百度知道Irrelevant result title 1: 查干湖,中国查干湖,吉林查干湖,查干湖旅游,查干湖冬捕,国家AAAA ...Irrelevant result title 2: 查干湖_百度百科Irrel	0.4302803324630859
zhcn general topic classifier training data distribution	Leveraging Satori Knowledge in Web Ranking StackMicroSegment and Index ServeMotivationTarget at semantic queries (*defined by MALTA)Often contain more than one entity and relationSometimes involve entity inferenceTerm matching may not handle s	0.42588639612007356
zhcn general topic classifier training data distribution	Interactive BingGoalSolving hard queryOverview Search engine is helping people solving problem. A lot of cases, search engine couldn’t solve problem at first shot. At this point, search engine need take more information to narrow down the user int	0.4227689772261371

zhcn document topic classifier	Zh-cn Document classification based on topicBackgroundWe want to do zh-cn document classification for better understanding the document type and topic. It can help ranking with document and  query category matching. We defined our category system: 69 	0.659966847952502
zhcn document topic classifier	Zhcn document classification based on topicJia Liu2012.11.14agendarTraining data selection&crawl&cleanFeature selection&cleanClassifierRating Bad case analysisTrainning data	0.5741117867841931
zhcn document topic classifier	Document classification based on urlBackgroundWe want to do document classification for better understanding the document type and document with query category match for ranking.  We will do zh-cn document classification based on url first, then docum	0.5010974927298673
zhcn document topic classifier	Zh-cn Transportation Segment Optimization by Pattern EngineJia Liu/Allen WangDSATsQuery: 吉林市到查干湖Relevant result title: 吉林市到查干湖怎么走近？_百度知道Irrelevant result title 1: 查干湖,中国查干湖,吉林查干湖,查干湖旅游,查干湖冬捕,国家AAAA ...Irrelevant result title 2: 查干湖_百度百科Irrel	0.4086650798330519
zhcn document topic classifier	Span ClassifierSpan classifier is a general infrastructure that can be used to run a fastrank based classifier on a sequence of terms from a query.  It can be used to apply rankonly or norelax to parts of the query based on the result of the model.  Fea	0.40463651342903734
zhcn document topic classifier	Zh-cn Transportation Segment Optimization by Pattern EngineIntroductionThe pattern queries can cover almost 10% in all queries. We can summarize lots of patterns on Query and Document sides for different segments. We can recognize key terms, relations	0.37710626589116475
zhcn document topic classifier	Introduction to L1Xiao WuSearch Platform Tiger Team AgendaL1 goals and challengesMetrics and measurementL1 ranker and perf optimizationL1 ranking Perf optimizationDebugging tools L1 training and shippingThinking and discussionL1 	0.3500515125097025
zhcn document topic classifier	Opal OSearch & XAP flight frameworkKevin Su & Duat Le06/22/2016OverviewOSearch basicsOpal OSearch high-level architectureProcess to onboard new feature for Opal OSearchXAP flight framework in OsearchOSearch basicsWhat's OSearch?A platf	0.3350638064681478
zhcn document topic classifier	File Relevance Experimentation Design DocRecall AnalysisTest the search quality of external services like OLS, 3S, QF and SPO Search.Search scenarios: 0-term search, term search, 3S (Insert File and Attach File).Compare the recall: diff of returne	0.33207626068300666
zhcn document topic classifier	Machine Learning Categorization & Popularity2012-08-30 | Nicolas NicolovGoalsShow how categorization and popularity systems work.Introduce important ML concepts.Illustrate ML techniques through examples.(aiming to be self-contained)Categoriz	0.3296077706634678

svm分类	SVM分类内容概要流程图预处理SVM分类器组合分类结果流程图内容概要流程图预处理SVM分类器组合分类结果特征选择特征，以文本行业分类来说，切词term特征的重要性“北京”是个没用的特征“速8”是个有用的特征“轻度”这个词呢？信息增益（Information Gain）   熵H是一个分布是否分散的表征，与信息相反概率估计P(ci) = ci类别的样本数 / 样本总数P(ci|t)  = t出现的属于ci	0.6787756807166829
svm分类	Svm分类模型：基本原理：将所有待分类的点映射到“高维空间”，然后在高维空间中找到一个能将这些点分开的“超平面”，这在理论上是被完全证明了是成立的，而且在实际计算中也是可行的。满足条件的“超平面”的个数不是唯一的。SVM需要的是利用这些超平面，找到这两类点之间的“最大间隔”。并非所有的数据都线性可分，将非线性映射到更高维的特征空间变成线性可分。（低维空间向量集通常难于划分，解决的方法是将它们映射到高维空间。）但这个办法带来的困难就是计算复杂度的增加，而核函数正好巧妙地解决了这个问题。也就是说，只要选用	0.674751401508303
svm分类	贝叶斯分类模型：基础知识：假设	X：是数据元组，由n个属性描述；	H：是某种假设，如数据元组属于某特定类C	P(H|X)：表示给定X的属性描述，找出元组X属于类C的概率举例：X：一位35岁的顾客，收入为4w美元；H：顾客将购买计算机P(H|X)：在X的条件下，H的后验概率。当我们知道顾客的年龄和收入时，顾客X将购买计算机的概率。P(H)：H的先验概率。任意给定顾客将购买计算机的概率，独立与X。P(X|H)：在条件H下，X的后验概率。已知顾客购买了计算机，顾客是一位3	0.6359019913615597
svm分类	K最近邻分类模型：原理：训练元组用n个属性描述，每个元组代表n维空间中的一个点，所有的训练元组存放在n维的模式空间。当给定一个未知元组时，KNN搜索该模式空间，找出最接近未知元组的k个训练元组。未知元组指派到它的k个最近邻中的多数类。“邻近性”用距离度量，如欧几里德距离。欧几里德距离：	设元组X1=(X11,X12,…X1n)，X2=(X21,X22,…X2n)，	Dist(X1,X2)=√ ∑ k= 1 n (X1i-X2i) 2 	使用上式之前，对每个属性的值规范化，以防止具有	0.6353925386984609
svm分类	排序及扩展：插入排序，选择排序（冒泡排序），使用二分思想求第k大数，快速排序，非递归的快速排序，使用快排思想求第k大数，归并排序，求逆序数，自然排序算法，堆排序，最小优先级队列，计数排序，桶排序，鸽巢排序（分块排序），基数排序，外部排序：二路归并，K路归并，胜者树，败者树。  算法一：使用插入或者选择排序，得到最大的K个数，时间复杂度为：O(N*k)。 冒泡排序： void swap(int * a,int * b){            //注意	0.6350753275211697
svm分类	克拉玛依公证处:本人因生活在国外，不能亲自到贵单位办理出生证明公证事项，兹授权委托雷春香女士全权代表我办理相关事项。对委托人在办理上述事项过程中所签署的有关文件，我均予以认可，并承担相应的法律责任。委托人：刘佳			委托人身份证号码：654301198608243929被委托人：雷春香		被委托人身份证号码：6526196207113926委托人：刘佳2018年5月24日	0.6350753275211697
svm分类	性能升级性能升级的几个层面：系统结构：模块分解，模块交互，系统构建中的粗略估算。算法和数据结构：获得快速模块的关键：表示数据的结构，操作数据的算法：索引结构及拉链归并。代码调优：分支预测等。循环：将循环体中不改变的变量移动到循环体外；多重循环嵌套顺序。函数调用：inline函数节省函数调用开销：若makefile中不指定至少-O优化，即使声明为inline函数，编译器也不会进行函数内联。内存寻址：避免重复内存寻址。Cpu流水线的分支预测：将满足概率最高的条件放在靠前的位置。	0.6350753275211697
svm分类	业务生成平台用户指南总体说明开发背景下一代网络是业务驱动的网络，在融合的下一代网络上高效、灵活地开发和部署各种丰富多彩的业务，从而提高网络使用率、增加收益的目标，是下一代网络的关键环节。下一代网络的发展要求呼叫与承载相分离、呼叫控制与业务相分离，使业务真正独立于网络，业务开发者不必关心与业务承载相关的底层网络知识以及具体的通信协议，只需利用业务生成平台提供的业务开发工具，就可以开发出灵活丰富且极具个性化的业务。 为了适合多种技术水平的业务开发人员的需要，现在主要有四种业务开发方式：	0.6350753275211697
svm分类	工作6周年5个月小记今天是中国时间8/24/2018，也就是我32岁的生日，这是一个不老也不再年轻的年纪。最近总是因为工作而郁郁寡欢，心中不快，所以决定记录总结一下，希望自己能有所释怀、转变、确立新的目标。从2012年3月31到现在，我已在微软Bing工作6年5个月。在此之前，我在百度实习9个月，在阿里巴巴实习2个月，在搜狗实习1个月。在微软北京CJK relevance组勤恳的工作2年6个月，从级别59升到61，做了1年半的DU, 1年的relevance。总体来说，老板们的风格是相关性主导基础	0.6336990232962056
svm分类	海量数据库的设计和实现淘宝海量数据库之一：来自业务的挑战(2010-11-24 11:34:38) 作为一个电子商务企业，从一开始，数据库及其事务能力在淘宝一直扮演着十分关键的角色，淘宝积累了丰富的数据库的架构和规划等方面的经验，产生了众多优秀的DBA。 淘宝是一家迅速发展的公司。全球网站排名公司Alexa提供的数据显示，2010年4月27日，Amazon、Ebay的用户占全球互联网用户的百分比分别为3.47%和2.68%，而淘宝的用户占全球互联网用户的百分比则达到了4.1%，淘宝网日	0.6329171805796695

statement of purpose of travel	Restaurant segment metrics collectionObjectiveTo understand user behavior/engagement on Restaurant answers.Why this is important? The metrics will help us understand:The comparisons between different answersWhat is important to our users and w	0.2403156202609864
statement of purpose of travel	Training data distributionContain categories as many as possible : 36 categies. The data of category in the same amountContain hudong data and  host dataPositive : negative = 1:7  ~ 1:10 categoryhudonghostpositivenegativeNegative_total	0.22344412518368592
statement of purpose of travel	CAL Problem, Vision and RoadmapContentsOverview	2Problem of today’s CAL	2Vision and Roadmap	3Start from simple but important one: infrastructure.	3Now comes core problem: Metrics	3Now comes to the interesting part: context	4Data	5Head qu	0.21427735296691147
statement of purpose of travel	Threshold Query Formulation Deep DiveGoal of the presentation is to communicate our approach for query formulation and get feedback on whether this aligns with overall Threshold goals.OverviewGoals & MetricsQF ModelRoadmapScenariosKey Ta	0.2040762774729518
statement of purpose of travel	I’d like to explain in more details my idea of improving Dolphin, by improving its robustness of query variations and some previously unseen terms. Our rules don’t cover many query patterns. E.g., {top rated chinese restaurants} works well, but not {chi	0.20032100634511507
statement of purpose of travel	Local Category Search Plan3 month StrategyData: Entity categorizationScalable, high precision/recallSegments: Food & Drink, Retail, Service, Auto, HotelMetaStream enrichmentQuery UnderstandingDolphin by defaultConsume PhoneBookQU to im	0.1982405267310224
statement of purpose of travel	QR MicrosegmentsSandeep AparajitAgendaWhat are microsegments?How does microsegment work in CAL?How can I add my own microsegment?DemoQuestions/SuggestionsWhat are Microsegments?Microsegment is a technique using which you can alter the be	0.19554370231593085
statement of purpose of travel	Relevance Experimentation with DUOverviewThe ideal end state for any relevance improvement would consist of having one or more DU features shipped in the index that is then leveraged by the latest production ranker. This would achieve the highest leve	0.1943925145949591
statement of purpose of travel	Relevance Debug InfrastructureProblemFrequent  daily metric fluctuationRelevance gain negated by regressions from Sep to Oct 2013Painful to investigateChallengeLocal stack is complex with lots of componentsVarious relevance events mixed toge	0.19421007225163842
statement of purpose of travel	Translation Model in Local Search- Shu HuangIntroductionTranslation model in web searchOdpTitle translation model in local searchData preparationModel trainingGenerate new metastreamIntroductionTranslation model used in web searchLea	0.19223322137407706

smartRelax_OFE_and_Training_Shorter (4)	SmartRelax OFE and TrainingOverviewAnalysis of smartrelax flightsOFE flight simulatorIs smartrelax ever bad?Smartrelax model training:Training method I: relax-specific targetsTraining method II: end-user targetsSmart Relax OFE and Training	0.7470711710450255
smartRelax_OFE_and_Training_Shorter (4)	SmartRelax training and evaluation from 15%/15% flightForay scorecard: 15%+15% datagatheringUser-triggered scorecardSSRx gain of 0.12%, for 3+4 word on vs. 3+4 word off. (NOT vs. prod.)Gain is 36% from SSR, 11% from TTS, 52% from TSRSSRx gains s	0.5338064571746607
smartRelax_OFE_and_Training_Shorter (4)	Smart Query Relaxation In Joint OptimizationA Cross-Group Collaborations Among QU/QR/CoreRanking/IS/MSR      Presented By : Xiaolong Li (Query Understanding)8/19/2013Smart Query Relaxation in JOPOutlineJOP V2 SummaryQuery Relaxation An	0.41335787064644786
smartRelax_OFE_and_Training_Shorter (4)	ElasticSearchInternalElasticSearch and oSearchElasticSearch  ArchitectureLucene FamilyoSearch  ArchitectureScenario and ScaleoSearchElasticSearchScope Strong structured dataImage with ANNUnstructured text Loose structured data	0.3110808779796273
smartRelax_OFE_and_Training_Shorter (4)	Keyword predictor-Ganesh Poomal -KefengOutlineThe problem and the objective for Keyword predictorTraining Data CollectionModel and FeaturesResultsKeyword PredictorProblem    In a search engine, user expresses their need for information	0.2927548103526476
smartRelax_OFE_and_Training_Shorter (4)	Summary and HighlightsIn April the metrics/measurement team released local AutoSuggest metric and shared initial transit measurement results; BLU team shipped CL 1.0 ontology and deployed BLU v3 to all markets; PBA team shipped a new L2 ranker and refre	0.2841880154244505
smartRelax_OFE_and_Training_Shorter (4)	Deep RelaxQuery Relaxation and L1 FidelityQuery Relaxation{printable iphone 7 user guide}rankonly:printable iphone 7 rankonly:user guiderankonly:printable iphone 7 user guideDeep Relax and vector similarity Encode query without each toke	0.27897312209221903
smartRelax_OFE_and_Training_Shorter (4)	OSG Threshold[Cortana/Improving Cortana Personalization Through Finances]functional specification[Shell/CAST]CONTACTSROLEName; AliasProgram ManagerColleen Hamilton; chamiltDeveloperQualityDesignPartner(s)ONE PAGE SPEC - Guideline	0.2787277487259401
smartRelax_OFE_and_Training_Shorter (4)	Microsoft Netherlands. Azure PlanPresenter nameSlide script: Thank you for taking the time today to walk through an end-to-end tour of Azure Security- the intensive and extensive work we’re doing to deliver a cloud you can trust.We’ll focus firs	0.2717723521049567
smartRelax_OFE_and_Training_Shorter (4)	Integrating Knowledge Graph in Web SearchEntity Triggering and CollectionsPresenter: Ze TianKnowledge GraphEntities and RelationsEntities: celebrities, people, generic terms (e.g. light bulb)Relations: sibling, spouse, people and their works	0.26637485504433434

smartRelax_15percentFlight	SmartRelax OFE and TrainingOverviewAnalysis of smartrelax flightsOFE flight simulatorIs smartrelax ever bad?Smartrelax model training:Training method I: relax-specific targetsTraining method II: end-user targetsSmart Relax OFE and Training	0.6669303325330975
smartRelax_15percentFlight	SmartRelax training and evaluation from 15%/15% flightForay scorecard: 15%+15% datagatheringUser-triggered scorecardSSRx gain of 0.12%, for 3+4 word on vs. 3+4 word off. (NOT vs. prod.)Gain is 36% from SSR, 11% from TTS, 52% from TSRSSRx gains s	0.5998987824596693
smartRelax_15percentFlight	ElasticSearchInternalElasticSearch and oSearchElasticSearch  ArchitectureLucene FamilyoSearch  ArchitectureScenario and ScaleoSearchElasticSearchScope Strong structured dataImage with ANNUnstructured text Loose structured data	0.3575241756219019
smartRelax_15percentFlight	Smart Query Relaxation In Joint OptimizationA Cross-Group Collaborations Among QU/QR/CoreRanking/IS/MSR      Presented By : Xiaolong Li (Query Understanding)8/19/2013Smart Query Relaxation in JOPOutlineJOP V2 SummaryQuery Relaxation An	0.3307444396786613
smartRelax_15percentFlight	Deep RelaxQuery Relaxation and L1 FidelityQuery Relaxation{printable iphone 7 user guide}rankonly:printable iphone 7 rankonly:user guiderankonly:printable iphone 7 user guideDeep Relax and vector similarity Encode query without each toke	0.3032352292117752
smartRelax_15percentFlight	Relaxcount=2 summaryRelaxcount=2 datagatheringDatagathering for relaxcount=2 branched path (3/14/15-3/20/15):Cal13a: control (OFE logging, relaxcount=2 off), 6% trafficCal13b: on (OFE logging, relaxcount=2 on for word count >=5), 12% traffic.Dat	0.28844742908144444
smartRelax_15percentFlight	Relaxcount=2Momo JengRelaxcount=2 datagatheringDatagathering flight for relaxcount=2:3/14/2015-3/20/2015Cal13a: control (OFE logging, relaxcount=2 off), 6% trafficCal13b: always on (OFE logging, relaxcount=2 on), 12% trafficThe flight was do	0.2780969885583758
smartRelax_15percentFlight	Combined ALterationsNeon\sodiumAgendaNeon AchievementsBreakdownsSodiumIdeas & PlanNeonOverall ProgressExceeded Neon Commitments on CQS!NeonCQS Deep-dive-34% Bad+14% Excellent-15% Bad+13% ExcellentDRDOCQS is impr	0.25779973464584816
smartRelax_15percentFlight	Anchor and Click Stream RankingSteven ZittrowerBing Local Search RelevanceHypothesisConverting local search’s unstructured and raw text streams into semi-structured forms will improve ranking and offer relevance benefits.TestUsing classifiers 	0.2538620938441519
smartRelax_15percentFlight	Restaurants Features and ToolsReview SnippetXAPOSearchQueryWPOLERWPO OSCacheItemCacheIdList of YpIdsFiltersSorterEntityUpdate PostFixEntity Update OSCache IdCache ItemYpId and PostFixUXReview Snippet Data GroupCac	0.24118311318713134

rerank		0.23530545504075626
rerank	Blue-Whale Multimedia Rank Data-FlowEugene Jian Huangjianhua@microsoft.com2012-03-13MM Page Static RankMedia LinkExpress RankMM Page Express RankMM PageSuper-Fresh RankMM PageSubmission RankMM PageEffective Rank Media Entit	0.09463301409647219
rerank	SKI Contextual Reranking V1 design doc User ScenarioWhole page relevance of “All Tab” in the SerpletContextual relevance of “File Tab” in the Serplet DeliverablesMicrosoft search serves as an intelligence service to take user query and return be	0.06373581576015669
rerank	浅谈Redis的原理与应用tianzhedong（董天喆）大纲What is RedisWhy RedisHow To Use RedisWhat Is RedisWhat is RedisWhat is Rediskey value store可以持久化的cacheHashTableMemory DB它的高性能都是基于内存操作的基础data structure serverRedis支持复杂的数据特性，比如List, Set等Redis	0.0538112340708484
rerank	Content Quality Classification & RankingGuihong Cao, Cheng NiuContent Quality for RankingContent quality = originality + trustworthy + information satisfaction + freshnessSpam sites, junk site, link farm, content farm, ….Search users are interes	0.04998783700062821
rerank	Module 2:Deployment Considerations© 2014 Microsoft Corporation. All rights reserved. MICROSOFT MAKES NO WARRANTIES, EXPRESS, IMPLIED OR STATUTORY, AS TO THE INFORMATION IN THIS PRESENTATION.11/28/2016 8:58 PMMicrosoft ServicesConditions and Te	0.03992501352222398
rerank	Partner Index as ServiceWhat is the Problem? RequirementCurrent status of Bing Image StackDiscoveryClient tend to provide feed for full corpusWeb crawlerImage Content RetrievalSpecial agreement, some even behind authentication for access	0.03508845048326126
rerank	Anchor and Click Stream RankingSteven ZittrowerBing Local Search RelevanceHypothesisConverting local search’s unstructured and raw text streams into semi-structured forms will improve ranking and offer relevance benefits.TestUsing classifiers 	0.029877874239877065
rerank	alterationsalterations: product goalimprove recallby adding terms (not replacing or dropping user-entered terms)using word:which are synonyms to the original terms(we are re-examining each of these for vnext)alterations: general principl	0.015522291778882664
rerank	PDI Document AnnotationPDI Ranking PlatformAgendaPDI and forward indexDocument AnnotationSodium update and MG planQ&A DSAT: {books by children}Issue: Document matches the query terms, but its surrounding words may change the intent of 	0.011422247806747596

relevanceDebug	Relevance Debug InfrastructureProblemFrequent  daily metric fluctuationRelevance gain negated by regressions from Sep to Oct 2013Painful to investigateChallengeLocal stack is complex with lots of componentsVarious relevance events mixed toge	0.5144464899123511
relevanceDebug	Successful Feeds Query DebuggingNikita Melnichenko, 2015-03-10Feeds query debugging overviewWhen to use:Checking a new rankerChecking new augmentation before running a scrapeComparing several rankersUnderstanding feature contributionDebugg	0.39836420230078123
relevanceDebug	WPO Local RelevancePing Yin2017-03-21OverviewWPO’s role in local relevance pipelineLocal Entity StampingArchitecture overviewWPO Local Relevance Models.Query: exton mall, User location: Wallingford, PAWPO RolesExtract/detect all entity	0.3807657135616429
relevanceDebug	Global relevance feature proposalFeature name: Title Match OptimizationPMJin GuoDevJia LiuTestReleaseALTeam site linkExecutive SummaryTitle is the summary/abstract of the document. Title Match is very important to SBS. Through many c	0.3521665090721424
relevanceDebug	Core Web RelevanceFY16 H2 PlanCore Web RelevanceFY16 H2 PlanCore Web RelevanceFY16 H2 PlanCore Web RelevanceFY16 H2 Plan	0.3037450943069845
relevanceDebug	Relevance Experimentation with DUOverviewThe ideal end state for any relevance improvement would consist of having one or more DU features shipped in the index that is then leveraged by the latest production ranker. This would achieve the highest leve	0.2937730832247371
relevanceDebug	Whole Page RelevanceShip Meeting 08/14/2012AgendaSummary of IssuesSpecial TopicsWhole Page Relevance - IssuesTeamIssue Description StatusOwnerDue Action UpdateINTL Mon-GsheldonNo major issuesCaptions MetricsSBS – Monthly 	0.2874758913030163
relevanceDebug	浅谈Redis的原理与应用tianzhedong（董天喆）大纲What is RedisWhy RedisHow To Use RedisWhat Is RedisWhat is RedisWhat is Rediskey value store可以持久化的cacheHashTableMemory DB它的高性能都是基于内存操作的基础data structure serverRedis支持复杂的数据特性，比如List, Set等Redis	0.2870840807806828
relevanceDebug	WPO Local Relevance Tech TalkWPO Local Relevance TeamOverviewWPO’s role in local relevance pipelineLocal ExperienceArchitecture overviewMetricsWPO Local Relevance Model IntroductionWPO Query understanding and Location understandingWhy do	0.286208702347821
relevanceDebug	Relevance ServiceScenarioIconApplicationDoc typeCandidatesModelRun0-termWord;OutlookWin32 client.All file typesMRUReuse ContentModel 1Client0-termPower PointWin32 client.Only ppt typeLocal + MRUReuse Conte	0.2715295395855058

redis原理与使用	浅谈Redis的原理与应用tianzhedong（董天喆）大纲What is RedisWhy RedisHow To Use RedisWhat Is RedisWhat is RedisWhat is Rediskey value store可以持久化的cacheHashTableMemory DB它的高性能都是基于内存操作的基础data structure serverRedis支持复杂的数据特性，比如List, Set等Redis	0.7834860901430621
redis原理与使用	贝叶斯分类模型：基础知识：假设	X：是数据元组，由n个属性描述；	H：是某种假设，如数据元组属于某特定类C	P(H|X)：表示给定X的属性描述，找出元组X属于类C的概率举例：X：一位35岁的顾客，收入为4w美元；H：顾客将购买计算机P(H|X)：在X的条件下，H的后验概率。当我们知道顾客的年龄和收入时，顾客X将购买计算机的概率。P(H)：H的先验概率。任意给定顾客将购买计算机的概率，独立与X。P(X|H)：在条件H下，X的后验概率。已知顾客购买了计算机，顾客是一位3	0.6464218518361775
redis原理与使用	HIVE介绍简介是什么hive是一个基于hadoop的数据仓库。使用hadoop-hdfs作为数据存储层；提供类似SQL的语言（HQL），通过hadoop-mapreduce完成数据计算；通过HQL语言提供使用者部分传统RDBMS一样的表格查询特性和分布式存储计算特性。类似的系统有yahoo的pig[1] ，google的sawzall[2]，microsoft的DryadLINQ[3]。架构图表 1 hive架构图[4]操作界面：CLI，Web，Thriftdrive	0.6442808017254232
redis原理与使用	K最近邻分类模型：原理：训练元组用n个属性描述，每个元组代表n维空间中的一个点，所有的训练元组存放在n维的模式空间。当给定一个未知元组时，KNN搜索该模式空间，找出最接近未知元组的k个训练元组。未知元组指派到它的k个最近邻中的多数类。“邻近性”用距离度量，如欧几里德距离。欧几里德距离：	设元组X1=(X11,X12,…X1n)，X2=(X21,X22,…X2n)，	Dist(X1,X2)=√ ∑ k= 1 n (X1i-X2i) 2 	使用上式之前，对每个属性的值规范化，以防止具有	0.6428024049546027
redis原理与使用	排序及扩展：插入排序，选择排序（冒泡排序），使用二分思想求第k大数，快速排序，非递归的快速排序，使用快排思想求第k大数，归并排序，求逆序数，自然排序算法，堆排序，最小优先级队列，计数排序，桶排序，鸽巢排序（分块排序），基数排序，外部排序：二路归并，K路归并，胜者树，败者树。  算法一：使用插入或者选择排序，得到最大的K个数，时间复杂度为：O(N*k)。 冒泡排序： void swap(int * a,int * b){            //注意	0.6421634093294367
redis原理与使用	克拉玛依公证处:本人因生活在国外，不能亲自到贵单位办理出生证明公证事项，兹授权委托雷春香女士全权代表我办理相关事项。对委托人在办理上述事项过程中所签署的有关文件，我均予以认可，并承担相应的法律责任。委托人：刘佳			委托人身份证号码：654301198608243929被委托人：雷春香		被委托人身份证号码：6526196207113926委托人：刘佳2018年5月24日	0.6421634093294367
redis原理与使用	性能升级性能升级的几个层面：系统结构：模块分解，模块交互，系统构建中的粗略估算。算法和数据结构：获得快速模块的关键：表示数据的结构，操作数据的算法：索引结构及拉链归并。代码调优：分支预测等。循环：将循环体中不改变的变量移动到循环体外；多重循环嵌套顺序。函数调用：inline函数节省函数调用开销：若makefile中不指定至少-O优化，即使声明为inline函数，编译器也不会进行函数内联。内存寻址：避免重复内存寻址。Cpu流水线的分支预测：将满足概率最高的条件放在靠前的位置。	0.6421634093294367
redis原理与使用	业务生成平台用户指南总体说明开发背景下一代网络是业务驱动的网络，在融合的下一代网络上高效、灵活地开发和部署各种丰富多彩的业务，从而提高网络使用率、增加收益的目标，是下一代网络的关键环节。下一代网络的发展要求呼叫与承载相分离、呼叫控制与业务相分离，使业务真正独立于网络，业务开发者不必关心与业务承载相关的底层网络知识以及具体的通信协议，只需利用业务生成平台提供的业务开发工具，就可以开发出灵活丰富且极具个性化的业务。 为了适合多种技术水平的业务开发人员的需要，现在主要有四种业务开发方式：	0.6421634093294367
redis原理与使用	工作6周年5个月小记今天是中国时间8/24/2018，也就是我32岁的生日，这是一个不老也不再年轻的年纪。最近总是因为工作而郁郁寡欢，心中不快，所以决定记录总结一下，希望自己能有所释怀、转变、确立新的目标。从2012年3月31到现在，我已在微软Bing工作6年5个月。在此之前，我在百度实习9个月，在阿里巴巴实习2个月，在搜狗实习1个月。在微软北京CJK relevance组勤恳的工作2年6个月，从级别59升到61，做了1年半的DU, 1年的relevance。总体来说，老板们的风格是相关性主导基础	0.6399805060039103
redis原理与使用	海量数据库的设计和实现淘宝海量数据库之一：来自业务的挑战(2010-11-24 11:34:38) 作为一个电子商务企业，从一开始，数据库及其事务能力在淘宝一直扮演着十分关键的角色，淘宝积累了丰富的数据库的架构和规划等方面的经验，产生了众多优秀的DBA。 淘宝是一家迅速发展的公司。全球网站排名公司Alexa提供的数据显示，2010年4月27日，Amazon、Ebay的用户占全球互联网用户的百分比分别为3.47%和2.68%，而淘宝的用户占全球互联网用户的百分比则达到了4.1%，淘宝网日	0.639501016557343

query分类分享	query分类—分享                     刘佳2011.6.8web query classification(query分类):	将web search query根据它的主题，分派到1个或者多个预先定义的分类中。web search query的特征：有噪声：拼写错误等长度很短：信息量少，特征少表意含糊：query可能包含多个含义,属于多个分类含义会随时间演变目标分类的特征：目标分类定义缺少语义注解一级或者多级分类分类数目：几	0.7983252460930047
query分类分享	Query语义重要度标准Query语义重要度标准目录1.	标注整体介绍	22.	标注方法介绍	22.1.	分析Query中term的依存关系	22.2.	标注各依存关系的重要度	32.3.	融合规则	32.3.1.	典型标注方法介绍	32.3.2.	特殊情况处理	42.3.3.	无损词	53.	各依存类型介绍与典型范例（双term）	63.1.	需求关系	63.2.	属性关系	73.3.	限定关系	93.4.	施事关系	103.5.	受事关系	0.7415607440941364
query分类分享	BS代码阅读：BS基本功能：索引相关性切词成分分析offset调权query解析 （where+what）多路归并 综合调权类聚（偏离点）query分类空间调权数据来源点击调权BS代码阅读：bs_cache:map库的term cachemap库term cache操作锁where库term cachewhere库term cache操作锁init_map_term_cache: 初始化map库term cachein	0.7381840354335324
query分类分享	排序及扩展：插入排序，选择排序（冒泡排序），使用二分思想求第k大数，快速排序，非递归的快速排序，使用快排思想求第k大数，归并排序，求逆序数，自然排序算法，堆排序，最小优先级队列，计数排序，桶排序，鸽巢排序（分块排序），基数排序，外部排序：二路归并，K路归并，胜者树，败者树。  算法一：使用插入或者选择排序，得到最大的K个数，时间复杂度为：O(N*k)。 冒泡排序： void swap(int * a,int * b){            //注意	0.7330643989059731
query分类分享	克拉玛依公证处:本人因生活在国外，不能亲自到贵单位办理出生证明公证事项，兹授权委托雷春香女士全权代表我办理相关事项。对委托人在办理上述事项过程中所签署的有关文件，我均予以认可，并承担相应的法律责任。委托人：刘佳			委托人身份证号码：654301198608243929被委托人：雷春香		被委托人身份证号码：6526196207113926委托人：刘佳2018年5月24日	0.7330643989059731
query分类分享	性能升级性能升级的几个层面：系统结构：模块分解，模块交互，系统构建中的粗略估算。算法和数据结构：获得快速模块的关键：表示数据的结构，操作数据的算法：索引结构及拉链归并。代码调优：分支预测等。循环：将循环体中不改变的变量移动到循环体外；多重循环嵌套顺序。函数调用：inline函数节省函数调用开销：若makefile中不指定至少-O优化，即使声明为inline函数，编译器也不会进行函数内联。内存寻址：避免重复内存寻址。Cpu流水线的分支预测：将满足概率最高的条件放在靠前的位置。	0.7330643989059731
query分类分享	业务生成平台用户指南总体说明开发背景下一代网络是业务驱动的网络，在融合的下一代网络上高效、灵活地开发和部署各种丰富多彩的业务，从而提高网络使用率、增加收益的目标，是下一代网络的关键环节。下一代网络的发展要求呼叫与承载相分离、呼叫控制与业务相分离，使业务真正独立于网络，业务开发者不必关心与业务承载相关的底层网络知识以及具体的通信协议，只需利用业务生成平台提供的业务开发工具，就可以开发出灵活丰富且极具个性化的业务。 为了适合多种技术水平的业务开发人员的需要，现在主要有四种业务开发方式：	0.7330643989059731
query分类分享	K最近邻分类模型：原理：训练元组用n个属性描述，每个元组代表n维空间中的一个点，所有的训练元组存放在n维的模式空间。当给定一个未知元组时，KNN搜索该模式空间，找出最接近未知元组的k个训练元组。未知元组指派到它的k个最近邻中的多数类。“邻近性”用距离度量，如欧几里德距离。欧几里德距离：	设元组X1=(X11,X12,…X1n)，X2=(X21,X22,…X2n)，	Dist(X1,X2)=√ ∑ k= 1 n (X1i-X2i) 2 	使用上式之前，对每个属性的值规范化，以防止具有	0.7326175087378061
query分类分享	贝叶斯分类模型：基础知识：假设	X：是数据元组，由n个属性描述；	H：是某种假设，如数据元组属于某特定类C	P(H|X)：表示给定X的属性描述，找出元组X属于类C的概率举例：X：一位35岁的顾客，收入为4w美元；H：顾客将购买计算机P(H|X)：在X的条件下，H的后验概率。当我们知道顾客的年龄和收入时，顾客X将购买计算机的概率。P(H)：H的先验概率。任意给定顾客将购买计算机的概率，独立与X。P(X|H)：在条件H下，X的后验概率。已知顾客购买了计算机，顾客是一位3	0.7315993669948134
query分类分享	C专家编程读书笔记难点关键字的用法：关键字用法extern在函数名前，表示该函数全局可见，一般缺省。即一个文件的全局变量和函数对其他文件，具有可见性。在变量或者函数前，表示对象的定义在别处进行。由于重载，在c++中调用以C方式编译的函数时，需要加extern “c”。static隐藏：修饰的对象对其他文件不可见，防止多个文件命名冲突。持久性：修饰的对象，存储在数据段或者bss段，和程序有相同的生命周期。只有一次初始化。3、修饰的变量未初始化时，默认为“0	0.7313032376706295

page number design and summary	Page number design and summaryBackgroundWe’ve seen in regular DSAT review meetings the DSATs that 2 or more pages are shown in top ten search results which belong to one document or the same topic sections. We want to get the page number to keep only 	0.5296957407612868
page number design and summary	SKI Contextual Reranking V1 design doc User ScenarioWhole page relevance of “All Tab” in the SerpletContextual relevance of “File Tab” in the Serplet DeliverablesMicrosoft search serves as an intelligence service to take user query and return be	0.3055166343509003
page number design and summary	FastRank--- a Decision-Tree based Ranking ModelYu SHIOutlineBackgroundAlgorithm overviewTraining implementationExperimentationChallengesReferencesBackgroundInvestigated by MSR in OsloShipped with July Tree 2010 (Denver)GoalsSpe	0.26796979758738626
page number design and summary	Production Models OverviewLU annotates incoming text input with semantic information in a contextual wayWorkflow built on top of Bing production infrastructure (QAS/XAP/Object Store)Feature representation: word embedding, n-grams and lexicons matche	0.25708083493159295
page number design and summary	Threshold Query Formulation Deep DiveGoal of the presentation is to communicate our approach for query formulation and get feedback on whether this aligns with overall Threshold goals.OverviewGoals & MetricsQF ModelRoadmapScenariosKey Ta	0.2561207803057387
page number design and summary	Whole Page RelevanceShip Meeting 08/14/2012AgendaSummary of IssuesSpecial TopicsWhole Page Relevance - IssuesTeamIssue Description StatusOwnerDue Action UpdateINTL Mon-GsheldonNo major issuesCaptions MetricsSBS – Monthly 	0.24466504460684319
page number design and summary	Keyword Predictor Design DocumentName: Ruchir RastogiMentor: Jia LiuManager: Leon ZhangProject overviewThe goal of this project is to design a machine-learning model that can predict keywords in a local query for improving local search relevance	0.2407291513485789
page number design and summary	Query Simplification Deep DiveJON Fu12/11/2017AgendaQuery Simplification Motivation and TheoryQuery Simplification for WebQuery Simplification for Cortana 3ARecent Progress in Query Simplification WorkReferencesIntroductionMotiva	0.24006462549179475
page number design and summary	Page | 2                                 <Si-09.1> Cross Page Junk Detection – V2Feature One-PagerDocument Version:0.9Authors:arahin, lidonzDocument Status:1.0Date:7/20/2014Feature OverviewDescription:Use new Main Body signal	0.23961045685966184
page number design and summary	Simplified Query Path SelectorSimplified query: current systemSimplified query path selectionCrf model produces a list of possible ways to place rankonly operatorQuery = “nibbana restaurant official site”nibbana restaurant rankonly:official site	0.23758918511861052

osearch	ElasticSearchInternalElasticSearch and oSearchElasticSearch  ArchitectureLucene FamilyoSearch  ArchitectureScenario and ScaleoSearchElasticSearchScope Strong structured dataImage with ANNUnstructured text Loose structured data	0.42762801096632025
osearch	Opal OSearch & XAP flight frameworkKevin Su & Duat Le06/22/2016OverviewOSearch basicsOpal OSearch high-level architectureProcess to onboard new feature for Opal OSearchXAP flight framework in OsearchOSearch basicsWhat's OSearch?A platf	0.2943356507816659
osearch	SmartRelax training and evaluation from 15%/15% flightForay scorecard: 15%+15% datagatheringUser-triggered scorecardSSRx gain of 0.12%, for 3+4 word on vs. 3+4 word off. (NOT vs. prod.)Gain is 36% from SSR, 11% from TTS, 52% from TSRSSRx gains s	0.25490965756537587
osearch	OSG Threshold[Cortana/Improving Cortana Personalization Through Finances]functional specification[Shell/CAST]CONTACTSROLEName; AliasProgram ManagerColleen Hamilton; chamiltDeveloperQualityDesignPartner(s)ONE PAGE SPEC - Guideline	0.16007466097254633
osearch		0.1590166075885527
osearch	Restaurants Features and ToolsReview SnippetXAPOSearchQueryWPOLERWPO OSCacheItemCacheIdList of YpIdsFiltersSorterEntityUpdate PostFixEntity Update OSCache IdCache ItemYpId and PostFixUXReview Snippet Data GroupCac	0.1478116710268939
osearch	Local Search Platform PM Onboarding GuideAuthors: Dany DaherDate: 10/18/2013Architecture OverviewHow Local Search Works Local Data Platform Architecture MetricsLocal Metrics:  http://jeffke/localMetrics/Definition of QLDCG: Local Discoun	0.1179597244712445
osearch	Bing Local Search				Phonebook vNext Design DocumentDev ownerMickadBuddy dev(s)MichstePM ownerDabargerContributorsFeature areaMilestoneTable of contents1	Overview	32	Goals/Non Goals	53	Dependencies	64	Risks/Open Issues	75	0.11793960916724357
osearch	Entity Pane and Fact AnswerPresenter: Ze TianJun 25, 2013IntroductionIntroductionIntroductionProblems to SolveDoes the user search for entities or facts of entities?E.g. “who is msft ceo” (Entity: Microsoft, Fact: Chief Executive O	0.11396053887436083
osearch	L-1B SPECIALIZED KNOWLEDGE QUESTIONNAIREMICROSOFT POSITION IN THE U.S.Provide the following information for your current position at the Microsoft.MICROSOFT POSITION ABROADProvide the following information for your position at the Microsoft’s su	0.10198795333620239

meta stream features	PAC: Features, Usage and ProcessThis is a document on how to get document features and build metaword/metastream via Page Analyzer and Classifier (PAC ) pipeline. ContentsKinds Of Features Supported By PAC	2Url/Title Features	2Body Features: Doc	0.47917005445558575
meta stream features	Meta-stream work summaryHeyong WangClickstream exampleOverview: Click-Stream generationWeb logsLocal logsLocal clicked dataJoin with Local IndexWeb Clicked data (query, url etc.)IE ClickBing ClickIE SessionIE Tool Bar…Web Click	0.3872380720485056
meta stream features	Summary and HighlightsIn April the metrics/measurement team released local AutoSuggest metric and shared initial transit measurement results; BLU team shipped CL 1.0 ontology and deployed BLU v3 to all markets; PBA team shipped a new L2 ranker and refre	0.3401145534150602
meta stream features	CosmosScope > StreamSetsHiren Patel & Saveen Reddy2014/02/06© 2012 Microsoft Corporation. All rights reserved. Microsoft, Windows, and other product names are or may be registered trademarks and/or trademarks in the U.S. and/or other countries.The	0.3335627725995432
meta stream features	[IMPORTANT]Please notify “featfun” if you want to edit this document!!!Metastream FeaturesWritten by: Tian Xia (tixia@microsoft.com)Table of Contents1. Overview	62. Basics	82.1 Metastreams	9Single instance metastream	9Multi-instance meta	0.332920982816998
meta stream features	CALQuery alterationAgendaRoadmap and VisionWhere are weWhere to goPlanHow to get thereProgress and looking aheadSodium so farMagnesium and beyondDeep DiveGolden QueryRoadmap & VisionWhere are weCurrent status/problem of CAL	0.3313083595681262
meta stream features	Restaurant segment metrics collectionObjectiveTo understand user behavior/engagement on Restaurant answers.Why this is important? The metrics will help us understand:The comparisons between different answersWhat is important to our users and w	0.30919147378720796
meta stream features	Metrics Pipeline & ToolsJia Liu / Xiaohui Sun / Alex SergeevASG Data Mining TeamDemo link: http://dmsql05/MetricsDefinitionTool/MetricsDefinition.aspx?DataSet=BFT&MetricName=HasCortanaChitChatsTopicsBing Live Metrics PipelineUsage and Perf	0.2962713785860848
meta stream features	Global relevance feature proposalFeature name: Title Match OptimizationPMJin GuoDevJia LiuTestReleaseALTeam site linkExecutive SummaryTitle is the summary/abstract of the document. Title Match is very important to SBS. Through many c	0.284360401854955
meta stream features	Ranker Training Pipeline IntroductionAgendaPipeline OverviewGCC platformExtractionData/Feature PreparationMain Ranker TrainingSegment RankersPipeline OverviewGR OctTree: gcclinkMain Steps:Metastream injection (just info here)Querys	0.2693591873431946

measurement	Summary and HighlightsIn April the metrics/measurement team released local AutoSuggest metric and shared initial transit measurement results; BLU team shipped CL 1.0 ontology and deployed BLU v3 to all markets; PBA team shipped a new L2 ranker and refre	0.2786139932319661
measurement	alterationsalterations: product goalimprove recallby adding terms (not replacing or dropping user-entered terms)using word:which are synonyms to the original terms(we are re-examining each of these for vnext)alterations: general principl	0.23748716892338326
measurement		0.22369877742419175
measurement	Introduction toas measurement platformOlli-Pekka TossavainenMSQ TeamSunnyvaleContentsOverviewAres AssetsData Web Store (DWS)Single HitApp core relevance exampleWhat is ARESFrom their web site:What’s been built on ARESMap Search	0.19753550167262923
measurement	Measurement PlanSmoke test:We will deploy ranker model under test and service to INT and ask SKI internal users to issue whatever queries they want. In this way, we can quickly get feedback using Microsoft private data and Bing API. People can get min	0.18806274777705728
measurement	Deal Ranking Improvement & MeasurementBackgroundAfter we shipped deal understanding, bad deals filtering, deal ranking for the entity search deals and popular deals nearby. We want to measure and improve our deal ranking based on user behaviors. We ca	0.17512378991633784
measurement	L-1B SPECIALIZED KNOWLEDGE QUESTIONNAIREMICROSOFT POSITION IN THE U.S.Provide the following information for your current position at the Microsoft.MICROSOFT POSITION ABROADProvide the following information for your position at the Microsoft’s su	0.15940692052267175
measurement	Integrating Knowledge Graph in Web SearchEntity Triggering and CollectionsPresenter: Ze TianKnowledge GraphEntities and RelationsEntities: celebrities, people, generic terms (e.g. light bulb)Relations: sibling, spouse, people and their works	0.1553895251543081
measurement	Restaurant segment metrics collectionObjectiveTo understand user behavior/engagement on Restaurant answers.Why this is important? The metrics will help us understand:The comparisons between different answersWhat is important to our users and w	0.15241259088061873
measurement	Pattern Based Term Weight FrameworkIntroductionPattern based term weight recognizes the importance for part of terms or all the terms based on patterns/templates/knowledge. There are 2 differences between general and pattern based term weight.Compar	0.1455924667642219

localDCG-Popularity	Local Search Popularity V2 DesignBing Local SearchDevXiaohui Liu, Fengxia PanPMDave BargeronMilestoneAl. M1ContributorsFeature Bug IDSignoffPM Spec Linkhttps://microsoft.sharepoint.com/teams/localsearch/_layouts/15/WopiFrame.aspx?s	0.3771995535124816
localDCG-Popularity	Local Popularity V2Xiaohui Liu, Dave Bargeron, Fengxia PanAgendaProblem and motivationSolutionTechnique deep diveFeature MeasurementPipeline GDI marketsFuture workMotivationEnable LDCG v2Improve local search relevanceRelated 	0.3197816810044536
localDCG-Popularity	Local Entity PopularityJia Liu4/23/2018Project statusStepsDetailsTime ScheduleInvestigateInvestigate old version local entity popularity:Problem define, measurement, feature extraction, training/publish pipeline, usage.12.4 – 12.18	0.287846830041427
localDCG-Popularity	Local DCG11/02/2012AgendaGoals of Local DCGHow Local DCG is calculatedComparison of Local DCG versus sNDCGOperationalization for scalePlan for international rolloutPlan for Local DCG enhancementsGoals of Local DCGGoalsActions take to	0.28609525776327505
localDCG-Popularity	Text Latitude Longitude S0:Local_L3DCG3 G0:Local_L3DCG3 S1:Local_L3DCG3 S2:Local_L3DCG3 Assignment RootCause(BadMetastream,PartialMatch,Cal,BadKeyword,OtherQU,Ranker,BingNotStable,Scraping,Metrics,MicroSegment,JudgeNoise,Unknown,BadEntity) BTC CanBeResolv	0.2647354808295937
localDCG-Popularity	Meta-stream work summaryHeyong WangClickstream exampleOverview: Click-Stream generationWeb logsLocal logsLocal clicked dataJoin with Local IndexWeb Clicked data (query, url etc.)IE ClickBing ClickIE SessionIE Tool Bar…Web Click	0.25013363553086815
localDCG-Popularity	CALQuery alterationAgendaRoadmap and VisionWhere are weWhere to goPlanHow to get thereProgress and looking aheadSodium so farMagnesium and beyondDeep DiveGolden QueryRoadmap & VisionWhere are weCurrent status/problem of CAL	0.2347505895153477
localDCG-Popularity	Location and Data Services Team all hands10/08/2014AgendaCelebrate – Wei, 5minsLocal partners – Andy, 10minsLocal Data Services – Alex, 15minsGeocoder and GeoSpatial Services – Jai, 20minsLocation and Autosuggest Services – Sid, 15minsBing	0.213709276714077
localDCG-Popularity	L3 in LocalKefeng DengOutlineL3 IntroductionUse L3 in localL3 exampleL3 introductionFor Local: 28 IS machines per row, about 5 million entities per machine. MinBLA = 50L3 introductionL3 featuresSet featuresFeature Statistics for top 	0.21364902724700874
localDCG-Popularity	Uses Of Clicks Logs In LocalRelevance	serajago, pingyin, dzpotashOverviewCUV LogsIntent Model ImprovementsTop Links Mining'sGoogle Directions/Maps ClicksDistance Ranking ImprovementsLocation ApproximationPer Category Distance Distributio	0.206184572895138

libsvm	libsvm的相关工具和使用方法libsvm工具：编译并能够使用 : libsvm-3.0.tarsvm的基本原理 ： libsvm-guide.pdflibsvm相关的grid工具 : [sep@ai-iknow-septest1.ai01.baidu.com auto_classifier]$ pwd grid_tools.py /home/sep/yangfan/Basic_Tools/for_lyq/auto_classifier特征筛选的相关资料和方法了解特征筛选方法	0.3551552284029383
libsvm	Jia Liu2013-08-05DU Pipeline Sodium Achievements And Magnesium Plans For CJK　　OutlineSodium AchievementsMagnesium PlanMagnesium Work ItemsSodium Work ItemsAppendixSodium AchievementsWrapstar rating signalsTaobao, tmall; qna; novel; v	0.2625056082440166
libsvm	Content Quality Progress & StatusFeb 23, 2012Yi Li, Guihong Cao, Santhosh Kodipaka, Cheng NiuDocument UnderstandingAgendaContent Quality Problem AreasNDCG vs. SBSSummarizationProblemWhat We DidBing StatusScraperXXXSegment Aut	0.22318186487209404
libsvm	Pattern Based Term WeightVersion 1Jia Liu2014-06-16FrameworkTerm AttributesSemantics definitionHuman understanding and knowledgeChange in different contextsLevels:KeywordAttributeRequirementStrong constraintWeak constraintVer	0.21402568374874698
libsvm	AGI UpdateDL Representation & Applications for NLU TasksSubhojit Som(Subhsom), Chen Zhou(chzho)Xia Song (xiaso), Saurabh Tiwary (satiwary)October. 2016Agenda / UpdatesMachine Reading ComprehensionLearning Generic Representation aka Semanti	0.2115978839549061
libsvm	DU items studyJia Liu2013-05-14AgendaPublication dateMain body blockDocument qualityurl static featuresPublication dateFreshness rankingYear in title, year in url, publication dateEn-us publication date coverage is ~20%Zh-cn public	0.21139645029966042
libsvm	Generic Entity Extraction in Sodium Owner: Chuanxin HuContributors: Kang Li, Yi LiOverviewThe understanding of entities and their relationship is a one of the key pillars supporting the Bing’s strategic bet on the knowledge graph. Today, Satori ca	0.205910436192205
libsvm	Pattern Based Term WeightJia Liu2014-05-06FrameworkTerm AttributesSemantics definitionHuman understanding and knowledgeChange in different contextsLevels:KeywordAttributeRequirementStrong constraintWeak constraintVerbUseless	0.19980650710820513
libsvm	DU work items on zh-cn market　　Jia Liu2013-05-14AgendaSerp classifierWrapstar rating signalsTaobao, tmall; qna; novel; videoGeneral classiferUrl-basedTopic-basedPage number extractionName entity recognitionPerson, location, organiz	0.19399281029979257
libsvm	DU Pipeline Sodium Achievements And Magnesium Plans　　Jia Liu2013-08-05OutlineSodium AchievementsMagnesium PlanMagnesium Work ItemsSodium Work ItemsAppendixSodium AchievementsWrapstar rating signalsTaobao, tmall; qna; novel; videoL3	0.19206543618881816

intro_tech_lu	Stateful Query Intent RefinementFeature OverviewStateful Query Intent Refinement is a Bing QR service that can be leveraged to guide users to their specific intent. Queries that have ambiguous intent or multiple intents/sub-intents can be refined usin	0.25189689010007243
intro_tech_lu	QR Team ReviewJan 2017Team IntroductionConceptXDeep QRAgendaQR Team MembersDev Manager: Ciya LiaoLeads: Garrett Kaminaga, Jingwen Lu, Saekoo Lee, Gord LueckPMs: Shyam Jayasankar, Jie CaiSTC-A Speller team: Yongen Gong and his teamWha	0.24445243773642042
intro_tech_lu	Fusion: Next Gen Web Intelligence Review with David KuJune 2016Goals:Power Bing and Bing Next with web open knowledgeNew post L2 ranking platform with MQ and contextual capability inherently Integrated ranking process provides jointly opti	0.23763566677345987
intro_tech_lu	Microsoft IT Technology AdoptionSee past and upcoming  talks at http://aka.ms/ITTechTalksSubscribe to IT Tech Talks DL @IT Tech Talk Invitethere’s a link on the Tech Talks siteQuestions about Tech Talks? Ask Justin Lane or Susan Sims.IT Tech T	0.2187512366095445
intro_tech_lu		0.2080043812970568
intro_tech_lu	Introduction to L1Xiao WuSearch Platform Tiger Team AgendaL1 goals and challengesMetrics and measurementL1 ranker and perf optimizationL1 ranking Perf optimizationDebugging tools L1 training and shippingThinking and discussionL1 	0.20745530143493543
intro_tech_lu	L3 in LocalKefeng DengOutlineL3 IntroductionUse L3 in localL3 exampleL3 introductionFor Local: 28 IS machines per row, about 5 million entities per machine. MinBLA = 50L3 introductionL3 featuresSet featuresFeature Statistics for top 	0.20677659176088467
intro_tech_lu	Fusion: Next Gen Web IntelligenceDeep Dive with Steven 1/6/2017Goals:Power Bing & Bing Next with web open knowledgeNew post L2 ranking platformImproved agility and scalabilityInherent MQ + contextual capability Integrated ranking process: 	0.1951134814573774
intro_tech_lu	Thoughts on Interest Graph – Experience, Business and TechnologyPersonalized recommendation that you don’t want to miss Author: Ting Cai Contributors: AC Surendran, Xiaodong Fan, Chuanxin Hu, Yan Ke, Tony Chor, Richard Qian1.	What is Interest Graph?	0.17262153837889024
intro_tech_lu	Translation ModelMei YangDU talk5/11/2011OutlineIntroduction to Machine Translation (MT)Introduction to phrase-based statistical machine translation (PBSMT)Translation Model @ DUFuture WorkIntroduction to MTTranslate one natural langua	0.16689719635628775

indexserve in bing v0.6	Index Serve in Bing SearchContents1	Introduction	81.1	Overview	81.2	Goals and constraints	82	IndexServe Stats at a glance	93	IndexServe Architecture Overview	93.1	Logical Query flow	93.2	Machine Functions	124	Runtime Services	124.1	FCS	0.5873938830705742
indexserve in bing v0.6	ID Phrase Should be removed? 1 all of y 2 bing 3 bing can you 4 bing could you 5 bing could you please 6 bing i d like to 7 bing i d like you to 8 bing i need to 9 bing i need you to 10 bing i wanna 11 bing i want to 12 bing i want you to 13 bing i would 	0.4680017928710303
indexserve in bing v0.6	Bing GC Deep DiveBingGCI 9/26/2014Introduction – Pavel, 2minsProject overview – Wei, 6minsBing GC XAP workflow – John, 10minsBing GC data pipeline and data ingestion – Florin, 7minsBing GC Offline relevance platform – Jian, 8minsSingle-poi	0.40215220817227804
indexserve in bing v0.6	Run web-search-like query against my dataSame Bing Web Search Indexing and Ranking engineIndex in a secondTransparent and real time index sync, no complex index-gen pipelinePrototype in an hourFast self-onboarding with freemium account, schema-d	0.37242522527833266
indexserve in bing v0.6	Index Quality UpdateAgendaMetrics UpdateSelection Model ImprovementRecall TierOffice ImprovementChallenges and Pain PointsHow to measure index quality?Ideally: sampling from all “good” images and see how much we covered.sampling from a	0.3323003165068142
indexserve in bing v0.6	Fusion: Next Gen Web Intelligence Review with David KuJune 2016Goals:Power Bing and Bing Next with web open knowledgeNew post L2 ranking platform with MQ and contextual capability inherently Integrated ranking process provides jointly opti	0.3299999074251097
indexserve in bing v0.6	Partner Index as ServiceWhat is the Problem? RequirementCurrent status of Bing Image StackDiscoveryClient tend to provide feed for full corpusWeb crawlerImage Content RetrievalSpecial agreement, some even behind authentication for access	0.3287574354245833
indexserve in bing v0.6	Bing Local Search				PBA Geo Location Feeds augmentation generation Dev ownerTetyana GolubBuddy dev(s)PM ownerDave BargeronContributorsFeature areaPBA Feeds query generationMilestoneAluminumTable of contents1	Overview	22	Goal	0.311539588006379
indexserve in bing v0.6	BingGC Multi-Pointer Stack11/4/2014BingGCI@microsoft.comMulti-Pointer ResolutionUsing a tiling system, we first find the correct Tile, then search inside to find matching entities:	 Chipotle Mission St 2nd StQuery: Chipotle Mission St 2nd St	0.3083043496037002
indexserve in bing v0.6	QueryString Category owner Searchvote url 寇仲最后和谁在一起 ranking  xiaopeng http://searchvote.com/default.aspx?reviewid=209877 布里斯班 ranking  xiaopeng http://searchvote.com/default.aspx?reviewid=211685 必应词典 ranking  xiaopeng http://searchvote.com/default.aspx?re	0.30060007242295506

hypertable介绍	hypertable介绍-1一 Hypertable 是什么：Hypertable 是一个正在进行中的开源项目，以google的bigtable论文为基础指导，使用c++语言实现。目的是为了解决大并发，大数据量的数据库需求。目前 只支持最基本的查询功能，对于事物，关联查询等都不支持。对单条查询的响应时间可能也不如传统数据库（要看数据量，量越大，对hypertable越有 力）。好处是，可以处理大量并发请求，和管理大量数据。可扩缩性好，扩容只需要增加集群中的机器就ok了。任何节点失效，既不会造成系统	0.5927517369091394
hypertable介绍	资源区confilter升级之词表匹配算法调研分析词表匹配贴吧confilter词表匹配算法介绍贴吧confilter词表匹配算法的分析trie树介绍trie树进行词表匹配的分析ac自动机介绍ac自动机进行词表匹配的分析改进内存的ac自动机介绍tst（ternary-search- tree）介绍tst（ternary-search- tree）进行词表匹配的分析资源confilter词表统计分析总结词表匹配confilter为内容过滤模块，词表匹配	0.4326675622857987
hypertable介绍	客户价值模型分享和讨论WHY/WHAT/HOWECom ASEA  ——  Advertisement Search Analysis2010-12-29为什么要做客户模型客户价值度模型客户关注点模型客户忠诚度模型……常用的客户价值模型RFM模型R(Recency)表示客户最近一次购买的时间有多远；F(Frequency)表示客户在最近一段时间内购买的次数；M (Monetary)表示最近一段时间内购买的金额2维RFM（消除购买次数与购买额之间的多重	0.43140822707369364
hypertable介绍	资源confilter升级之词表匹配算法详细设计及对比贴吧词表算法抽取ac自动机改进内存的ac自动机测试环境的搭建测试数据与对比分析贴吧词表匹配算法抽取bitmap原理：将词表中的一行字符串的前3个字节（可以小于3）在bitmap中标识。用于在匹配输入串时，快速定位词表中是否有当前指针指向的字符串前3个字节为首的过滤词，若有继续匹配，否则指针后移。具体实现：3个字节的二进制数，即表示：0-256^3。动态分配2^24bit的空间，即（2^24bit）/((8bi	0.4188954075498589
hypertable介绍	BS代码阅读：BS基本功能：索引相关性切词成分分析offset调权query解析 （where+what）多路归并 综合调权类聚（偏离点）query分类空间调权数据来源点击调权BS代码阅读：bs_cache:map库的term cachemap库term cache操作锁where库term cachewhere库term cache操作锁init_map_term_cache: 初始化map库term cachein	0.41786355680315623
hypertable介绍	hbase介绍阳云2011.10.27存储问题怎么持久化存储10亿行以上不断更新的数据并且保证其实时响应？HBase是什么分布式数据库，基于Google Bigtable2模型分布式、面向列、多维度、稀疏、高扩展、高性能、持久化的数据存储系统运行在Hadoop-HDFS上多副本，保证可靠性2007年开始，2008.2 成为Apache Hadoop开源项目的子项目；目前版本: 0.9HBase不是什么不是一个关系型SQL数据库！没有join操	0.4094356541973018
hypertable介绍	C专家编程读书笔记难点关键字的用法：关键字用法extern在函数名前，表示该函数全局可见，一般缺省。即一个文件的全局变量和函数对其他文件，具有可见性。在变量或者函数前，表示对象的定义在别处进行。由于重载，在c++中调用以C方式编译的函数时，需要加extern “c”。static隐藏：修饰的对象对其他文件不可见，防止多个文件命名冲突。持久性：修饰的对象，存储在数据段或者bss段，和程序有相同的生命周期。只有一次初始化。3、修饰的变量未初始化时，默认为“0	0.409087717412783
hypertable介绍	K最近邻分类模型：原理：训练元组用n个属性描述，每个元组代表n维空间中的一个点，所有的训练元组存放在n维的模式空间。当给定一个未知元组时，KNN搜索该模式空间，找出最接近未知元组的k个训练元组。未知元组指派到它的k个最近邻中的多数类。“邻近性”用距离度量，如欧几里德距离。欧几里德距离：	设元组X1=(X11,X12,…X1n)，X2=(X21,X22,…X2n)，	Dist(X1,X2)=√ ∑ k= 1 n (X1i-X2i) 2 	使用上式之前，对每个属性的值规范化，以防止具有	0.4084128003585985
hypertable介绍	排序及扩展：插入排序，选择排序（冒泡排序），使用二分思想求第k大数，快速排序，非递归的快速排序，使用快排思想求第k大数，归并排序，求逆序数，自然排序算法，堆排序，最小优先级队列，计数排序，桶排序，鸽巢排序（分块排序），基数排序，外部排序：二路归并，K路归并，胜者树，败者树。  算法一：使用插入或者选择排序，得到最大的K个数，时间复杂度为：O(N*k)。 冒泡排序： void swap(int * a,int * b){            //注意	0.4080201195097153
hypertable介绍	克拉玛依公证处:本人因生活在国外，不能亲自到贵单位办理出生证明公证事项，兹授权委托雷春香女士全权代表我办理相关事项。对委托人在办理上述事项过程中所签署的有关文件，我均予以认可，并承担相应的法律责任。委托人：刘佳			委托人身份证号码：654301198608243929被委托人：雷春香		被委托人身份证号码：6526196207113926委托人：刘佳2018年5月24日	0.4080201195097153

how cal alterations works	alterationsalterations: product goalimprove recallby adding terms (not replacing or dropping user-entered terms)using word:which are synonyms to the original terms(we are re-examining each of these for vnext)alterations: general principl	0.41767067742241815
how cal alterations works	Bitext Alignment for Alteration Candidate GenerationJan 2018Alteration BasicsCAL alteration architecture is a big funnelCurrent mouth of the funnel is the altlist – a non-context-sensitive relation of <source, target, score>Built over time, qu	0.413210486193263
how cal alterations works	Phrasal Alterations & CAL Infra 		Page 2 of 2Phrasal Alterations & CAL Infra DescriptionPhrasal Alterations is going to add CAL the functionality of doing N-to-M alterations. Given a query, CAL is going to generate multiple candidate queries without	0.3852322461591075
how cal alterations works	CALQuery alterationAgendaRoadmap and VisionWhere are weWhere to goPlanHow to get thereProgress and looking aheadSodium so farMagnesium and beyondDeep DiveGolden QueryRoadmap & VisionWhere are weCurrent status/problem of CAL	0.27261843623655685
how cal alterations works	CAL MultiQuery {Matching\Ranking}		Page 3 of 4CAL MultiQuery {Matching\Ranking}DescriptionCAL is going to optimize against matching\ranking separately and will issue different queries to each tier. CAL will be leveraging several operator such as:m	0.23328234366856349
how cal alterations works	Combined ALterationsNeon\sodiumAgendaNeon AchievementsBreakdownsSodiumIdeas & PlanNeonOverall ProgressExceeded Neon Commitments on CQS!NeonCQS Deep-dive-34% Bad+14% Excellent-15% Bad+13% ExcellentDRDOCQS is impr	0.20626759558407393
how cal alterations works	CAL OFE logsOFE raw logs are cooked with the CALOFELogExtraction script, located in answers_alterations\private\OfflineDataGen\QueryAlteration\CALOFE\CALOFE.slnCooking the raw logsTo cook your logs, you need to runanswers_alterations\private\Offli	0.19127040635063414
how cal alterations works	Primary Category: What Is It, Why Is It Important, & How Do We Measure ItBing Local & Geospatial – ShruthiM, DillTellClassificationProcess in which local business entities are categorized based on the type of products and/or services that the busine	0.18300724626510662
how cal alterations works	Training data distributionContain categories as many as possible : 36 categies. The data of category in the same amountContain hudong data and  host dataPositive : negative = 1:7  ~ 1:10 categoryhudonghostpositivenegativeNegative_total	0.1596126992259112
how cal alterations works	Global CAL Aluminum PlanJunfeng ZhouAgendaMagnesium StatusAluminum FocusProjectsMagnesium Status - ReleasesJuly: aggressive relaxation on no result queriesSept: relax count classifier, morphological alterationsOct: JO v1Nov: morphologi	0.15517011617185186

hive介绍	HIVE介绍简介是什么hive是一个基于hadoop的数据仓库。使用hadoop-hdfs作为数据存储层；提供类似SQL的语言（HQL），通过hadoop-mapreduce完成数据计算；通过HQL语言提供使用者部分传统RDBMS一样的表格查询特性和分布式存储计算特性。类似的系统有yahoo的pig[1] ，google的sawzall[2]，microsoft的DryadLINQ[3]。架构图表 1 hive架构图[4]操作界面：CLI，Web，Thriftdrive	0.6264237104656583
hive介绍	BS代码阅读：BS基本功能：索引相关性切词成分分析offset调权query解析 （where+what）多路归并 综合调权类聚（偏离点）query分类空间调权数据来源点击调权BS代码阅读：bs_cache:map库的term cachemap库term cache操作锁where库term cachewhere库term cache操作锁init_map_term_cache: 初始化map库term cachein	0.5439260731334958
hive介绍	排序及扩展：插入排序，选择排序（冒泡排序），使用二分思想求第k大数，快速排序，非递归的快速排序，使用快排思想求第k大数，归并排序，求逆序数，自然排序算法，堆排序，最小优先级队列，计数排序，桶排序，鸽巢排序（分块排序），基数排序，外部排序：二路归并，K路归并，胜者树，败者树。  算法一：使用插入或者选择排序，得到最大的K个数，时间复杂度为：O(N*k)。 冒泡排序： void swap(int * a,int * b){            //注意	0.5387465526598101
hive介绍	克拉玛依公证处:本人因生活在国外，不能亲自到贵单位办理出生证明公证事项，兹授权委托雷春香女士全权代表我办理相关事项。对委托人在办理上述事项过程中所签署的有关文件，我均予以认可，并承担相应的法律责任。委托人：刘佳			委托人身份证号码：654301198608243929被委托人：雷春香		被委托人身份证号码：6526196207113926委托人：刘佳2018年5月24日	0.5387465526598101
hive介绍	性能升级性能升级的几个层面：系统结构：模块分解，模块交互，系统构建中的粗略估算。算法和数据结构：获得快速模块的关键：表示数据的结构，操作数据的算法：索引结构及拉链归并。代码调优：分支预测等。循环：将循环体中不改变的变量移动到循环体外；多重循环嵌套顺序。函数调用：inline函数节省函数调用开销：若makefile中不指定至少-O优化，即使声明为inline函数，编译器也不会进行函数内联。内存寻址：避免重复内存寻址。Cpu流水线的分支预测：将满足概率最高的条件放在靠前的位置。	0.5387465526598101
hive介绍	业务生成平台用户指南总体说明开发背景下一代网络是业务驱动的网络，在融合的下一代网络上高效、灵活地开发和部署各种丰富多彩的业务，从而提高网络使用率、增加收益的目标，是下一代网络的关键环节。下一代网络的发展要求呼叫与承载相分离、呼叫控制与业务相分离，使业务真正独立于网络，业务开发者不必关心与业务承载相关的底层网络知识以及具体的通信协议，只需利用业务生成平台提供的业务开发工具，就可以开发出灵活丰富且极具个性化的业务。 为了适合多种技术水平的业务开发人员的需要，现在主要有四种业务开发方式：	0.5387465526598101
hive介绍	K最近邻分类模型：原理：训练元组用n个属性描述，每个元组代表n维空间中的一个点，所有的训练元组存放在n维的模式空间。当给定一个未知元组时，KNN搜索该模式空间，找出最接近未知元组的k个训练元组。未知元组指派到它的k个最近邻中的多数类。“邻近性”用距离度量，如欧几里德距离。欧几里德距离：	设元组X1=(X11,X12,…X1n)，X2=(X21,X22,…X2n)，	Dist(X1,X2)=√ ∑ k= 1 n (X1i-X2i) 2 	使用上式之前，对每个属性的值规范化，以防止具有	0.5385785565763772
hive介绍	Svm分类模型：基本原理：将所有待分类的点映射到“高维空间”，然后在高维空间中找到一个能将这些点分开的“超平面”，这在理论上是被完全证明了是成立的，而且在实际计算中也是可行的。满足条件的“超平面”的个数不是唯一的。SVM需要的是利用这些超平面，找到这两类点之间的“最大间隔”。并非所有的数据都线性可分，将非线性映射到更高维的特征空间变成线性可分。（低维空间向量集通常难于划分，解决的方法是将它们映射到高维空间。）但这个办法带来的困难就是计算复杂度的增加，而核函数正好巧妙地解决了这个问题。也就是说，只要选用	0.5359882456159974
hive介绍	C专家编程读书笔记难点关键字的用法：关键字用法extern在函数名前，表示该函数全局可见，一般缺省。即一个文件的全局变量和函数对其他文件，具有可见性。在变量或者函数前，表示对象的定义在别处进行。由于重载，在c++中调用以C方式编译的函数时，需要加extern “c”。static隐藏：修饰的对象对其他文件不可见，防止多个文件命名冲突。持久性：修饰的对象，存储在数据段或者bss段，和程序有相同的生命周期。只有一次初始化。3、修饰的变量未初始化时，默认为“0	0.5335716412346379
hive介绍	工作6周年5个月小记今天是中国时间8/24/2018，也就是我32岁的生日，这是一个不老也不再年轻的年纪。最近总是因为工作而郁郁寡欢，心中不快，所以决定记录总结一下，希望自己能有所释怀、转变、确立新的目标。从2012年3月31到现在，我已在微软Bing工作6年5个月。在此之前，我在百度实习9个月，在阿里巴巴实习2个月，在搜狗实习1个月。在微软北京CJK relevance组勤恳的工作2年6个月，从级别59升到61，做了1年半的DU, 1年的relevance。总体来说，老板们的风格是相关性主导基础	0.5325389532602424

hbase分析报告	hbase介绍阳云2011.10.27存储问题怎么持久化存储10亿行以上不断更新的数据并且保证其实时响应？HBase是什么分布式数据库，基于Google Bigtable2模型分布式、面向列、多维度、稀疏、高扩展、高性能、持久化的数据存储系统运行在Hadoop-HDFS上多副本，保证可靠性2007年开始，2008.2 成为Apache Hadoop开源项目的子项目；目前版本: 0.9HBase不是什么不是一个关系型SQL数据库！没有join操	0.7925786747129899
hbase分析报告	Hbase分析报告本文基于环境hadoop-0.16.4 和 hbase-0.1.3 编写Hbase是一个分布式开源数据库，基于Hadoop分布式文件系统，模仿并提供了基于Google文件系统的Bigtable数据库的所有功能。Hbaes的目标是处理非常庞大的表，可以用普通的计算机处理超过10亿行数据，并且有数百万列元素组成的数据表。Hbase可以直接使用本地文件系统或者Hadoop作为数据存储方式，不过为了提高数据可靠性和系统的健壮性，发挥Hbase处理大数据量等功能，需要使用Hadoo	0.7844461427814717
hbase分析报告	贝叶斯分类模型：基础知识：假设	X：是数据元组，由n个属性描述；	H：是某种假设，如数据元组属于某特定类C	P(H|X)：表示给定X的属性描述，找出元组X属于类C的概率举例：X：一位35岁的顾客，收入为4w美元；H：顾客将购买计算机P(H|X)：在X的条件下，H的后验概率。当我们知道顾客的年龄和收入时，顾客X将购买计算机的概率。P(H)：H的先验概率。任意给定顾客将购买计算机的概率，独立与X。P(X|H)：在条件H下，X的后验概率。已知顾客购买了计算机，顾客是一位3	0.7650098183268235
hbase分析报告	K最近邻分类模型：原理：训练元组用n个属性描述，每个元组代表n维空间中的一个点，所有的训练元组存放在n维的模式空间。当给定一个未知元组时，KNN搜索该模式空间，找出最接近未知元组的k个训练元组。未知元组指派到它的k个最近邻中的多数类。“邻近性”用距离度量，如欧几里德距离。欧几里德距离：	设元组X1=(X11,X12,…X1n)，X2=(X21,X22,…X2n)，	Dist(X1,X2)=√ ∑ k= 1 n (X1i-X2i) 2 	使用上式之前，对每个属性的值规范化，以防止具有	0.7614343513185952
hbase分析报告	排序及扩展：插入排序，选择排序（冒泡排序），使用二分思想求第k大数，快速排序，非递归的快速排序，使用快排思想求第k大数，归并排序，求逆序数，自然排序算法，堆排序，最小优先级队列，计数排序，桶排序，鸽巢排序（分块排序），基数排序，外部排序：二路归并，K路归并，胜者树，败者树。  算法一：使用插入或者选择排序，得到最大的K个数，时间复杂度为：O(N*k)。 冒泡排序： void swap(int * a,int * b){            //注意	0.7608206570924949
hbase分析报告	克拉玛依公证处:本人因生活在国外，不能亲自到贵单位办理出生证明公证事项，兹授权委托雷春香女士全权代表我办理相关事项。对委托人在办理上述事项过程中所签署的有关文件，我均予以认可，并承担相应的法律责任。委托人：刘佳			委托人身份证号码：654301198608243929被委托人：雷春香		被委托人身份证号码：6526196207113926委托人：刘佳2018年5月24日	0.7608206570924949
hbase分析报告	性能升级性能升级的几个层面：系统结构：模块分解，模块交互，系统构建中的粗略估算。算法和数据结构：获得快速模块的关键：表示数据的结构，操作数据的算法：索引结构及拉链归并。代码调优：分支预测等。循环：将循环体中不改变的变量移动到循环体外；多重循环嵌套顺序。函数调用：inline函数节省函数调用开销：若makefile中不指定至少-O优化，即使声明为inline函数，编译器也不会进行函数内联。内存寻址：避免重复内存寻址。Cpu流水线的分支预测：将满足概率最高的条件放在靠前的位置。	0.7608206570924949
hbase分析报告	业务生成平台用户指南总体说明开发背景下一代网络是业务驱动的网络，在融合的下一代网络上高效、灵活地开发和部署各种丰富多彩的业务，从而提高网络使用率、增加收益的目标，是下一代网络的关键环节。下一代网络的发展要求呼叫与承载相分离、呼叫控制与业务相分离，使业务真正独立于网络，业务开发者不必关心与业务承载相关的底层网络知识以及具体的通信协议，只需利用业务生成平台提供的业务开发工具，就可以开发出灵活丰富且极具个性化的业务。 为了适合多种技术水平的业务开发人员的需要，现在主要有四种业务开发方式：	0.7608206570924949
hbase分析报告	BS代码阅读：BS基本功能：索引相关性切词成分分析offset调权query解析 （where+what）多路归并 综合调权类聚（偏离点）query分类空间调权数据来源点击调权BS代码阅读：bs_cache:map库的term cachemap库term cache操作锁where库term cachewhere库term cache操作锁init_map_term_cache: 初始化map库term cachein	0.7607901698030138
hbase分析报告	海量数据库的设计和实现淘宝海量数据库之一：来自业务的挑战(2010-11-24 11:34:38) 作为一个电子商务企业，从一开始，数据库及其事务能力在淘宝一直扮演着十分关键的角色，淘宝积累了丰富的数据库的架构和规划等方面的经验，产生了众多优秀的DBA。 淘宝是一家迅速发展的公司。全球网站排名公司Alexa提供的数据显示，2010年4月27日，Amazon、Ebay的用户占全球互联网用户的百分比分别为3.47%和2.68%，而淘宝的用户占全球互联网用户的百分比则达到了4.1%，淘宝网日	0.7579845668359091

hbase介绍	Hbase分析报告本文基于环境hadoop-0.16.4 和 hbase-0.1.3 编写Hbase是一个分布式开源数据库，基于Hadoop分布式文件系统，模仿并提供了基于Google文件系统的Bigtable数据库的所有功能。Hbaes的目标是处理非常庞大的表，可以用普通的计算机处理超过10亿行数据，并且有数百万列元素组成的数据表。Hbase可以直接使用本地文件系统或者Hadoop作为数据存储方式，不过为了提高数据可靠性和系统的健壮性，发挥Hbase处理大数据量等功能，需要使用Hadoo	0.6859363332592507
hbase介绍	hbase介绍阳云2011.10.27存储问题怎么持久化存储10亿行以上不断更新的数据并且保证其实时响应？HBase是什么分布式数据库，基于Google Bigtable2模型分布式、面向列、多维度、稀疏、高扩展、高性能、持久化的数据存储系统运行在Hadoop-HDFS上多副本，保证可靠性2007年开始，2008.2 成为Apache Hadoop开源项目的子项目；目前版本: 0.9HBase不是什么不是一个关系型SQL数据库！没有join操	0.6804686060187365
hbase介绍	贝叶斯分类模型：基础知识：假设	X：是数据元组，由n个属性描述；	H：是某种假设，如数据元组属于某特定类C	P(H|X)：表示给定X的属性描述，找出元组X属于类C的概率举例：X：一位35岁的顾客，收入为4w美元；H：顾客将购买计算机P(H|X)：在X的条件下，H的后验概率。当我们知道顾客的年龄和收入时，顾客X将购买计算机的概率。P(H)：H的先验概率。任意给定顾客将购买计算机的概率，独立与X。P(X|H)：在条件H下，X的后验概率。已知顾客购买了计算机，顾客是一位3	0.6336923342221928
hbase介绍	K最近邻分类模型：原理：训练元组用n个属性描述，每个元组代表n维空间中的一个点，所有的训练元组存放在n维的模式空间。当给定一个未知元组时，KNN搜索该模式空间，找出最接近未知元组的k个训练元组。未知元组指派到它的k个最近邻中的多数类。“邻近性”用距离度量，如欧几里德距离。欧几里德距离：	设元组X1=(X11,X12,…X1n)，X2=(X21,X22,…X2n)，	Dist(X1,X2)=√ ∑ k= 1 n (X1i-X2i) 2 	使用上式之前，对每个属性的值规范化，以防止具有	0.6304826851900347
hbase介绍	排序及扩展：插入排序，选择排序（冒泡排序），使用二分思想求第k大数，快速排序，非递归的快速排序，使用快排思想求第k大数，归并排序，求逆序数，自然排序算法，堆排序，最小优先级队列，计数排序，桶排序，鸽巢排序（分块排序），基数排序，外部排序：二路归并，K路归并，胜者树，败者树。  算法一：使用插入或者选择排序，得到最大的K个数，时间复杂度为：O(N*k)。 冒泡排序： void swap(int * a,int * b){            //注意	0.6298674297353991
hbase介绍	克拉玛依公证处:本人因生活在国外，不能亲自到贵单位办理出生证明公证事项，兹授权委托雷春香女士全权代表我办理相关事项。对委托人在办理上述事项过程中所签署的有关文件，我均予以认可，并承担相应的法律责任。委托人：刘佳			委托人身份证号码：654301198608243929被委托人：雷春香		被委托人身份证号码：6526196207113926委托人：刘佳2018年5月24日	0.6298674297353991
hbase介绍	性能升级性能升级的几个层面：系统结构：模块分解，模块交互，系统构建中的粗略估算。算法和数据结构：获得快速模块的关键：表示数据的结构，操作数据的算法：索引结构及拉链归并。代码调优：分支预测等。循环：将循环体中不改变的变量移动到循环体外；多重循环嵌套顺序。函数调用：inline函数节省函数调用开销：若makefile中不指定至少-O优化，即使声明为inline函数，编译器也不会进行函数内联。内存寻址：避免重复内存寻址。Cpu流水线的分支预测：将满足概率最高的条件放在靠前的位置。	0.6298674297353991
hbase介绍	业务生成平台用户指南总体说明开发背景下一代网络是业务驱动的网络，在融合的下一代网络上高效、灵活地开发和部署各种丰富多彩的业务，从而提高网络使用率、增加收益的目标，是下一代网络的关键环节。下一代网络的发展要求呼叫与承载相分离、呼叫控制与业务相分离，使业务真正独立于网络，业务开发者不必关心与业务承载相关的底层网络知识以及具体的通信协议，只需利用业务生成平台提供的业务开发工具，就可以开发出灵活丰富且极具个性化的业务。 为了适合多种技术水平的业务开发人员的需要，现在主要有四种业务开发方式：	0.6298674297353991
hbase介绍	海量数据库的设计和实现淘宝海量数据库之一：来自业务的挑战(2010-11-24 11:34:38) 作为一个电子商务企业，从一开始，数据库及其事务能力在淘宝一直扮演着十分关键的角色，淘宝积累了丰富的数据库的架构和规划等方面的经验，产生了众多优秀的DBA。 淘宝是一家迅速发展的公司。全球网站排名公司Alexa提供的数据显示，2010年4月27日，Amazon、Ebay的用户占全球互联网用户的百分比分别为3.47%和2.68%，而淘宝的用户占全球互联网用户的百分比则达到了4.1%，淘宝网日	0.6279760757307661
hbase介绍	神经网络原理及应用介绍Anti RD：王伟琼、张爱华主要内容特点及应用场景神经网络原理我们的经验和教训多线程训练下一步的工作应用场景分类预测时间允许的场合使用并行化等方法加速测试过程很快，且可以方便的使用hadoop平台环境比较固定的场合数据的统计特性变化不大需要定量预测的场合给出未知数据的定量预测神经网络特点优点对噪音数据有较好的适应能力对未知数据具有较好的预测分类能力拟合各种函数得出定量值缺点学习时间较长	0.6278525965600935

hadoop介绍-阳云	Hadoop介绍阳云2011.03主要内容Hadoop应用背景Hadoop介绍Hdfs的介绍Mapred的介绍HiveHbase开心网hadoop使用现状背景解决单机无法完成的大存储(>1TB)和大规模计算基于RDBMS的存储和计算瓶颈扩展差容错差 可以开发自己的分布式系统开发成本高通用性差mpi？一个消息传递库利用mpi开发成本依旧很高无容错Hadoop简介Google的GFS，MapReduce	0.759185009793929
hadoop介绍-阳云	HIVE介绍简介是什么hive是一个基于hadoop的数据仓库。使用hadoop-hdfs作为数据存储层；提供类似SQL的语言（HQL），通过hadoop-mapreduce完成数据计算；通过HQL语言提供使用者部分传统RDBMS一样的表格查询特性和分布式存储计算特性。类似的系统有yahoo的pig[1] ，google的sawzall[2]，microsoft的DryadLINQ[3]。架构图表 1 hive架构图[4]操作界面：CLI，Web，Thriftdrive	0.7107424982773456
hadoop介绍-阳云	SVM分类内容概要流程图预处理SVM分类器组合分类结果流程图内容概要流程图预处理SVM分类器组合分类结果特征选择特征，以文本行业分类来说，切词term特征的重要性“北京”是个没用的特征“速8”是个有用的特征“轻度”这个词呢？信息增益（Information Gain）   熵H是一个分布是否分散的表征，与信息相反概率估计P(ci) = ci类别的样本数 / 样本总数P(ci|t)  = t出现的属于ci	0.6484874874390862
hadoop介绍-阳云	Hbase分析报告本文基于环境hadoop-0.16.4 和 hbase-0.1.3 编写Hbase是一个分布式开源数据库，基于Hadoop分布式文件系统，模仿并提供了基于Google文件系统的Bigtable数据库的所有功能。Hbaes的目标是处理非常庞大的表，可以用普通的计算机处理超过10亿行数据，并且有数百万列元素组成的数据表。Hbase可以直接使用本地文件系统或者Hadoop作为数据存储方式，不过为了提高数据可靠性和系统的健壮性，发挥Hbase处理大数据量等功能，需要使用Hadoo	0.6467301238371859
hadoop介绍-阳云	Svm分类模型：基本原理：将所有待分类的点映射到“高维空间”，然后在高维空间中找到一个能将这些点分开的“超平面”，这在理论上是被完全证明了是成立的，而且在实际计算中也是可行的。满足条件的“超平面”的个数不是唯一的。SVM需要的是利用这些超平面，找到这两类点之间的“最大间隔”。并非所有的数据都线性可分，将非线性映射到更高维的特征空间变成线性可分。（低维空间向量集通常难于划分，解决的方法是将它们映射到高维空间。）但这个办法带来的困难就是计算复杂度的增加，而核函数正好巧妙地解决了这个问题。也就是说，只要选用	0.6463838834274332
hadoop介绍-阳云	K最近邻分类模型：原理：训练元组用n个属性描述，每个元组代表n维空间中的一个点，所有的训练元组存放在n维的模式空间。当给定一个未知元组时，KNN搜索该模式空间，找出最接近未知元组的k个训练元组。未知元组指派到它的k个最近邻中的多数类。“邻近性”用距离度量，如欧几里德距离。欧几里德距离：	设元组X1=(X11,X12,…X1n)，X2=(X21,X22,…X2n)，	Dist(X1,X2)=√ ∑ k= 1 n (X1i-X2i) 2 	使用上式之前，对每个属性的值规范化，以防止具有	0.6414742287152743
hadoop介绍-阳云	排序及扩展：插入排序，选择排序（冒泡排序），使用二分思想求第k大数，快速排序，非递归的快速排序，使用快排思想求第k大数，归并排序，求逆序数，自然排序算法，堆排序，最小优先级队列，计数排序，桶排序，鸽巢排序（分块排序），基数排序，外部排序：二路归并，K路归并，胜者树，败者树。  算法一：使用插入或者选择排序，得到最大的K个数，时间复杂度为：O(N*k)。 冒泡排序： void swap(int * a,int * b){            //注意	0.6408876277844606
hadoop介绍-阳云	克拉玛依公证处:本人因生活在国外，不能亲自到贵单位办理出生证明公证事项，兹授权委托雷春香女士全权代表我办理相关事项。对委托人在办理上述事项过程中所签署的有关文件，我均予以认可，并承担相应的法律责任。委托人：刘佳			委托人身份证号码：654301198608243929被委托人：雷春香		被委托人身份证号码：6526196207113926委托人：刘佳2018年5月24日	0.6408876277844606
hadoop介绍-阳云	性能升级性能升级的几个层面：系统结构：模块分解，模块交互，系统构建中的粗略估算。算法和数据结构：获得快速模块的关键：表示数据的结构，操作数据的算法：索引结构及拉链归并。代码调优：分支预测等。循环：将循环体中不改变的变量移动到循环体外；多重循环嵌套顺序。函数调用：inline函数节省函数调用开销：若makefile中不指定至少-O优化，即使声明为inline函数，编译器也不会进行函数内联。内存寻址：避免重复内存寻址。Cpu流水线的分支预测：将满足概率最高的条件放在靠前的位置。	0.6408876277844606
hadoop介绍-阳云	业务生成平台用户指南总体说明开发背景下一代网络是业务驱动的网络，在融合的下一代网络上高效、灵活地开发和部署各种丰富多彩的业务，从而提高网络使用率、增加收益的目标，是下一代网络的关键环节。下一代网络的发展要求呼叫与承载相分离、呼叫控制与业务相分离，使业务真正独立于网络，业务开发者不必关心与业务承载相关的底层网络知识以及具体的通信协议，只需利用业务生成平台提供的业务开发工具，就可以开发出灵活丰富且极具个性化的业务。 为了适合多种技术水平的业务开发人员的需要，现在主要有四种业务开发方式：	0.6408876277844606

deep-dive-QuerySimplification-final	Query Simplification Deep DiveJON Fu12/11/2017AgendaQuery Simplification Motivation and TheoryQuery Simplification for WebQuery Simplification for Cortana 3ARecent Progress in Query Simplification WorkReferencesIntroductionMotiva	0.6449769438029391
deep-dive-QuerySimplification-final	QU Deep Dive 2: Query Simplification and Recurrent Neural NetworkXiaolong Li (Lead of QU Fundamentals TEAM)2/12/2015AgendaQUFun Team ResponsibilitiesRecent Deliverables Query Simplification for WebQuery Simplification for Cortana 3ARec	0.5423358477886835
deep-dive-QuerySimplification-final	Simplified Query Path SelectorSimplified query: current systemSimplified query path selectionCrf model produces a list of possible ways to place rankonly operatorQuery = “nibbana restaurant official site”nibbana restaurant rankonly:official site	0.5393603115166733
deep-dive-QuerySimplification-final	Threshold Query Formulation Deep DiveGoal of the presentation is to communicate our approach for query formulation and get feedback on whether this aligns with overall Threshold goals.OverviewGoals & MetricsQF ModelRoadmapScenariosKey Ta	0.500260123255703
deep-dive-QuerySimplification-final	Deep Dive on Statistical Simplification Model for Hard QueriesBin Zhang (intern, University of Washington)Xiaolong Li, Ye-Yi Wang (Bing)Xiaodong He (MSR)9/11/2012OutlineHard query backgroundDeletion modelsTraining dataOnline experiment	0.467837597615682
deep-dive-QuerySimplification-final	Analyzed Query represents all information derived from all classification tasks executed on the Query. QAS supports 3 basic classifications tasks: binary classification (Domain Classification), entity extraction (Query Parse), category classification (Dom	0.44259576409688006
deep-dive-QuerySimplification-final	Deep Dive: Query Generic Entity Extraction (GEE)Zhen Liao04/22/2016OutlineOverview of GEEFAQ for GEEArchitecture and ModelingRecent breakthrough via Deep LearningLessons we’ve learnedGeneric Entity Extraction for Queries: What is the g	0.4404817621718824
deep-dive-QuerySimplification-final	Reading List for Natural Language Query ParsingThis is for improving our NL query parsing for entity/local triggering.By NL query parsing, our goal is to automatically extract the structured information from the query, normally by segmenting queries a	0.38854425278246935
deep-dive-QuerySimplification-final	Augmented Query Parser Using Deep LearningDemi Guo (Bing Local Intern t-deguo)Manager: Leon ZhangMentor: Simona CabuzHello everyone, Today, I’m going to present my intern project: Augmented query parser using deep learning.About Me My name i	0.3861559539177403
deep-dive-QuerySimplification-final	I’d like to explain in more details my idea of improving Dolphin, by improving its robustness of query variations and some previously unseen terms. Our rules don’t cover many query patterns. E.g., {top rated chinese restaurants} works well, but not {chi	0.37976106858603315

clickStreamSummary	Meta-stream work summaryHeyong WangClickstream exampleOverview: Click-Stream generationWeb logsLocal logsLocal clicked dataJoin with Local IndexWeb Clicked data (query, url etc.)IE ClickBing ClickIE SessionIE Tool Bar…Web Click	0.3713547266841601
clickStreamSummary	Anchor and Click Stream RankingSteven ZittrowerBing Local Search RelevanceHypothesisConverting local search’s unstructured and raw text streams into semi-structured forms will improve ranking and offer relevance benefits.TestUsing classifiers 	0.2904255757713174
clickStreamSummary	ElasticSearchInternalElasticSearch and oSearchElasticSearch  ArchitectureLucene FamilyoSearch  ArchitectureScenario and ScaleoSearchElasticSearchScope Strong structured dataImage with ANNUnstructured text Loose structured data	0.21905123292566653
clickStreamSummary	Home TeamLocal Brown Baghttp://aka.ms/gethometeam ADContactsBusiness cardsAppsEmailsWeb searchThe opportunity For consumers: Most people prefer to use referrals, or “word of mouth” Competition doesn’t embrace thisAmazon – anony	0.20090040722085858
clickStreamSummary	Competitive Query-Entity ClickMicrosoft ConfidentialMicrosoft ConfidentialGoalCreate a dataset that is readily available to utilize and analyze query-entity click patterns on competitive dataCompetitive Engine: GoogleMicrosoft ConfidentialCo	0.20086306535619863
clickStreamSummary	Span ClassifierSpan classifier is a general infrastructure that can be used to run a fastrank based classifier on a sequence of terms from a query.  It can be used to apply rankonly or norelax to parts of the query based on the result of the model.  Fea	0.1287478401065511
clickStreamSummary	Document classification based on urlBackgroundWe want to do document classification for better understanding the document type and document with query category match for ranking.  We will do zh-cn document classification based on url first, then docum	0.12577578526195457
clickStreamSummary	Restaurants Features and ToolsReview SnippetXAPOSearchQueryWPOLERWPO OSCacheItemCacheIdList of YpIdsFiltersSorterEntityUpdate PostFixEntity Update OSCache IdCache ItemYpId and PostFixUXReview Snippet Data GroupCac	0.1215004689247073
clickStreamSummary	 Core Web RelevanceInformation Platform GroupBing Spam & JunkFeature OwnersProgram ManagersMichael AbboudDevelopersPavel Karpovich, Lidong Zhao, Gregory Minasyants, Ashok Ponnuswami,  Eugene Remizov, Mikhail BorbotDev ManagerLuke ChenM	0.10664073627625377
clickStreamSummary	Global relevance feature proposalFeature name: Title Match OptimizationPMJin GuoDevJia LiuTestReleaseALTeam site linkExecutive SummaryTitle is the summary/abstract of the document. Title Match is very important to SBS. Through many c	0.09951423308327496

cal deepdive - relaxation - v2	Deep RelaxQuery Relaxation and L1 FidelityQuery Relaxation{printable iphone 7 user guide}rankonly:printable iphone 7 rankonly:user guiderankonly:printable iphone 7 user guideDeep Relax and vector similarity Encode query without each toke	0.5751845701901321
cal deepdive - relaxation - v2	cal deepdiverelaxationdec 2017AgendaProduct GoalsQuery SimplificationMechanism/RuntimeCRF Model TrainingQS Path SelectionOffline SimulatorSmart RelaxMechanism & TrainingRelaxation: ImpactRelaxation: Product goalsImprove Rec	0.4178988099680415
cal deepdive - relaxation - v2	Bing Location Understanding (BLU) As a ServiceDeep-Dive PresentationRajasi Saha (tech lead for BLU infrastructure)Jian Wu (tech lead for BLU relevance)Microsoft ConfidentialOutlineIntroduction to BLUBLU as a serviceMotivationScenarios an	0.3675380246421977
cal deepdive - relaxation - v2	Relaxcount=2 summaryRelaxcount=2 datagatheringDatagathering for relaxcount=2 branched path (3/14/15-3/20/15):Cal13a: control (OFE logging, relaxcount=2 off), 6% trafficCal13b: on (OFE logging, relaxcount=2 on for word count >=5), 12% traffic.Dat	0.30485623594557215
cal deepdive - relaxation - v2	Deal Ranking ImprovementsDeal Understanding ImprovementsGoal: Increase general deal coverage (deal product type from specific to general).Solution: Identify the prefix and suffix of title by punctuations and prep. Remove the prefix and suffix from t	0.30431990979826706
cal deepdive - relaxation - v2	Deal Understanding and RankingBackgroundDeal is a very big segment in Bing Opal. We crawl store and single deals/coupons regularly from websites like groupon.com, coupons.com, restaurants.com, retailmenot.com, dealcatcher.com, dealplus.com and so on. 	0.30404149080820747
cal deepdive - relaxation - v2	Bing IQ Deep Learning ProgressAlejandro Gutierrez, Anton Savin, Frank Guo, Luis Velazco, Gilbert Wong7/22/2016Overall Plan and PrioritiesLearn Deep Learning and Neural NetworkLearn CNTK (Computational Network Toolkit) by walking through the exam	0.2932180329122985
cal deepdive - relaxation - v2	Deal Ranking Improvement & MeasurementBackgroundAfter we shipped deal understanding, bad deals filtering, deal ranking for the entity search deals and popular deals nearby. We want to measure and improve our deal ranking based on user behaviors. We ca	0.279198618346886
cal deepdive - relaxation - v2	Project-N DeepDiveAbstractSimilarity issue has been one of the biggest problems of zh-CN relevance for years but not well got solved. In this document, we will focus on one of the main problem of similarity - entity/phrase mismatch issue in query/doc 	0.2790068346476588
cal deepdive - relaxation - v2	Deep Dive on Statistical Simplification Model for Hard QueriesBin Zhang (intern, University of Washington)Xiaolong Li, Ye-Yi Wang (Bing)Xiaodong He (MSR)9/11/2012OutlineHard query backgroundDeletion modelsTraining dataOnline experiment	0.2756040345585476

bs理解	BS代码阅读：BS基本功能：索引相关性切词成分分析offset调权query解析 （where+what）多路归并 综合调权类聚（偏离点）query分类空间调权数据来源点击调权BS代码阅读：bs_cache:map库的term cachemap库term cache操作锁where库term cachewhere库term cache操作锁init_map_term_cache: 初始化map库term cachein	0.6075611284526252
bs理解	贝叶斯分类模型：基础知识：假设	X：是数据元组，由n个属性描述；	H：是某种假设，如数据元组属于某特定类C	P(H|X)：表示给定X的属性描述，找出元组X属于类C的概率举例：X：一位35岁的顾客，收入为4w美元；H：顾客将购买计算机P(H|X)：在X的条件下，H的后验概率。当我们知道顾客的年龄和收入时，顾客X将购买计算机的概率。P(H)：H的先验概率。任意给定顾客将购买计算机的概率，独立与X。P(X|H)：在条件H下，X的后验概率。已知顾客购买了计算机，顾客是一位3	0.5840091888691608
bs理解	Svm分类模型：基本原理：将所有待分类的点映射到“高维空间”，然后在高维空间中找到一个能将这些点分开的“超平面”，这在理论上是被完全证明了是成立的，而且在实际计算中也是可行的。满足条件的“超平面”的个数不是唯一的。SVM需要的是利用这些超平面，找到这两类点之间的“最大间隔”。并非所有的数据都线性可分，将非线性映射到更高维的特征空间变成线性可分。（低维空间向量集通常难于划分，解决的方法是将它们映射到高维空间。）但这个办法带来的困难就是计算复杂度的增加，而核函数正好巧妙地解决了这个问题。也就是说，只要选用	0.5781585047631635
bs理解	神经网络原理及应用介绍Anti RD：王伟琼、张爱华主要内容特点及应用场景神经网络原理我们的经验和教训多线程训练下一步的工作应用场景分类预测时间允许的场合使用并行化等方法加速测试过程很快，且可以方便的使用hadoop平台环境比较固定的场合数据的统计特性变化不大需要定量预测的场合给出未知数据的定量预测神经网络特点优点对噪音数据有较好的适应能力对未知数据具有较好的预测分类能力拟合各种函数得出定量值缺点学习时间较长	0.5779890043217883
bs理解	K最近邻分类模型：原理：训练元组用n个属性描述，每个元组代表n维空间中的一个点，所有的训练元组存放在n维的模式空间。当给定一个未知元组时，KNN搜索该模式空间，找出最接近未知元组的k个训练元组。未知元组指派到它的k个最近邻中的多数类。“邻近性”用距离度量，如欧几里德距离。欧几里德距离：	设元组X1=(X11,X12,…X1n)，X2=(X21,X22,…X2n)，	Dist(X1,X2)=√ ∑ k= 1 n (X1i-X2i) 2 	使用上式之前，对每个属性的值规范化，以防止具有	0.5762788623132599
bs理解	排序及扩展：插入排序，选择排序（冒泡排序），使用二分思想求第k大数，快速排序，非递归的快速排序，使用快排思想求第k大数，归并排序，求逆序数，自然排序算法，堆排序，最小优先级队列，计数排序，桶排序，鸽巢排序（分块排序），基数排序，外部排序：二路归并，K路归并，胜者树，败者树。  算法一：使用插入或者选择排序，得到最大的K个数，时间复杂度为：O(N*k)。 冒泡排序： void swap(int * a,int * b){            //注意	0.5756662147034028
bs理解	克拉玛依公证处:本人因生活在国外，不能亲自到贵单位办理出生证明公证事项，兹授权委托雷春香女士全权代表我办理相关事项。对委托人在办理上述事项过程中所签署的有关文件，我均予以认可，并承担相应的法律责任。委托人：刘佳			委托人身份证号码：654301198608243929被委托人：雷春香		被委托人身份证号码：6526196207113926委托人：刘佳2018年5月24日	0.5756662147034028
bs理解	性能升级性能升级的几个层面：系统结构：模块分解，模块交互，系统构建中的粗略估算。算法和数据结构：获得快速模块的关键：表示数据的结构，操作数据的算法：索引结构及拉链归并。代码调优：分支预测等。循环：将循环体中不改变的变量移动到循环体外；多重循环嵌套顺序。函数调用：inline函数节省函数调用开销：若makefile中不指定至少-O优化，即使声明为inline函数，编译器也不会进行函数内联。内存寻址：避免重复内存寻址。Cpu流水线的分支预测：将满足概率最高的条件放在靠前的位置。	0.5756662147034028
bs理解	业务生成平台用户指南总体说明开发背景下一代网络是业务驱动的网络，在融合的下一代网络上高效、灵活地开发和部署各种丰富多彩的业务，从而提高网络使用率、增加收益的目标，是下一代网络的关键环节。下一代网络的发展要求呼叫与承载相分离、呼叫控制与业务相分离，使业务真正独立于网络，业务开发者不必关心与业务承载相关的底层网络知识以及具体的通信协议，只需利用业务生成平台提供的业务开发工具，就可以开发出灵活丰富且极具个性化的业务。 为了适合多种技术水平的业务开发人员的需要，现在主要有四种业务开发方式：	0.5756662147034028
bs理解	SVM分类内容概要流程图预处理SVM分类器组合分类结果流程图内容概要流程图预处理SVM分类器组合分类结果特征选择特征，以文本行业分类来说，切词term特征的重要性“北京”是个没用的特征“速8”是个有用的特征“轻度”这个词呢？信息增益（Information Gain）   熵H是一个分布是否分散的表征，与信息相反概率估计P(ci) = ci类别的样本数 / 样本总数P(ci|t)  = t出现的属于ci	0.5754556557528216

as字符串重查优化及评估结果	BS代码阅读：BS基本功能：索引相关性切词成分分析offset调权query解析 （where+what）多路归并 综合调权类聚（偏离点）query分类空间调权数据来源点击调权BS代码阅读：bs_cache:map库的term cachemap库term cache操作锁where库term cachewhere库term cache操作锁init_map_term_cache: 初始化map库term cachein	0.9301598653213575
as字符串重查优化及评估结果	As字符串重查优化及评估结果：背景	当bs返回的结果为空，或者返回的结果数小于30，as会进行字符串重查。即将所有的商铺名称及id建立后缀数组(suffix_name,shop_id)。字符串重查时，将检索请求的what query切词，依次取出其中的term，根据term在后缀数组中找到一系列的shop_id，进行去重及过滤，最后将所有term对应的shop_id的列表进行求交，得到结果。结果数的最大值为10000。优化方法：原实现方法：建立后缀数组：求出商铺名称的所有后缀，结构体快	0.9279941188279007
as字符串重查优化及评估结果	贝叶斯分类模型：基础知识：假设	X：是数据元组，由n个属性描述；	H：是某种假设，如数据元组属于某特定类C	P(H|X)：表示给定X的属性描述，找出元组X属于类C的概率举例：X：一位35岁的顾客，收入为4w美元；H：顾客将购买计算机P(H|X)：在X的条件下，H的后验概率。当我们知道顾客的年龄和收入时，顾客X将购买计算机的概率。P(H)：H的先验概率。任意给定顾客将购买计算机的概率，独立与X。P(X|H)：在条件H下，X的后验概率。已知顾客购买了计算机，顾客是一位3	0.9267976881486625
as字符串重查优化及评估结果	排序及扩展：插入排序，选择排序（冒泡排序），使用二分思想求第k大数，快速排序，非递归的快速排序，使用快排思想求第k大数，归并排序，求逆序数，自然排序算法，堆排序，最小优先级队列，计数排序，桶排序，鸽巢排序（分块排序），基数排序，外部排序：二路归并，K路归并，胜者树，败者树。  算法一：使用插入或者选择排序，得到最大的K个数，时间复杂度为：O(N*k)。 冒泡排序： void swap(int * a,int * b){            //注意	0.9259905212572214
as字符串重查优化及评估结果	克拉玛依公证处:本人因生活在国外，不能亲自到贵单位办理出生证明公证事项，兹授权委托雷春香女士全权代表我办理相关事项。对委托人在办理上述事项过程中所签署的有关文件，我均予以认可，并承担相应的法律责任。委托人：刘佳			委托人身份证号码：654301198608243929被委托人：雷春香		被委托人身份证号码：6526196207113926委托人：刘佳2018年5月24日	0.9259905212572214
as字符串重查优化及评估结果	性能升级性能升级的几个层面：系统结构：模块分解，模块交互，系统构建中的粗略估算。算法和数据结构：获得快速模块的关键：表示数据的结构，操作数据的算法：索引结构及拉链归并。代码调优：分支预测等。循环：将循环体中不改变的变量移动到循环体外；多重循环嵌套顺序。函数调用：inline函数节省函数调用开销：若makefile中不指定至少-O优化，即使声明为inline函数，编译器也不会进行函数内联。内存寻址：避免重复内存寻址。Cpu流水线的分支预测：将满足概率最高的条件放在靠前的位置。	0.9259905212572214
as字符串重查优化及评估结果	业务生成平台用户指南总体说明开发背景下一代网络是业务驱动的网络，在融合的下一代网络上高效、灵活地开发和部署各种丰富多彩的业务，从而提高网络使用率、增加收益的目标，是下一代网络的关键环节。下一代网络的发展要求呼叫与承载相分离、呼叫控制与业务相分离，使业务真正独立于网络，业务开发者不必关心与业务承载相关的底层网络知识以及具体的通信协议，只需利用业务生成平台提供的业务开发工具，就可以开发出灵活丰富且极具个性化的业务。 为了适合多种技术水平的业务开发人员的需要，现在主要有四种业务开发方式：	0.9259905212572214
as字符串重查优化及评估结果	K最近邻分类模型：原理：训练元组用n个属性描述，每个元组代表n维空间中的一个点，所有的训练元组存放在n维的模式空间。当给定一个未知元组时，KNN搜索该模式空间，找出最接近未知元组的k个训练元组。未知元组指派到它的k个最近邻中的多数类。“邻近性”用距离度量，如欧几里德距离。欧几里德距离：	设元组X1=(X11,X12,…X1n)，X2=(X21,X22,…X2n)，	Dist(X1,X2)=√ ∑ k= 1 n (X1i-X2i) 2 	使用上式之前，对每个属性的值规范化，以防止具有	0.9259357259789498
as字符串重查优化及评估结果	C专家编程读书笔记难点关键字的用法：关键字用法extern在函数名前，表示该函数全局可见，一般缺省。即一个文件的全局变量和函数对其他文件，具有可见性。在变量或者函数前，表示对象的定义在别处进行。由于重载，在c++中调用以C方式编译的函数时，需要加extern “c”。static隐藏：修饰的对象对其他文件不可见，防止多个文件命名冲突。持久性：修饰的对象，存储在数据段或者bss段，和程序有相同的生命周期。只有一次初始化。3、修饰的变量未初始化时，默认为“0	0.9238555416937714
as字符串重查优化及评估结果	工作6周年5个月小记今天是中国时间8/24/2018，也就是我32岁的生日，这是一个不老也不再年轻的年纪。最近总是因为工作而郁郁寡欢，心中不快，所以决定记录总结一下，希望自己能有所释怀、转变、确立新的目标。从2012年3月31到现在，我已在微软Bing工作6年5个月。在此之前，我在百度实习9个月，在阿里巴巴实习2个月，在搜狗实习1个月。在微软北京CJK relevance组勤恳的工作2年6个月，从级别59升到61，做了1年半的DU, 1年的relevance。总体来说，老板们的风格是相关性主导基础	0.9233559567273402

[DRAFT] Special Topic - Primary Category	Whole Page RelevanceShip Meeting 08/14/2012AgendaSummary of IssuesSpecial TopicsWhole Page Relevance - IssuesTeamIssue Description StatusOwnerDue Action UpdateINTL Mon-GsheldonNo major issuesCaptions MetricsSBS – Monthly 	0.33697504468660217
[DRAFT] Special Topic - Primary Category	Restaurant segment metrics collectionObjectiveTo understand user behavior/engagement on Restaurant answers.Why this is important? The metrics will help us understand:The comparisons between different answersWhat is important to our users and w	0.3281852375652825
[DRAFT] Special Topic - Primary Category	Decision Tree Ensemble decodeAdaboost Decision tree:A forest.  One feature can be multiple nodes.Support Market checkingWord/entity classificationOne or more feature set inputMeaning[DecisionTree]Roots=90  (tree number)Nodes=630 (all n	0.31428799071125374
[DRAFT] Special Topic - Primary Category	TopChainNumber MasterId Label Type Name Phone AddressLine City Website Closed LastYearImpression LCMScore ChainId ChainName Score LPLink SparsedFeatureVector r 873x114637191399090866 0 http://maps.google.com/maps/place?cid=14233605658129796921 Ion Bank 36	0.3106311037334857
[DRAFT] Special Topic - Primary Category	Provider Feature Measured Coverage Corrected Coverage(Exclude No Rating) Improved Coverage Estimate(Include No Rating) Note Amazon Price Amazon Availability Amazon Rating&Count >95% >92% 1. A known client issue:The current logic is to show the rating&cou	0.30709995643182036
[DRAFT] Special Topic - Primary Category	Page number design and summaryBackgroundWe’ve seen in regular DSAT review meetings the DSATs that 2 or more pages are shown in top ten search results which belong to one document or the same topic sections. We want to get the page number to keep only 	0.3034571488599919
[DRAFT] Special Topic - Primary Category	Threshold Query Formulation Deep DiveGoal of the presentation is to communicate our approach for query formulation and get feedback on whether this aligns with overall Threshold goals.OverviewGoals & MetricsQF ModelRoadmapScenariosKey Ta	0.2959465095537005
[DRAFT] Special Topic - Primary Category	Machine Learning Categorization & Popularity2012-08-30 | Nicolas NicolovGoalsShow how categorization and popularity systems work.Introduce important ML concepts.Illustrate ML techniques through examples.(aiming to be self-contained)Categoriz	0.2929356470245117
[DRAFT] Special Topic - Primary Category	Local Category Search Plan3 month StrategyData: Entity categorizationScalable, high precision/recallSegments: Food & Drink, Retail, Service, Auto, HotelMetaStream enrichmentQuery UnderstandingDolphin by defaultConsume PhoneBookQU to im	0.29284477375995516
[DRAFT] Special Topic - Primary Category	Global relevance feature proposalFeature name: Title Match OptimizationPMJin GuoDevJia LiuTestReleaseALTeam site linkExecutive SummaryTitle is the summary/abstract of the document. Title Match is very important to SBS. Through many c	0.28949108338731594

Zhcn transportation segment Optimization by Pattern Engine	Zh-cn Transportation Segment Optimization by Pattern EngineIntroductionThe pattern queries can cover almost 10% in all queries. We can summarize lots of patterns on Query and Document sides for different segments. We can recognize key terms, relations	0.7343946433777923
Zhcn transportation segment Optimization by Pattern Engine	Zh-cn Transportation Segment Optimization by Pattern EngineJia Liu/Allen WangDSATsQuery: 吉林市到查干湖Relevant result title: 吉林市到查干湖怎么走近？_百度知道Irrelevant result title 1: 查干湖,中国查干湖,吉林查干湖,查干湖旅游,查干湖冬捕,国家AAAA ...Irrelevant result title 2: 查干湖_百度百科Irrel	0.7071409049236723
Zhcn transportation segment Optimization by Pattern Engine	Zhcn document classification based on topicJia Liu2012.11.14agendarTraining data selection&crawl&cleanFeature selection&cleanClassifierRating Bad case analysisTrainning data	0.5131744791435322
Zhcn transportation segment Optimization by Pattern Engine	QR Micro SegmentOverviewMicro Segment is way to fix corner case that main Bing ranking pipeline couldn’t fix easily by machine learning. There are many ways to do micro segment. Micro segment can be done in many layers. QR, matching, L1, L2, L3, …. To	0.4509769556853281
Zhcn transportation segment Optimization by Pattern Engine	Zh-cn Document classification based on topicBackgroundWe want to do zh-cn document classification for better understanding the document type and topic. It can help ranking with document and  query category matching. We defined our category system: 69 	0.4452014694744674
Zhcn transportation segment Optimization by Pattern Engine	OPG- Business Continuity PlanTellMeService, Shredder, AugmentationService, Enrichment, UCIService (Insights), Entity ServiceDocument Revision HistoryDateAuthorChange NotesLeader Sign off4/30/2018alyanInitial document5/10/2019alyanU	0.443603766257244
Zhcn transportation segment Optimization by Pattern Engine	Microsoft ConfidentialSeptember 14, 2016Relevance Next and Artificial IntelligenceRelevance and Intent OffsiteFebruary 8thOur PrioritiesExpand our Capabilities towards a full fledged AGI Engine, with focus on Knowledge, NL/Semantic Understandi	0.44014025704926707
Zhcn transportation segment Optimization by Pattern Engine	Introduction to L1Xiao WuSearch Platform Tiger Team AgendaL1 goals and challengesMetrics and measurementL1 ranker and perf optimizationL1 ranking Perf optimizationDebugging tools L1 training and shippingThinking and discussionL1 	0.43212993602065897
Zhcn transportation segment Optimization by Pattern Engine	Containment and Conflation – Sprint  2Story DescriptionDone?In Demo?Implement and ship Segment Studio integration changes for Preconflation and MatchYYIdentify top K entity setYYRoot cause why entities have too many identifiersYY	0.4290164013779126
Zhcn transportation segment Optimization by Pattern Engine	Query Rewriting Micro SegmentWhy QR Micro SegmentMicro Segment is way to fix corner case that main Bing ranking pipeline couldn’t fix easily by machine learningThere are many ways to do micro segment. Micro segment can be done in many layers. QR, 	0.41781576750309896

Zh-Cn publication date design doc	Zh-cn Publication date design docBackgroundDesignPublication date from wrapstarPublication date from URLPublication date from titlescore(c1) = w11*f1+w12*f2+w13*f3+w14*f4+w15*f5+bias1score(c2) = w21*f1+w22*f2+w23*f3+w24*f4+w25*f5+bias2Pack	0.6176885974188598
Zh-Cn publication date design doc	Zh-cn Document classification based on topicBackgroundWe want to do zh-cn document classification for better understanding the document type and topic. It can help ranking with document and  query category matching. We defined our category system: 69 	0.5517152050895362
Zh-Cn publication date design doc	Publication date optimization for zh-cn marketBackgroundPublication date is a very fundamental and important feature. It can help fresh ranking, whole page user experience: caption date show and freshness internal metrics, also to solve mainline out	0.5101710317474271
Zh-Cn publication date design doc	DU work items on zh-cn market　　Jia Liu2013-05-14AgendaSerp classifierWrapstar rating signalsTaobao, tmall; qna; novel; videoGeneral classiferUrl-basedTopic-basedPage number extractionName entity recognitionPerson, location, organiz	0.4196167477682112
Zh-Cn publication date design doc	Zhcn document classification based on topicJia Liu2012.11.14agendarTraining data selection&crawl&cleanFeature selection&cleanClassifierRating Bad case analysisTrainning data	0.40383169150446757
Zh-Cn publication date design doc	Publication Date Optimization Design and Implement For zh-cn MarketReview and CommentMei Yang; Ted WildAuthorJia LiuDesignBackgroundPublication date is a very fundamental and important feature. It can help fresh ranking, solve mainline out	0.39715749655614613
Zh-Cn publication date design doc	Zh-cn Transportation Segment Optimization by Pattern EngineJia Liu/Allen WangDSATsQuery: 吉林市到查干湖Relevant result title: 吉林市到查干湖怎么走近？_百度知道Irrelevant result title 1: 查干湖,中国查干湖,吉林查干湖,查干湖旅游,查干湖冬捕,国家AAAA ...Irrelevant result title 2: 查干湖_百度百科Irrel	0.3609637935962167
Zh-Cn publication date design doc	DU items studyJia Liu2013-05-14AgendaPublication dateMain body blockDocument qualityurl static featuresPublication dateFreshness rankingYear in title, year in url, publication dateEn-us publication date coverage is ~20%Zh-cn public	0.32886597514515065
Zh-Cn publication date design doc	Site Quality ClassificationGuihong CaoDefinition of the ProblemWhat is site quality?Google’s definition includes the following dimensionsDuplicated content within the siteTrustworthyOn demand media? Quality controlSite authorityAuthor 	0.2919211509695097
Zh-Cn publication date design doc	PERM Labor Certification Questionnaire:  Technical (continued)PERM Labor Certification Questionnaire (Technical)Please complete the information requested in this questionnaire carefully.  This information is necessary for the legal analysis and prepar	0.28994277351018916

Zh-Cn Document Classification Based On Url design doc	Zh-cn Document classification based on topicBackgroundWe want to do zh-cn document classification for better understanding the document type and topic. It can help ranking with document and  query category matching. We defined our category system: 69 	0.7711303315706023
Zh-Cn Document Classification Based On Url design doc	Document classification based on urlBackgroundWe want to do document classification for better understanding the document type and document with query category match for ranking.  We will do zh-cn document classification based on url first, then docum	0.6615126538066024
Zh-Cn Document Classification Based On Url design doc	Zh-cn Publication date design docBackgroundDesignPublication date from wrapstarPublication date from URLPublication date from titlescore(c1) = w11*f1+w12*f2+w13*f3+w14*f4+w15*f5+bias1score(c2) = w21*f1+w22*f2+w23*f3+w24*f4+w25*f5+bias2Pack	0.6220168205798602
Zh-Cn Document Classification Based On Url design doc	Zhcn document classification based on topicJia Liu2012.11.14agendarTraining data selection&crawl&cleanFeature selection&cleanClassifierRating Bad case analysisTrainning data	0.604230554538519
Zh-Cn Document Classification Based On Url design doc	Zh-cn Transportation Segment Optimization by Pattern EngineJia Liu/Allen WangDSATsQuery: 吉林市到查干湖Relevant result title: 吉林市到查干湖怎么走近？_百度知道Irrelevant result title 1: 查干湖,中国查干湖,吉林查干湖,查干湖旅游,查干湖冬捕,国家AAAA ...Irrelevant result title 2: 查干湖_百度百科Irrel	0.5735068744876061
Zh-Cn Document Classification Based On Url design doc	Publication date optimization for zh-cn marketBackgroundPublication date is a very fundamental and important feature. It can help fresh ranking, whole page user experience: caption date show and freshness internal metrics, also to solve mainline out	0.5196895101923051
Zh-Cn Document Classification Based On Url design doc	Keyword Predictor Design DocumentName: Ruchir RastogiMentor: Jia LiuManager: Leon ZhangProject overviewThe goal of this project is to design a machine-learning model that can predict keywords in a local query for improving local search relevance	0.456973817226693
Zh-Cn Document Classification Based On Url design doc	DU work items on zh-cn market　　Jia Liu2013-05-14AgendaSerp classifierWrapstar rating signalsTaobao, tmall; qna; novel; videoGeneral classiferUrl-basedTopic-basedPage number extractionName entity recognitionPerson, location, organiz	0.443557495117732
Zh-Cn Document Classification Based On Url design doc	Zh-cn Transportation Segment Optimization by Pattern EngineIntroductionThe pattern queries can cover almost 10% in all queries. We can summarize lots of patterns on Query and Document sides for different segments. We can recognize key terms, relations	0.4272189118767682
Zh-Cn Document Classification Based On Url design doc	Entity Categorization Using Convolutional Neural NetworkWeiwu Zhu8/23/2018AgendaMotivationCNN introductionCNN in NLPCNN based entity categorizationMeasurementMotivationTaxonomy mapping is not scalable (Feature Normalization)Nee	0.4263872540185497

Zh-Cn Document Classification Based On Topic design doc	Zh-cn Document classification based on topicBackgroundWe want to do zh-cn document classification for better understanding the document type and topic. It can help ranking with document and  query category matching. We defined our category system: 69 	0.840737746800867
Zh-Cn Document Classification Based On Topic design doc	Zhcn document classification based on topicJia Liu2012.11.14agendarTraining data selection&crawl&cleanFeature selection&cleanClassifierRating Bad case analysisTrainning data	0.6517127532309889
Zh-Cn Document Classification Based On Topic design doc	Document classification based on urlBackgroundWe want to do document classification for better understanding the document type and document with query category match for ranking.  We will do zh-cn document classification based on url first, then docum	0.5546049244186627
Zh-Cn Document Classification Based On Topic design doc	Zh-cn Transportation Segment Optimization by Pattern EngineJia Liu/Allen WangDSATsQuery: 吉林市到查干湖Relevant result title: 吉林市到查干湖怎么走近？_百度知道Irrelevant result title 1: 查干湖,中国查干湖,吉林查干湖,查干湖旅游,查干湖冬捕,国家AAAA ...Irrelevant result title 2: 查干湖_百度百科Irrel	0.5138364691409969
Zh-Cn Document Classification Based On Topic design doc	File Relevance Experimentation Design DocRecall AnalysisTest the search quality of external services like OLS, 3S, QF and SPO Search.Search scenarios: 0-term search, term search, 3S (Insert File and Attach File).Compare the recall: diff of returne	0.47574672615518404
Zh-Cn Document Classification Based On Topic design doc	Zh-cn Transportation Segment Optimization by Pattern EngineIntroductionThe pattern queries can cover almost 10% in all queries. We can summarize lots of patterns on Query and Document sides for different segments. We can recognize key terms, relations	0.4749004918609317
Zh-Cn Document Classification Based On Topic design doc	Keyword Predictor Design DocumentName: Ruchir RastogiMentor: Jia LiuManager: Leon ZhangProject overviewThe goal of this project is to design a machine-learning model that can predict keywords in a local query for improving local search relevance	0.4657771987298685
Zh-Cn Document Classification Based On Topic design doc	Publication date optimization for zh-cn marketBackgroundPublication date is a very fundamental and important feature. It can help fresh ranking, whole page user experience: caption date show and freshness internal metrics, also to solve mainline out	0.4532877341447154
Zh-Cn Document Classification Based On Topic design doc	Zh-cn Publication date design docBackgroundDesignPublication date from wrapstarPublication date from URLPublication date from titlescore(c1) = w11*f1+w12*f2+w13*f3+w14*f4+w15*f5+bias1score(c2) = w21*f1+w22*f2+w23*f3+w24*f4+w25*f5+bias2Pack	0.4478765305468437
Zh-Cn Document Classification Based On Topic design doc	Entity Categorization Using Convolutional Neural NetworkWeiwu Zhu8/23/2018AgendaMotivationCNN introductionCNN in NLPCNN based entity categorizationMeasurementMotivationTaxonomy mapping is not scalable (Feature Normalization)Nee	0.405056476635138

YPCutoff Selection	YPCutoff Selection                                                                                    -Ganesh Poomal GirirajanQuery Flow in IndexFilterSet GenerationL1 RankingL2 RankingExampleQuery: Southeast{Miami,Florida}-broward county sc	0.3912465977615694
YPCutoff Selection	Entity Selection Pipeline Design DocScope:This document covers the design for entity selection pipeline in GDPV3. Near-Dupe clustering is not covered in this v1 version. The goal for this pipeline is to reduce junk rate and improve NII by stamping pub	0.20169280374987192
YPCutoff Selection	PA Selection StackKeng-hao Chang3/8/2017AgendaQuery (offer) understandingRetail classifierCategorizerCRFSelection algorithmsRIIRNGSRanking methodsL0, L1, L1.5, L2, Attribute-awareRetail experiencePA stack via Components*RnR	0.1981190964242022
YPCutoff Selection	Pthreads mutex vs Pthreads spinlock 锁机制(lock) 是多线程编程中最常用的同步机制,用来对多线程间共享的临界区(Critical Section) 进行保护。Pthreads提供了多种锁机制,常见的有：1) Mutex（互斥量）：pthread_mutex_***2) Spin lock（自旋锁）：pthread_spin_***3) Condition Variable（条件变量）：pthread_con_***4) Read/Write 	0.19049401809626082
YPCutoff Selection	唐蕾电话: (+86) 180-0132-3861Email: tanglei91@126.com工作经历                                                                    04/2014至今 :    	中国电信集团系统集成有限责任公司 软件测试工程师1.招标测试时间:05/2016至今项目描述：通过招标测试帮助甲方找到合适的厂家做他们项目中的某些模块。项目职责：负责招标测试跟产品经理讨论并细化需	0.17254898245536626
YPCutoff Selection	L4 Experiment PipelineDate: Aug 20th, 2013Author: Bangyong LiangMotivation:L4’s functionality is to merge results from multiple queries. L4 has two types of merging strategies. One is query level merger and the other one is document level merger. 	0.1692978082848896
YPCutoff Selection	Index Quality UpdateAgendaMetrics UpdateSelection Model ImprovementRecall TierOffice ImprovementChallenges and Pain PointsHow to measure index quality?Ideally: sampling from all “good” images and see how much we covered.sampling from a	0.16742471808780512
YPCutoff Selection	客户价值模型分享和讨论WHY/WHAT/HOWECom ASEA  ——  Advertisement Search Analysis2010-12-29为什么要做客户模型客户价值度模型客户关注点模型客户忠诚度模型……常用的客户价值模型RFM模型R(Recency)表示客户最近一次购买的时间有多远；F(Frequency)表示客户在最近一段时间内购买的次数；M (Monetary)表示最近一段时间内购买的金额2维RFM（消除购买次数与购买额之间的多重	0.16036900153855396
YPCutoff Selection	贴吧PHP交互层演进历程&CAMEL简介zhouren@baidu.com演进历程	随交互层演化划分出四个阶段思考	交互层需要解决那些问题？	怎样解决这些问题？CAMEL介绍	CAMEL也就是贴吧PHP中间层，用于解决交互层方面的问题；	CAMEL，骆驼（沙漠之舟），寓意：中间层在无论多么恶劣的环境下，也要提供良好的运输能力；SUMMERY背景LAMP架构的初次尝试；PHP系统的流量在100万～1000万；跨系统交互少；产出：随club项	0.15975390734254327
YPCutoff Selection	SVM分类内容概要流程图预处理SVM分类器组合分类结果流程图内容概要流程图预处理SVM分类器组合分类结果特征选择特征，以文本行业分类来说，切词term特征的重要性“北京”是个没用的特征“速8”是个有用的特征“轻度”这个词呢？信息增益（Information Gain）   熵H是一个分布是否分散的表征，与信息相反概率估计P(ci) = ci类别的样本数 / 样本总数P(ci|t)  = t出现的属于ci	0.15706151163437215

Wrapstar rating signals for zh-cn documents	Wrapstar rating signalsfor zh-cn documentsJia LiuWrapstar rating signals for rankingWrapstar Taobao ratingWrapstar Tmall ratingWrapstar Qna ratingWrapstar Book ratingWrapstar Video ratingDsats examplesTaobao examplesQuery=“蓝色休闲裤	淘宝”	0.811838295131893
Wrapstar rating signals for zh-cn documents	Zh-cn Document classification based on topicBackgroundWe want to do zh-cn document classification for better understanding the document type and topic. It can help ranking with document and  query category matching. We defined our category system: 69 	0.5177544931160515
Wrapstar rating signals for zh-cn documents	Zh-cn Publication date design docBackgroundDesignPublication date from wrapstarPublication date from URLPublication date from titlescore(c1) = w11*f1+w12*f2+w13*f3+w14*f4+w15*f5+bias1score(c2) = w21*f1+w22*f2+w23*f3+w24*f4+w25*f5+bias2Pack	0.4295560715086969
Wrapstar rating signals for zh-cn documents	DU work items on zh-cn market　　Jia Liu2013-05-14AgendaSerp classifierWrapstar rating signalsTaobao, tmall; qna; novel; videoGeneral classiferUrl-basedTopic-basedPage number extractionName entity recognitionPerson, location, organiz	0.41431148928970324
Wrapstar rating signals for zh-cn documents	Deal Ranking Improvement & MeasurementBackgroundAfter we shipped deal understanding, bad deals filtering, deal ranking for the entity search deals and popular deals nearby. We want to measure and improve our deal ranking based on user behaviors. We ca	0.3644770009592671
Wrapstar rating signals for zh-cn documents	NGram Language Model based Url Breaking – Design DocumentStatusOngoingIntroductionUrl is a very important signal for ranking, particularly for tail queries and navigation queries. This signal has 100% url coverage, which really makes it different 	0.33769571376028745
Wrapstar rating signals for zh-cn documents	Zhcn document classification based on topicJia Liu2012.11.14agendarTraining data selection&crawl&cleanFeature selection&cleanClassifierRating Bad case analysisTrainning data	0.33672357385471036
Wrapstar rating signals for zh-cn documents	Bing Ads Insight Track Weekly Review11/09/2015Primary KPIs  -- Product UsageCallout –NA- A memory cache mechanism was deployed last week for data platform, which benefits around half traffic and latency decreased significantly.Primary KPIs –	0.3359983342318634
Wrapstar rating signals for zh-cn documents	Introduction to dynamic ranking Xiao WuOutlinesIntroductionRelevance MeasurementDynamic rankingRanking FeaturesRanking DataRanking modelsRelevance ExperiementIntroductionWhat is dynamic rankingRanking based on query dependent featu	0.31577190915051995
Wrapstar rating signals for zh-cn documents	Bing Ads Insight Track Weekly Review9/07/2015Primary KPIs  -- Product UsageCallout –NAPrimary KPIs – Platform ServiceHighlights/Lowlights: (http://adspulse/Report/61998 ) Callout – N/AUser feedbacks (Premium Tool Phase 1 release) 	0.3146038004320717

WrapStar On-Demand Design	Wrapstar rating signalsfor zh-cn documentsJia LiuWrapstar rating signals for rankingWrapstar Taobao ratingWrapstar Tmall ratingWrapstar Qna ratingWrapstar Book ratingWrapstar Video ratingDsats examplesTaobao examplesQuery=“蓝色休闲裤	淘宝”	0.5869227575849638
WrapStar On-Demand Design	WrapStar On-Demand DesignDrafted by ZiliuContentsContext2Design Goals2Automation2Deployment Agility2High Availability2Non-Goals2Metrics2Required Changes3Orchestration3AP Migrations3Pipeline Evolution3Tools/services refactoring3	0.5275198509571867
WrapStar On-Demand Design	Deal Ranking Improvement & MeasurementBackgroundAfter we shipped deal understanding, bad deals filtering, deal ranking for the entity search deals and popular deals nearby. We want to measure and improve our deal ranking based on user behaviors. We ca	0.4107699235145422
WrapStar On-Demand Design	Deal Understanding and RankingBackgroundDeal is a very big segment in Bing Opal. We crawl store and single deals/coupons regularly from websites like groupon.com, coupons.com, restaurants.com, retailmenot.com, dealcatcher.com, dealplus.com and so on. 	0.347579341590506
WrapStar On-Demand Design	Scraper overview(and more)Ofer ShterlingSean KingContentBrag.Demo (maybe)Throw some dirt.Suggest the Scraper isn’t that interesting.Recurrences tool.I hope I won’t have to show to many workflow.ScraperWe have between 500 to 1.5k sc	0.3203017571136404
WrapStar On-Demand Design	SKI Contextual Reranking V1 design doc User ScenarioWhole page relevance of “All Tab” in the SerpletContextual relevance of “File Tab” in the Serplet DeliverablesMicrosoft search serves as an intelligence service to take user query and return be	0.29441603190828347
WrapStar On-Demand Design	PBA Dependency and DebugMing Wu2014-01-28PBA DependenciesLocation Understanding (LES/BLU)Location info (explicit/implicit) – fulfill detailed location infoProvide location related features to phonebook CRFXapQuServiceAnswer (QAS)For most c	0.2709864107854577
WrapStar On-Demand Design	Page number design and summaryBackgroundWe’ve seen in regular DSAT review meetings the DSATs that 2 or more pages are shown in top ten search results which belong to one document or the same topic sections. We want to get the page number to keep only 	0.26865116806928635
WrapStar On-Demand Design	QR Team ReviewJan 2017Team IntroductionConceptXDeep QRAgendaQR Team MembersDev Manager: Ciya LiaoLeads: Garrett Kaminaga, Jingwen Lu, Saekoo Lee, Gord LueckPMs: Shyam Jayasankar, Jie CaiSTC-A Speller team: Yongen Gong and his teamWha	0.2570957752787173
WrapStar On-Demand Design	Zh-cn Publication date design docBackgroundDesignPublication date from wrapstarPublication date from URLPublication date from titlescore(c1) = w11*f1+w12*f2+w13*f3+w14*f4+w15*f5+bias1score(c2) = w21*f1+w22*f2+w23*f3+w24*f4+w25*f5+bias2Pack	0.25227135476418483

Word representations	Word representationsMotivationWhy word representations?StructureWhy vectors?Distance and similarityBuild models that will automatically understand language for us.Vector space modelsVector space modelsCount based methodsDSM (distribu	0.5843610272014975
Word representations	Keyword predictor-Ganesh Poomal -KefengOutlineThe problem and the objective for Keyword predictorTraining Data CollectionModel and FeaturesResultsKeyword PredictorProblem    In a search engine, user expresses their need for information	0.2870914164697398
Word representations	Threshold Query Formulation Deep DiveGoal of the presentation is to communicate our approach for query formulation and get feedback on whether this aligns with overall Threshold goals.OverviewGoals & MetricsQF ModelRoadmapScenariosKey Ta	0.23510658036317938
Word representations	Keyword Prediction for Local SearchesRuchir RastogiMentor: Jia LiuManager: Leon ZhangOutlineProblem statementTraining data and clean-up strategiesConditional random field (CRF) modelsDeep learning modelsEnd to end measurementConclusi	0.21764429026685117
Word representations	alterationsalterations: product goalimprove recallby adding terms (not replacing or dropping user-entered terms)using word:which are synonyms to the original terms(we are re-examining each of these for vnext)alterations: general principl	0.21674273560493673
Word representations	Entity Pane and Fact AnswerPresenter: Ze TianJun 25, 2013IntroductionIntroductionIntroductionProblems to SolveDoes the user search for entities or facts of entities?E.g. “who is msft ceo” (Entity: Microsoft, Fact: Chief Executive O	0.21013836747552997
Word representations	Wind Up Impact on Existing adInsight Feature Plan03/25/2015ContextTo Enable “Wind Up for Premium” as high priority, we decide to make following resource adjustmentImpact to Existing Product/Feature AreaFocus AreaProducts/FeaturesResource	0.19773243832611692
Word representations	QR MicrosegmentsSandeep AparajitAgendaWhat are microsegments?How does microsegment work in CAL?How can I add my own microsegment?DemoQuestions/SuggestionsWhat are Microsegments?Microsegment is a technique using which you can alter the be	0.18066386032687437
Word representations	Query Rewriting Micro SegmentWhy QR Micro SegmentMicro Segment is way to fix corner case that main Bing ranking pipeline couldn’t fix easily by machine learningThere are many ways to do micro segment. Micro segment can be done in many layers. QR, 	0.17026313578093652
Word representations	No Results Workflow ImprovementsBackgroundToday’s No Results workflow looks at the number of documents returned by WebAnswer, and if it is exactly zero, will make a second call to alterations for aggressive treatment, and a second call to WebAnswer wi	0.16877025292380918

Windows Search RS5 Updates	Windows Search RS5July 9, 2018ContextCortana branded searchbox in taskbar has two key experiences:A speech first Cortana NL experienceA search first typing experience – we refer to this as Windows SearchWindows Search Key StatsUSERS: 160m mo	0.453754423838464
Windows Search RS5 Updates	CAL User’s GuideLast Update April 5, 2013 by Garrett KaminagaChange Log4/5/13garretkSkeleton outline, operational detailsOverviewCAL (Combined ALterations) analyzes the spell-corrected user query, and attempts to augment it to improve releva	0.2831111548553279
Windows Search RS5 Updates	Local Search Popularity V2 DesignBing Local SearchDevXiaohui Liu, Fengxia PanPMDave BargeronMilestoneAl. M1ContributorsFeature Bug IDSignoffPM Spec Linkhttps://microsoft.sharepoint.com/teams/localsearch/_layouts/15/WopiFrame.aspx?s	0.28166942099413217
Windows Search RS5 Updates	Restaurants Features and ToolsReview SnippetXAPOSearchQueryWPOLERWPO OSCacheItemCacheIdList of YpIdsFiltersSorterEntityUpdate PostFixEntity Update OSCache IdCache ItemYpId and PostFixUXReview Snippet Data GroupCac	0.2725569864772562
Windows Search RS5 Updates	Run web-search-like query against my dataSame Bing Web Search Indexing and Ranking engineIndex in a secondTransparent and real time index sync, no complex index-gen pipelinePrototype in an hourFast self-onboarding with freemium account, schema-d	0.2675046441790091
Windows Search RS5 Updates	QueryString Category owner Searchvote url 寇仲最后和谁在一起 ranking  xiaopeng http://searchvote.com/default.aspx?reviewid=209877 布里斯班 ranking  xiaopeng http://searchvote.com/default.aspx?reviewid=211685 必应词典 ranking  xiaopeng http://searchvote.com/default.aspx?re	0.26552451432203744
Windows Search RS5 Updates	Bing Local Search				Phonebook vNext Design DocumentDev ownerMickadBuddy dev(s)MichstePM ownerDabargerContributorsFeature areaMilestoneTable of contents1	Overview	32	Goals/Non Goals	53	Dependencies	64	Risks/Open Issues	75	0.26084445980407805
Windows Search RS5 Updates	Location and Data Services Team all hands10/08/2014AgendaCelebrate – Wei, 5minsLocal partners – Andy, 10minsLocal Data Services – Alex, 15minsGeocoder and GeoSpatial Services – Jai, 20minsLocation and Autosuggest Services – Sid, 15minsBing	0.2548674389949579
Windows Search RS5 Updates	CosmosScope > StreamSetsHiren Patel & Saveen Reddy2014/02/06© 2012 Microsoft Corporation. All rights reserved. Microsoft, Windows, and other product names are or may be registered trademarks and/or trademarks in the U.S. and/or other countries.The	0.25188397489662073
Windows Search RS5 Updates	AgendaBusiness Update (20 min)Guest Speaker - Saurabh(20 min)FY19 Update (40 min)New Hires / Anniversaries (10 min)Demos (20 min)Q&A (10 min)Bing Dashboard – December ‘18- Harry Level GoalGreen : on / above targetOrange :  -ve trend 	0.24916628477395275

Whole Page Relevance - Issues	Whole Page RelevanceShip Meeting 08/14/2012AgendaSummary of IssuesSpecial TopicsWhole Page Relevance - IssuesTeamIssue Description StatusOwnerDue Action UpdateINTL Mon-GsheldonNo major issuesCaptions MetricsSBS – Monthly 	0.623562048440111
Whole Page Relevance - Issues	Microsoft ConfidentialSeptember 14, 2016Relevance Next and our Path to AGIAll HandsFeb 10th 2016Relevance Next and our Path to AGIRelevance OpportunitiesAGI: Project Turing Relevance PowerSubstrate RelevanceDemos! Q&AAgendaFY16	0.33226334591389517
Whole Page Relevance - Issues	Relevance Experimentation with DUOverviewThe ideal end state for any relevance improvement would consist of having one or more DU features shipped in the index that is then leveraged by the latest production ranker. This would achieve the highest leve	0.3321336769718268
Whole Page Relevance - Issues	Global relevance feature proposalFeature name: Title Match OptimizationPMJin GuoDevJia LiuTestReleaseALTeam site linkExecutive SummaryTitle is the summary/abstract of the document. Title Match is very important to SBS. Through many c	0.2825623061168663
Whole Page Relevance - Issues	 Core Web RelevanceInformation Platform GroupBing Spam & JunkFeature OwnersProgram ManagersMichael AbboudDevelopersPavel Karpovich, Lidong Zhao, Gregory Minasyants, Ashok Ponnuswami,  Eugene Remizov, Mikhail BorbotDev ManagerLuke ChenM	0.26963710213453285
Whole Page Relevance - Issues	Microsoft ConfidentialSeptember 14, 2016Relevance Next and Artificial IntelligenceRelevance and Intent OffsiteFebruary 8thOur PrioritiesExpand our Capabilities towards a full fledged AGI Engine, with focus on Knowledge, NL/Semantic Understandi	0.26391422161184325
Whole Page Relevance - Issues	Relevance Debug InfrastructureProblemFrequent  daily metric fluctuationRelevance gain negated by regressions from Sep to Oct 2013Painful to investigateChallengeLocal stack is complex with lots of componentsVarious relevance events mixed toge	0.262360468113561
Whole Page Relevance - Issues	Leveraging Satori Knowledge Graph in Web Ranking StackMicroSegment and Index ServeThe demo is about how to leverage Satori Knowledge Graph in Web ranking. It is joint work among relevance microsegment, Satori and index serve teams.MotivationSome	0.2573877579537463
Whole Page Relevance - Issues	File Relevance Experimentation Design DocRecall AnalysisTest the search quality of external services like OLS, 3S, QF and SPO Search.Search scenarios: 0-term search, term search, 3S (Insert File and Attach File).Compare the recall: diff of returne	0.2502091355861581
Whole Page Relevance - Issues	Leveraging Satori Knowledge in Web Ranking StackMicroSegment and Index ServeMotivationTarget at semantic queries (*defined by MALTA)Often contain more than one entity and relationSometimes involve entity inferenceTerm matching may not handle s	0.229387093809022

WPO_Local_Relevance_201703	WPO Local RelevancePing Yin2017-03-21OverviewWPO’s role in local relevance pipelineLocal Entity StampingArchitecture overviewWPO Local Relevance Models.Query: exton mall, User location: Wallingford, PAWPO RolesExtract/detect all entity	0.6555572095822148
WPO_Local_Relevance_201703	WPO Local Relevance Tech TalkWPO Local Relevance TeamOverviewWPO’s role in local relevance pipelineLocal ExperienceArchitecture overviewMetricsWPO Local Relevance Model IntroductionWPO Query understanding and Location understandingWhy do	0.6532498199697311
WPO_Local_Relevance_201703	Local Relevance SQR (en-us + en-ca)March 14, 2017AgendaContext & Scope:EN-US & EN-CA, Mobile and SERP relevance focusedPBA (pre-web) relevance focusedQuality measurements DSAT examplesGeneral issuesKey Segments (Restaurants, Hotels, Re	0.4164346537015716
WPO_Local_Relevance_201703	Distance Model, LDS, L3Knowledge SharingNikita Melnichenko, Bing Local2017-04-21Overview of PBA relevance flow in FeedsL1Keyword matchWPOL2 levelRankerTruncationCategory matchName matchLogical DistanceUI sortingGIMXIMGDM	0.4129950051882425
WPO_Local_Relevance_201703	Core Web RelevanceFY16 H2 PlanCore Web RelevanceFY16 H2 PlanCore Web RelevanceFY16 H2 PlanCore Web RelevanceFY16 H2 Plan	0.3874432857886693
WPO_Local_Relevance_201703	Local Junk Detection and DemotionJia Liu2017-06-14GDP Pipeline View: local data pipelineTriple StoreGOALStore every entity as a set of triples.Track all changes to an entity.TripleColumnDetailsSubjectThe guid of a triple’s pa	0.38613098481756514
WPO_Local_Relevance_201703	Distance Model Updates in LDCG V2Local Relevance and Measurement TeamAgendaDistance feature in LDCG V1Why was the switch to computing distance made?First implementation of Distance feature in LDCG V2, & improvement areasProcess followed for 	0.36669842680287446
WPO_Local_Relevance_201703	BLU V3 Minghua Zhang      01/26/2016Next version of BLU Relevance Infrastructure​OutlineWhy BLU v3BLU v3 DesignCurrent StatusFuture WorkWhy BLU v3 (1)Limitations of current BLU infrastructureFeaturesCouldn’t utilize QAS feature	0.35514941131071215
WPO_Local_Relevance_201703	Relevance ServiceScenarioIconApplicationDoc typeCandidatesModelRun0-termWord;OutlookWin32 client.All file typesMRUReuse ContentModel 1Client0-termPower PointWin32 client.Only ppt typeLocal + MRUReuse Conte	0.3546903688174205
WPO_Local_Relevance_201703	L3 Distance Model for LocalNikita Melnichenko, Bing Local2016-04-12AgendaIntroduction to the Distance problemPrevious workA new approach: experiments and designResultsFuture developmentIntroduction to the Distance problemWe say “it’s a	0.3538000489906391

WPO Local Relevance Tech Talk	WPO Local Relevance Tech TalkWPO Local Relevance TeamOverviewWPO’s role in local relevance pipelineLocal ExperienceArchitecture overviewMetricsWPO Local Relevance Model IntroductionWPO Query understanding and Location understandingWhy do	0.7948115649846467
WPO Local Relevance Tech Talk	WPO Local RelevancePing Yin2017-03-21OverviewWPO’s role in local relevance pipelineLocal Entity StampingArchitecture overviewWPO Local Relevance Models.Query: exton mall, User location: Wallingford, PAWPO RolesExtract/detect all entity	0.5771175931214048
WPO Local Relevance Tech Talk	Local Junk Detection and DemotionJia Liu2017-06-14GDP Pipeline View: local data pipelineTriple StoreGOALStore every entity as a set of triples.Track all changes to an entity.TripleColumnDetailsSubjectThe guid of a triple’s pa	0.41965351565464903
WPO Local Relevance Tech Talk	Distance Model Updates in LDCG V2Local Relevance and Measurement TeamAgendaDistance feature in LDCG V1Why was the switch to computing distance made?First implementation of Distance feature in LDCG V2, & improvement areasProcess followed for 	0.39757032521185054
WPO Local Relevance Tech Talk	L3 in LocalKefeng DengOutlineL3 IntroductionUse L3 in localL3 exampleL3 introductionFor Local: 28 IS machines per row, about 5 million entities per machine. MinBLA = 50L3 introductionL3 featuresSet featuresFeature Statistics for top 	0.38867884538435765
WPO Local Relevance Tech Talk	Microsoft IT Technology AdoptionSee past and upcoming  talks at http://aka.ms/ITTechTalksSubscribe to IT Tech Talks DL @IT Tech Talk Invitethere’s a link on the Tech Talks siteQuestions about Tech Talks? Ask Justin Lane or Susan Sims.IT Tech T	0.3821679657863913
WPO Local Relevance Tech Talk	Local Relevance SQR (en-us + en-ca)March 14, 2017AgendaContext & Scope:EN-US & EN-CA, Mobile and SERP relevance focusedPBA (pre-web) relevance focusedQuality measurements DSAT examplesGeneral issuesKey Segments (Restaurants, Hotels, Re	0.37575457428184506
WPO Local Relevance Tech Talk	L3 Distance Model for LocalNikita Melnichenko, Bing Local2016-04-12AgendaIntroduction to the Distance problemPrevious workA new approach: experiments and designResultsFuture developmentIntroduction to the Distance problemWe say “it’s a	0.35866606159146097
WPO Local Relevance Tech Talk	Text Latitude Longitude S0:Local_L3DCG3 G0:Local_L3DCG3 S1:Local_L3DCG3 S2:Local_L3DCG3 Assignment RootCause(BadMetastream,PartialMatch,Cal,BadKeyword,OtherQU,Ranker,BingNotStable,Scraping,Metrics,MicroSegment,JudgeNoise,Unknown,BadEntity) BTC CanBeResolv	0.3570617011302631
WPO Local Relevance Tech Talk	Distance Model, LDS, L3Knowledge SharingNikita Melnichenko, Bing Local2017-04-21Overview of PBA relevance flow in FeedsL1Keyword matchWPOL2 levelRankerTruncationCategory matchName matchLogical DistanceUI sortingGIMXIMGDM	0.35357876113085884

Vortex4WebRankingV1	VORTEXTowards An E2E Vector-based Search StackProjects OverviewVector-based Retrieval(ANN recall path)L2 vector injectionVector-based RankingDeep Dejavu SpaceVWideDeep in FusionProjects OverviewVector-based RetrievalL2 vector i	0.4658554569787186
Vortex4WebRankingV1	libsvm的相关工具和使用方法libsvm工具：编译并能够使用 : libsvm-3.0.tarsvm的基本原理 ： libsvm-guide.pdflibsvm相关的grid工具 : [sep@ai-iknow-septest1.ai01.baidu.com auto_classifier]$ pwd grid_tools.py /home/sep/yangfan/Basic_Tools/for_lyq/auto_classifier特征筛选的相关资料和方法了解特征筛选方法	0.3396562760772078
Vortex4WebRankingV1	Relevance ServiceScenarioIconApplicationDoc typeCandidatesModelRun0-termWord;OutlookWin32 client.All file typesMRUReuse ContentModel 1Client0-termPower PointWin32 client.Only ppt typeLocal + MRUReuse Conte	0.3202757080988537
Vortex4WebRankingV1	Nlp情感分析工具使用执行步骤：分词执行程序：Shenbian_exlib_segpos使用说明： 	usage: ./Shenbian_exlib_segpos  segDictPath tagDictPath inputfile outputtype      			exDictLib > outputfile具体使用举例：     ./Shenbian_exlib_segpos ../../../../lib_wordseg/worddict_1-3-4-3_PD_B	0.3137827126797794
Vortex4WebRankingV1	成交日期 买卖标志 成交价格 成交数量 成交金额 2016年亏319 2015及2016年已完结 20160105 买入 100 897 20160108 卖出 8 200 1600 20150615 买入 100 1889 20150615 买入 100 1840 20150624 卖出 100 1585 20150720 买入 100 1073 20150721 买入 100 1098 20150721 买入 100 1086 20150723 买入 100 1110 20150818 卖出 500 	0.30802836744518003
Vortex4WebRankingV1	 阿里浏览器DNS解析加速布可2010.12.31AgendaDNS解析过程DNS协议阿里浏览器DNS解析加速浏览器查找域名的IPtaobao.com浏览器缓存(2-30min)系统缓存(DNS client resolver cache)Local DNS递归查询->dns1.禁用IE的dns缓存：Start Registry Editor. Locate and click the following key in the reg	0.2955060579777268
Vortex4WebRankingV1	HIVE介绍简介是什么hive是一个基于hadoop的数据仓库。使用hadoop-hdfs作为数据存储层；提供类似SQL的语言（HQL），通过hadoop-mapreduce完成数据计算；通过HQL语言提供使用者部分传统RDBMS一样的表格查询特性和分布式存储计算特性。类似的系统有yahoo的pig[1] ，google的sawzall[2]，microsoft的DryadLINQ[3]。架构图表 1 hive架构图[4]操作界面：CLI，Web，Thriftdrive	0.2842087296070851
Vortex4WebRankingV1	贴吧PHP交互层演进历程&CAMEL简介zhouren@baidu.com演进历程	随交互层演化划分出四个阶段思考	交互层需要解决那些问题？	怎样解决这些问题？CAMEL介绍	CAMEL也就是贴吧PHP中间层，用于解决交互层方面的问题；	CAMEL，骆驼（沙漠之舟），寓意：中间层在无论多么恶劣的环境下，也要提供良好的运输能力；SUMMERY背景LAMP架构的初次尝试；PHP系统的流量在100万～1000万；跨系统交互少；产出：随club项	0.2839108459876051
Vortex4WebRankingV1	文本自动分类介绍刘佳liujia0595@163.com2011.3.3文本自动分类：指在给定的分类体系下，根据文本的内容用计算机程序确定文本所属类别的过程函数映射过程：	A：待分类的文本集合，B：分类体系中的类别集f：映射规则是系统根据已经掌握的每类若干样本的数据信息，总结出分类的规律性而建立的判别公式和判别规则。一般采用机器学习的方法进行自动文本分类。  即:基于训练集的文本自动分类文本自动分类介绍典型的有监督的分类流程典型的自动分类系统流程定义	0.2817754454383709
Vortex4WebRankingV1	成交日期 买卖标志 成交价格 成交数量 成交金额 20160105 买入 100 897 20160108 卖出 8 200 1600 成交日期 买卖标志 成交价格 成交数量 成交金额 20160106 买入 100 1702 20160113 买入 100 1532 20160325 卖出 100 1695 20160708 卖出 100 1570 20160725 卖出 500 10700 20160802 卖出 300 6660 20160802 卖出 200 4430 20160803 卖出 20	0.27572607034309093

Using Cosmos Search REST APIs to query and get statistics of your historical jobs	CosmosSearch RESTful APIsWe now provide the cosmos search REST APIs to enable users to get more insights of their historical SCOPE jobs. This document walks through the basic steps to try out this API.If you have any questions for this document or wan	0.7554858139029196
Using Cosmos Search REST APIs to query and get statistics of your historical jobs	Interactive BingGoalSolving hard queryOverview Search engine is helping people solving problem. A lot of cases, search engine couldn’t solve problem at first shot. At this point, search engine need take more information to narrow down the user int	0.455866323330021
Using Cosmos Search REST APIs to query and get statistics of your historical jobs	Restaurant segment metrics collectionObjectiveTo understand user behavior/engagement on Restaurant answers.Why this is important? The metrics will help us understand:The comparisons between different answersWhat is important to our users and w	0.4545363580081617
Using Cosmos Search REST APIs to query and get statistics of your historical jobs	CosmosStreamSetsSaveen Reddy2014/04/15http://aka.ms/CosmosPresentationshttp://aka.ms/CosmosCodeSamples© 2012 Microsoft Corporation. All rights reserved. Microsoft, Windows, and other product names are or may be registered trademarks and/or tra	0.45258090417995483
Using Cosmos Search REST APIs to query and get statistics of your historical jobs	Cosmos Scope Aluminum M3 Release Announcement Cosmos Scope Aluminum M3 ReleaseThis and previous announcements are stored here.Code Samples can be found at http://aka.ms/CosmosCodeSamplesYou can find information about using Beta SDKs in this docu	0.44971194581061363
Using Cosmos Search REST APIs to query and get statistics of your historical jobs	Run web-search-like query against my dataSame Bing Web Search Indexing and Ranking engineIndex in a secondTransparent and real time index sync, no complex index-gen pipelinePrototype in an hourFast self-onboarding with freemium account, schema-d	0.44304329081319993
Using Cosmos Search REST APIs to query and get statistics of your historical jobs	Reading List for Natural Language Query ParsingThis is for improving our NL query parsing for entity/local triggering.By NL query parsing, our goal is to automatically extract the structured information from the query, normally by segmenting queries a	0.4335722974805439
Using Cosmos Search REST APIs to query and get statistics of your historical jobs	Simplified Query Path SelectorSimplified query: current systemSimplified query path selectionCrf model produces a list of possible ways to place rankonly operatorQuery = “nibbana restaurant official site”nibbana restaurant rankonly:official site	0.4282671112037517
Using Cosmos Search REST APIs to query and get statistics of your historical jobs	Query AugmentationsTable of Contents1. Syntax Overview	22. Constraints	6General rules for operators	7Basic Operators	7Scoring and non-scoring constraint operators	9Stream Operators	9Literal Operators	10Meta Operators	11URL Operators	13	0.4229960854004376
Using Cosmos Search REST APIs to query and get statistics of your historical jobs	Index Serve in Bing SearchContents1	Introduction	81.1	Overview	81.2	Goals and constraints	82	IndexServe Stats at a glance	93	IndexServe Architecture Overview	93.1	Logical Query flow	93.2	Machine Functions	124	Runtime Services	124.1	FCS	0.4163362621478063

Uses Of Clicks Logs In LocalRelevance	Uses Of Clicks Logs In LocalRelevance	serajago, pingyin, dzpotashOverviewCUV LogsIntent Model ImprovementsTop Links Mining'sGoogle Directions/Maps ClicksDistance Ranking ImprovementsLocation ApproximationPer Category Distance Distributio	0.5616208744710844
Uses Of Clicks Logs In LocalRelevance	Meta-stream work summaryHeyong WangClickstream exampleOverview: Click-Stream generationWeb logsLocal logsLocal clicked dataJoin with Local IndexWeb Clicked data (query, url etc.)IE ClickBing ClickIE SessionIE Tool Bar…Web Click	0.39761996661860866
Uses Of Clicks Logs In LocalRelevance	Local Search Popularity V2 DesignBing Local SearchDevXiaohui Liu, Fengxia PanPMDave BargeronMilestoneAl. M1ContributorsFeature Bug IDSignoffPM Spec Linkhttps://microsoft.sharepoint.com/teams/localsearch/_layouts/15/WopiFrame.aspx?s	0.32534096753658664
Uses Of Clicks Logs In LocalRelevance	WPO Local Relevance Tech TalkWPO Local Relevance TeamOverviewWPO’s role in local relevance pipelineLocal ExperienceArchitecture overviewMetricsWPO Local Relevance Model IntroductionWPO Query understanding and Location understandingWhy do	0.318022504624545
Uses Of Clicks Logs In LocalRelevance	WPO Local RelevancePing Yin2017-03-21OverviewWPO’s role in local relevance pipelineLocal Entity StampingArchitecture overviewWPO Local Relevance Models.Query: exton mall, User location: Wallingford, PAWPO RolesExtract/detect all entity	0.3162353043219287
Uses Of Clicks Logs In LocalRelevance	Bing Local Functional DetailsDocument StatusDate Created6/25/2013Last Updated2/28/2014Current StatusDraft Key StakeholdersProgram ManagementDany Daher; Tony Angell; Sumitra Sheth; Product ManagementTBD;Executive SponsorsEric Ca	0.27729925367114655
Uses Of Clicks Logs In LocalRelevance	Debug Address Queries8/23/2013Bing Local Search RelevanceNTCG MetricsDocumentationhttps://microsoft-my.sharepoint.com/personal/aoakley_microsoft_com/Documents/2013/2013-05-22%20Maps%20metrics%20Qi.pptx?web=1Use it to identify the group of quer	0.26893210022031
Uses Of Clicks Logs In LocalRelevance	Microsoft ConfidentialClick to edit Master title styleEdit Master text stylesSecond levelThird levelFourth levelFifth levelMicrosoft ConfidentialMicrosoft ConfidentialMicrosoft ConfidentialGISELLI PANONTINIDEEPANKAR DUBEYSubstrate 	0.25720652505921554
Uses Of Clicks Logs In LocalRelevance	CAL OFE logsOFE raw logs are cooked with the CALOFELogExtraction script, located in answers_alterations\private\OfflineDataGen\QueryAlteration\CALOFE\CALOFE.slnCooking the raw logsTo cook your logs, you need to runanswers_alterations\private\Offli	0.25663104957335914
Uses Of Clicks Logs In LocalRelevance	Competitive Query-Entity ClickMicrosoft ConfidentialMicrosoft ConfidentialGoalCreate a dataset that is readily available to utilize and analyze query-entity click patterns on competitive dataCompetitive Engine: GoogleMicrosoft ConfidentialCo	0.2397870172139102

Unix高级环境编程读书笔记	Unix高级环境编程读书笔记第七章 进程环境C程序总是从main函数开始执行，main函数的原型：int main(int argc,  char* argv[]);argc:命令行参数个数argv:指向各个命令参数的指针 测试main函数参数： 测试结果： 使用size命令查看可执行文件的正文段、数据段、bss段的长度：dec：十进制表示三个段的总长度hex：十六进制表示三个段的总长度 共享库使得可执行文件不再需要包含公用的库例程，	0.8807573934141419
Unix高级环境编程读书笔记	Svm分类模型：基本原理：将所有待分类的点映射到“高维空间”，然后在高维空间中找到一个能将这些点分开的“超平面”，这在理论上是被完全证明了是成立的，而且在实际计算中也是可行的。满足条件的“超平面”的个数不是唯一的。SVM需要的是利用这些超平面，找到这两类点之间的“最大间隔”。并非所有的数据都线性可分，将非线性映射到更高维的特征空间变成线性可分。（低维空间向量集通常难于划分，解决的方法是将它们映射到高维空间。）但这个办法带来的困难就是计算复杂度的增加，而核函数正好巧妙地解决了这个问题。也就是说，只要选用	0.8640115181990683
Unix高级环境编程读书笔记	SVM分类内容概要流程图预处理SVM分类器组合分类结果流程图内容概要流程图预处理SVM分类器组合分类结果特征选择特征，以文本行业分类来说，切词term特征的重要性“北京”是个没用的特征“速8”是个有用的特征“轻度”这个词呢？信息增益（Information Gain）   熵H是一个分布是否分散的表征，与信息相反概率估计P(ci) = ci类别的样本数 / 样本总数P(ci|t)  = t出现的属于ci	0.8631732151501283
Unix高级环境编程读书笔记	贝叶斯分类模型：基础知识：假设	X：是数据元组，由n个属性描述；	H：是某种假设，如数据元组属于某特定类C	P(H|X)：表示给定X的属性描述，找出元组X属于类C的概率举例：X：一位35岁的顾客，收入为4w美元；H：顾客将购买计算机P(H|X)：在X的条件下，H的后验概率。当我们知道顾客的年龄和收入时，顾客X将购买计算机的概率。P(H)：H的先验概率。任意给定顾客将购买计算机的概率，独立与X。P(X|H)：在条件H下，X的后验概率。已知顾客购买了计算机，顾客是一位3	0.8623900136244042
Unix高级环境编程读书笔记	BS代码阅读：BS基本功能：索引相关性切词成分分析offset调权query解析 （where+what）多路归并 综合调权类聚（偏离点）query分类空间调权数据来源点击调权BS代码阅读：bs_cache:map库的term cachemap库term cache操作锁where库term cachewhere库term cache操作锁init_map_term_cache: 初始化map库term cachein	0.8620150106793362
Unix高级环境编程读书笔记	K最近邻分类模型：原理：训练元组用n个属性描述，每个元组代表n维空间中的一个点，所有的训练元组存放在n维的模式空间。当给定一个未知元组时，KNN搜索该模式空间，找出最接近未知元组的k个训练元组。未知元组指派到它的k个最近邻中的多数类。“邻近性”用距离度量，如欧几里德距离。欧几里德距离：	设元组X1=(X11,X12,…X1n)，X2=(X21,X22,…X2n)，	Dist(X1,X2)=√ ∑ k= 1 n (X1i-X2i) 2 	使用上式之前，对每个属性的值规范化，以防止具有	0.8595208162465908
Unix高级环境编程读书笔记	排序及扩展：插入排序，选择排序（冒泡排序），使用二分思想求第k大数，快速排序，非递归的快速排序，使用快排思想求第k大数，归并排序，求逆序数，自然排序算法，堆排序，最小优先级队列，计数排序，桶排序，鸽巢排序（分块排序），基数排序，外部排序：二路归并，K路归并，胜者树，败者树。  算法一：使用插入或者选择排序，得到最大的K个数，时间复杂度为：O(N*k)。 冒泡排序： void swap(int * a,int * b){            //注意	0.8593210917721045
Unix高级环境编程读书笔记	克拉玛依公证处:本人因生活在国外，不能亲自到贵单位办理出生证明公证事项，兹授权委托雷春香女士全权代表我办理相关事项。对委托人在办理上述事项过程中所签署的有关文件，我均予以认可，并承担相应的法律责任。委托人：刘佳			委托人身份证号码：654301198608243929被委托人：雷春香		被委托人身份证号码：6526196207113926委托人：刘佳2018年5月24日	0.8593210917721045
Unix高级环境编程读书笔记	性能升级性能升级的几个层面：系统结构：模块分解，模块交互，系统构建中的粗略估算。算法和数据结构：获得快速模块的关键：表示数据的结构，操作数据的算法：索引结构及拉链归并。代码调优：分支预测等。循环：将循环体中不改变的变量移动到循环体外；多重循环嵌套顺序。函数调用：inline函数节省函数调用开销：若makefile中不指定至少-O优化，即使声明为inline函数，编译器也不会进行函数内联。内存寻址：避免重复内存寻址。Cpu流水线的分支预测：将满足概率最高的条件放在靠前的位置。	0.8593210917721045
Unix高级环境编程读书笔记	业务生成平台用户指南总体说明开发背景下一代网络是业务驱动的网络，在融合的下一代网络上高效、灵活地开发和部署各种丰富多彩的业务，从而提高网络使用率、增加收益的目标，是下一代网络的关键环节。下一代网络的发展要求呼叫与承载相分离、呼叫控制与业务相分离，使业务真正独立于网络，业务开发者不必关心与业务承载相关的底层网络知识以及具体的通信协议，只需利用业务生成平台提供的业务开发工具，就可以开发出灵活丰富且极具个性化的业务。 为了适合多种技术水平的业务开发人员的需要，现在主要有四种业务开发方式：	0.8593210917721045

US_ImPo_How_To_Update_Your_Dependents	Microsoft US Immigration PortalHow To Update Your DependentsJuly 24, 2017Step 1: Log in to your account by clicking “Log In”, either in the header or in the banner image.Step 2: Go to Your Family from the header, or by selecting “Manage Your Depen	0.3468975743113367
US_ImPo_How_To_Update_Your_Dependents	PBA Dependency and DebugMing Wu2014-01-28PBA DependenciesLocation Understanding (LES/BLU)Location info (explicit/implicit) – fulfill detailed location infoProvide location related features to phonebook CRFXapQuServiceAnswer (QAS)For most c	0.2524064120692904
US_ImPo_How_To_Update_Your_Dependents	Index Quality UpdateAgendaMetrics UpdateSelection Model ImprovementRecall TierOffice ImprovementChallenges and Pain PointsHow to measure index quality?Ideally: sampling from all “good” images and see how much we covered.sampling from a	0.21467643297179295
US_ImPo_How_To_Update_Your_Dependents	AgendaBusiness Update (20 min)Guest Speaker - Saurabh(20 min)FY19 Update (40 min)New Hires / Anniversaries (10 min)Demos (20 min)Q&A (10 min)Bing Dashboard – December ‘18- Harry Level GoalGreen : on / above targetOrange :  -ve trend 	0.20632594854394726
US_ImPo_How_To_Update_Your_Dependents	Relevance Experimentation with DUOverviewThe ideal end state for any relevance improvement would consist of having one or more DU features shipped in the index that is then leveraged by the latest production ranker. This would achieve the highest leve	0.20231626363881128
US_ImPo_How_To_Update_Your_Dependents	Deal Ranking ImprovementsDeal Understanding ImprovementsGoal: Increase general deal coverage (deal product type from specific to general).Solution: Identify the prefix and suffix of title by punctuations and prep. Remove the prefix and suffix from t	0.19452998178047182
US_ImPo_How_To_Update_Your_Dependents	Wind Up Impact on Existing adInsight Feature Plan03/25/2015ContextTo Enable “Wind Up for Premium” as high priority, we decide to make following resource adjustmentImpact to Existing Product/Feature AreaFocus AreaProducts/FeaturesResource	0.19315740383673052
US_ImPo_How_To_Update_Your_Dependents	SVMT UpdateNovember 2016AgendaMorning (10:00-12:00)Overview – 15 minQnA:MALTA – 55 minInfoBot – 30 minLunch break (12:00-1:00)Afternoon (1:00-3:00)Query:Deep QR – 30 minRanking:ConceptX – 30 minFusion – 30 minNapa – 30 minO	0.1745447141986237
US_ImPo_How_To_Update_Your_Dependents	Training Data Repository v2Sourabh ChandakAgendaWhy TDR v2TDR explainedOnboarding processNext StepsSummaryDependenciesQuestionsProblemTraining data The most valuable resource for any ranker training experiment. Comprises of <quer	0.16971637025002334
US_ImPo_How_To_Update_Your_Dependents	I’d like to explain in more details my idea of improving Dolphin, by improving its robustness of query variations and some previously unseen terms. Our rules don’t cover many query patterns. E.g., {top rated chinese restaurants} works well, but not {chi	0.15450054978823952

UCI-Test Validation_ After Action Report	Location and Data Services Team all hands10/08/2014AgendaCelebrate – Wei, 5minsLocal partners – Andy, 10minsLocal Data Services – Alex, 15minsGeocoder and GeoSpatial Services – Jai, 20minsLocation and Autosuggest Services – Sid, 15minsBing	0.3837222423934171
UCI-Test Validation_ After Action Report	Bing Local Functional DetailsDocument StatusDate Created6/25/2013Last Updated2/28/2014Current StatusDraft Key StakeholdersProgram ManagementDany Daher; Tony Angell; Sumitra Sheth; Product ManagementTBD;Executive SponsorsEric Ca	0.3631806520664895
UCI-Test Validation_ After Action Report	File Relevance Experimentation Design DocRecall AnalysisTest the search quality of external services like OLS, 3S, QF and SPO Search.Search scenarios: 0-term search, term search, 3S (Insert File and Attach File).Compare the recall: diff of returne	0.3611027609755737
UCI-Test Validation_ After Action Report	IQ Team RecapH1 2016FY16H1 AccomplishmentsTeamSSRxen-* Desktop SBSen-* Mobile SBSen-* Semantic SBSCore Web Relevance0.55/0.62.46/3.02.65/3.01.88/2.0Adult LeakageSpamJunkCQDCGMPCMALTABing@WorkSubstrate0.02/0.01	0.35900311311487393
UCI-Test Validation_ After Action Report	Term Attributes GuidelineTerm attributes: 核心词，需求词，属性词，强限定词，弱限定词，动作词，无损词核心词: Query的本体/实体。需求词:对检索对象/结果的来源、资源类型、格式和交互行为方式的限定。(以下query实例出自2012Q4 measurement set)限定搜索结果的来源或者垂直频道Query需求词李宇春 贴吧贴吧初中名校图片图片ufc李铁拳视频视频后金地图地图习近平 百科百	0.35878808252977507
UCI-Test Validation_ After Action Report	After Action Report TellMeService, Shredder, AugmentationService, Enrichment, UCIService (Insights), Entity Service<<insert Service Name>>	 [Technology /Service Name]Disaster Recovery Plan (DRP)	 						Office Group Name : After Action Report 	0.3586106467230542
UCI-Test Validation_ After Action Report	L-1B SPECIALIZED KNOWLEDGE QUESTIONNAIREMICROSOFT POSITION IN THE U.S.Provide the following information for your current position at the Microsoft.MICROSOFT POSITION ABROADProvide the following information for your position at the Microsoft’s su	0.3554195083602326
UCI-Test Validation_ After Action Report	Abacus Query Pattern SpecThis document describes how the query GEE pattern is passing from CAL into PDR, and generate a series of features depending on the <querypattern, URL-host> level matching. Query Property of GEEHere is the query property defi	0.3538378315051461
UCI-Test Validation_ After Action Report	Training Data Repository v2Sourabh ChandakAgendaWhy TDR v2TDR explainedOnboarding processNext StepsSummaryDependenciesQuestionsProblemTraining data The most valuable resource for any ranker training experiment. Comprises of <quer	0.35372190988462104
UCI-Test Validation_ After Action Report	Query AugmentationsTable of Contents1. Syntax Overview	22. Constraints	6General rules for operators	7Basic Operators	7Scoring and non-scoring constraint operators	9Stream Operators	9Literal Operators	10Meta Operators	11URL Operators	13	0.34763611491286617

UCI-Business Continuity Plan (BCP)	OPG- Business Continuity PlanTellMeService, Shredder, AugmentationService, Enrichment, UCIService (Insights), Entity ServiceDocument Revision HistoryDateAuthorChange NotesLeader Sign off4/30/2018alyanInitial document5/10/2019alyanU	0.5729500154066899
UCI-Business Continuity Plan (BCP)	BusinessV3TaxonomyClassifierAugust, 2018Daniel WeinshenkerMicrosoft ConfidentialAgendaMicrosoft ConfidentialPurpose / OverviewDemoData Pipeline / Lexicon GenerationMeasurementQASChallenges / Future WorkPurpose We want to improve 	0.4030923428564694
UCI-Business Continuity Plan (BCP)	Entity Categorization Using Convolutional Neural NetworkWeiwu Zhu8/23/2018AgendaMotivationCNN introductionCNN in NLPCNN based entity categorizationMeasurementMotivationTaxonomy mapping is not scalable (Feature Normalization)Nee	0.3725659505930444
UCI-Business Continuity Plan (BCP)	DSAT Mining & LSRBhagirath AddepalliCUV Log Based DSAT IdentificationIdentifying Google Local Answer Clicks from CUV LogsFor local queries, Google pushes users to search on MapClicking on Map results in url of type: https://www.google.com/webhp?	0.3591403188875015
UCI-Business Continuity Plan (BCP)	Containment and Conflation – Sprint  2Story DescriptionDone?In Demo?Implement and ship Segment Studio integration changes for Preconflation and MatchYYIdentify top K entity setYYRoot cause why entities have too many identifiersYY	0.3399353756729534
UCI-Business Continuity Plan (BCP)	https://cosmos11.osdinfra.net/cosmos/skypedata.adhoc/local/SkypeFeedback/Mined/v2/full/ FULLActionEntity.sshttps://cosmos11.osdinfra.net/cosmos/skypedata.adhoc/local/SkypeFeedback/Mined/v2/1d/ SkypeFeedback.ssSkypeSHRComments.ssSkypeSupportSea	0.33064097514495333
UCI-Business Continuity Plan (BCP)	Machine Learning Categorization & Popularity2012-08-30 | Nicolas NicolovGoalsShow how categorization and popularity systems work.Introduce important ML concepts.Illustrate ML techniques through examples.(aiming to be self-contained)Categoriz	0.3249783551280798
UCI-Business Continuity Plan (BCP)	Training Data Repository v2Sourabh ChandakAgendaWhy TDR v2TDR explainedOnboarding processNext StepsSummaryDependenciesQuestionsProblemTraining data The most valuable resource for any ranker training experiment. Comprises of <quer	0.32002185692984453
UCI-Business Continuity Plan (BCP)	DU Pipeline Sodium Achievements And Magnesium Plans　　Jia Liu2013-08-05OutlineSodium AchievementsMagnesium PlanMagnesium Work ItemsSodium Work ItemsAppendixSodium AchievementsWrapstar rating signalsTaobao, tmall; qna; novel; videoL3	0.3118414879828599
UCI-Business Continuity Plan (BCP)	Zh-cn Transportation Segment Optimization by Pattern EngineJia Liu/Allen WangDSATsQuery: 吉林市到查干湖Relevant result title: 吉林市到查干湖怎么走近？_百度知道Irrelevant result title 1: 查干湖,中国查干湖,吉林查干湖,查干湖旅游,查干湖冬捕,国家AAAA ...Irrelevant result title 2: 查干湖_百度百科Irrel	0.304958639707743

Transportation Segment Optimization By Pattern Engine	Zh-cn Transportation Segment Optimization by Pattern EngineIntroductionThe pattern queries can cover almost 10% in all queries. We can summarize lots of patterns on Query and Document sides for different segments. We can recognize key terms, relations	0.6438184660479571
Transportation Segment Optimization By Pattern Engine	Zh-cn Transportation Segment Optimization by Pattern EngineJia Liu/Allen WangDSATsQuery: 吉林市到查干湖Relevant result title: 吉林市到查干湖怎么走近？_百度知道Irrelevant result title 1: 查干湖,中国查干湖,吉林查干湖,查干湖旅游,查干湖冬捕,国家AAAA ...Irrelevant result title 2: 查干湖_百度百科Irrel	0.5490794073603309
Transportation Segment Optimization By Pattern Engine	QR Micro SegmentOverviewMicro Segment is way to fix corner case that main Bing ranking pipeline couldn’t fix easily by machine learning. There are many ways to do micro segment. Micro segment can be done in many layers. QR, matching, L1, L2, L3, …. To	0.4560748932659615
Transportation Segment Optimization By Pattern Engine	Leveraging Satori Knowledge in Web Ranking StackMicroSegment and Index ServeMotivationTarget at semantic queries (*defined by MALTA)Often contain more than one entity and relationSometimes involve entity inferenceTerm matching may not handle s	0.43971810856656324
Transportation Segment Optimization By Pattern Engine	Query Rewriting Micro SegmentWhy QR Micro SegmentMicro Segment is way to fix corner case that main Bing ranking pipeline couldn’t fix easily by machine learningThere are many ways to do micro segment. Micro segment can be done in many layers. QR, 	0.43056482265448803
Transportation Segment Optimization By Pattern Engine	Containment and Conflation – Sprint  2Story DescriptionDone?In Demo?Implement and ship Segment Studio integration changes for Preconflation and MatchYYIdentify top K entity setYYRoot cause why entities have too many identifiersYY	0.4271715375445424
Transportation Segment Optimization By Pattern Engine	Microsoft ConfidentialSeptember 14, 2016Relevance Next and Artificial IntelligenceRelevance and Intent OffsiteFebruary 8thOur PrioritiesExpand our Capabilities towards a full fledged AGI Engine, with focus on Knowledge, NL/Semantic Understandi	0.4252588893441671
Transportation Segment Optimization By Pattern Engine	Restaurant segment metrics collectionObjectiveTo understand user behavior/engagement on Restaurant answers.Why this is important? The metrics will help us understand:The comparisons between different answersWhat is important to our users and w	0.42265919380995354
Transportation Segment Optimization By Pattern Engine	Global relevance feature proposalFeature name: Title Match OptimizationPMJin GuoDevJia LiuTestReleaseALTeam site linkExecutive SummaryTitle is the summary/abstract of the document. Title Match is very important to SBS. Through many c	0.41988100431646075
Transportation Segment Optimization By Pattern Engine	Simplified Query Path SelectorSimplified query: current systemSimplified query path selectionCrf model produces a list of possible ways to place rankonly operatorQuery = “nibbana restaurant official site”nibbana restaurant rankonly:official site	0.41385341123353725

TranslationModel	Translation Model in Local Search- Shu HuangIntroductionTranslation model in web searchOdpTitle translation model in local searchData preparationModel trainingGenerate new metastreamIntroductionTranslation model used in web searchLea	0.4392492296355181
TranslationModel	Translation ModelMei YangDU talk5/11/2011OutlineIntroduction to Machine Translation (MT)Introduction to phrase-based statistical machine translation (PBSMT)Translation Model @ DUFuture WorkIntroduction to MTTranslate one natural langua	0.27499569727898054
TranslationModel		0.24315172306230715
TranslationModel	FastRank--- a Decision-Tree based Ranking ModelYu SHIOutlineBackgroundAlgorithm overviewTraining implementationExperimentationChallengesReferencesBackgroundInvestigated by MSR in OsloShipped with July Tree 2010 (Denver)GoalsSpe	0.2291311015200597
TranslationModel	Index Quality UpdateAgendaMetrics UpdateSelection Model ImprovementRecall TierOffice ImprovementChallenges and Pain PointsHow to measure index quality?Ideally: sampling from all “good” images and see how much we covered.sampling from a	0.2133060506027335
TranslationModel	TopChainNumber MasterId Label Type Name Phone AddressLine City Website Closed LastYearImpression LCMScore ChainId ChainName Score LPLink SparsedFeatureVector r 873x114637191399090866 0 http://maps.google.com/maps/place?cid=14233605658129796921 Ion Bank 36	0.16136689284723463
TranslationModel	Term expansion summaryGoalsVisible changes in ARDSImprove “no match” issuesImprove rank qualityLimit FPs. Pre-work neededPort names tagger to C#/C++Query timeWSD and entity taggerEntity tagging in query logs (Britney Spears bio -> <p	0.1588561709444457
TranslationModel	I’d like to explain in more details my idea of improving Dolphin, by improving its robustness of query variations and some previously unseen terms. Our rules don’t cover many query patterns. E.g., {top rated chinese restaurants} works well, but not {chi	0.15209940288231083
TranslationModel	Decision Tree Ensemble decodeAdaboost Decision tree:A forest.  One feature can be multiple nodes.Support Market checkingWord/entity classificationOne or more feature set inputMeaning[DecisionTree]Roots=90  (tree number)Nodes=630 (all n	0.14117178201482158
TranslationModel	Translation Model APIStatus: Sodium-2, API Version 6.7OverviewThe TM API – including support for high compression - was developed as one of several architectural considerations to ship machine translation model features to production, initially for 	0.1357272960185747

Translation Model API - Sodium-1 (2013)	Translation Model APIStatus: Sodium-2, API Version 6.7OverviewThe TM API – including support for high compression - was developed as one of several architectural considerations to ship machine translation model features to production, initially for 	0.7057072911334523
Translation Model API - Sodium-1 (2013)	Translation Model in Local Search- Shu HuangIntroductionTranslation model in web searchOdpTitle translation model in local searchData preparationModel trainingGenerate new metastreamIntroductionTranslation model used in web searchLea	0.4571959773526897
Translation Model API - Sodium-1 (2013)	Translation ModelMei YangDU talk5/11/2011OutlineIntroduction to Machine Translation (MT)Introduction to phrase-based statistical machine translation (PBSMT)Translation Model @ DUFuture WorkIntroduction to MTTranslate one natural langua	0.4439694972432547
Translation Model API - Sodium-1 (2013)	ML Model Scorecard Analysis8/8/2019Unexpected term search movementhttps://exp.microsoft.com/xcard/?view=4e77b420-7b77-4e41-92ac-8e84f506fb01Check correctness of scorecard metric implementationCalculate term AVG rank from raw data streamsSearch	0.4385983671152457
Translation Model API - Sodium-1 (2013)	Index Quality UpdateAgendaMetrics UpdateSelection Model ImprovementRecall TierOffice ImprovementChallenges and Pain PointsHow to measure index quality?Ideally: sampling from all “good” images and see how much we covered.sampling from a	0.4355099460444576
Translation Model API - Sodium-1 (2013)	Module 2:Deployment Considerations© 2014 Microsoft Corporation. All rights reserved. MICROSOFT MAKES NO WARRANTIES, EXPRESS, IMPLIED OR STATUTORY, AS TO THE INFORMATION IN THIS PRESENTATION.11/28/2016 8:58 PMMicrosoft ServicesConditions and Te	0.4289731635271215
Translation Model API - Sodium-1 (2013)	Global relevance feature proposalFeature name: Title Match OptimizationPMJin GuoDevJia LiuTestReleaseALTeam site linkExecutive SummaryTitle is the summary/abstract of the document. Title Match is very important to SBS. Through many c	0.40787209999554835
Translation Model API - Sodium-1 (2013)	Generic Entity Extraction in Sodium Owner: Chuanxin HuContributors: Kang Li, Yi LiOverviewThe understanding of entities and their relationship is a one of the key pillars supporting the Bing’s strategic bet on the knowledge graph. Today, Satori ca	0.39615294528247463
Translation Model API - Sodium-1 (2013)	Summary and HighlightsIn April the metrics/measurement team released local AutoSuggest metric and shared initial transit measurement results; BLU team shipped CL 1.0 ontology and deployed BLU v3 to all markets; PBA team shipped a new L2 ranker and refre	0.39500000535252733
Translation Model API - Sodium-1 (2013)	Local Search Popularity V2 DesignBing Local SearchDevXiaohui Liu, Fengxia PanPMDave BargeronMilestoneAl. M1ContributorsFeature Bug IDSignoffPM Spec Linkhttps://microsoft.sharepoint.com/teams/localsearch/_layouts/15/WopiFrame.aspx?s	0.3943691910273621

Translation Model	Translation Model in Local Search- Shu HuangIntroductionTranslation model in web searchOdpTitle translation model in local searchData preparationModel trainingGenerate new metastreamIntroductionTranslation model used in web searchLea	0.5512417137919554
Translation Model	Translation ModelMei YangDU talk5/11/2011OutlineIntroduction to Machine Translation (MT)Introduction to phrase-based statistical machine translation (PBSMT)Translation Model @ DUFuture WorkIntroduction to MTTranslate one natural langua	0.33249018140323827
Translation Model	FastRank--- a Decision-Tree based Ranking ModelYu SHIOutlineBackgroundAlgorithm overviewTraining implementationExperimentationChallengesReferencesBackgroundInvestigated by MSR in OsloShipped with July Tree 2010 (Denver)GoalsSpe	0.22935289594148653
Translation Model	I’d like to explain in more details my idea of improving Dolphin, by improving its robustness of query variations and some previously unseen terms. Our rules don’t cover many query patterns. E.g., {top rated chinese restaurants} works well, but not {chi	0.22448703703647924
Translation Model		0.21367657995586203
Translation Model	Index Quality UpdateAgendaMetrics UpdateSelection Model ImprovementRecall TierOffice ImprovementChallenges and Pain PointsHow to measure index quality?Ideally: sampling from all “good” images and see how much we covered.sampling from a	0.19108312815613332
Translation Model	Name Entity Recognition based on Perceptron modelBackgroundWe have many name entity DSATs like user searched name “XYZ”, and the results may be “XY”,”YZ” or “XYW” related. We have done QU name entity recognition for zh-cn market already. So we want to	0.18747630537256876
Translation Model	Translation Model APIStatus: Sodium-2, API Version 6.7OverviewThe TM API – including support for high compression - was developed as one of several architectural considerations to ship machine translation model features to production, initially for 	0.1593106188717358
Translation Model	Term expansion summaryGoalsVisible changes in ARDSImprove “no match” issuesImprove rank qualityLimit FPs. Pre-work neededPort names tagger to C#/C++Query timeWSD and entity taggerEntity tagging in query logs (Britney Spears bio -> <p	0.15030792408048194
Translation Model	Golden QueryEvery query countsImprove relevance: Relevance TechniquesWin/Loss basedGood technique has better win/loss ratioGeneric Ranker always doesn’t have good win/loss ratioWe do technique triage, and better win/loss ratio technique got sh	0.13642098340984302

TrainingDataRepositoryv2	Training Data Repository v2Sourabh ChandakAgendaWhy TDR v2TDR explainedOnboarding processNext StepsSummaryDependenciesQuestionsProblemTraining data The most valuable resource for any ranker training experiment. Comprises of <quer	0.47572157668076215
TrainingDataRepositoryv2	Ranker Training Pipeline IntroductionAgendaPipeline OverviewGCC platformExtractionData/Feature PreparationMain Ranker TrainingSegment RankersPipeline OverviewGR OctTree: gcclinkMain Steps:Metastream injection (just info here)Querys	0.3935761810284433
TrainingDataRepositoryv2	Keyword Prediction for Local SearchesRuchir RastogiMentor: Jia LiuManager: Leon ZhangOutlineProblem statementTraining data and clean-up strategiesConditional random field (CRF) modelsDeep learning modelsEnd to end measurementConclusi	0.3867163348573826
TrainingDataRepositoryv2	Meta-stream work summaryHeyong WangClickstream exampleOverview: Click-Stream generationWeb logsLocal logsLocal clicked dataJoin with Local IndexWeb Clicked data (query, url etc.)IE ClickBing ClickIE SessionIE Tool Bar…Web Click	0.3777567390492038
TrainingDataRepositoryv2	MQ for CALOverviewSpellerQASMQTriggerMQSingleQueryChainChainChainAugmentAugmentAugmentTailQuerySimplifiedSPCombSP1SP2Sp3AugmentAugmentPropertyBag - SQQueryAlterationListQueryAlterationSetQueryAlterationType	0.36453741744928564
TrainingDataRepositoryv2	Document classification based on urlBackgroundWe want to do document classification for better understanding the document type and document with query category match for ranking.  We will do zh-cn document classification based on url first, then docum	0.3555084699025245
TrainingDataRepositoryv2	Keyword Predictor Design DocumentName: Ruchir RastogiMentor: Jia LiuManager: Leon ZhangProject overviewThe goal of this project is to design a machine-learning model that can predict keywords in a local query for improving local search relevance	0.3455946386348733
TrainingDataRepositoryv2	LEDB Transition8/6/2014ScopeLEDB serialization jobsLEDB Object Store publish jobsLEDB Odyssey Publish job for the VanueMap featureEntity Schema update and maintenanceObject Store payload size and perf SLAPartner engagement and change manag	0.34151041355507006
TrainingDataRepositoryv2	TermX TrainingLast saved by Gord Lueck, 8/17/2015 2:15 PMContentsTermX Training	1Overview	1Prerequisites	1Inputs	1Translation Model Generation	2TermX_GenerateTrainingData	2TermX_GenerateTM	2TermX Trim Model	3TermX_PostProcess TM	3C	0.3388176214011363
TrainingDataRepositoryv2	How do we train SM-CRF for APN?AgendaOverviewGeneration of Lexicons (in aether)Generation of RegEx FeaturesCRF Training Pipeline (in aether)CRF Eval Pipeline (in aether)Debugging ToolsQuestions?OverviewCRF is responsible for entity e	0.31257601704562504

Tmall and taobao rating design doc	Tmall&Taobao Rating MetawordsBackgroundWe’ve seen in regular DSAT review meetings the DSATs that we rank too high Tmall or Taobao page with low quality(Tmall page:low sales volume; Taobao page: low sales volume or shop with poor reputation).  Zh-CN ha	0.594279544834379
Tmall and taobao rating design doc	Wrapstar rating signalsfor zh-cn documentsJia LiuWrapstar rating signals for rankingWrapstar Taobao ratingWrapstar Tmall ratingWrapstar Qna ratingWrapstar Book ratingWrapstar Video ratingDsats examplesTaobao examplesQuery=“蓝色休闲裤	淘宝”	0.4603119746362122
Tmall and taobao rating design doc	Deal Understanding and RankingBackgroundDeal is a very big segment in Bing Opal. We crawl store and single deals/coupons regularly from websites like groupon.com, coupons.com, restaurants.com, retailmenot.com, dealcatcher.com, dealplus.com and so on. 	0.3159579122423947
Tmall and taobao rating design doc	Publication Date Optimization Design and Implement For zh-cn MarketReview and CommentMei Yang; Ted WildAuthorJia LiuDesignBackgroundPublication date is a very fundamental and important feature. It can help fresh ranking, solve mainline out	0.30999243774827856
Tmall and taobao rating design doc	NGram Language Model based Url Breaking – Design DocumentStatusOngoingIntroductionUrl is a very important signal for ranking, particularly for tail queries and navigation queries. This signal has 100% url coverage, which really makes it different 	0.29781234993015115
Tmall and taobao rating design doc	Google Mobile vs Desktop RankDiff StudyNov 2017GoalsUnderstand what Google does differently on Mobile, if anythingDrive product ideas & shape ranking improvements on MobileUnderstand any possible impact to Algo scrapes & metricsDrive scrapin	0.2876126245075542
Tmall and taobao rating design doc	Deal Ranking Improvement & MeasurementBackgroundAfter we shipped deal understanding, bad deals filtering, deal ranking for the entity search deals and popular deals nearby. We want to measure and improve our deal ranking based on user behaviors. We ca	0.2865749671653393
Tmall and taobao rating design doc	DU work items on zh-cn market　　Jia Liu2013-05-14AgendaSerp classifierWrapstar rating signalsTaobao, tmall; qna; novel; videoGeneral classiferUrl-basedTopic-basedPage number extractionName entity recognitionPerson, location, organiz	0.28385282560312225
Tmall and taobao rating design doc	Brownbag:ElasticSearch ExtensibilityHeather Nakama (henakama)Azure Search09/04/14AgendaIntroductionModulesPluginsFinding extensibility pointsEnd-to-end exampleTips and tricksQ/AIntroductionHeather NakamaDeveloper with Azure S	0.2777302048559195
Tmall and taobao rating design doc	SPAM & JunkSi Planning Cheng Niu, Alex Rahin6/18/2014Agenda	Focus AreasMetricsSPAM/Junk Metrics BreakdownData Analysis and Project DefinitionFocus AreasImprove SPAM Detection (~35% of team bandwidth)Stolen ContentContent Keyword St	0.2627871363794555

Tiger Migration	Tiger MigrationKefeng Deng6/15/2015Microsoft ConfidentialTiger MigrationMotivationTiger IntroductionHow do we get thereCurrent statusRemaining works6/15/2015Microsoft ConfidentialMotivationSame index serve architecture as Satori 	0.5817842467754402
Tiger Migration	Tiger Index BrownbagHui ShenSearch Platform Tiger TeamAgenda	OverviewKey ideasTiger architectureTiger ++ 2/24/2012Agenda	OverviewKey ideasTiger architectureTiger ++ 2/24/2012What is Tiger IndexAn new index serve technol	0.3940084092548746
Tiger Migration	[IMPORTANT]Please notify “featfun” if you want to edit this document!!!Metastream FeaturesWritten by: Tian Xia (tixia@microsoft.com)Table of Contents1. Overview	62. Basics	82.1 Metastreams	9Single instance metastream	9Multi-instance meta	0.30581157085247623
Tiger Migration	Introduction to L1Xiao WuSearch Platform Tiger Team AgendaL1 goals and challengesMetrics and measurementL1 ranker and perf optimizationL1 ranking Perf optimizationDebugging tools L1 training and shippingThinking and discussionL1 	0.2804684829891919
Tiger Migration	PBA Query Understanding MigrationTetyana Golub | Ming WuMotivationPBAvnextCurrent QU logic is complicated and hard to migrateLimitation from hard coded logicCurrent QU logic is complicated and not very flexibleHard to add new feature or adju	0.24081443116262516
Tiger Migration	Translation Model in Local Search- Shu HuangIntroductionTranslation model in web searchOdpTitle translation model in local searchData preparationModel trainingGenerate new metastreamIntroductionTranslation model used in web searchLea	0.23484340297406794
Tiger Migration	Integrating Knowledge Graph in Web SearchEntity Triggering and CollectionsPresenter: Ze TianKnowledge GraphEntities and RelationsEntities: celebrities, people, generic terms (e.g. light bulb)Relations: sibling, spouse, people and their works	0.23394064325373587
Tiger Migration	Local Search Entity Schema for RelationShips (Entity Containment, Affinities) Short blurb of what this spec is aboutMilestone:  MagnesiumSpec StatusDraftTFS Feature IDPM/Doc OwnerSandhya GuntreddyContributors Scott, Bruno,Andrew,Prajakta	0.23261923305590476
Tiger Migration	Query Rewriting Micro SegmentWhy QR Micro SegmentMicro Segment is way to fix corner case that main Bing ranking pipeline couldn’t fix easily by machine learningThere are many ways to do micro segment. Micro segment can be done in many layers. QR, 	0.2267794665280958
Tiger Migration	BingGC Multi-Pointer Stack11/4/2014BingGCI@microsoft.comMulti-Pointer ResolutionUsing a tiling system, we first find the correct Tile, then search inside to find matching entities:	 Chipotle Mission St 2nd StQuery: Chipotle Mission St 2nd St	0.21721215483151954

Tiger Brownbag 2012-02-24	Tiger Index BrownbagHui ShenSearch Platform Tiger TeamAgenda	OverviewKey ideasTiger architectureTiger ++ 2/24/2012Agenda	OverviewKey ideasTiger architectureTiger ++ 2/24/2012What is Tiger IndexAn new index serve technol	0.6540670939818624
Tiger Brownbag 2012-02-24	Tiger MigrationKefeng Deng6/15/2015Microsoft ConfidentialTiger MigrationMotivationTiger IntroductionHow do we get thereCurrent statusRemaining works6/15/2015Microsoft ConfidentialMotivationSame index serve architecture as Satori 	0.4452773556532143
Tiger Brownbag 2012-02-24	Brownbag:ElasticSearch ExtensibilityHeather Nakama (henakama)Azure Search09/04/14AgendaIntroductionModulesPluginsFinding extensibility pointsEnd-to-end exampleTips and tricksQ/AIntroductionHeather NakamaDeveloper with Azure S	0.39873994047852285
Tiger Brownbag 2012-02-24	Introduction to L1Xiao WuSearch Platform Tiger Team AgendaL1 goals and challengesMetrics and measurementL1 ranker and perf optimizationL1 ranking Perf optimizationDebugging tools L1 training and shippingThinking and discussionL1 	0.3819464123807866
Tiger Brownbag 2012-02-24	SVMT UpdateNovember 2016AgendaMorning (10:00-12:00)Overview – 15 minQnA:MALTA – 55 minInfoBot – 30 minLunch break (12:00-1:00)Afternoon (1:00-3:00)Query:Deep QR – 30 minRanking:ConceptX – 30 minFusion – 30 minNapa – 30 minO	0.33380261347173185
Tiger Brownbag 2012-02-24	NTCG DebuggingSteven Zittrower01/30/2015AgendaNTCGNTCG DashboardOverview of BLU Architecture (Address Specific)Address Debugging in QATNTCGNTCG (Normalized Total Cumulative Gain) is a composite metric that measures address query releva	0.320277878306648
Tiger Brownbag 2012-02-24	Bing Ads Insight Track Weekly Review9/22/2015Primary KPIs  -- Product UsageCallout –NAKSP WoW usage increase by 223.58% on 9/14 was mainly driven by API-AdCenterAdIntelligenceService_V9 with the dev token 002234PN5W617046 whose associated accoun	0.31605542581074564
Tiger Brownbag 2012-02-24	Microsoft ConfidentialSeptember 14, 2016DRAFTSearch and AI PM Team MeetingApril 14th 2017Our MissionWho are we?Thoughts on PMQ&AAgendaThe 5 Priorities for Artificial Intelligence and Research Bing becomes 10 billion dollar business	0.30199315183824765
Tiger Brownbag 2012-02-24	Dynamic ConflationGanesh Poomal Girirajan  Kefeng                                                    Qiang WuAcknowledgementsChiping Tang: Helped us get the UPDR judgments for Training and Evaluation.Shital Shah, Aamer Mohammed: Helped us stam	0.29579984728425274
Tiger Brownbag 2012-02-24	Successful Feeds Query DebuggingNikita Melnichenko, 2015-03-10Feeds query debugging overviewWhen to use:Checking a new rankerChecking new augmentation before running a scrapeComparing several rankersUnderstanding feature contributionDebugg	0.28192053871107636

Thoughts on Interest Graph - Experience,  Business and Technology	Thoughts on Interest Graph – Experience, Business and TechnologyPersonalized recommendation that you don’t want to miss Author: Ting Cai Contributors: AC Surendran, Xiaodong Fan, Chuanxin Hu, Yan Ke, Tony Chor, Richard Qian1.	What is Interest Graph?	0.8600817512877936
Thoughts on Interest Graph - Experience,  Business and Technology	Threshold Query Formulation Deep DiveGoal of the presentation is to communicate our approach for query formulation and get feedback on whether this aligns with overall Threshold goals.OverviewGoals & MetricsQF ModelRoadmapScenariosKey Ta	0.4621692657857673
Thoughts on Interest Graph - Experience,  Business and Technology	Deal Ranking ImprovementsDeal Understanding ImprovementsGoal: Increase general deal coverage (deal product type from specific to general).Solution: Identify the prefix and suffix of title by punctuations and prep. Remove the prefix and suffix from t	0.4491264112385733
Thoughts on Interest Graph - Experience,  Business and Technology	Index Quality Team’s Deep Learning ExperienceLuke ChenOutlineMotivationsCNTK/Phily ExperienceIQ team DL projects highlightsResourcesMotivationsRecent progress in deep neural net provides inspirations to upgrade Bing’s machine learning stac	0.44834682001936177
Thoughts on Interest Graph - Experience,  Business and Technology	Relevance Experimentation with DUOverviewThe ideal end state for any relevance improvement would consist of having one or more DU features shipped in the index that is then leveraged by the latest production ranker. This would achieve the highest leve	0.4359833645719085
Thoughts on Interest Graph - Experience,  Business and Technology	Integrating Knowledge Graph in Web SearchEntity Triggering and CollectionsPresenter: Ze TianKnowledge GraphEntities and RelationsEntities: celebrities, people, generic terms (e.g. light bulb)Relations: sibling, spouse, people and their works	0.43441561933921513
Thoughts on Interest Graph - Experience,  Business and Technology	Containment and Conflation – Sprint  2Story DescriptionDone?In Demo?Implement and ship Segment Studio integration changes for Preconflation and MatchYYIdentify top K entity setYYRoot cause why entities have too many identifiersYY	0.4252905115508311
Thoughts on Interest Graph - Experience,  Business and Technology	SKI online feature extraction design docTo build ML model to detect user intent and re-rank search result from different providers, we need training data. This document mainly covers the design how to collect the training data from the real Office usage	0.41300743050376526
Thoughts on Interest Graph - Experience,  Business and Technology	File Relevance Experimentation Design DocRecall AnalysisTest the search quality of external services like OLS, 3S, QF and SPO Search.Search scenarios: 0-term search, term search, 3S (Insert File and Attach File).Compare the recall: diff of returne	0.4103538674836383
Thoughts on Interest Graph - Experience,  Business and Technology	Query Formulation Review of FY15 Goals and Silicon achievements/learningsSilicon ScorecardAreaGoalAchievementQF Relevance(Autosuggest, Related Search)SSRx+0.052Annualized Revenue+$58mRelated Search RelevanceBeat G on DO defect ra	0.3917940547695758

The Data Skew Problem (2011-03-11)	The Data Skew ProblemFei Xu2/27/2018The Scheduled TalksMarch 18th Dave Maltz – OSD future network March 25th Pat – TBD April 1st Pat – TBDApril 8th Brad – Terasort in 12 minutesApril 15th Eric – The Global Scheduler April 22nd Brian – 	0.6834148094720482
The Data Skew Problem (2011-03-11)	Local Relevance SQR (en-us + en-ca)March 14, 2017AgendaContext & Scope:EN-US & EN-CA, Mobile and SERP relevance focusedPBA (pre-web) relevance focusedQuality measurements DSAT examplesGeneral issuesKey Segments (Restaurants, Hotels, Re	0.3935782054788484
The Data Skew Problem (2011-03-11)	Local Junk Detection and DemotionJia Liu2017-06-14GDP Pipeline View: local data pipelineTriple StoreGOALStore every entity as a set of triples.Track all changes to an entity.TripleColumnDetailsSubjectThe guid of a triple’s pa	0.37427458573520345
The Data Skew Problem (2011-03-11)	Online Click Labels for CAL Ranker:End – To End:aether://experiments/31148112-679c-476c-91d0-bb3ebbef81c2Continuous trained module continuously trains trees using HRS and then the ranker.OFE Ranker Training Pipeline:aether://experiments/01dbe0	0.36645253453071397
The Data Skew Problem (2011-03-11)	Entity Selection ModelJia Liu2017-11-08GDP Pipeline View: local data pipelineEntity TypesEntity Types:Open/CloseHead/TailNonJunk/JunkJunk TypesGhost: Local business existed beforeJunk: General name like “Lock smith”, “ATM”Move/Br	0.35438612350602994
The Data Skew Problem (2011-03-11)	Local Probe bugsContents1.	Phone number format replacement	22.	Data on the Live Site does not correspond to data in the Local Probe	43.	Second time corrections	54.	Cuisine Selection	65.	Market settings affecting cuisine output	76.	Ranking is	0.3537871114090608
The Data Skew Problem (2011-03-11)	Translation Model APIStatus: Sodium-2, API Version 6.7OverviewThe TM API – including support for high compression - was developed as one of several architectural considerations to ship machine translation model features to production, initially for 	0.3532978377779647
The Data Skew Problem (2011-03-11)	SKI online feature extraction design docTo build ML model to detect user intent and re-rank search result from different providers, we need training data. This document mainly covers the design how to collect the training data from the real Office usage	0.3503113889626371
The Data Skew Problem (2011-03-11)	Training Data Repository v2Sourabh ChandakAgendaWhy TDR v2TDR explainedOnboarding processNext StepsSummaryDependenciesQuestionsProblemTraining data The most valuable resource for any ranker training experiment. Comprises of <quer	0.3469291909426534
The Data Skew Problem (2011-03-11)	Spam/Junk Technology Review8/8/2017 Pavel KarpovichAgendaSpam/Junk OverviewReview of current system and metricsSJRE Fishtank pipelines UrlExclusion and Defect Subranker	Blue Whale Spam Types of Fresh SpamActions to Detect Fresh	0.3417655200736795

TermX Training	TermX TrainingLast saved by Gord Lueck, 8/17/2015 2:15 PMContentsTermX Training	1Overview	1Prerequisites	1Inputs	1Translation Model Generation	2TermX_GenerateTrainingData	2TermX_GenerateTM	2TermX Trim Model	3TermX_PostProcess TM	3C	0.3759674269470653
TermX Training	PERM Labor Certification Questionnaire:  Technical (continued)PERM Labor Certification Questionnaire (Technical)Please complete the information requested in this questionnaire carefully.  This information is necessary for the legal analysis and prepar	0.3470881030311118
TermX Training	TermX: the Query Rewriting Engine for BingCore Relevance PM Meeting | Shu Zheng | Jan 5th, 2016AgendaWhat is TermX? Technique DeepdiveCurrent StateFuture WorksWhat is TermX? TermX = TermExp = Term ExpansionThe query rewriting engine for 	0.24693684378228473
TermX Training		0.21122035195596164
TermX Training	WPO Local Relevance Tech TalkWPO Local Relevance TeamOverviewWPO’s role in local relevance pipelineLocal ExperienceArchitecture overviewMetricsWPO Local Relevance Model IntroductionWPO Query understanding and Location understandingWhy do	0.19495632266029694
TermX Training	TopChainNumber MasterId Label Type Name Phone AddressLine City Website Closed LastYearImpression LCMScore ChainId ChainName Score LPLink SparsedFeatureVector r 873x114637191399090866 0 http://maps.google.com/maps/place?cid=14233605658129796921 Ion Bank 36	0.15569013044632782
TermX Training	Training data distributionContain categories as many as possible : 36 categies. The data of category in the same amountContain hudong data and  host dataPositive : negative = 1:7  ~ 1:10 categoryhudonghostpositivenegativeNegative_total	0.14620438891405574
TermX Training	Who Am I?Name: Jefferson WangClass: Rising CS SeniorUniversity: Georgia TechTeam: Bing Local RelevanceMentor: Supriya HarpaleManager: Jian WuProject SummaryTitle: QAS MLG Featurizer DebuggerDescription: Minimize the time it takes for a	0.13734437407409095
TermX Training	Golden QueryEvery query countsImprove relevance: Relevance TechniquesWin/Loss basedGood technique has better win/loss ratioGeneric Ranker always doesn’t have good win/loss ratioWe do technique triage, and better win/loss ratio technique got sh	0.13464420522142673
TermX Training	Translation ModelMei YangDU talk5/11/2011OutlineIntroduction to Machine Translation (MT)Introduction to phrase-based statistical machine translation (PBSMT)Translation Model @ DUFuture WorkIntroduction to MTTranslate one natural langua	0.1309236061226936

TermX Deep Dive 20151022	TermX Deep Dive	Gord Lueck 2015.09.22ContributorsSaekoo LeeGarrett KaminagaJunfeng ZhouAsad MohuiddinKaan OzelGord LueckCiya LiaoCAL Alteration SystemsCoreCAL is the query rewriting engine for bingCustomers:  Bing Web, Ads, Local	0.4461268842920412
TermX Deep Dive 20151022	Deep RelaxQuery Relaxation and L1 FidelityQuery Relaxation{printable iphone 7 user guide}rankonly:printable iphone 7 rankonly:user guiderankonly:printable iphone 7 user guideDeep Relax and vector similarity Encode query without each toke	0.3869287534672359
TermX Deep Dive 20151022	Bing Location Understanding (BLU) As a ServiceDeep-Dive PresentationRajasi Saha (tech lead for BLU infrastructure)Jian Wu (tech lead for BLU relevance)Microsoft ConfidentialOutlineIntroduction to BLUBLU as a serviceMotivationScenarios an	0.37920867018513704
TermX Deep Dive 20151022	Local DCG11/02/2012AgendaGoals of Local DCGHow Local DCG is calculatedComparison of Local DCG versus sNDCGOperationalization for scalePlan for international rolloutPlan for Local DCG enhancementsGoals of Local DCGGoalsActions take to	0.35295787602199635
TermX Deep Dive 20151022	Bing GC Deep DiveBingGCI 9/26/2014Introduction – Pavel, 2minsProject overview – Wei, 6minsBing GC XAP workflow – John, 10minsBing GC data pipeline and data ingestion – Florin, 7minsBing GC Offline relevance platform – Jian, 8minsSingle-poi	0.3512181574911222
TermX Deep Dive 20151022	Query Automotive & Vehicle Services (90056) Banking & Finance (90111) Beauty & Spa (90353) Food & Drink (90232) Healthcare (90375) Professionals & Services (90496) Real Estate (90584) Retail (90628) Sports & Recreation (90848) Travel (90881) Other Categor	0.3489399029514123
TermX Deep Dive 20151022	Author: Tony AngellDate: 08/01/13LocalProbe Improvements for Corrections Analysis and DebuggingTable of ContentsP0 Issues	2Issue: LocalProbe is unpredictable in the amount of time it takes to return a query and how long it takes to investigate a	0.3476294599584067
TermX Deep Dive 20151022	m:OrgQuery Owner Issue Notes m:SrcTerm m:Candidate m:Judgment m:FoundOnGoogle m:FoundOnBingPreWeb mFoundOn:BingPostWebQrOnly m:FoundOnBingPostWeb m:FoundInAltList m:NegativeBreakdown m:altType m:isInWordNet m:OrgPathString $2 nets tickets Kaan tickets tic	0.3458405551954774
TermX Deep Dive 20151022	Deep Dive on Statistical Simplification Model for Hard QueriesBin Zhang (intern, University of Washington)Xiaolong Li, Ye-Yi Wang (Bing)Xiaodong He (MSR)9/11/2012OutlineHard query backgroundDeletion modelsTraining dataOnline experiment	0.33190264718141055
TermX Deep Dive 20151022	cal deepdiverelaxationdec 2017AgendaProduct GoalsQuery SimplificationMechanism/RuntimeCRF Model TrainingQS Path SelectionOffline SimulatorSmart RelaxMechanism & TrainingRelaxation: ImpactRelaxation: Product goalsImprove Rec	0.3315378273386143

TermX 20160907	TermX: the Query Rewriting Engine for BingCore Relevance PM Meeting | Shu Zheng | Jan 5th, 2016AgendaWhat is TermX? Technique DeepdiveCurrent StateFuture WorksWhat is TermX? TermX = TermExp = Term ExpansionThe query rewriting engine for 	0.3221919502191091
TermX 20160907	Local DCG11/02/2012AgendaGoals of Local DCGHow Local DCG is calculatedComparison of Local DCG versus sNDCGOperationalization for scalePlan for international rolloutPlan for Local DCG enhancementsGoals of Local DCGGoalsActions take to	0.2833743754825107
TermX 20160907	Text Latitude Longitude S0:Local_L3DCG3 G0:Local_L3DCG3 S1:Local_L3DCG3 S2:Local_L3DCG3 Assignment RootCause(BadMetastream,PartialMatch,Cal,BadKeyword,OtherQU,Ranker,BingNotStable,Scraping,Metrics,MicroSegment,JudgeNoise,Unknown,BadEntity) BTC CanBeResolv	0.2784241671490149
TermX 20160907	Location and Data Services Team all hands10/08/2014AgendaCelebrate – Wei, 5minsLocal partners – Andy, 10minsLocal Data Services – Alex, 15minsGeocoder and GeoSpatial Services – Jai, 20minsLocation and Autosuggest Services – Sid, 15minsBing	0.2720213303060704
TermX 20160907	成交日期 买卖标志 成交价格 成交数量 成交金额 20160106 买入 100 1702 20160113 买入 100 1532 20160325 卖出 100 1695 20160708 卖出 100 1570 20160725 卖出 500 10700 20160802 卖出 300 6660 20160802 卖出 200 4430 20160803 卖出 200 4672 20160908 卖出 100 2695 成交日期 买卖标志 成交价格 成交数量 成交金额 20160112 买入 100	0.2637853919925431
TermX 20160907	成交日期 买卖标志 成交价格 成交数量 成交金额 2016年亏319 2015及2016年已完结 20160105 买入 100 897 20160108 卖出 8 200 1600 20150615 买入 100 1889 20150615 买入 100 1840 20150624 卖出 100 1585 20150720 买入 100 1073 20150721 买入 100 1098 20150721 买入 100 1086 20150723 买入 100 1110 20150818 卖出 500 	0.24902204706026868
TermX 20160907	Publication Date Optimization Design and Implement For zh-cn MarketReview and CommentMei Yang; Ted WildAuthorJia LiuDesignBackgroundPublication date is a very fundamental and important feature. It can help fresh ranking, solve mainline out	0.24733649886582718
TermX 20160907	WPO Local RelevancePing Yin2017-03-21OverviewWPO’s role in local relevance pipelineLocal Entity StampingArchitecture overviewWPO Local Relevance Models.Query: exton mall, User location: Wallingford, PAWPO RolesExtract/detect all entity	0.2427563288858465
TermX 20160907	Query Automotive & Vehicle Services (90056) Banking & Finance (90111) Beauty & Spa (90353) Food & Drink (90232) Healthcare (90375) Professionals & Services (90496) Real Estate (90584) Retail (90628) Sports & Recreation (90848) Travel (90881) Other Categor	0.2386602494620945
TermX 20160907	Pattern Based Term WeightVersion 1Jia Liu2014-06-16FrameworkTerm AttributesSemantics definitionHuman understanding and knowledgeChange in different contextsLevels:KeywordAttributeRequirementStrong constraintWeak constraintVer	0.23574793646082076

TermX - the Query Rewriting Engine for Bing	TermX: the Query Rewriting Engine for BingCore Relevance PM Meeting | Shu Zheng | Jan 5th, 2016AgendaWhat is TermX? Technique DeepdiveCurrent StateFuture WorksWhat is TermX? TermX = TermExp = Term ExpansionThe query rewriting engine for 	0.6888903330060917
TermX - the Query Rewriting Engine for Bing	Query Rewriting Micro SegmentWhy QR Micro SegmentMicro Segment is way to fix corner case that main Bing ranking pipeline couldn’t fix easily by machine learningThere are many ways to do micro segment. Micro segment can be done in many layers. QR, 	0.5564315391381314
TermX - the Query Rewriting Engine for Bing	Stateful Query Intent RefinementFeature OverviewStateful Query Intent Refinement is a Bing QR service that can be leveraged to guide users to their specific intent. Queries that have ambiguous intent or multiple intents/sub-intents can be refined usin	0.40674775159820015
TermX - the Query Rewriting Engine for Bing	BingGC Multi-Pointer Stack11/4/2014BingGCI@microsoft.comMulti-Pointer ResolutionUsing a tiling system, we first find the correct Tile, then search inside to find matching entities:	 Chipotle Mission St 2nd StQuery: Chipotle Mission St 2nd St	0.39082693060634643
TermX - the Query Rewriting Engine for Bing	Golden QueryEvery query countsImprove relevance: Relevance TechniquesWin/Loss basedGood technique has better win/loss ratioGeneric Ranker always doesn’t have good win/loss ratioWe do technique triage, and better win/loss ratio technique got sh	0.38601884475631476
TermX - the Query Rewriting Engine for Bing	Successful Feeds Query DebuggingNikita Melnichenko, 2015-03-10Feeds query debugging overviewWhen to use:Checking a new rankerChecking new augmentation before running a scrapeComparing several rankersUnderstanding feature contributionDebugg	0.3809567537354261
TermX - the Query Rewriting Engine for Bing	QR Micro SegmentOverviewMicro Segment is way to fix corner case that main Bing ranking pipeline couldn’t fix easily by machine learning. There are many ways to do micro segment. Micro segment can be done in many layers. QR, matching, L1, L2, L3, …. To	0.3790724895628621
TermX - the Query Rewriting Engine for Bing	QueryString Category owner Searchvote url 寇仲最后和谁在一起 ranking  xiaopeng http://searchvote.com/default.aspx?reviewid=209877 布里斯班 ranking  xiaopeng http://searchvote.com/default.aspx?reviewid=211685 必应词典 ranking  xiaopeng http://searchvote.com/default.aspx?re	0.36263816196019055
TermX - the Query Rewriting Engine for Bing	Reading List for Natural Language Query ParsingThis is for improving our NL query parsing for entity/local triggering.By NL query parsing, our goal is to automatically extract the structured information from the query, normally by segmenting queries a	0.36225998149305033
TermX - the Query Rewriting Engine for Bing	Interactive BingGoalSolving hard queryOverview Search engine is helping people solving problem. A lot of cases, search engine couldn’t solve problem at first shot. At this point, search engine need take more information to narrow down the user int	0.355639889584489

Term expansion summary	Term expansion summaryGoalsVisible changes in ARDSImprove “no match” issuesImprove rank qualityLimit FPs. Pre-work neededPort names tagger to C#/C++Query timeWSD and entity taggerEntity tagging in query logs (Britney Spears bio -> <p	0.4353502201481497
Term expansion summary	Thoughts on Interest Graph – Experience, Business and TechnologyPersonalized recommendation that you don’t want to miss Author: Ting Cai Contributors: AC Surendran, Xiaodong Fan, Chuanxin Hu, Yan Ke, Tony Chor, Richard Qian1.	What is Interest Graph?	0.2726657955173752
Term expansion summary	Pattern Based Term Weight FrameworkIntroductionPattern based term weight recognizes the importance for part of terms or all the terms based on patterns/templates/knowledge. There are 2 differences between general and pattern based term weight.Compar	0.2678574935115395
Term expansion summary	TermX: the Query Rewriting Engine for BingCore Relevance PM Meeting | Shu Zheng | Jan 5th, 2016AgendaWhat is TermX? Technique DeepdiveCurrent StateFuture WorksWhat is TermX? TermX = TermExp = Term ExpansionThe query rewriting engine for 	0.2612085964314305
Term expansion summary	Entity Pane and Fact AnswerPresenter: Ze TianJun 25, 2013IntroductionIntroductionIntroductionProblems to SolveDoes the user search for entities or facts of entities?E.g. “who is msft ceo” (Entity: Microsoft, Fact: Chief Executive O	0.26046730335226126
Term expansion summary	I’d like to explain in more details my idea of improving Dolphin, by improving its robustness of query variations and some previously unseen terms. Our rules don’t cover many query patterns. E.g., {top rated chinese restaurants} works well, but not {chi	0.24615202504873482
Term expansion summary	PERM Labor Certification Questionnaire:  Technical (continued)PERM Labor Certification Questionnaire (Technical)Please complete the information requested in this questionnaire carefully.  This information is necessary for the legal analysis and prepar	0.23714900631188537
Term expansion summary	Summary and HighlightsIn April the metrics/measurement team released local AutoSuggest metric and shared initial transit measurement results; BLU team shipped CL 1.0 ontology and deployed BLU v3 to all markets; PBA team shipped a new L2 ranker and refre	0.2358439205812072
Term expansion summary	Integrating Knowledge Graph in Web SearchEntity Triggering and CollectionsPresenter: Ze TianKnowledge GraphEntities and RelationsEntities: celebrities, people, generic terms (e.g. light bulb)Relations: sibling, spouse, people and their works	0.22667798500812272
Term expansion summary	FastRank--- a Decision-Tree based Ranking ModelYu SHIOutlineBackgroundAlgorithm overviewTraining implementationExperimentationChallengesReferencesBackgroundInvestigated by MSR in OsloShipped with July Tree 2010 (Denver)GoalsSpe	0.2236747647158237

Term Weight Based On Patterns Guideline	Pattern Based Term Weight FrameworkIntroductionPattern based term weight recognizes the importance for part of terms or all the terms based on patterns/templates/knowledge. There are 2 differences between general and pattern based term weight.Compar	0.7411446398703275
Term Weight Based On Patterns Guideline	Pattern Based Term WeightJia Liu2014-05-06FrameworkTerm AttributesSemantics definitionHuman understanding and knowledgeChange in different contextsLevels:KeywordAttributeRequirementStrong constraintWeak constraintVerbUseless	0.5702299739333329
Term Weight Based On Patterns Guideline	Pattern Based Term WeightVersion 1Jia Liu2014-06-16FrameworkTerm AttributesSemantics definitionHuman understanding and knowledgeChange in different contextsLevels:KeywordAttributeRequirementStrong constraintWeak constraintVer	0.5317469724619678
Term Weight Based On Patterns Guideline	Play Book of Pattern Engine Based Micro-segment PlatformIntroductionNow, per query pattern match features (PMFs) are available for ranking. You can get PMFs of your own pattern groups (PGs) immediately after several simple steps. With these signals, r	0.44163377151634786
Term Weight Based On Patterns Guideline	Measurement PlanSmoke test:We will deploy ranker model under test and service to INT and ask SKI internal users to issue whatever queries they want. In this way, we can quickly get feedback using Microsoft private data and Bing API. People can get min	0.43392126322922037
Term Weight Based On Patterns Guideline	Abacus Query Pattern SpecThis document describes how the query GEE pattern is passing from CAL into PDR, and generate a series of features depending on the <querypattern, URL-host> level matching. Query Property of GEEHere is the query property defi	0.414832033976563
Term Weight Based On Patterns Guideline	Local and mm magnesium asksCALApril 2013Microsoft ConfidentialContextWe are expanding to many international markets for Win-blueCAL/Speller impact can range from -1 to +2 points in DCG. Recent MM US DSAT analysis (Dec 2012) showed close to 1	0.40903647281409466
Term Weight Based On Patterns Guideline	alterationsalterations: product goalimprove recallby adding terms (not replacing or dropping user-entered terms)using word:which are synonyms to the original terms(we are re-examining each of these for vnext)alterations: general principl	0.39405330721613585
Term Weight Based On Patterns Guideline	Term expansion summaryGoalsVisible changes in ARDSImprove “no match” issuesImprove rank qualityLimit FPs. Pre-work neededPort names tagger to C#/C++Query timeWSD and entity taggerEntity tagging in query logs (Britney Spears bio -> <p	0.38368920528783257
Term Weight Based On Patterns Guideline	YPCutoff Selection                                                                                    -Ganesh Poomal GirirajanQuery Flow in IndexFilterSet GenerationL1 RankingL2 RankingExampleQuery: Southeast{Miami,Florida}-broward county sc	0.36658894181588564

Term Weight Based On Patterns Framework	Pattern Based Term Weight FrameworkIntroductionPattern based term weight recognizes the importance for part of terms or all the terms based on patterns/templates/knowledge. There are 2 differences between general and pattern based term weight.Compar	0.8236015243771108
Term Weight Based On Patterns Framework	Pattern Based Term WeightJia Liu2014-05-06FrameworkTerm AttributesSemantics definitionHuman understanding and knowledgeChange in different contextsLevels:KeywordAttributeRequirementStrong constraintWeak constraintVerbUseless	0.6708462204670338
Term Weight Based On Patterns Framework	Pattern Based Term WeightVersion 1Jia Liu2014-06-16FrameworkTerm AttributesSemantics definitionHuman understanding and knowledgeChange in different contextsLevels:KeywordAttributeRequirementStrong constraintWeak constraintVer	0.6235350369184135
Term Weight Based On Patterns Framework	Play Book of Pattern Engine Based Micro-segment PlatformIntroductionNow, per query pattern match features (PMFs) are available for ranking. You can get PMFs of your own pattern groups (PGs) immediately after several simple steps. With these signals, r	0.5105421689648179
Term Weight Based On Patterns Framework	Measurement PlanSmoke test:We will deploy ranker model under test and service to INT and ask SKI internal users to issue whatever queries they want. In this way, we can quickly get feedback using Microsoft private data and Bing API. People can get min	0.46457210911992464
Term Weight Based On Patterns Framework	Local and mm magnesium asksCALApril 2013Microsoft ConfidentialContextWe are expanding to many international markets for Win-blueCAL/Speller impact can range from -1 to +2 points in DCG. Recent MM US DSAT analysis (Dec 2012) showed close to 1	0.4496808328696595
Term Weight Based On Patterns Framework	Abacus Query Pattern SpecThis document describes how the query GEE pattern is passing from CAL into PDR, and generate a series of features depending on the <querypattern, URL-host> level matching. Query Property of GEEHere is the query property defi	0.41398252385645096
Term Weight Based On Patterns Framework	YPCutoff Selection                                                                                    -Ganesh Poomal GirirajanQuery Flow in IndexFilterSet GenerationL1 RankingL2 RankingExampleQuery: Southeast{Miami,Florida}-broward county sc	0.40511048114291537
Term Weight Based On Patterns Framework	Entity Pane and Fact AnswerPresenter: Ze TianJun 25, 2013IntroductionIntroductionIntroductionProblems to SolveDoes the user search for entities or facts of entities?E.g. “who is msft ceo” (Entity: Microsoft, Fact: Chief Executive O	0.3987321561900949
Term Weight Based On Patterns Framework	Simplified Query Path SelectorSimplified query: current systemSimplified query path selectionCrf model produces a list of possible ways to place rankonly operatorQuery = “nibbana restaurant official site”nibbana restaurant rankonly:official site	0.38394929049710497

Svm分类模型	SVM分类内容概要流程图预处理SVM分类器组合分类结果流程图内容概要流程图预处理SVM分类器组合分类结果特征选择特征，以文本行业分类来说，切词term特征的重要性“北京”是个没用的特征“速8”是个有用的特征“轻度”这个词呢？信息增益（Information Gain）   熵H是一个分布是否分散的表征，与信息相反概率估计P(ci) = ci类别的样本数 / 样本总数P(ci|t)  = t出现的属于ci	0.8010096635253436
Svm分类模型	Svm分类模型：基本原理：将所有待分类的点映射到“高维空间”，然后在高维空间中找到一个能将这些点分开的“超平面”，这在理论上是被完全证明了是成立的，而且在实际计算中也是可行的。满足条件的“超平面”的个数不是唯一的。SVM需要的是利用这些超平面，找到这两类点之间的“最大间隔”。并非所有的数据都线性可分，将非线性映射到更高维的特征空间变成线性可分。（低维空间向量集通常难于划分，解决的方法是将它们映射到高维空间。）但这个办法带来的困难就是计算复杂度的增加，而核函数正好巧妙地解决了这个问题。也就是说，只要选用	0.7983726391413891
Svm分类模型	贝叶斯分类模型：基础知识：假设	X：是数据元组，由n个属性描述；	H：是某种假设，如数据元组属于某特定类C	P(H|X)：表示给定X的属性描述，找出元组X属于类C的概率举例：X：一位35岁的顾客，收入为4w美元；H：顾客将购买计算机P(H|X)：在X的条件下，H的后验概率。当我们知道顾客的年龄和收入时，顾客X将购买计算机的概率。P(H)：H的先验概率。任意给定顾客将购买计算机的概率，独立与X。P(X|H)：在条件H下，X的后验概率。已知顾客购买了计算机，顾客是一位3	0.7711431891165569
Svm分类模型	K最近邻分类模型：原理：训练元组用n个属性描述，每个元组代表n维空间中的一个点，所有的训练元组存放在n维的模式空间。当给定一个未知元组时，KNN搜索该模式空间，找出最接近未知元组的k个训练元组。未知元组指派到它的k个最近邻中的多数类。“邻近性”用距离度量，如欧几里德距离。欧几里德距离：	设元组X1=(X11,X12,…X1n)，X2=(X21,X22,…X2n)，	Dist(X1,X2)=√ ∑ k= 1 n (X1i-X2i) 2 	使用上式之前，对每个属性的值规范化，以防止具有	0.7695862993474082
Svm分类模型	排序及扩展：插入排序，选择排序（冒泡排序），使用二分思想求第k大数，快速排序，非递归的快速排序，使用快排思想求第k大数，归并排序，求逆序数，自然排序算法，堆排序，最小优先级队列，计数排序，桶排序，鸽巢排序（分块排序），基数排序，外部排序：二路归并，K路归并，胜者树，败者树。  算法一：使用插入或者选择排序，得到最大的K个数，时间复杂度为：O(N*k)。 冒泡排序： void swap(int * a,int * b){            //注意	0.7692697002176511
Svm分类模型	克拉玛依公证处:本人因生活在国外，不能亲自到贵单位办理出生证明公证事项，兹授权委托雷春香女士全权代表我办理相关事项。对委托人在办理上述事项过程中所签署的有关文件，我均予以认可，并承担相应的法律责任。委托人：刘佳			委托人身份证号码：654301198608243929被委托人：雷春香		被委托人身份证号码：6526196207113926委托人：刘佳2018年5月24日	0.7692697002176511
Svm分类模型	性能升级性能升级的几个层面：系统结构：模块分解，模块交互，系统构建中的粗略估算。算法和数据结构：获得快速模块的关键：表示数据的结构，操作数据的算法：索引结构及拉链归并。代码调优：分支预测等。循环：将循环体中不改变的变量移动到循环体外；多重循环嵌套顺序。函数调用：inline函数节省函数调用开销：若makefile中不指定至少-O优化，即使声明为inline函数，编译器也不会进行函数内联。内存寻址：避免重复内存寻址。Cpu流水线的分支预测：将满足概率最高的条件放在靠前的位置。	0.7692697002176511
Svm分类模型	业务生成平台用户指南总体说明开发背景下一代网络是业务驱动的网络，在融合的下一代网络上高效、灵活地开发和部署各种丰富多彩的业务，从而提高网络使用率、增加收益的目标，是下一代网络的关键环节。下一代网络的发展要求呼叫与承载相分离、呼叫控制与业务相分离，使业务真正独立于网络，业务开发者不必关心与业务承载相关的底层网络知识以及具体的通信协议，只需利用业务生成平台提供的业务开发工具，就可以开发出灵活丰富且极具个性化的业务。 为了适合多种技术水平的业务开发人员的需要，现在主要有四种业务开发方式：	0.7692697002176511
Svm分类模型	工作6周年5个月小记今天是中国时间8/24/2018，也就是我32岁的生日，这是一个不老也不再年轻的年纪。最近总是因为工作而郁郁寡欢，心中不快，所以决定记录总结一下，希望自己能有所释怀、转变、确立新的目标。从2012年3月31到现在，我已在微软Bing工作6年5个月。在此之前，我在百度实习9个月，在阿里巴巴实习2个月，在搜狗实习1个月。在微软北京CJK relevance组勤恳的工作2年6个月，从级别59升到61，做了1年半的DU, 1年的relevance。总体来说，老板们的风格是相关性主导基础	0.7675494601895142
Svm分类模型	海量数据库的设计和实现淘宝海量数据库之一：来自业务的挑战(2010-11-24 11:34:38) 作为一个电子商务企业，从一开始，数据库及其事务能力在淘宝一直扮演着十分关键的角色，淘宝积累了丰富的数据库的架构和规划等方面的经验，产生了众多优秀的DBA。 淘宝是一家迅速发展的公司。全球网站排名公司Alexa提供的数据显示，2010年4月27日，Amazon、Ebay的用户占全球互联网用户的百分比分别为3.47%和2.68%，而淘宝的用户占全球互联网用户的百分比则达到了4.1%，淘宝网日	0.7666710928538504

SubstrateAuthInPictures	Microsoft ConfidentialSubstrate Day 2018 Naresh SundaramSubstrate Architecture Overview1High level framing Distributed Computing Fabric @Scale2Physical Fabric – Datacenters & Servers3Data Tier - Scalability & Availability4Logical	0.3376018125470626
SubstrateAuthInPictures	FastRank--- a Decision-Tree based Ranking ModelYu SHIOutlineBackgroundAlgorithm overviewTraining implementationExperimentationChallengesReferencesBackgroundInvestigated by MSR in OsloShipped with July Tree 2010 (Denver)GoalsSpe	0.26736763239598843
SubstrateAuthInPictures	Local Category Search Plan3 month StrategyData: Entity categorizationScalable, high precision/recallSegments: Food & Drink, Retail, Service, Auto, HotelMetaStream enrichmentQuery UnderstandingDolphin by defaultConsume PhoneBookQU to im	0.25051604437023933
SubstrateAuthInPictures	Publication date optimization for Japan marketBackgroundPublication date is very important to fresh queries, outdated issues and caption date showing. Now the coverage of publication date for Japan market is very low because publication date extract	0.23200533635463574
SubstrateAuthInPictures	Threshold Query Formulation Deep DiveGoal of the presentation is to communicate our approach for query formulation and get feedback on whether this aligns with overall Threshold goals.OverviewGoals & MetricsQF ModelRoadmapScenariosKey Ta	0.23164244479207755
SubstrateAuthInPictures	Microsoft ConfidentialSubstrate Day 2018 Michelle QuintonBuilding onthe Substrate:From Scenario to SolutionSubstrate PatternsStoring DataProcessing DataAuth for Data AccessBuilding a Compliant ServiceThere are many talks today and I 	0.21495788631570964
SubstrateAuthInPictures	Auto Category Classification PipelineHanqing Cui2012/10/25OutlinePain PointsThinkingAuto Category Classification PipelineAuto Page LabelingData SamplingTrainingFeature SelectionThresholdIterative TrainingInitial Seed Model Creati	0.20833539774599977
SubstrateAuthInPictures	InstructionS FOR obtaining photographsfor your applicationPHOTO REQUIREMENTS:Your photographs must be:2x2 inches in size Identical Taken within 30 days of filing the application(s), showing current appearance In color Full face, front view	0.18160538302928525
SubstrateAuthInPictures	Publication date optimization for zh-cn marketBackgroundPublication date is a very fundamental and important feature. It can help fresh ranking, whole page user experience: caption date show and freshness internal metrics, also to solve mainline out	0.1802047212355299
SubstrateAuthInPictures	Index Quality UpdateAgendaMetrics UpdateSelection Model ImprovementRecall TierOffice ImprovementChallenges and Pain PointsHow to measure index quality?Ideally: sampling from all “good” images and see how much we covered.sampling from a	0.1717289895916165

Substrate Architecture Overview_Final	FastRank--- a Decision-Tree based Ranking ModelYu SHIOutlineBackgroundAlgorithm overviewTraining implementationExperimentationChallengesReferencesBackgroundInvestigated by MSR in OsloShipped with July Tree 2010 (Denver)GoalsSpe	0.44508222003874043
Substrate Architecture Overview_Final	Spam/Junk Technology ReviewAgendaSpam/Junk OverviewReview of current metrics and pipelinesExample of recently shipped technologiesJunk page elimination by cross page signalsAnti-{malicious page redirection spam attack}Looking aheadSpam in 	0.3886808331633787
Substrate Architecture Overview_Final	Local Category Search Plan3 month StrategyData: Entity categorizationScalable, high precision/recallSegments: Food & Drink, Retail, Service, Auto, HotelMetaStream enrichmentQuery UnderstandingDolphin by defaultConsume PhoneBookQU to im	0.36762287231436863
Substrate Architecture Overview_Final	Microsoft ConfidentialSubstrate Day 2018 Naresh SundaramSubstrate Architecture Overview1High level framing Distributed Computing Fabric @Scale2Physical Fabric – Datacenters & Servers3Data Tier - Scalability & Availability4Logical	0.3641806250280527
Substrate Architecture Overview_Final	Anchor and Click Stream RankingSteven ZittrowerBing Local Search RelevanceHypothesisConverting local search’s unstructured and raw text streams into semi-structured forms will improve ranking and offer relevance benefits.TestUsing classifiers 	0.35591298327617943
Substrate Architecture Overview_Final	Ranker Training Pipeline IntroductionAgendaPipeline OverviewGCC platformExtractionData/Feature PreparationMain Ranker TrainingSegment RankersPipeline OverviewGR OctTree: gcclinkMain Steps:Metastream injection (just info here)Querys	0.3435367563232699
Substrate Architecture Overview_Final	Auto Category Classification PipelineHanqing Cui2012/10/25OutlinePain PointsThinkingAuto Category Classification PipelineAuto Page LabelingData SamplingTrainingFeature SelectionThresholdIterative TrainingInitial Seed Model Creati	0.34300870829156227
Substrate Architecture Overview_Final	Training data distributionContain categories as many as possible : 36 categies. The data of category in the same amountContain hudong data and  host dataPositive : negative = 1:7  ~ 1:10 categoryhudonghostpositivenegativeNegative_total	0.3331242959368904
Substrate Architecture Overview_Final	Publication date optimization for zh-cn marketBackgroundPublication date is a very fundamental and important feature. It can help fresh ranking, whole page user experience: caption date show and freshness internal metrics, also to solve mainline out	0.3146866305941086
Substrate Architecture Overview_Final	Threshold Query Formulation Deep DiveGoal of the presentation is to communicate our approach for query formulation and get feedback on whether this aligns with overall Threshold goals.OverviewGoals & MetricsQF ModelRoadmapScenariosKey Ta	0.292253594962622

Substrate - Scenario to Solution_CB Updated	Microsoft ConfidentialSubstrate Day 2018 Michelle QuintonBuilding onthe Substrate:From Scenario to SolutionSubstrate PatternsStoring DataProcessing DataAuth for Data AccessBuilding a Compliant ServiceThere are many talks today and I 	0.4430385004175433
Substrate - Scenario to Solution_CB Updated	Microsoft ConfidentialSubstrate Day 2018 Naresh SundaramSubstrate Architecture Overview1High level framing Distributed Computing Fabric @Scale2Physical Fabric – Datacenters & Servers3Data Tier - Scalability & Availability4Logical	0.41281117664685163
Substrate - Scenario to Solution_CB Updated	FastRank--- a Decision-Tree based Ranking ModelYu SHIOutlineBackgroundAlgorithm overviewTraining implementationExperimentationChallengesReferencesBackgroundInvestigated by MSR in OsloShipped with July Tree 2010 (Denver)GoalsSpe	0.35143045859401345
Substrate - Scenario to Solution_CB Updated	Local Category Search Plan3 month StrategyData: Entity categorizationScalable, high precision/recallSegments: Food & Drink, Retail, Service, Auto, HotelMetaStream enrichmentQuery UnderstandingDolphin by defaultConsume PhoneBookQU to im	0.32267322447764824
Substrate - Scenario to Solution_CB Updated	WrapStar On-Demand DesignDrafted by ZiliuContentsContext2Design Goals2Automation2Deployment Agility2High Availability2Non-Goals2Metrics2Required Changes3Orchestration3AP Migrations3Pipeline Evolution3Tools/services refactoring3	0.32157075689836806
Substrate - Scenario to Solution_CB Updated	Zhcn document classification based on topicJia Liu2012.11.14agendarTraining data selection&crawl&cleanFeature selection&cleanClassifierRating Bad case analysisTrainning data	0.312833289317188
Substrate - Scenario to Solution_CB Updated	Global relevance feature proposalFeature name: Title Match OptimizationPMJin GuoDevJia LiuTestReleaseALTeam site linkExecutive SummaryTitle is the summary/abstract of the document. Title Match is very important to SBS. Through many c	0.30960496734231746
Substrate - Scenario to Solution_CB Updated	Relevance Debug InfrastructureProblemFrequent  daily metric fluctuationRelevance gain negated by regressions from Sep to Oct 2013Painful to investigateChallengeLocal stack is complex with lots of componentsVarious relevance events mixed toge	0.30398078449805427
Substrate - Scenario to Solution_CB Updated	QU Deep Dive 2: Query Simplification and Recurrent Neural NetworkXiaolong Li (Lead of QU Fundamentals TEAM)2/12/2015AgendaQUFun Team ResponsibilitiesRecent Deliverables Query Simplification for WebQuery Simplification for Cortana 3ARec	0.3019927412201884
Substrate - Scenario to Solution_CB Updated	Entity Categorization Using Convolutional Neural NetworkWeiwu Zhu8/23/2018AgendaMotivationCNN introductionCNN in NLPCNN based entity categorizationMeasurementMotivationTaxonomy mapping is not scalable (Feature Normalization)Nee	0.2991985651757138

StreamSets-(2014-04-15)	CosmosScope > StreamSetsHiren Patel & Saveen Reddy2014/02/06© 2012 Microsoft Corporation. All rights reserved. Microsoft, Windows, and other product names are or may be registered trademarks and/or trademarks in the U.S. and/or other countries.The	0.3616054215013533
StreamSets-(2014-04-15)	唐蕾电话: (+86) 180-0132-3861Email: tanglei91@126.com工作经历                                                                    04/2014至今 :    	中国电信集团系统集成有限责任公司 软件测试工程师1.招标测试时间:05/2016至今项目描述：通过招标测试帮助甲方找到合适的厂家做他们项目中的某些模块。项目职责：负责招标测试跟产品经理讨论并细化需	0.30661618025134374
StreamSets-(2014-04-15)	成交日期 买卖标志 成交价格 成交数量 成交金额 20160106 买入 100 1702 20160113 买入 100 1532 20160325 卖出 100 1695 20160708 卖出 100 1570 20160725 卖出 500 10700 20160802 卖出 300 6660 20160802 卖出 200 4430 20160803 卖出 200 4672 20160908 卖出 100 2695 成交日期 买卖标志 成交价格 成交数量 成交金额 20160112 买入 100	0.30480862813264276
StreamSets-(2014-04-15)	空检索优化：背景：空检索请求耗时分析：统计7.21的所有空检索耗时：(71551个)      1 10144.000000      2 bs:4767252.000000       ----->66.63ms      3 390.000000      4 统计：2818865.000000   ----->39.4ms      5 1187696.000000      6 1588991.000000          7 7554473.000000	0.3001823699979356
StreamSets-(2014-04-15)	成交日期 买卖标志 成交价格 成交数量 成交金额 2016年亏319 2015及2016年已完结 20160105 买入 100 897 20160108 卖出 8 200 1600 20150615 买入 100 1889 20150615 买入 100 1840 20150624 卖出 100 1585 20150720 买入 100 1073 20150721 买入 100 1098 20150721 买入 100 1086 20150723 买入 100 1110 20150818 卖出 500 	0.2944953128281228
StreamSets-(2014-04-15)	BLU V3 Minghua Zhang      01/26/2016Next version of BLU Relevance Infrastructure​OutlineWhy BLU v3BLU v3 DesignCurrent StatusFuture WorkWhy BLU v3 (1)Limitations of current BLU infrastructureFeaturesCouldn’t utilize QAS feature	0.28990611951711465
StreamSets-(2014-04-15)	Blue-Whale Multimedia Rank Data-FlowEugene Jian Huangjianhua@microsoft.com2012-03-13MM Page Static RankMedia LinkExpress RankMM Page Express RankMM PageSuper-Fresh RankMM PageSubmission RankMM PageEffective Rank Media Entit	0.287980326794515
StreamSets-(2014-04-15)	成交日期 买卖标志 成交价格 成交数量 成交金额 20160105 买入 100 897 20160108 卖出 8 200 1600 成交日期 买卖标志 成交价格 成交数量 成交金额 20160106 买入 100 1702 20160113 买入 100 1532 20160325 卖出 100 1695 20160708 卖出 100 1570 20160725 卖出 500 10700 20160802 卖出 300 6660 20160802 卖出 200 4430 20160803 卖出 20	0.2841180356509919
StreamSets-(2014-04-15)	CosmosStreamSetsSaveen Reddy2014/04/15http://aka.ms/CosmosPresentationshttp://aka.ms/CosmosCodeSamples© 2012 Microsoft Corporation. All rights reserved. Microsoft, Windows, and other product names are or may be registered trademarks and/or tra	0.279186099413622
StreamSets-(2014-04-15)	贴吧大数据存储luhongbo@baidu.com2011-8-7/31目录概述和现状设计原则pbFrs负载均衡发展方向2011-8-7/31贴吧数据概述2011-8-7/31贴吧存储现状按照功能做模块水平拆分各模块均为数据单机模式镜像抗压力2011-8-7/31设计要求和原则性能（更新、浏览）访问模式决定设计最优化内存使用有效利用磁盘特性硬盘？Flash？顺序io还是随机读写？区别对待高峰期和	0.27112388857007236

Stateful Query Intent Refinement	Stateful Query Intent RefinementFeature OverviewStateful Query Intent Refinement is a Bing QR service that can be leveraged to guide users to their specific intent. Queries that have ambiguous intent or multiple intents/sub-intents can be refined usin	0.7564702975169967
Stateful Query Intent Refinement	Threshold Query Formulation Deep DiveGoal of the presentation is to communicate our approach for query formulation and get feedback on whether this aligns with overall Threshold goals.OverviewGoals & MetricsQF ModelRoadmapScenariosKey Ta	0.4386822135162774
Stateful Query Intent Refinement	Analyzed Query represents all information derived from all classification tasks executed on the Query. QAS supports 3 basic classifications tasks: binary classification (Domain Classification), entity extraction (Query Parse), category classification (Dom	0.41127921109716725
Stateful Query Intent Refinement	Simplified Query Path SelectorSimplified query: current systemSimplified query path selectionCrf model produces a list of possible ways to place rankonly operatorQuery = “nibbana restaurant official site”nibbana restaurant rankonly:official site	0.3661469796705374
Stateful Query Intent Refinement	Introduction toas measurement platformOlli-Pekka TossavainenMSQ TeamSunnyvaleContentsOverviewAres AssetsData Web Store (DWS)Single HitApp core relevance exampleWhat is ARESFrom their web site:What’s been built on ARESMap Search	0.36556068729874286
Stateful Query Intent Refinement	Relevance Experimentation with DUOverviewThe ideal end state for any relevance improvement would consist of having one or more DU features shipped in the index that is then leveraged by the latest production ranker. This would achieve the highest leve	0.3458945954707526
Stateful Query Intent Refinement	Query AugmentationsTable of Contents1. Syntax Overview	22. Constraints	6General rules for operators	7Basic Operators	7Scoring and non-scoring constraint operators	9Stream Operators	9Literal Operators	10Meta Operators	11URL Operators	13	0.31596385687474765
Stateful Query Intent Refinement	RelaxCount Classifier in JO V3By: Gord Lueck, 2013.09.04BackgroundCAL now has the ability to ship with a relaxcount classifier.  That is, a trained decision tree that is designed to predict the relaxcount decision on a query.  The classifier can be 	0.3018272055578693
Stateful Query Intent Refinement	Index Quality UpdateAgendaMetrics UpdateSelection Model ImprovementRecall TierOffice ImprovementChallenges and Pain PointsHow to measure index quality?Ideally: sampling from all “good” images and see how much we covered.sampling from a	0.29797082018603305
Stateful Query Intent Refinement	Partner Index as ServiceWhat is the Problem? RequirementCurrent status of Bing Image StackDiscoveryClient tend to provide feed for full corpusWeb crawlerImage Content RetrievalSpecial agreement, some even behind authentication for access	0.29795628303083377

Speller_Related_Issues_Solutions	Speller Related Issues & SolutionsMing Wu2014-01-08Speller Related Issues – in nativePBA reads spell corrected query from Speller kif responseAssumes offsets are on raw query, which is not the caseE.g. {   piza hut} -> {pizzaiza hut}Proposed	0.7249686802743478
Speller_Related_Issues_Solutions	L-1B SPECIALIZED KNOWLEDGE QUESTIONNAIREMICROSOFT POSITION IN THE U.S.Provide the following information for your current position at the Microsoft.MICROSOFT POSITION ABROADProvide the following information for your position at the Microsoft’s su	0.4220634158616231
Speller_Related_Issues_Solutions	LES with Speller in BFPRAnton AmirovBenefitsSupport for misspelled location, metrics improvementAlignment with web resultsCurrent statusHybridLESRaw QuerySpell Corrected QuerySpellerFLEFLEWithSpellerSome answers (AmberAlerts, Electio	0.3970227089357033
Speller_Related_Issues_Solutions	NGram Language Model based Url Breaking – Design DocumentStatusOngoingIntroductionUrl is a very important signal for ranking, particularly for tail queries and navigation queries. This signal has 100% url coverage, which really makes it different 	0.39536669060565915
Speller_Related_Issues_Solutions	Spam/Junk Technology Review8/8/2017 Pavel KarpovichAgendaSpam/Junk OverviewReview of current system and metricsSJRE Fishtank pipelines UrlExclusion and Defect Subranker	Blue Whale Spam Types of Fresh SpamActions to Detect Fresh	0.38121306745843603
Speller_Related_Issues_Solutions	Deal UnderstandingDeals with Low Quality: (some features/rules are listed below)Features/RulesExamplesNo user used; no verified informationThe policies about return365 Day Return Policy;Free Returns on All Orders; 45 Day Return Money Back 	0.3622210701301896
Speller_Related_Issues_Solutions	Spam/Junk Technology ReviewAgendaSpam/Junk OverviewReview of current metrics and pipelinesExample of recently shipped technologiesJunk page elimination by cross page signalsAnti-{malicious page redirection spam attack}Looking aheadSpam in 	0.36017968904958114
Speller_Related_Issues_Solutions	cal deepdiverelaxationdec 2017AgendaProduct GoalsQuery SimplificationMechanism/RuntimeCRF Model TrainingQS Path SelectionOffline SimulatorSmart RelaxMechanism & TrainingRelaxation: ImpactRelaxation: Product goalsImprove Rec	0.35102084890770585
Speller_Related_Issues_Solutions	Relevance ServiceScenarioIconApplicationDoc typeCandidatesModelRun0-termWord;OutlookWin32 client.All file typesMRUReuse ContentModel 1Client0-termPower PointWin32 client.Only ppt typeLocal + MRUReuse Conte	0.3271560158233359
Speller_Related_Issues_Solutions	The follow diagram illustrates the whole pipelineThe session ranker uses the following features from four categoriesOn Session:A session is defined to be a sequence of user’s clicks and queries. In this project we refine the session to be the peri	0.30738877411323146

Spec - Title Match Optimization	Click to edit Master title styleEdit Master text stylesSecond levelThird levelFourth levelFifth levelThis deck is intended for use with INTERNAL AND EXTERNAL audiences.The slides and talking points are designed to help you tell our culture s	0.36259593416268426
Spec - Title Match Optimization	ML Model Scorecard Analysis8/8/2019Unexpected term search movementhttps://exp.microsoft.com/xcard/?view=4e77b420-7b77-4e41-92ac-8e84f506fb01Check correctness of scorecard metric implementationCalculate term AVG rank from raw data streamsSearch	0.34233739481898506
Spec - Title Match Optimization	CAL MultiQuery {Matching\Ranking}		Page 3 of 4CAL MultiQuery {Matching\Ranking}DescriptionCAL is going to optimize against matching\ranking separately and will issue different queries to each tier. CAL will be leveraging several operator such as:m	0.3419306853051554
Spec - Title Match Optimization	Golden QueryEvery query countsImprove relevance: Relevance TechniquesWin/Loss basedGood technique has better win/loss ratioGeneric Ranker always doesn’t have good win/loss ratioWe do technique triage, and better win/loss ratio technique got sh	0.340432825794793
Spec - Title Match Optimization	L2 General Title MatchJia Liu2/25/2014N-Gram Table6B Documents TitleN-Gram is continually builtTitle: A B C D3-Gram: A B C, B C D1-Gram to 10-Gram, N is in [1…10]Format: N-gram \t Len \t FrequencyTable Guid:3ce6e18c-ad7e-47e0-94ec-dfd6	0.3353253278446961
Spec - Title Match Optimization	Index Quality UpdateAgendaMetrics UpdateSelection Model ImprovementRecall TierOffice ImprovementChallenges and Pain PointsHow to measure index quality?Ideally: sampling from all “good” images and see how much we covered.sampling from a	0.33466854377782634
Spec - Title Match Optimization	L-1B SPECIALIZED KNOWLEDGE QUESTIONNAIREMICROSOFT POSITION IN THE U.S.Provide the following information for your current position at the Microsoft.MICROSOFT POSITION ABROADProvide the following information for your position at the Microsoft’s su	0.33069590297166496
Spec - Title Match Optimization	Successful Feeds Query DebuggingNikita Melnichenko, 2015-03-10Feeds query debugging overviewWhen to use:Checking a new rankerChecking new augmentation before running a scrapeComparing several rankersUnderstanding feature contributionDebugg	0.32755108561933943
Spec - Title Match Optimization	Microsoft ConfidentialClick to edit Master title styleEdit Master text stylesSecond levelThird levelFourth levelFifth levelMicrosoft ConfidentialMicrosoft ConfidentialMicrosoft ConfidentialGISELLI PANONTINIDEEPANKAR DUBEYSubstrate 	0.32556420960713484
Spec - Title Match Optimization	Speller Related Issues & SolutionsMing Wu2014-01-08Speller Related Issues – in nativePBA reads spell corrected query from Speller kif responseAssumes offsets are on raw query, which is not the caseE.g. {   piza hut} -> {pizzaiza hut}Proposed	0.3238481009954143

Span Classifier	Span ClassifierSpan classifier is a general infrastructure that can be used to run a fastrank based classifier on a sequence of terms from a query.  It can be used to apply rankonly or norelax to parts of the query based on the result of the model.  Fea	0.646993777677377
Span Classifier	Document classification based on urlBackgroundWe want to do document classification for better understanding the document type and document with query category match for ranking.  We will do zh-cn document classification based on url first, then docum	0.2792977467232486
Span Classifier	Spam/Junk Technology ReviewAgendaSpam/Junk OverviewReview of current metrics and pipelinesExample of recently shipped technologiesJunk page elimination by cross page signalsAnti-{malicious page redirection spam attack}Looking aheadSpam in 	0.27503357763165975
Span Classifier	Page Classifiers OverviewJakub Szymanski (jakubs)AgendaType of models available in QASProcess for training modelsClick graph service (QEP)Training models - MLGResourcesMicrosoft ConfidentialWhat is a binary query classifier {family t	0.2745280560632032
Span Classifier	Spam/Junk Technology Review8/8/2017 Pavel KarpovichAgendaSpam/Junk OverviewReview of current system and metricsSJRE Fishtank pipelines UrlExclusion and Defect Subranker	Blue Whale Spam Types of Fresh SpamActions to Detect Fresh	0.27195549401455593
Span Classifier	SPAM & JunkSi Planning Cheng Niu, Alex Rahin6/18/2014Agenda	Focus AreasMetricsSPAM/Junk Metrics BreakdownData Analysis and Project DefinitionFocus AreasImprove SPAM Detection (~35% of team bandwidth)Stolen ContentContent Keyword St	0.22478575349809926
Span Classifier	PA Selection StackKeng-hao Chang3/8/2017AgendaQuery (offer) understandingRetail classifierCategorizerCRFSelection algorithmsRIIRNGSRanking methodsL0, L1, L1.5, L2, Attribute-awareRetail experiencePA stack via Components*RnR	0.181732237825068
Span Classifier	Zh-cn Document classification based on topicBackgroundWe want to do zh-cn document classification for better understanding the document type and topic. It can help ranking with document and  query category matching. We defined our category system: 69 	0.17497437109886968
Span Classifier	ODP Classification: Summarizing Pages as a Topic DistributionNov 17, 2010Paul Bennett (pauben), MSR CLUESJoint work with Max Chickering & Susan Dumais© 2006 Microsoft Corporation. All rights reserved. Microsoft, Windows, Windows Vista and ot	0.15906748386035857
Span Classifier	CRF Parser AnalysisBusiness category searchOverviewParser (phonebook)CRF ParserqueryLocation featuresCRF featuresQuery parsetoken[tag] token[tag] … token[tag]userBLUbusiness_namebusiness_categorylocationlocation_separatorbu	0.1588788061569275

SpamJunk-Review-Deep-Dive-8-8-2017	Spam/Junk Technology Review8/8/2017 Pavel KarpovichAgendaSpam/Junk OverviewReview of current system and metricsSJRE Fishtank pipelines UrlExclusion and Defect Subranker	Blue Whale Spam Types of Fresh SpamActions to Detect Fresh	0.5972015251629499
SpamJunk-Review-Deep-Dive-8-8-2017	Spam/Junk Technology ReviewAgendaSpam/Junk OverviewReview of current metrics and pipelinesExample of recently shipped technologiesJunk page elimination by cross page signalsAnti-{malicious page redirection spam attack}Looking aheadSpam in 	0.5173308152077258
SpamJunk-Review-Deep-Dive-8-8-2017	SPAM & JunkSi Planning Cheng Niu, Alex Rahin6/18/2014Agenda	Focus AreasMetricsSPAM/Junk Metrics BreakdownData Analysis and Project DefinitionFocus AreasImprove SPAM Detection (~35% of team bandwidth)Stolen ContentContent Keyword St	0.4605380982008429
SpamJunk-Review-Deep-Dive-8-8-2017	Query Automotive & Vehicle Services (90056) Banking & Finance (90111) Beauty & Spa (90353) Food & Drink (90232) Healthcare (90375) Professionals & Services (90496) Real Estate (90584) Retail (90628) Sports & Recreation (90848) Travel (90881) Other Categor	0.3712005074683482
SpamJunk-Review-Deep-Dive-8-8-2017	11/17 AGI review with HarryCES: cover AI for OfficeCo-market with NvidiaMPQnA Keep in Jordi’s demo in the Dec AI eventAbortion query is very controversial	Not our responsibility to make the decision for the user but it’s the search engine’s re	0.3563827145498159
SpamJunk-Review-Deep-Dive-8-8-2017	Deal Ranking Improvement & MeasurementBackgroundAfter we shipped deal understanding, bad deals filtering, deal ranking for the entity search deals and popular deals nearby. We want to measure and improve our deal ranking based on user behaviors. We ca	0.3419687492339606
SpamJunk-Review-Deep-Dive-8-8-2017	Bing Location Understanding (BLU) As a ServiceDeep-Dive PresentationRajasi Saha (tech lead for BLU infrastructure)Jian Wu (tech lead for BLU relevance)Microsoft ConfidentialOutlineIntroduction to BLUBLU as a serviceMotivationScenarios an	0.324754718103962
SpamJunk-Review-Deep-Dive-8-8-2017	AgendaBusiness Update (20 min)Guest Speaker - Saurabh(20 min)FY19 Update (40 min)New Hires / Anniversaries (10 min)Demos (20 min)Q&A (10 min)Bing Dashboard – December ‘18- Harry Level GoalGreen : on / above targetOrange :  -ve trend 	0.31811059541537334
SpamJunk-Review-Deep-Dive-8-8-2017	Speller Related Issues & SolutionsMing Wu2014-01-08Speller Related Issues – in nativePBA reads spell corrected query from Speller kif responseAssumes offsets are on raw query, which is not the caseE.g. {   piza hut} -> {pizzaiza hut}Proposed	0.31614833256306285
SpamJunk-Review-Deep-Dive-8-8-2017	1/29 AGI ReviewAttendees: Harry Shum, Yi-Min Wang, David Ku, Steven Yao, Jianfeng Gao, Saurabh Tiwary, JJ Liu, Mir RosenbergTask Oriented Dialog AgentsJianfengShare the “Hail Caesar” slide (rule-based vs. RL dialog)Write what we discussed on Cor	0.3157090391269978

SpamJunk-Review-2016	Spam/Junk Technology Review8/8/2017 Pavel KarpovichAgendaSpam/Junk OverviewReview of current system and metricsSJRE Fishtank pipelines UrlExclusion and Defect Subranker	Blue Whale Spam Types of Fresh SpamActions to Detect Fresh	0.6028633777440121
SpamJunk-Review-2016	Spam/Junk Technology ReviewAgendaSpam/Junk OverviewReview of current metrics and pipelinesExample of recently shipped technologiesJunk page elimination by cross page signalsAnti-{malicious page redirection spam attack}Looking aheadSpam in 	0.55737214118284
SpamJunk-Review-2016	SPAM & JunkSi Planning Cheng Niu, Alex Rahin6/18/2014Agenda	Focus AreasMetricsSPAM/Junk Metrics BreakdownData Analysis and Project DefinitionFocus AreasImprove SPAM Detection (~35% of team bandwidth)Stolen ContentContent Keyword St	0.4746431288992949
SpamJunk-Review-2016	BLU V3 Minghua Zhang      01/26/2016Next version of BLU Relevance Infrastructure​OutlineWhy BLU v3BLU v3 DesignCurrent StatusFuture WorkWhy BLU v3 (1)Limitations of current BLU infrastructureFeaturesCouldn’t utilize QAS feature	0.27883890403258266
SpamJunk-Review-2016	Blue-Whale Multimedia Rank Data-FlowEugene Jian Huangjianhua@microsoft.com2012-03-13MM Page Static RankMedia LinkExpress RankMM Page Express RankMM PageSuper-Fresh RankMM PageSubmission RankMM PageEffective Rank Media Entit	0.25586550050056855
SpamJunk-Review-2016	CosmosScope > StreamSetsHiren Patel & Saveen Reddy2014/02/06© 2012 Microsoft Corporation. All rights reserved. Microsoft, Windows, and other product names are or may be registered trademarks and/or trademarks in the U.S. and/or other countries.The	0.2326895952851319
SpamJunk-Review-2016	Paul LuberPrincipal Group PMSamim ErdoganPrincipal Pm ManagerIntroducing Substrate 	MICROSOFT CONFIDENTIALSubstrate Day 2018A cloud platform for compliant, scalable apps that offer intelligent experiences built on rich user data.What is Su	0.22917407916607613
SpamJunk-Review-2016	AgendaBusiness Update (20 min)Guest Speaker - Saurabh(20 min)FY19 Update (40 min)New Hires / Anniversaries (10 min)Demos (20 min)Q&A (10 min)Bing Dashboard – December ‘18- Harry Level GoalGreen : on / above targetOrange :  -ve trend 	0.21262411533329212
SpamJunk-Review-2016	FY19 Search & AI Roadmap Review: Intelligent QnAMay 2018PM: Ali Alvi, Kaan Ozel, Ganga Venkatasubramanian, Oana NicolovDev: Xia Song, Doran ChakrabortyAgendaOverall QnA Opportunity and GoalsSemi-Structured DataMALTATuring for QnAAGI En	0.21025247966264726
SpamJunk-Review-2016	Microsoft US Immigration PortalHow To Update Your DependentsJuly 24, 2017Step 1: Log in to your account by clicking “Log In”, either in the header or in the banner image.Step 2: Go to Your Family from the header, or by selecting “Manage Your Depen	0.20888121135411775

SmartRelax_3way	SmartRelax OFE and TrainingOverviewAnalysis of smartrelax flightsOFE flight simulatorIs smartrelax ever bad?Smartrelax model training:Training method I: relax-specific targetsTraining method II: end-user targetsSmart Relax OFE and Training	0.646906130331896
SmartRelax_3way	SmartRelax training and evaluation from 15%/15% flightForay scorecard: 15%+15% datagatheringUser-triggered scorecardSSRx gain of 0.12%, for 3+4 word on vs. 3+4 word off. (NOT vs. prod.)Gain is 36% from SSR, 11% from TTS, 52% from TSRSSRx gains s	0.4540875854205362
SmartRelax_3way	Smart Query Relaxation In Joint OptimizationA Cross-Group Collaborations Among QU/QR/CoreRanking/IS/MSR      Presented By : Xiaolong Li (Query Understanding)8/19/2013Smart Query Relaxation in JOPOutlineJOP V2 SummaryQuery Relaxation An	0.357182267429473
SmartRelax_3way	Deep RelaxQuery Relaxation and L1 FidelityQuery Relaxation{printable iphone 7 user guide}rankonly:printable iphone 7 rankonly:user guiderankonly:printable iphone 7 user guideDeep Relax and vector similarity Encode query without each toke	0.25141887446175026
SmartRelax_3way	OSG Threshold[Cortana/Improving Cortana Personalization Through Finances]functional specification[Shell/CAST]CONTACTSROLEName; AliasProgram ManagerColleen Hamilton; chamiltDeveloperQualityDesignPartner(s)ONE PAGE SPEC - Guideline	0.18646809069317366
SmartRelax_3way	Relaxcount=2 summaryRelaxcount=2 datagatheringDatagathering for relaxcount=2 branched path (3/14/15-3/20/15):Cal13a: control (OFE logging, relaxcount=2 off), 6% trafficCal13b: on (OFE logging, relaxcount=2 on for word count >=5), 12% traffic.Dat	0.17804343433277872
SmartRelax_3way	ElasticSearchInternalElasticSearch and oSearchElasticSearch  ArchitectureLucene FamilyoSearch  ArchitectureScenario and ScaleoSearchElasticSearchScope Strong structured dataImage with ANNUnstructured text Loose structured data	0.173049520176986
SmartRelax_3way	Relaxcount=2Momo JengRelaxcount=2 datagatheringDatagathering flight for relaxcount=2:3/14/2015-3/20/2015Cal13a: control (OFE logging, relaxcount=2 off), 6% trafficCal13b: always on (OFE logging, relaxcount=2 on), 12% trafficThe flight was do	0.17147594022330628
SmartRelax_3way	BS代码阅读：BS基本功能：索引相关性切词成分分析offset调权query解析 （where+what）多路归并 综合调权类聚（偏离点）query分类空间调权数据来源点击调权BS代码阅读：bs_cache:map库的term cachemap库term cache操作锁where库term cachewhere库term cache操作锁init_map_term_cache: 初始化map库term cachein	0.15643786915283753
SmartRelax_3way	Smart relax, 3-way choiceMomo JengOffline simulationGeneral process for offline simulation:We have n choices to decide between, where n is small.Given choices A, B, and C, randomly show users A, B, or C.Randomization can be per-user (i.e. se	0.15061830730026513

SmartQueryRelaxationInJOP-Jan-dev-talk-2013-08-19	SmartRelax OFE and TrainingOverviewAnalysis of smartrelax flightsOFE flight simulatorIs smartrelax ever bad?Smartrelax model training:Training method I: relax-specific targetsTraining method II: end-user targetsSmart Relax OFE and Training	0.5601175763262862
SmartQueryRelaxationInJOP-Jan-dev-talk-2013-08-19	Smart Query Relaxation In Joint OptimizationA Cross-Group Collaborations Among QU/QR/CoreRanking/IS/MSR      Presented By : Xiaolong Li (Query Understanding)8/19/2013Smart Query Relaxation in JOPOutlineJOP V2 SummaryQuery Relaxation An	0.5058769076049466
SmartQueryRelaxationInJOP-Jan-dev-talk-2013-08-19	Distance Model, LDS, L3Knowledge SharingNikita Melnichenko, Bing Local2017-04-21Overview of PBA relevance flow in FeedsL1Keyword matchWPOL2 levelRankerTruncationCategory matchName matchLogical DistanceUI sortingGIMXIMGDM	0.4586346244385676
SmartQueryRelaxationInJOP-Jan-dev-talk-2013-08-19	Restaurants Features and ToolsReview SnippetXAPOSearchQueryWPOLERWPO OSCacheItemCacheIdList of YpIdsFiltersSorterEntityUpdate PostFixEntity Update OSCache IdCache ItemYpId and PostFixUXReview Snippet Data GroupCac	0.45512975129440797
SmartQueryRelaxationInJOP-Jan-dev-talk-2013-08-19	SmartRelax training and evaluation from 15%/15% flightForay scorecard: 15%+15% datagatheringUser-triggered scorecardSSRx gain of 0.12%, for 3+4 word on vs. 3+4 word off. (NOT vs. prod.)Gain is 36% from SSR, 11% from TTS, 52% from TSRSSRx gains s	0.44607347597486685
SmartQueryRelaxationInJOP-Jan-dev-talk-2013-08-19	ElasticSearchInternalElasticSearch and oSearchElasticSearch  ArchitectureLucene FamilyoSearch  ArchitectureScenario and ScaleoSearchElasticSearchScope Strong structured dataImage with ANNUnstructured text Loose structured data	0.4423125429176084
SmartQueryRelaxationInJOP-Jan-dev-talk-2013-08-19	ML Model Scorecard Analysis8/8/2019Unexpected term search movementhttps://exp.microsoft.com/xcard/?view=4e77b420-7b77-4e41-92ac-8e84f506fb01Check correctness of scorecard metric implementationCalculate term AVG rank from raw data streamsSearch	0.43089157815309725
SmartQueryRelaxationInJOP-Jan-dev-talk-2013-08-19	Spam/Junk Technology Review8/8/2017 Pavel KarpovichAgendaSpam/Junk OverviewReview of current system and metricsSJRE Fishtank pipelines UrlExclusion and Defect Subranker	Blue Whale Spam Types of Fresh SpamActions to Detect Fresh	0.43058460510217655
SmartQueryRelaxationInJOP-Jan-dev-talk-2013-08-19	cal deepdiverelaxationdec 2017AgendaProduct GoalsQuery SimplificationMechanism/RuntimeCRF Model TrainingQS Path SelectionOffline SimulatorSmart RelaxMechanism & TrainingRelaxation: ImpactRelaxation: Product goalsImprove Rec	0.42322015544029185
SmartQueryRelaxationInJOP-Jan-dev-talk-2013-08-19	学士学位证明BACHELOR DEGREE CERTIFICATEThis is to certify that Ms. Jia Liu, born in August 1986, with the specialty of Computer Science and Technology at Beijing University of Posts and Telecommunications from September 2005 to July 2009, has passed all req	0.4184980613128614

Ski.Search.OnlineFeatureExtraction	SKI online feature extraction design docTo build ML model to detect user intent and re-rank search result from different providers, we need training data. This document mainly covers the design how to collect the training data from the real Office usage	0.45424824179773415
Ski.Search.OnlineFeatureExtraction	ElasticSearchInternalElasticSearch and oSearchElasticSearch  ArchitectureLucene FamilyoSearch  ArchitectureScenario and ScaleoSearchElasticSearchScope Strong structured dataImage with ANNUnstructured text Loose structured data	0.4530809680732615
Ski.Search.OnlineFeatureExtraction	Combined ALterationsNeon\sodiumAgendaNeon AchievementsBreakdownsSodiumIdeas & PlanNeonOverall ProgressExceeded Neon Commitments on CQS!NeonCQS Deep-dive-34% Bad+14% Excellent-15% Bad+13% ExcellentDRDOCQS is impr	0.360462111933605
Ski.Search.OnlineFeatureExtraction	Local Search Online Learning Lihong LiFengxia PanAgendaOnline LearningBiased user engagement dataLocal results positional bias estimation method & ExperimentOffline click evaluatorL2 ranker improvement using online click dataExperiment &	0.34713027559691423
Ski.Search.OnlineFeatureExtraction	Run web-search-like query against my dataSame Bing Web Search Indexing and Ranking engineIndex in a secondTransparent and real time index sync, no complex index-gen pipelinePrototype in an hourFast self-onboarding with freemium account, schema-d	0.3281451490049687
Ski.Search.OnlineFeatureExtraction	ODP Classification: Summarizing Pages as a Topic DistributionNov 17, 2010Paul Bennett (pauben), MSR CLUESJoint work with Max Chickering & Susan Dumais© 2006 Microsoft Corporation. All rights reserved. Microsoft, Windows, Windows Vista and ot	0.32468704201902343
Ski.Search.OnlineFeatureExtraction	SKI Contextual Reranking V1 design doc User ScenarioWhole page relevance of “All Tab” in the SerpletContextual relevance of “File Tab” in the Serplet DeliverablesMicrosoft search serves as an intelligence service to take user query and return be	0.32051741707782816
Ski.Search.OnlineFeatureExtraction	Distance-Aware Local SearchZhao Zhout-zhazho@microsoft.comOutlineProject Goal and MotivationMethodologyExperimental ResultsConclusionBackgroundEntities having LatLonNew York City (40.7127,-74.0059) Facing East Restaurant (47.619905, 	0.31130800126670566
Ski.Search.OnlineFeatureExtraction	Keyword Prediction for Local SearchesRuchir RastogiMentor: Jia LiuManager: Leon ZhangOutlineProblem statementTraining data and clean-up strategiesConditional random field (CRF) modelsDeep learning modelsEnd to end measurementConclusi	0.3104460082867131
Ski.Search.OnlineFeatureExtraction	Zhcn document classification based on topicJia Liu2012.11.14agendarTraining data selection&crawl&cleanFeature selection&cleanClassifierRating Bad case analysisTrainning data	0.30411615649087703

Site Quality Classification	Site Quality ClassificationGuihong CaoDefinition of the ProblemWhat is site quality?Google’s definition includes the following dimensionsDuplicated content within the siteTrustworthyOn demand media? Quality controlSite authorityAuthor 	0.5718218446176526
Site Quality Classification	Span ClassifierSpan classifier is a general infrastructure that can be used to run a fastrank based classifier on a sequence of terms from a query.  It can be used to apply rankonly or norelax to parts of the query based on the result of the model.  Fea	0.3814366146393249
Site Quality Classification	Content Quality Classification & RankingGuihong Cao, Cheng NiuContent Quality for RankingContent quality = originality + trustworthy + information satisfaction + freshnessSpam sites, junk site, link farm, content farm, ….Search users are interes	0.32840530849451716
Site Quality Classification	File Relevance Experimentation Design DocRecall AnalysisTest the search quality of external services like OLS, 3S, QF and SPO Search.Search scenarios: 0-term search, term search, 3S (Insert File and Attach File).Compare the recall: diff of returne	0.3235269046075515
Site Quality Classification	Document classification based on urlBackgroundWe want to do document classification for better understanding the document type and document with query category match for ranking.  We will do zh-cn document classification based on url first, then docum	0.2957780782874062
Site Quality Classification	Analyzed Query represents all information derived from all classification tasks executed on the Query. QAS supports 3 basic classifications tasks: binary classification (Domain Classification), entity extraction (Query Parse), category classification (Dom	0.288163729164014
Site Quality Classification	L-1B SPECIALIZED KNOWLEDGE QUESTIONNAIREMICROSOFT POSITION IN THE U.S.Provide the following information for your current position at the Microsoft.MICROSOFT POSITION ABROADProvide the following information for your position at the Microsoft’s su	0.2865138664901612
Site Quality Classification	Normalization and Parsing OverviewTypes of NormalizationLimiting to just normalization, there are actually several different types of normalization which may be interesting:WhitespaceThis is:Converting all whitespace characters to spacestrippi	0.2856260149742253
Site Quality Classification	Query Simplification Deep DiveJON Fu12/11/2017AgendaQuery Simplification Motivation and TheoryQuery Simplification for WebQuery Simplification for Cortana 3ARecent Progress in Query Simplification WorkReferencesIntroductionMotiva	0.2839141101672231
Site Quality Classification	Zhcn document classification based on topicJia Liu2012.11.14agendarTraining data selection&crawl&cleanFeature selection&cleanClassifierRating Bad case analysisTrainning data	0.2650285032293927

Simplified Query Datagathering Summary	Simplified Query Path SelectorSimplified query: current systemSimplified query path selectionCrf model produces a list of possible ways to place rankonly operatorQuery = “nibbana restaurant official site”nibbana restaurant rankonly:official site	0.6577532919856138
Simplified Query Datagathering Summary	Query Simplification Deep DiveJON Fu12/11/2017AgendaQuery Simplification Motivation and TheoryQuery Simplification for WebQuery Simplification for Cortana 3ARecent Progress in Query Simplification WorkReferencesIntroductionMotiva	0.554117328494445
Simplified Query Datagathering Summary	Run web-search-like query against my dataSame Bing Web Search Indexing and Ranking engineIndex in a secondTransparent and real time index sync, no complex index-gen pipelinePrototype in an hourFast self-onboarding with freemium account, schema-d	0.5040842559442299
Simplified Query Datagathering Summary	Reading List for Natural Language Query ParsingThis is for improving our NL query parsing for entity/local triggering.By NL query parsing, our goal is to automatically extract the structured information from the query, normally by segmenting queries a	0.44257445196798084
Simplified Query Datagathering Summary	Publication date optimization for Japan marketBackgroundPublication date is very important to fresh queries, outdated issues and caption date showing. Now the coverage of publication date for Japan market is very low because publication date extract	0.418961187507896
Simplified Query Datagathering Summary	Span ClassifierSpan classifier is a general infrastructure that can be used to run a fastrank based classifier on a sequence of terms from a query.  It can be used to apply rankonly or norelax to parts of the query based on the result of the model.  Fea	0.41669608417266235
Simplified Query Datagathering Summary	I’d like to explain in more details my idea of improving Dolphin, by improving its robustness of query variations and some previously unseen terms. Our rules don’t cover many query patterns. E.g., {top rated chinese restaurants} works well, but not {chi	0.4078961205901981
Simplified Query Datagathering Summary	FastRank--- a Decision-Tree based Ranking ModelYu SHIOutlineBackgroundAlgorithm overviewTraining implementationExperimentationChallengesReferencesBackgroundInvestigated by MSR in OsloShipped with July Tree 2010 (Denver)GoalsSpe	0.38685078464971534
Simplified Query Datagathering Summary	Query AugmentationsTable of Contents1. Syntax Overview	22. Constraints	6General rules for operators	7Basic Operators	7Scoring and non-scoring constraint operators	9Stream Operators	9Literal Operators	10Meta Operators	11URL Operators	13	0.38502582517357553
Simplified Query Datagathering Summary	Analyzed Query represents all information derived from all classification tasks executed on the Query. QAS supports 3 basic classifications tasks: binary classification (Domain Classification), entity extraction (Query Parse), category classification (Dom	0.383719549147169

SimpleCategoryQueryAnalysis_32272	Author: Tony AngellDate: 08/01/13LocalProbe Improvements for Corrections Analysis and DebuggingTable of ContentsP0 Issues	2Issue: LocalProbe is unpredictable in the amount of time it takes to return a query and how long it takes to investigate a	0.5007891471793829
SimpleCategoryQueryAnalysis_32272	Publication Date Optimization Design and Implement For zh-cn MarketReview and CommentMei Yang; Ted WildAuthorJia LiuDesignBackgroundPublication date is a very fundamental and important feature. It can help fresh ranking, solve mainline out	0.4917480805849044
SimpleCategoryQueryAnalysis_32272	Query Simplification Deep DiveJON Fu12/11/2017AgendaQuery Simplification Motivation and TheoryQuery Simplification for WebQuery Simplification for Cortana 3ARecent Progress in Query Simplification WorkReferencesIntroductionMotiva	0.48789435911116574
SimpleCategoryQueryAnalysis_32272	QueryString Category owner Searchvote url 寇仲最后和谁在一起 ranking  xiaopeng http://searchvote.com/default.aspx?reviewid=209877 布里斯班 ranking  xiaopeng http://searchvote.com/default.aspx?reviewid=211685 必应词典 ranking  xiaopeng http://searchvote.com/default.aspx?re	0.4788622204410862
SimpleCategoryQueryAnalysis_32272	Simplified Query Path SelectorSimplified query: current systemSimplified query path selectionCrf model produces a list of possible ways to place rankonly operatorQuery = “nibbana restaurant official site”nibbana restaurant rankonly:official site	0.4786276481799779
SimpleCategoryQueryAnalysis_32272	Entity Categorization Using Convolutional Neural NetworkWeiwu Zhu8/23/2018AgendaMotivationCNN introductionCNN in NLPCNN based entity categorizationMeasurementMotivationTaxonomy mapping is not scalable (Feature Normalization)Nee	0.4658567031689897
SimpleCategoryQueryAnalysis_32272	AgendaAres Data Access FrameworkEntitySet Creation WorkflowMetric CalculatorQuestion & AnswerARES logical conceptsARES AssetsLogical ModelEntity/RelationRelated RVT data model ARES Data ModelUnit of ExecutionEntityJobTask	0.465387396612375
SimpleCategoryQueryAnalysis_32272	Keyword Prediction for Local SearchesRuchir RastogiMentor: Jia LiuManager: Leon ZhangOutlineProblem statementTraining data and clean-up strategiesConditional random field (CRF) modelsDeep learning modelsEnd to end measurementConclusi	0.4588176332047034
SimpleCategoryQueryAnalysis_32272	Local Category Search Plan3 month StrategyData: Entity categorizationScalable, high precision/recallSegments: Food & Drink, Retail, Service, Auto, HotelMetaStream enrichmentQuery UnderstandingDolphin by defaultConsume PhoneBookQU to im	0.4549609559754173
SimpleCategoryQueryAnalysis_32272	Pattern Based Term WeightVersion 1Jia Liu2014-06-16FrameworkTerm AttributesSemantics definitionHuman understanding and knowledgeChange in different contextsLevels:KeywordAttributeRequirementStrong constraintWeak constraintVer	0.44985439394913446

SimpleCategoryQueryAnalysis	Simplified Query Path SelectorSimplified query: current systemSimplified query path selectionCrf model produces a list of possible ways to place rankonly operatorQuery = “nibbana restaurant official site”nibbana restaurant rankonly:official site	0.5135685523377805
SimpleCategoryQueryAnalysis	Query Simplification Deep DiveJON Fu12/11/2017AgendaQuery Simplification Motivation and TheoryQuery Simplification for WebQuery Simplification for Cortana 3ARecent Progress in Query Simplification WorkReferencesIntroductionMotiva	0.49259427529291416
SimpleCategoryQueryAnalysis	Index Quality UpdateAgendaMetrics UpdateSelection Model ImprovementRecall TierOffice ImprovementChallenges and Pain PointsHow to measure index quality?Ideally: sampling from all “good” images and see how much we covered.sampling from a	0.45639427953623435
SimpleCategoryQueryAnalysis	Publication Date Optimization Design and Implement For zh-cn MarketReview and CommentMei Yang; Ted WildAuthorJia LiuDesignBackgroundPublication date is a very fundamental and important feature. It can help fresh ranking, solve mainline out	0.44850417382279
SimpleCategoryQueryAnalysis	Keyword Prediction for Local SearchesRuchir RastogiMentor: Jia LiuManager: Leon ZhangOutlineProblem statementTraining data and clean-up strategiesConditional random field (CRF) modelsDeep learning modelsEnd to end measurementConclusi	0.4429195768690914
SimpleCategoryQueryAnalysis	Local Category Search Plan3 month StrategyData: Entity categorizationScalable, high precision/recallSegments: Food & Drink, Retail, Service, Auto, HotelMetaStream enrichmentQuery UnderstandingDolphin by defaultConsume PhoneBookQU to im	0.43691510008623685
SimpleCategoryQueryAnalysis	Entity Categorization Using Convolutional Neural NetworkWeiwu Zhu8/23/2018AgendaMotivationCNN introductionCNN in NLPCNN based entity categorizationMeasurementMotivationTaxonomy mapping is not scalable (Feature Normalization)Nee	0.43594855762861906
SimpleCategoryQueryAnalysis	Author: Tony AngellDate: 08/01/13LocalProbe Improvements for Corrections Analysis and DebuggingTable of ContentsP0 Issues	2Issue: LocalProbe is unpredictable in the amount of time it takes to return a query and how long it takes to investigate a	0.43455170510118885
SimpleCategoryQueryAnalysis	QueryString Category owner Searchvote url 寇仲最后和谁在一起 ranking  xiaopeng http://searchvote.com/default.aspx?reviewid=209877 布里斯班 ranking  xiaopeng http://searchvote.com/default.aspx?reviewid=211685 必应词典 ranking  xiaopeng http://searchvote.com/default.aspx?re	0.43195845146149225
SimpleCategoryQueryAnalysis	AgendaAres Data Access FrameworkEntitySet Creation WorkflowMetric CalculatorQuestion & AnswerARES logical conceptsARES AssetsLogical ModelEntity/RelationRelated RVT data model ARES Data ModelUnit of ExecutionEntityJobTask	0.42766760185478714

Si09.1-Cross Page Junk Detection V2	Page | 2                                 <Si-09.1> Cross Page Junk Detection – V2Feature One-PagerDocument Version:0.9Authors:arahin, lidonzDocument Status:1.0Date:7/20/2014Feature OverviewDescription:Use new Main Body signal	0.7628359334999099
Si09.1-Cross Page Junk Detection V2	Crawler Tech TalkOctober 14, 2008AgendaOverview of Msnbot Internal Data FlowFlow of Chunks and Chunk MetadataReal-Time MonitoringDaily Data Reporting SubsystemPrevious Instances Requiring InterventionPotential Future ProblemsQ&AMsnbot 	0.39375184785353246
Si09.1-Cross Page Junk Detection V2	Query Simplification Deep DiveJON Fu12/11/2017AgendaQuery Simplification Motivation and TheoryQuery Simplification for WebQuery Simplification for Cortana 3ARecent Progress in Query Simplification WorkReferencesIntroductionMotiva	0.37361353187542967
Si09.1-Cross Page Junk Detection V2	Online Click Labels for CAL Ranker:End – To End:aether://experiments/31148112-679c-476c-91d0-bb3ebbef81c2Continuous trained module continuously trains trees using HRS and then the ranker.OFE Ranker Training Pipeline:aether://experiments/01dbe0	0.37174409015515575
Si09.1-Cross Page Junk Detection V2	Spam/Junk Technology Review8/8/2017 Pavel KarpovichAgendaSpam/Junk OverviewReview of current system and metricsSJRE Fishtank pipelines UrlExclusion and Defect Subranker	Blue Whale Spam Types of Fresh SpamActions to Detect Fresh	0.36942071378992
Si09.1-Cross Page Junk Detection V2	SPAM & JunkSi Planning Cheng Niu, Alex Rahin6/18/2014Agenda	Focus AreasMetricsSPAM/Junk Metrics BreakdownData Analysis and Project DefinitionFocus AreasImprove SPAM Detection (~35% of team bandwidth)Stolen ContentContent Keyword St	0.36597127223849013
Si09.1-Cross Page Junk Detection V2	Bing GC Deep DiveBingGCI 9/26/2014Introduction – Pavel, 2minsProject overview – Wei, 6minsBing GC XAP workflow – John, 10minsBing GC data pipeline and data ingestion – Florin, 7minsBing GC Offline relevance platform – Jian, 8minsSingle-poi	0.3625561322442814
Si09.1-Cross Page Junk Detection V2	CJK RELEVANCE ALL HANDS03/06/201401Qi ASG Memo02MS Poll	03USBS MeasurementAGENDA04Win in USBSVideoEbookMemo DocWatch the VideoVideoIntroductionWho We AreOur VisionClosingDiscussion and QnA01Qi ASG Memo02	0.35116948624330463
Si09.1-Cross Page Junk Detection V2	Local Probe WinPhone AppPrint Date: 0000-00-00Spec StatusDraftTFS Feature IDRelease[Release]PMJacob Haynes Florian VossDesign[Design]Milestone[Milestone]Dev[Dev]User Research[User Research]Feature Team[Feature Team]Test	0.3471176451178414
Si09.1-Cross Page Junk Detection V2	LDCG V3Knowledge Transfer2017-04-14Brett Clippingdale, Sean King, Vikas Mittal, Li JiangLDCG V3 OutlineLDCG V2 vs V3: High-level comparisonLDCG V3: New distance ModelV2 vs V3 OverviewLDCG V3: GeoIntent HIT appLDCG V3: Calculate distance 	0.34592049165208744

Search and User Journeys	ElasticSearchInternalElasticSearch and oSearchElasticSearch  ArchitectureLucene FamilyoSearch  ArchitectureScenario and ScaleoSearchElasticSearchScope Strong structured dataImage with ANNUnstructured text Loose structured data	0.2765044062501363
Search and User Journeys	Keyword Prediction for Local SearchesRuchir RastogiMentor: Jia LiuManager: Leon ZhangOutlineProblem statementTraining data and clean-up strategiesConditional random field (CRF) modelsDeep learning modelsEnd to end measurementConclusi	0.21682842031196442
Search and User Journeys	Local Search Platform PM Onboarding GuideAuthors: Dany DaherDate: 10/18/2013Architecture OverviewHow Local Search Works Local Data Platform Architecture MetricsLocal Metrics:  http://jeffke/localMetrics/Definition of QLDCG: Local Discoun	0.20610688426565615
Search and User Journeys	Files Reuse in OfficeMahaveer KothariAgendaIntroductionHigh level overviewChallengesIntegration with Ideas/SearchWhat’s NextQ & AIntroductionHistory about reuse slides in PowerPoint. Documents supported. Document gallery Archit	0.19495410967929905
Search and User Journeys	Interactive BingGoalSolving hard queryOverview Search engine is helping people solving problem. A lot of cases, search engine couldn’t solve problem at first shot. At this point, search engine need take more information to narrow down the user int	0.18639500961266336
Search and User Journeys	BusinessV3TaxonomyClassifierAugust, 2018Daniel WeinshenkerMicrosoft ConfidentialAgendaMicrosoft ConfidentialPurpose / OverviewDemoData Pipeline / Lexicon GenerationMeasurementQASChallenges / Future WorkPurpose We want to improve 	0.15545940946692655
Search and User Journeys	Name Entity Recognition based on Perceptron modelBackgroundWe have many name entity DSATs like user searched name “XYZ”, and the results may be “XY”,”YZ” or “XYW” related. We have done QU name entity recognition for zh-cn market already. So we want to	0.15097946902218448
Search and User Journeys	CRF Parser AnalysisBusiness category searchOverviewParser (phonebook)CRF ParserqueryLocation featuresCRF featuresQuery parsetoken[tag] token[tag] … token[tag]userBLUbusiness_namebusiness_categorylocationlocation_separatorbu	0.1488667226028164
Search and User Journeys	Restaurants Features and ToolsReview SnippetXAPOSearchQueryWPOLERWPO OSCacheItemCacheIdList of YpIdsFiltersSorterEntityUpdate PostFixEntity Update OSCache IdCache ItemYpId and PostFixUXReview Snippet Data GroupCac	0.1446951235799404
Search and User Journeys	Keyword Predictor Design DocumentName: Ruchir RastogiMentor: Jia LiuManager: Leon ZhangProject overviewThe goal of this project is to design a machine-learning model that can predict keywords in a local query for improving local search relevance	0.14454318692305265

Search & AI Platform All Hands 2019-01	FY19 Search & AI Roadmap Review: Intelligent QnAMay 2018PM: Ali Alvi, Kaan Ozel, Ganga Venkatasubramanian, Oana NicolovDev: Xia Song, Doran ChakrabortyAgendaOverall QnA Opportunity and GoalsSemi-Structured DataMALTATuring for QnAAGI En	0.44045717574381654
Search & AI Platform All Hands 2019-01	Local Search Platform PM Onboarding GuideAuthors: Dany DaherDate: 10/18/2013Architecture OverviewHow Local Search Works Local Data Platform Architecture MetricsLocal Metrics:  http://jeffke/localMetrics/Definition of QLDCG: Local Discoun	0.38156873432765887
Search & AI Platform All Hands 2019-01	Local Search Popularity V2 DesignBing Local SearchDevXiaohui Liu, Fengxia PanPMDave BargeronMilestoneAl. M1ContributorsFeature Bug IDSignoffPM Spec Linkhttps://microsoft.sharepoint.com/teams/localsearch/_layouts/15/WopiFrame.aspx?s	0.37225524093571666
Search & AI Platform All Hands 2019-01	Opal OSearch & XAP flight frameworkKevin Su & Duat Le06/22/2016OverviewOSearch basicsOpal OSearch high-level architectureProcess to onboard new feature for Opal OSearchXAP flight framework in OsearchOSearch basicsWhat's OSearch?A platf	0.3673938591133779
Search & AI Platform All Hands 2019-01	FY19 Search & AI Roadmap Review: QRMay 2018Jie Cai, Garrett Kaminaga, Jingwen Lu, Momo JengMotivation – QR Query understanding and rewrite is the first opportunity for Bing to understand users’ intents;In current production, query rewrite is a	0.36413482986317547
Search & AI Platform All Hands 2019-01	Zhcn document classification based on topicJia Liu2012.11.14agendarTraining data selection&crawl&cleanFeature selection&cleanClassifierRating Bad case analysisTrainning data	0.35984662085960795
Search & AI Platform All Hands 2019-01	Introduction to L1Xiao WuSearch Platform Tiger Team AgendaL1 goals and challengesMetrics and measurementL1 ranker and perf optimizationL1 ranking Perf optimizationDebugging tools L1 training and shippingThinking and discussionL1 	0.33205444761422503
Search & AI Platform All Hands 2019-01	NTCG DebuggingSteven Zittrower01/30/2015AgendaNTCGNTCG DashboardOverview of BLU Architecture (Address Specific)Address Debugging in QATNTCGNTCG (Normalized Total Cumulative Gain) is a composite metric that measures address query releva	0.31962862840356077
Search & AI Platform All Hands 2019-01	Local Search – Entity Containment Short blurb of what this spec is aboutMilestone:  MG,ALSpec StatusDraftTFS Feature IDPMSandhya GuntreddyContributorsRajesh Srivastava, Prajakta Joshi,Kanad, PrashantSpec Location:https://microsoft.sh	0.31757429386843816
Search & AI Platform All Hands 2019-01	11/17 AGI review with HarryCES: cover AI for OfficeCo-market with NvidiaMPQnA Keep in Jordi’s demo in the Dec AI eventAbortion query is very controversial	Not our responsibility to make the decision for the user but it’s the search engine’s re	0.31614409576931535

Scraper_ARIA_RecurrenceManager	Scraper overview(and more)Ofer ShterlingSean KingContentBrag.Demo (maybe)Throw some dirt.Suggest the Scraper isn’t that interesting.Recurrences tool.I hope I won’t have to show to many workflow.ScraperWe have between 500 to 1.5k sc	0.3801273956900206
Scraper_ARIA_RecurrenceManager	Span ClassifierSpan classifier is a general infrastructure that can be used to run a fastrank based classifier on a sequence of terms from a query.  It can be used to apply rankonly or norelax to parts of the query based on the result of the model.  Fea	0.21168937640351124
Scraper_ARIA_RecurrenceManager	Issue Solution Scrape Instability  - Unable to get stable scrapes Short term- @Nikita - Try two changes together to see if that helps. Long Term - @Ping to investigate- Request index team to investigate- Support for URP scrapes (Lockdown and send URP q	0.2069283044677517
Scraper_ARIA_RecurrenceManager	Brownbag:ElasticSearch ExtensibilityHeather Nakama (henakama)Azure Search09/04/14AgendaIntroductionModulesPluginsFinding extensibility pointsEnd-to-end exampleTips and tricksQ/AIntroductionHeather NakamaDeveloper with Azure S	0.20617905885406584
Scraper_ARIA_RecurrenceManager	Anchor and Click Stream RankingSteven ZittrowerBing Local Search RelevanceHypothesisConverting local search’s unstructured and raw text streams into semi-structured forms will improve ranking and offer relevance benefits.TestUsing classifiers 	0.20551179451501836
Scraper_ARIA_RecurrenceManager	Name Entity Recognition based on Perceptron modelBackgroundWe have many name entity DSATs like user searched name “XYZ”, and the results may be “XY”,”YZ” or “XYW” related. We have done QU name entity recognition for zh-cn market already. So we want to	0.20178157269314667
Scraper_ARIA_RecurrenceManager	Files Reuse in OfficeMahaveer KothariAgendaIntroductionHigh level overviewChallengesIntegration with Ideas/SearchWhat’s NextQ & AIntroductionHistory about reuse slides in PowerPoint. Documents supported. Document gallery Archit	0.19314219780877925
Scraper_ARIA_RecurrenceManager	Distributed Deep Learning: New Driving Force of Artificial IntelligenceTie-Yan LiuPrincipal Researcher Microsoft Research AsiaAI Is Making Break-through!2016/12/21Tie-Yan Liu -  Distributed Deep Learningvs.Sedol LeeAtari Games“Deep	0.19196268196548202
Scraper_ARIA_RecurrenceManager	Click through handling & Organic search on One Map and Mobile L2. Challenge & problemsCurrently we have a lot of issues with click through experience.  For example, click see more results link on local listing experience get single entity pane experie	0.18849844889494088
Scraper_ARIA_RecurrenceManager	ElasticSearchInternalElasticSearch and oSearchElasticSearch  ArchitectureLucene FamilyoSearch  ArchitectureScenario and ScaleoSearchElasticSearchScope Strong structured dataImage with ANNUnstructured text Loose structured data	0.1784428007559781

Scope-StreamSets	Anchor and Click Stream RankingSteven ZittrowerBing Local Search RelevanceHypothesisConverting local search’s unstructured and raw text streams into semi-structured forms will improve ranking and offer relevance benefits.TestUsing classifiers 	0.2559498535280889
Scope-StreamSets	CosmosScope > StreamSetsHiren Patel & Saveen Reddy2014/02/06© 2012 Microsoft Corporation. All rights reserved. Microsoft, Windows, and other product names are or may be registered trademarks and/or trademarks in the U.S. and/or other countries.The	0.21523395578513865
Scope-StreamSets	Meta-stream work summaryHeyong WangClickstream exampleOverview: Click-Stream generationWeb logsLocal logsLocal clicked dataJoin with Local IndexWeb Clicked data (query, url etc.)IE ClickBing ClickIE SessionIE Tool Bar…Web Click	0.1898804897579502
Scope-StreamSets	Cosmos Scope Aluminum M3 Release Announcement Cosmos Scope Aluminum M3 ReleaseThis and previous announcements are stored here.Code Samples can be found at http://aka.ms/CosmosCodeSamplesYou can find information about using Beta SDKs in this docu	0.16243406196604454
Scope-StreamSets	CosmosScope> Complex Data TypesMichael Rys & Saveen Reddy2015/02/25http://aka.ms/CosmosPresentations© 2012 Microsoft Corporation. All rights reserved. Microsoft, Windows, and other product names are or may be registered trademarks and/or tradema	0.15291900695107652
Scope-StreamSets	Daniel Bernhardt, STC Europe, danber@microsoft.comFeed ExplorerQuick Start GuideIntroductionFeedExplorer is a tool for exploring the Provider Feeds and Master Trees for MSN/Bing Local Search. The current capabilities of the tool include:Suppor	0.15085082733132327
Scope-StreamSets	CRF Parser AnalysisBusiness category searchOverviewParser (phonebook)CRF ParserqueryLocation featuresCRF featuresQuery parsetoken[tag] token[tag] … token[tag]userBLUbusiness_namebusiness_categorylocationlocation_separatorbu	0.1496059025034407
Scope-StreamSets	Local Probe bugsContents1.	Phone number format replacement	22.	Data on the Live Site does not correspond to data in the Local Probe	43.	Second time corrections	54.	Cuisine Selection	65.	Market settings affecting cuisine output	76.	Ranking is	0.14507292075091935
Scope-StreamSets	SmartRelax training and evaluation from 15%/15% flightForay scorecard: 15%+15% datagatheringUser-triggered scorecardSSRx gain of 0.12%, for 3+4 word on vs. 3+4 word off. (NOT vs. prod.)Gain is 36% from SSR, 11% from TTS, 52% from TSRSSRx gains s	0.14403180285305422
Scope-StreamSets	A Step by step guide to Creating a new Block in the DU V2 PipelineThis document will demonstrate how to create a new block, including the testing and deployment for the new DU Pipeline.  To begin, if you do not yet have a block name, please send an em	0.135036466170663

Scope-Modules	Scope > Modules Author: Lianjie Zhu	Date: 3/15/2015SummaryModules are a key component for Cosmos customers to build their data platforms. In summary they allow developers to simplify how their data is consumed by others by bundling/packaging Scope	0.3592644014056157
Scope-Modules	ML Model Scorecard Analysis8/8/2019Unexpected term search movementhttps://exp.microsoft.com/xcard/?view=4e77b420-7b77-4e41-92ac-8e84f506fb01Check correctness of scorecard metric implementationCalculate term AVG rank from raw data streamsSearch	0.27746480244888283
Scope-Modules	Cosmos Scope Aluminum M3 Release Announcement Cosmos Scope Aluminum M3 ReleaseThis and previous announcements are stored here.Code Samples can be found at http://aka.ms/CosmosCodeSamplesYou can find information about using Beta SDKs in this docu	0.25187458846916877
Scope-Modules	Entity Selection ModelJia Liu2017-11-08GDP Pipeline View: local data pipelineEntity TypesEntity Types:Open/CloseHead/TailNonJunk/JunkJunk TypesGhost: Local business existed beforeJunk: General name like “Lock smith”, “ATM”Move/Br	0.23760049405387432
Scope-Modules	Handbook of MLGProcessor AEther ModulesContents1.	Introduction	72.	MLGProcessor Modules	82.1.	Common Module Parameters	8Inputs	8Outputs	8Parameters	92.2.	BodySurfaceStream	9Inputs	9Outputs	92.3.	BoundaryView	9Examples	102.4.	Char	0.20201348913891137
Scope-Modules	Zhcn document classification based on topicJia Liu2012.11.14agendarTraining data selection&crawl&cleanFeature selection&cleanClassifierRating Bad case analysisTrainning data	0.16118031723393136
Scope-Modules	NGram Language Model based Url Breaking – Design DocumentStatusOngoingIntroductionUrl is a very important signal for ranking, particularly for tail queries and navigation queries. This signal has 100% url coverage, which really makes it different 	0.149522112963295
Scope-Modules	CAL OverviewPhysical InfrastructurePHR machine functionCO3 (WA) 44 machines, 6-10 kQPSCH1D (Chicago) 83 machines, 4-8 kQPSBN1 (VA) 62 machines, 6-16 kQPSDB3 (Dublin) 16 machines, 1-5 kQPSSG1 (Singapore) 9 machines, 1-4 kQPSBJ1 (Beijing) 3 	0.14940942882718938
Scope-Modules	SKI online feature extraction design docTo build ML model to detect user intent and re-rank search result from different providers, we need training data. This document mainly covers the design how to collect the training data from the real Office usage	0.14339262859804064
Scope-Modules	Scraper overview(and more)Ofer ShterlingSean KingContentBrag.Demo (maybe)Throw some dirt.Suggest the Scraper isn’t that interesting.Recurrences tool.I hope I won’t have to show to many workflow.ScraperWe have between 500 to 1.5k sc	0.14175267571663971

Scope-Complex-Data-Types	CosmosScope> Complex Data TypesMichael Rys & Saveen Reddy2015/02/25http://aka.ms/CosmosPresentations© 2012 Microsoft Corporation. All rights reserved. Microsoft, Windows, and other product names are or may be registered trademarks and/or tradema	0.38510331892072164
Scope-Complex-Data-Types	Scope > Modules Author: Lianjie Zhu	Date: 3/15/2015SummaryModules are a key component for Cosmos customers to build their data platforms. In summary they allow developers to simplify how their data is consumed by others by bundling/packaging Scope	0.36012485228865243
Scope-Complex-Data-Types	Entity Selection ModelJia Liu2017-11-08GDP Pipeline View: local data pipelineEntity TypesEntity Types:Open/CloseHead/TailNonJunk/JunkJunk TypesGhost: Local business existed beforeJunk: General name like “Lock smith”, “ATM”Move/Br	0.33949091844136914
Scope-Complex-Data-Types	Bing Local Functional DetailsDocument StatusDate Created6/25/2013Last Updated2/28/2014Current StatusDraft Key StakeholdersProgram ManagementDany Daher; Tony Angell; Sumitra Sheth; Product ManagementTBD;Executive SponsorsEric Ca	0.329321036884376
Scope-Complex-Data-Types	Zhcn document classification based on topicJia Liu2012.11.14agendarTraining data selection&crawl&cleanFeature selection&cleanClassifierRating Bad case analysisTrainning data	0.3259462092569257
Scope-Complex-Data-Types	Local Probe bugsContents1.	Phone number format replacement	22.	Data on the Live Site does not correspond to data in the Local Probe	43.	Second time corrections	54.	Cuisine Selection	65.	Market settings affecting cuisine output	76.	Ranking is	0.3125625355661888
Scope-Complex-Data-Types	Publication date optimization for zh-cn marketBackgroundPublication date is a very fundamental and important feature. It can help fresh ranking, whole page user experience: caption date show and freshness internal metrics, also to solve mainline out	0.29776050024948425
Scope-Complex-Data-Types	AgendaAres Data Access FrameworkEntitySet Creation WorkflowMetric CalculatorQuestion & AnswerARES logical conceptsARES AssetsLogical ModelEntity/RelationRelated RVT data model ARES Data ModelUnit of ExecutionEntityJobTask	0.29507922034151135
Scope-Complex-Data-Types	Location and Data Services Team all hands10/08/2014AgendaCelebrate – Wei, 5minsLocal partners – Andy, 10minsLocal Data Services – Alex, 15minsGeocoder and GeoSpatial Services – Jai, 20minsLocation and Autosuggest Services – Sid, 15minsBing	0.28942128204699846
Scope-Complex-Data-Types	Cosmos Scope Aluminum M3 Release Announcement Cosmos Scope Aluminum M3 ReleaseThis and previous announcements are stored here.Code Samples can be found at http://aka.ms/CosmosCodeSamplesYou can find information about using Beta SDKs in this docu	0.27722846662979783

Satori	Satori Introduction2012-09-20  yukaihAgendaOverviewMajor ModulesIngestionConflationServingGet Started in Local BoxUseful linksAppendix: Satori Local PipelineOverview - SatoriMission: build the largest, freshest, and most accurate E	0.26252943494988323
Satori	Leveraging Satori Knowledge Graph in Web Ranking StackMicroSegment and Index ServeThe demo is about how to leverage Satori Knowledge Graph in Web ranking. It is joint work among relevance microsegment, Satori and index serve teams.MotivationSome	0.20909866086820666
Satori		0.18437784452660042
Satori	DSAT Mining & LSRBhagirath AddepalliCUV Log Based DSAT IdentificationIdentifying Google Local Answer Clicks from CUV LogsFor local queries, Google pushes users to search on MapClicking on Map results in url of type: https://www.google.com/webhp?	0.1484098322679973
Satori	Leveraging Satori Knowledge in Web Ranking StackMicroSegment and Index ServeMotivationTarget at semantic queries (*defined by MALTA)Often contain more than one entity and relationSometimes involve entity inferenceTerm matching may not handle s	0.1225758864367954
Satori	Keyword Predictor Summer 2018 SummaryIntern: Ruchir Rastogi (rrastogi@stanford.edu)Mentor: Jia LiuThe Aether ID’s listed in this document are more up to date than the one’s listed in the PowerPoint.PipelinesTraining data clean-up pipelineAethe	0.1220475384426927
Satori	Tmall&Taobao Rating MetawordsBackgroundWe’ve seen in regular DSAT review meetings the DSATs that we rank too high Tmall or Taobao page with low quality(Tmall page:low sales volume; Taobao page: low sales volume or shop with poor reputation).  Zh-CN ha	0.09573114811769498
Satori	CosmosScope> Complex Data TypesMichael Rys & Saveen Reddy2015/02/25http://aka.ms/CosmosPresentations© 2012 Microsoft Corporation. All rights reserved. Microsoft, Windows, and other product names are or may be registered trademarks and/or tradema	0.0876493877564682
Satori	Jia Liu2013-08-05DU Pipeline Sodium Achievements And Magnesium Plans For CJK　　OutlineSodium AchievementsMagnesium PlanMagnesium Work ItemsSodium Work ItemsAppendixSodium AchievementsWrapstar rating signalsTaobao, tmall; qna; novel; v	0.07959301004830846
Satori	CNTK Junk Classifier PrototypeAnton Savin and Gilbert Wong6/3/2016Overall Plan and PrioritiesLearn Deep Learning and Neural NetworkLearn CNTK (Computational Network Toolkit) by walking through the examplesBuild a junk classifier using CNTKEv	0.07772488538257945

SPAM-Junk_06182014	SPAM & JunkSi Planning Cheng Niu, Alex Rahin6/18/2014Agenda	Focus AreasMetricsSPAM/Junk Metrics BreakdownData Analysis and Project DefinitionFocus AreasImprove SPAM Detection (~35% of team bandwidth)Stolen ContentContent Keyword St	0.62520839758969
SPAM-Junk_06182014	Spam/Junk Technology Review8/8/2017 Pavel KarpovichAgendaSpam/Junk OverviewReview of current system and metricsSJRE Fishtank pipelines UrlExclusion and Defect Subranker	Blue Whale Spam Types of Fresh SpamActions to Detect Fresh	0.5900041023092378
SPAM-Junk_06182014	Spam/Junk Technology ReviewAgendaSpam/Junk OverviewReview of current metrics and pipelinesExample of recently shipped technologiesJunk page elimination by cross page signalsAnti-{malicious page redirection spam attack}Looking aheadSpam in 	0.4974746155575284
SPAM-Junk_06182014	BLU V3 Minghua Zhang      01/26/2016Next version of BLU Relevance Infrastructure​OutlineWhy BLU v3BLU v3 DesignCurrent StatusFuture WorkWhy BLU v3 (1)Limitations of current BLU infrastructureFeaturesCouldn’t utilize QAS feature	0.3938691796668575
SPAM-Junk_06182014	Page | 2                                 <Si-09.1> Cross Page Junk Detection – V2Feature One-PagerDocument Version:0.9Authors:arahin, lidonzDocument Status:1.0Date:7/20/2014Feature OverviewDescription:Use new Main Body signal	0.35260194090062735
SPAM-Junk_06182014	Local Junk Detection and DemotionJia Liu2017-06-14GDP Pipeline View: local data pipelineTriple StoreGOALStore every entity as a set of triples.Track all changes to an entity.TripleColumnDetailsSubjectThe guid of a triple’s pa	0.3413099795632745
SPAM-Junk_06182014	Paul LuberPrincipal Group PMSamim ErdoganPrincipal Pm ManagerIntroducing Substrate 	MICROSOFT CONFIDENTIALSubstrate Day 2018A cloud platform for compliant, scalable apps that offer intelligent experiences built on rich user data.What is Su	0.3097701203926466
SPAM-Junk_06182014	Blue-Whale Multimedia Rank Data-FlowEugene Jian Huangjianhua@microsoft.com2012-03-13MM Page Static RankMedia LinkExpress RankMM Page Express RankMM PageSuper-Fresh RankMM PageSubmission RankMM PageEffective Rank Media Entit	0.2972741198918414
SPAM-Junk_06182014	PO Box 91059Seattle, WA 98111-9159	VISION 	Member Claim Form 	for Microsoft  This form is to be used for Vision claims (routine exam and hardware) where you incurred expenses from a provider who did not bill the plan directly.For Medical or De	0.2849150403306779
SPAM-Junk_06182014	SVMT UpdateNovember 2016AgendaMorning (10:00-12:00)Overview – 15 minQnA:MALTA – 55 minInfoBot – 30 minLunch break (12:00-1:00)Afternoon (1:00-3:00)Query:Deep QR – 30 minRanking:ConceptX – 30 minFusion – 30 minNapa – 30 minO	0.28141407619252234

Ruchir Rastogi - Team Meeting Presentation	Keyword Predictor Summer 2018 SummaryIntern: Ruchir Rastogi (rrastogi@stanford.edu)Mentor: Jia LiuThe Aether ID’s listed in this document are more up to date than the one’s listed in the PowerPoint.PipelinesTraining data clean-up pipelineAethe	0.47763976176754347
Ruchir Rastogi - Team Meeting Presentation	L2 Ranker Training and Feature Management						-- Shu HuangOutlineL2 ranker and truncation rankerFeature extractionFake L2 rankerFeature extraction pipelineMutiple ideal querysetsL2 ranker and truncation rankerFind the current prod ran	0.42902968242911416
Ruchir Rastogi - Team Meeting Presentation	Introduction to L1Xiao WuSearch Platform Tiger Team AgendaL1 goals and challengesMetrics and measurementL1 ranker and perf optimizationL1 ranking Perf optimizationDebugging tools L1 training and shippingThinking and discussionL1 	0.4098843838975958
Ruchir Rastogi - Team Meeting Presentation	OPG- Business Continuity PlanTellMeService, Shredder, AugmentationService, Enrichment, UCIService (Insights), Entity ServiceDocument Revision HistoryDateAuthorChange NotesLeader Sign off4/30/2018alyanInitial document5/10/2019alyanU	0.40250663019435456
Ruchir Rastogi - Team Meeting Presentation	QR Team ReviewJan 2017Team IntroductionConceptXDeep QRAgendaQR Team MembersDev Manager: Ciya LiaoLeads: Garrett Kaminaga, Jingwen Lu, Saekoo Lee, Gord LueckPMs: Shyam Jayasankar, Jie CaiSTC-A Speller team: Yongen Gong and his teamWha	0.3962165938806031
Ruchir Rastogi - Team Meeting Presentation	Ranker Training Pipeline IntroductionAgendaPipeline OverviewGCC platformExtractionData/Feature PreparationMain Ranker TrainingSegment RankersPipeline OverviewGR OctTree: gcclinkMain Steps:Metastream injection (just info here)Querys	0.39039869248514975
Ruchir Rastogi - Team Meeting Presentation	AgendaAres Data Access FrameworkEntitySet Creation WorkflowMetric CalculatorQuestion & AnswerARES logical conceptsARES AssetsLogical ModelEntity/RelationRelated RVT data model ARES Data ModelUnit of ExecutionEntityJobTask	0.3798310217555965
Ruchir Rastogi - Team Meeting Presentation	DU feature usage summary about en-us and zh-cn prod ranker:<more detail please refer to the attached report>Basics:99 APF in en-us Ranker.47 APF in zh-cn Ranker.41 APF appear both in en-us Ranker and zh-cn Ranker. 58 APF only appear in  en-us 	0.374287302940716
Ruchir Rastogi - Team Meeting Presentation	Introduction to dynamic ranking Xiao WuOutlinesIntroductionRelevance MeasurementDynamic rankingRanking FeaturesRanking DataRanking modelsRelevance ExperiementIntroductionWhat is dynamic rankingRanking based on query dependent featu	0.3678444297471339
Ruchir Rastogi - Team Meeting Presentation	Keyword Predictor Design DocumentName: Ruchir RastogiMentor: Jia LiuManager: Leon ZhangProject overviewThe goal of this project is to design a machine-learning model that can predict keywords in a local query for improving local search relevance	0.3616258039598371

Restaurants Features	Restaurants Features and ToolsReview SnippetXAPOSearchQueryWPOLERWPO OSCacheItemCacheIdList of YpIdsFiltersSorterEntityUpdate PostFixEntity Update OSCache IdCache ItemYpId and PostFixUXReview Snippet Data GroupCac	0.3644958328566298
Restaurants Features	Restaurant segment metrics collectionObjectiveTo understand user behavior/engagement on Restaurant answers.Why this is important? The metrics will help us understand:The comparisons between different answersWhat is important to our users and w	0.30292263756755156
Restaurants Features	Deal UnderstandingDeals with Low Quality: (some features/rules are listed below)Features/RulesExamplesNo user used; no verified informationThe policies about return365 Day Return Policy;Free Returns on All Orders; 45 Day Return Money Back 	0.26564896575088914
Restaurants Features	Wind Up Impact on Existing adInsight Feature Plan03/25/2015ContextTo Enable “Wind Up for Premium” as high priority, we decide to make following resource adjustmentImpact to Existing Product/Feature AreaFocus AreaProducts/FeaturesResource	0.23087304225346897
Restaurants Features	PAC: Features, Usage and ProcessThis is a document on how to get document features and build metaword/metastream via Page Analyzer and Classifier (PAC ) pipeline. ContentsKinds Of Features Supported By PAC	2Url/Title Features	2Body Features: Doc	0.22297256044873193
Restaurants Features	[IMPORTANT]Please notify “featfun” if you want to edit this document!!!Metastream FeaturesWritten by: Tian Xia (tixia@microsoft.com)Table of Contents1. Overview	62. Basics	82.1 Metastreams	9Single instance metastream	9Multi-instance meta	0.2228985942476245
Restaurants Features	Global relevance feature proposalFeature name: Title Match OptimizationPMJin GuoDevJia LiuTestReleaseALTeam site linkExecutive SummaryTitle is the summary/abstract of the document. Title Match is very important to SBS. Through many c	0.205804692623589
Restaurants Features	Path Classifier FeaturesLast saved 16 March 2015 (build 3790878) by Garrett Kaminaga.NotesFeature names are composed of a group name and a feature name, separated by underscoreFeature values are always UInt32.  There are various encoding mechanism	0.20302728593384956
Restaurants Features	OSG Threshold[Cortana/Improving Cortana Personalization Through Finances]functional specification[Shell/CAST]CONTACTSROLEName; AliasProgram ManagerColleen Hamilton; chamiltDeveloperQualityDesignPartner(s)ONE PAGE SPEC - Guideline	0.19769179086697905
Restaurants Features	DU items studyJia Liu2013-05-14AgendaPublication dateMain body blockDocument qualityurl static featuresPublication dateFreshness rankingYear in title, year in url, publication dateEn-us publication date coverage is ~20%Zh-cn public	0.19566124684430802

RestaurantMetricsOnePager	Restaurant segment metrics collectionObjectiveTo understand user behavior/engagement on Restaurant answers.Why this is important? The metrics will help us understand:The comparisons between different answersWhat is important to our users and w	0.32968170528489305
RestaurantMetricsOnePager	MQ for CALOverviewSpellerQASMQTriggerMQSingleQueryChainChainChainAugmentAugmentAugmentTailQuerySimplifiedSPCombSP1SP2Sp3AugmentAugmentPropertyBag - SQQueryAlterationListQueryAlterationSetQueryAlterationType	0.2731022140916562
RestaurantMetricsOnePager	Metrics Pipeline & ToolsJia Liu / Xiaohui Sun / Alex SergeevASG Data Mining TeamDemo link: http://dmsql05/MetricsDefinitionTool/MetricsDefinition.aspx?DataSet=BFT&MetricName=HasCortanaChitChatsTopicsBing Live Metrics PipelineUsage and Perf	0.24792340670755272
RestaurantMetricsOnePager	TopChainNumber MasterId Label Type Name Phone AddressLine City Website Closed LastYearImpression LCMScore ChainId ChainName Score LPLink SparsedFeatureVector r 873x114637191399090866 0 http://maps.google.com/maps/place?cid=14233605658129796921 Ion Bank 36	0.20945895111180132
RestaurantMetricsOnePager	CosmosStreamSetsSaveen Reddy2014/04/15http://aka.ms/CosmosPresentationshttp://aka.ms/CosmosCodeSamples© 2012 Microsoft Corporation. All rights reserved. Microsoft, Windows, and other product names are or may be registered trademarks and/or tra	0.19727165614212006
RestaurantMetricsOnePager	CosmosScope> Complex Data TypesMichael Rys & Saveen Reddy2015/02/25http://aka.ms/CosmosPresentations© 2012 Microsoft Corporation. All rights reserved. Microsoft, Windows, and other product names are or may be registered trademarks and/or tradema	0.19611723141102852
RestaurantMetricsOnePager	Ranker Training Pipeline IntroductionAgendaPipeline OverviewGCC platformExtractionData/Feature PreparationMain Ranker TrainingSegment RankersPipeline OverviewGR OctTree: gcclinkMain Steps:Metastream injection (just info here)Querys	0.186281443938355
RestaurantMetricsOnePager	Zh-cn Transportation Segment Optimization by Pattern EngineJia Liu/Allen WangDSATsQuery: 吉林市到查干湖Relevant result title: 吉林市到查干湖怎么走近？_百度知道Irrelevant result title 1: 查干湖,中国查干湖,吉林查干湖,查干湖旅游,查干湖冬捕,国家AAAA ...Irrelevant result title 2: 查干湖_百度百科Irrel	0.1787481856427323
RestaurantMetricsOnePager	Introduction toas measurement platformOlli-Pekka TossavainenMSQ TeamSunnyvaleContentsOverviewAres AssetsData Web Store (DWS)Single HitApp core relevance exampleWhat is ARESFrom their web site:What’s been built on ARESMap Search	0.1785312569932071
RestaurantMetricsOnePager	SPAM & JunkSi Planning Cheng Niu, Alex Rahin6/18/2014Agenda	Focus AreasMetricsSPAM/Junk Metrics BreakdownData Analysis and Project DefinitionFocus AreasImprove SPAM Detection (~35% of team bandwidth)Stolen ContentContent Keyword St	0.1784977269156022

Requests to improve Agility	Deal Ranking ImprovementsDeal Understanding ImprovementsGoal: Increase general deal coverage (deal product type from specific to general).Solution: Identify the prefix and suffix of title by punctuations and prep. Remove the prefix and suffix from t	0.34150474201630615
Requests to improve Agility	Relevance Experimentation with DUOverviewThe ideal end state for any relevance improvement would consist of having one or more DU features shipped in the index that is then leveraged by the latest production ranker. This would achieve the highest leve	0.339223823086099
Requests to improve Agility	CoreCAL Improvements		Page 2 of 5CoreCAL ImprovementsDescriptionDuring Sodium, CAL Team would invest on optimizing separately for L0\L1\L2 on top of current CoreCAL improvements. Multiple Query Project will target Fidelity\SBS\SSRx while CoreCAL imp	0.3048224215452363
Requests to improve Agility	Publication date optimization for zh-cn marketBackgroundPublication date is a very fundamental and important feature. It can help fresh ranking, whole page user experience: caption date show and freshness internal metrics, also to solve mainline out	0.30145477437383644
Requests to improve Agility	I’d like to explain in more details my idea of improving Dolphin, by improving its robustness of query variations and some previously unseen terms. Our rules don’t cover many query patterns. E.g., {top rated chinese restaurants} works well, but not {chi	0.28247506805605715
Requests to improve Agility	Publication Date Optimization Design and Implement For zh-cn MarketReview and CommentMei Yang; Ted WildAuthorJia LiuDesignBackgroundPublication date is a very fundamental and important feature. It can help fresh ranking, solve mainline out	0.27915539942288486
Requests to improve Agility	LES with Speller in BFPRAnton AmirovBenefitsSupport for misspelled location, metrics improvementAlignment with web resultsCurrent statusHybridLESRaw QuerySpell Corrected QuerySpellerFLEFLEWithSpellerSome answers (AmberAlerts, Electio	0.27435680343279734
Requests to improve Agility	Normalization and Parsing OverviewTypes of NormalizationLimiting to just normalization, there are actually several different types of normalization which may be interesting:WhitespaceThis is:Converting all whitespace characters to spacestrippi	0.2675549103176322
Requests to improve Agility	Project-N DeepDiveAbstractSimilarity issue has been one of the biggest problems of zh-CN relevance for years but not well got solved. In this document, we will focus on one of the main problem of similarity - entity/phrase mismatch issue in query/doc 	0.2660298383605958
Requests to improve Agility	File Relevance Experimentation Design DocRecall AnalysisTest the search quality of external services like OLS, 3S, QF and SPO Search.Search scenarios: 0-term search, term search, 3S (Insert File and Attach File).Compare the recall: diff of returne	0.25918794185162647

Report_Jan_3_2018_copy	TermX: the Query Rewriting Engine for BingCore Relevance PM Meeting | Shu Zheng | Jan 5th, 2016AgendaWhat is TermX? Technique DeepdiveCurrent StateFuture WorksWhat is TermX? TermX = TermExp = Term ExpansionThe query rewriting engine for 	0.2641242015967426
Report_Jan_3_2018_copy	Multi-Query Issue and QR/Ranking Joint Optimization Bhuvan MiddhaJonas BarklundYinzhe YuYuan Wang6/26/2012AgendaPresentation TopicTime/PresenterIntroduction/QR/Ranking for Joint Optimization3:05 pm – 3:30 pm [Bhuvan/Jonas]Joint Opt	0.25269030533763015
Report_Jan_3_2018_copy	Spam/Junk Technology ReviewAgendaSpam/Junk OverviewReview of current metrics and pipelinesExample of recently shipped technologiesJunk page elimination by cross page signalsAnti-{malicious page redirection spam attack}Looking aheadSpam in 	0.23999936739751923
Report_Jan_3_2018_copy	PDI Document AnnotationPDI Ranking PlatformAgendaPDI and forward indexDocument AnnotationSodium update and MG planQ&A DSAT: {books by children}Issue: Document matches the query terms, but its surrounding words may change the intent of 	0.22485121135848496
Report_Jan_3_2018_copy	CAL MultiQuery {Matching\Ranking}		Page 3 of 4CAL MultiQuery {Matching\Ranking}DescriptionCAL is going to optimize against matching\ranking separately and will issue different queries to each tier. CAL will be leveraging several operator such as:m	0.22322532617867552
Report_Jan_3_2018_copy	SVMT UpdateNovember 2016AgendaMorning (10:00-12:00)Overview – 15 minQnA:MALTA – 55 minInfoBot – 30 minLunch break (12:00-1:00)Afternoon (1:00-3:00)Query:Deep QR – 30 minRanking:ConceptX – 30 minFusion – 30 minNapa – 30 minO	0.2200707603798667
Report_Jan_3_2018_copy	Bing Local Functional DetailsDocument StatusDate Created6/25/2013Last Updated2/28/2014Current StatusDraft Key StakeholdersProgram ManagementDany Daher; Tony Angell; Sumitra Sheth; Product ManagementTBD;Executive SponsorsEric Ca	0.2194196623513381
Report_Jan_3_2018_copy	PA Selection StackKeng-hao Chang3/8/2017AgendaQuery (offer) understandingRetail classifierCategorizerCRFSelection algorithmsRIIRNGSRanking methodsL0, L1, L1.5, L2, Attribute-awareRetail experiencePA stack via Components*RnR	0.2142221032714659
Report_Jan_3_2018_copy	Mobile 100k Compete Data analysis with G - Simulation Report6/6/2014Mobile Simulation AnalysisThis analysis compares Google and Bing on iOS for 3 querysets.REPORTS GENERATED FOR **: Overall Metrics Coverage (WP, ML and Bot)IY (WP, ML and Bot	0.2062457292235574
Report_Jan_3_2018_copy	Project-N DeepDiveAbstractSimilarity issue has been one of the biggest problems of zh-CN relevance for years but not well got solved. In this document, we will focus on one of the main problem of similarity - entity/phrase mismatch issue in query/doc 	0.20612678721998826

Relevance Next and our Path to Artificial General Intelligence	Microsoft ConfidentialSeptember 14, 2016Relevance Next and Artificial IntelligenceRelevance and Intent OffsiteFebruary 8thOur PrioritiesExpand our Capabilities towards a full fledged AGI Engine, with focus on Knowledge, NL/Semantic Understandi	0.5253212889694661
Relevance Next and our Path to Artificial General Intelligence	Relevance Debug InfrastructureProblemFrequent  daily metric fluctuationRelevance gain negated by regressions from Sep to Oct 2013Painful to investigateChallengeLocal stack is complex with lots of componentsVarious relevance events mixed toge	0.4825893401261776
Relevance Next and our Path to Artificial General Intelligence	Relevance Experimentation with DUOverviewThe ideal end state for any relevance improvement would consist of having one or more DU features shipped in the index that is then leveraged by the latest production ranker. This would achieve the highest leve	0.4726871930127529
Relevance Next and our Path to Artificial General Intelligence	Distributed Deep Learning: New Driving Force of Artificial IntelligenceTie-Yan LiuPrincipal Researcher Microsoft Research AsiaAI Is Making Break-through!2016/12/21Tie-Yan Liu -  Distributed Deep Learningvs.Sedol LeeAtari Games“Deep	0.46227492546354587
Relevance Next and our Path to Artificial General Intelligence	Abacus Query Pattern SpecThis document describes how the query GEE pattern is passing from CAL into PDR, and generate a series of features depending on the <querypattern, URL-host> level matching. Query Property of GEEHere is the query property defi	0.4406291587528647
Relevance Next and our Path to Artificial General Intelligence	Microsoft ConfidentialSeptember 14, 2016Microsoft’s Artificial General Intelligence Effort at ASG and DLTCLi Deng, Rangan Majumder, Saurabh Tiwary, Sean Yang, Mir Rosenberg, Jianfeng GaoDefinitionsDeep learning is a class of machine learni	0.4321946334584383
Relevance Next and our Path to Artificial General Intelligence	Entity Pane and Fact AnswerPresenter: Ze TianJun 25, 2013IntroductionIntroductionIntroductionProblems to SolveDoes the user search for entities or facts of entities?E.g. “who is msft ceo” (Entity: Microsoft, Fact: Chief Executive O	0.4306296741847536
Relevance Next and our Path to Artificial General Intelligence	Combined ALterationsNeon\sodiumAgendaNeon AchievementsBreakdownsSodiumIdeas & PlanNeonOverall ProgressExceeded Neon Commitments on CQS!NeonCQS Deep-dive-34% Bad+14% Excellent-15% Bad+13% ExcellentDRDOCQS is impr	0.42863018493225824
Relevance Next and our Path to Artificial General Intelligence	Pattern Based Term Weight FrameworkIntroductionPattern based term weight recognizes the importance for part of terms or all the terms based on patterns/templates/knowledge. There are 2 differences between general and pattern based term weight.Compar	0.4282781193483128
Relevance Next and our Path to Artificial General Intelligence	Microsoft ConfidentialSeptember 14, 2016Relevance Next and our Path to AGIAll HandsFeb 10th 2016Relevance Next and our Path to AGIRelevance OpportunitiesAGI: Project Turing Relevance PowerSubstrate RelevanceDemos! Q&AAgendaFY16	0.4259845357722072

Relevance Experimentation with DU	Relevance Experimentation with DUOverviewThe ideal end state for any relevance improvement would consist of having one or more DU features shipped in the index that is then leveraged by the latest production ranker. This would achieve the highest leve	0.6467832171083483
Relevance Experimentation with DU	Relevance Debug InfrastructureProblemFrequent  daily metric fluctuationRelevance gain negated by regressions from Sep to Oct 2013Painful to investigateChallengeLocal stack is complex with lots of componentsVarious relevance events mixed toge	0.4912267783850792
Relevance Experimentation with DU	File Relevance Experimentation Design DocRecall AnalysisTest the search quality of external services like OLS, 3S, QF and SPO Search.Search scenarios: 0-term search, term search, 3S (Insert File and Attach File).Compare the recall: diff of returne	0.41450186328756206
Relevance Experimentation with DU	Generic Entity Extraction in Sodium Owner: Chuanxin HuContributors: Kang Li, Yi LiOverviewThe understanding of entities and their relationship is a one of the key pillars supporting the Bing’s strategic bet on the knowledge graph. Today, Satori ca	0.3268842068849554
Relevance Experimentation with DU	Fast Brain – Memorization & InferenceQuery based memorization and inferenceLarge Memorization -  1B queries, clicks (Q-D) and moreDeep Brain100 - 200B Doc/Page IndexRecall, Tail and Scalability focusedLess dependency on popularity signalHeur	0.3161863260295278
Relevance Experimentation with DU	Global relevance feature proposalFeature name: Title Match OptimizationPMJin GuoDevJia LiuTestReleaseALTeam site linkExecutive SummaryTitle is the summary/abstract of the document. Title Match is very important to SBS. Through many c	0.26025537607738025
Relevance Experimentation with DU	L4 Experiment PipelineDate: Aug 20th, 2013Author: Bangyong LiangMotivation:L4’s functionality is to merge results from multiple queries. L4 has two types of merging strategies. One is query level merger and the other one is document level merger. 	0.2561471185232867
Relevance Experimentation with DU	Relevance and AIBing and Information Platform GroupFY18 AGI Encoder RoadmapFeature OwnersProgram ManagersNitin SharmaDevelopersSaurabh Tiwary, Gargi GhoshResearchersMarketingPartnersYantao Li, Weihu, GuihongOverviewAGI Encoder go	0.25429207036008555
Relevance Experimentation with DU	Core Web RelevanceFY16 H2 PlanCore Web RelevanceFY16 H2 PlanCore Web RelevanceFY16 H2 PlanCore Web RelevanceFY16 H2 Plan	0.2542226444099074
Relevance Experimentation with DU	LES with Speller in BFPRAnton AmirovBenefitsSupport for misspelled location, metrics improvementAlignment with web resultsCurrent statusHybridLESRaw QuerySpell Corrected QuerySpellerFLEFLEWithSpellerSome answers (AmberAlerts, Electio	0.248623561302955

Relaxcount=2 summary	Relaxcount=2 summaryRelaxcount=2 datagatheringDatagathering for relaxcount=2 branched path (3/14/15-3/20/15):Cal13a: control (OFE logging, relaxcount=2 off), 6% trafficCal13b: on (OFE logging, relaxcount=2 on for word count >=5), 12% traffic.Dat	0.5145127158857357
Relaxcount=2 summary	Relaxcount=2Momo JengRelaxcount=2 datagatheringDatagathering flight for relaxcount=2:3/14/2015-3/20/2015Cal13a: control (OFE logging, relaxcount=2 off), 6% trafficCal13b: always on (OFE logging, relaxcount=2 on), 12% trafficThe flight was do	0.4397053350578467
Relaxcount=2 summary	RelaxCount Classifier in JO V3By: Gord Lueck, 2013.09.04BackgroundCAL now has the ability to ship with a relaxcount classifier.  That is, a trained decision tree that is designed to predict the relaxcount decision on a query.  The classifier can be 	0.4083771821160499
Relaxcount=2 summary	Deep RelaxQuery Relaxation and L1 FidelityQuery Relaxation{printable iphone 7 user guide}rankonly:printable iphone 7 rankonly:user guiderankonly:printable iphone 7 user guideDeep Relax and vector similarity Encode query without each toke	0.29936325607588615
Relaxcount=2 summary	SmartRelax OFE and TrainingOverviewAnalysis of smartrelax flightsOFE flight simulatorIs smartrelax ever bad?Smartrelax model training:Training method I: relax-specific targetsTraining method II: end-user targetsSmart Relax OFE and Training	0.29784299699595496
Relaxcount=2 summary	Summary and HighlightsIn April the metrics/measurement team released local AutoSuggest metric and shared initial transit measurement results; BLU team shipped CL 1.0 ontology and deployed BLU v3 to all markets; PBA team shipped a new L2 ranker and refre	0.23081112209915258
Relaxcount=2 summary	Smart Query Relaxation In Joint OptimizationA Cross-Group Collaborations Among QU/QR/CoreRanking/IS/MSR      Presented By : Xiaolong Li (Query Understanding)8/19/2013Smart Query Relaxation in JOPOutlineJOP V2 SummaryQuery Relaxation An	0.2040192626120282
Relaxcount=2 summary	Smart relax, 3-way choiceMomo JengOffline simulationGeneral process for offline simulation:We have n choices to decide between, where n is small.Given choices A, B, and C, randomly show users A, B, or C.Randomization can be per-user (i.e. se	0.20053072239053787
Relaxcount=2 summary	SmartRelax training and evaluation from 15%/15% flightForay scorecard: 15%+15% datagatheringUser-triggered scorecardSSRx gain of 0.12%, for 3+4 word on vs. 3+4 word off. (NOT vs. prod.)Gain is 36% from SSR, 11% from TTS, 52% from TSRSSRx gains s	0.1914804058099678
Relaxcount=2 summary	CosmosSearch RESTful APIsWe now provide the cosmos search REST APIs to enable users to get more insights of their historical SCOPE jobs. This document walks through the basic steps to try out this API.If you have any questions for this document or wan	0.19128222418679786

Relaxcount=2	Relaxcount=2 summaryRelaxcount=2 datagatheringDatagathering for relaxcount=2 branched path (3/14/15-3/20/15):Cal13a: control (OFE logging, relaxcount=2 off), 6% trafficCal13b: on (OFE logging, relaxcount=2 on for word count >=5), 12% traffic.Dat	0.4723548687145122
Relaxcount=2	Relaxcount=2Momo JengRelaxcount=2 datagatheringDatagathering flight for relaxcount=2:3/14/2015-3/20/2015Cal13a: control (OFE logging, relaxcount=2 off), 6% trafficCal13b: always on (OFE logging, relaxcount=2 on), 12% trafficThe flight was do	0.4631172084740162
Relaxcount=2	RelaxCount Classifier in JO V3By: Gord Lueck, 2013.09.04BackgroundCAL now has the ability to ship with a relaxcount classifier.  That is, a trained decision tree that is designed to predict the relaxcount decision on a query.  The classifier can be 	0.3425757867770415
Relaxcount=2	Deep RelaxQuery Relaxation and L1 FidelityQuery Relaxation{printable iphone 7 user guide}rankonly:printable iphone 7 rankonly:user guiderankonly:printable iphone 7 user guideDeep Relax and vector similarity Encode query without each toke	0.2743618789259446
Relaxcount=2		0.2742717190380345
Relaxcount=2	SmartRelax OFE and TrainingOverviewAnalysis of smartrelax flightsOFE flight simulatorIs smartrelax ever bad?Smartrelax model training:Training method I: relax-specific targetsTraining method II: end-user targetsSmart Relax OFE and Training	0.18395712800554387
Relaxcount=2	Smart relax, 3-way choiceMomo JengOffline simulationGeneral process for offline simulation:We have n choices to decide between, where n is small.Given choices A, B, and C, randomly show users A, B, or C.Randomization can be per-user (i.e. se	0.1393174320918979
Relaxcount=2	CosmosSearch RESTful APIsWe now provide the cosmos search REST APIs to enable users to get more insights of their historical SCOPE jobs. This document walks through the basic steps to try out this API.If you have any questions for this document or wan	0.13175304096612928
Relaxcount=2	Entity Pane and Fact AnswerPresenter: Ze TianJun 25, 2013IntroductionIntroductionIntroductionProblems to SolveDoes the user search for entities or facts of entities?E.g. “who is msft ceo” (Entity: Microsoft, Fact: Chief Executive O	0.12723850765878372
Relaxcount=2	Anchor and Click Stream RankingSteven ZittrowerBing Local Search RelevanceHypothesisConverting local search’s unstructured and raw text streams into semi-structured forms will improve ranking and offer relevance benefits.TestUsing classifiers 	0.12709081055062474

RelaxCount Classifier in JO V3	RelaxCount Classifier in JO V3By: Gord Lueck, 2013.09.04BackgroundCAL now has the ability to ship with a relaxcount classifier.  That is, a trained decision tree that is designed to predict the relaxcount decision on a query.  The classifier can be 	0.6649353940727104
RelaxCount Classifier in JO V3	Relaxcount=2Momo JengRelaxcount=2 datagatheringDatagathering flight for relaxcount=2:3/14/2015-3/20/2015Cal13a: control (OFE logging, relaxcount=2 off), 6% trafficCal13b: always on (OFE logging, relaxcount=2 on), 12% trafficThe flight was do	0.45218358511368806
RelaxCount Classifier in JO V3	Relaxcount=2 summaryRelaxcount=2 datagatheringDatagathering for relaxcount=2 branched path (3/14/15-3/20/15):Cal13a: control (OFE logging, relaxcount=2 off), 6% trafficCal13b: on (OFE logging, relaxcount=2 on for word count >=5), 12% traffic.Dat	0.349464929971167
RelaxCount Classifier in JO V3	Span ClassifierSpan classifier is a general infrastructure that can be used to run a fastrank based classifier on a sequence of terms from a query.  It can be used to apply rankonly or norelax to parts of the query based on the result of the model.  Fea	0.3237724080027228
RelaxCount Classifier in JO V3	NGram Language Model based Url Breaking – Design DocumentStatusOngoingIntroductionUrl is a very important signal for ranking, particularly for tail queries and navigation queries. This signal has 100% url coverage, which really makes it different 	0.29765853585235136
RelaxCount Classifier in JO V3	Smart Query Relaxation In Joint OptimizationA Cross-Group Collaborations Among QU/QR/CoreRanking/IS/MSR      Presented By : Xiaolong Li (Query Understanding)8/19/2013Smart Query Relaxation in JOPOutlineJOP V2 SummaryQuery Relaxation An	0.27229941564901466
RelaxCount Classifier in JO V3	SmartRelax OFE and TrainingOverviewAnalysis of smartrelax flightsOFE flight simulatorIs smartrelax ever bad?Smartrelax model training:Training method I: relax-specific targetsTraining method II: end-user targetsSmart Relax OFE and Training	0.26153525671301775
RelaxCount Classifier in JO V3	Deep RelaxQuery Relaxation and L1 FidelityQuery Relaxation{printable iphone 7 user guide}rankonly:printable iphone 7 rankonly:user guiderankonly:printable iphone 7 user guideDeep Relax and vector similarity Encode query without each toke	0.2606383354865932
RelaxCount Classifier in JO V3	Introduction to dynamic ranking Xiao WuOutlinesIntroductionRelevance MeasurementDynamic rankingRanking FeaturesRanking DataRanking modelsRelevance ExperiementIntroductionWhat is dynamic rankingRanking based on query dependent featu	0.2532820612269727
RelaxCount Classifier in JO V3	ODP Classification: Summarizing Pages as a Topic DistributionNov 17, 2010Paul Bennett (pauben), MSR CLUESJoint work with Max Chickering & Susan Dumais© 2006 Microsoft Corporation. All rights reserved. Microsoft, Windows, Windows Vista and ot	0.24540271441590059

Reading List		0.3440885644087468
Reading List	No Results Workflow ImprovementsBackgroundToday’s No Results workflow looks at the number of documents returned by WebAnswer, and if it is exactly zero, will make a second call to alterations for aggressive treatment, and a second call to WebAnswer wi	0.1548809475074744
Reading List	Thoughts on Interest Graph – Experience, Business and TechnologyPersonalized recommendation that you don’t want to miss Author: Ting Cai Contributors: AC Surendran, Xiaodong Fan, Chuanxin Hu, Yan Ke, Tony Chor, Richard Qian1.	What is Interest Graph?	0.09367250421799321
Reading List	Named Entity RecognizerTao Peng and Kang LiEntity names recognitionRecognize person, location and organization namesBOSTON, April  16 - Kevin Garnett helped the Boston Celtics beat the L. A. Lakers in last year's NBA final. ( Tony Gutierrez / Asso	0.08077245692775059
Reading List	Bitext Alignment for Alteration Candidate GenerationJan 2018Alteration BasicsCAL alteration architecture is a big funnelCurrent mouth of the funnel is the altlist – a non-context-sensitive relation of <source, target, score>Built over time, qu	0.07989688602612602
Reading List	This workbook contains Parent Child Relationship matrix of provider given relationships. Currently only navteq provides this information and that is the only one which is included here. Parent Category Parent Count Child Count 11579 Hospitals And Medical 	0.07185160082978312
Reading List	US Privoder List 7/21/2016 internal/external  licensed/crawled Job scheduled isSeed comments for KAG whitelist for KAG? commetns for Feed en-US-FTWMissingEntityCorrection  Internal Internal allowed Y Dsats admin added reported missing business internally 	0.06347102993977871
Reading List	Deal UnderstandingDeals with Low Quality: (some features/rules are listed below)Features/RulesExamplesNo user used; no verified informationThe policies about return365 Day Return Policy;Free Returns on All Orders; 45 Day Return Money Back 	0.05980397056488619
Reading List	alterationsalterations: product goalimprove recallby adding terms (not replacing or dropping user-entered terms)using word:which are synonyms to the original terms(we are re-examining each of these for vnext)alterations: general principl	0.05064380964717245
Reading List	Local Probe bugsContents1.	Phone number format replacement	22.	Data on the Live Site does not correspond to data in the Local Probe	43.	Second time corrections	54.	Cuisine Selection	65.	Market settings affecting cuisine output	76.	Ranking is	0.04028059303670499

RankerAnalysis	L2 Ranker Training and Feature Management						-- Shu HuangOutlineL2 ranker and truncation rankerFeature extractionFake L2 rankerFeature extraction pipelineMutiple ideal querysetsL2 ranker and truncation rankerFind the current prod ran	0.42744791038265567
RankerAnalysis	FastRank--- a Decision-Tree based Ranking ModelYu SHIOutlineBackgroundAlgorithm overviewTraining implementationExperimentationChallengesReferencesBackgroundInvestigated by MSR in OsloShipped with July Tree 2010 (Denver)GoalsSpe	0.35170028537421977
RankerAnalysis	Content Quality Classification & RankingGuihong Cao, Cheng NiuContent Quality for RankingContent quality = originality + trustworthy + information satisfaction + freshnessSpam sites, junk site, link farm, content farm, ….Search users are interes	0.2973396855687378
RankerAnalysis	Introduction to dynamic ranking Xiao WuOutlinesIntroductionRelevance MeasurementDynamic rankingRanking FeaturesRanking DataRanking modelsRelevance ExperiementIntroductionWhat is dynamic rankingRanking based on query dependent featu	0.2671975899053867
RankerAnalysis	Wrapstar rating signalsfor zh-cn documentsJia LiuWrapstar rating signals for rankingWrapstar Taobao ratingWrapstar Tmall ratingWrapstar Qna ratingWrapstar Book ratingWrapstar Video ratingDsats examplesTaobao examplesQuery=“蓝色休闲裤	淘宝”	0.26063317700763333
RankerAnalysis	YPCutoff Selection                                                                                    -Ganesh Poomal GirirajanQuery Flow in IndexFilterSet GenerationL1 RankingL2 RankingExampleQuery: Southeast{Miami,Florida}-broward county sc	0.2533706721552268
RankerAnalysis	Ranker Training Pipeline IntroductionAgendaPipeline OverviewGCC platformExtractionData/Feature PreparationMain Ranker TrainingSegment RankersPipeline OverviewGR OctTree: gcclinkMain Steps:Metastream injection (just info here)Querys	0.24427680860115325
RankerAnalysis	Deal Ranking Improvement & MeasurementBackgroundAfter we shipped deal understanding, bad deals filtering, deal ranking for the entity search deals and popular deals nearby. We want to measure and improve our deal ranking based on user behaviors. We ca	0.23943029993468248
RankerAnalysis	Google Mobile vs Desktop RankDiff StudyNov 2017GoalsUnderstand what Google does differently on Mobile, if anythingDrive product ideas & shape ranking improvements on MobileUnderstand any possible impact to Algo scrapes & metricsDrive scrapin	0.23799837639812635
RankerAnalysis	Leveraging Satori Knowledge Graph in Web Ranking StackMicroSegment and Index ServeThe demo is about how to leverage Satori Knowledge Graph in Web ranking. It is joint work among relevance microsegment, Satori and index serve teams.MotivationSome	0.23365480636143157

Ranker Training Pipeline Introduction for QR	Ranker Training Pipeline IntroductionAgendaPipeline OverviewGCC platformExtractionData/Feature PreparationMain Ranker TrainingSegment RankersPipeline OverviewGR OctTree: gcclinkMain Steps:Metastream injection (just info here)Querys	0.7130520442981775
Ranker Training Pipeline Introduction for QR	L2 Ranker Training and Feature Management						-- Shu HuangOutlineL2 ranker and truncation rankerFeature extractionFake L2 rankerFeature extraction pipelineMutiple ideal querysetsL2 ranker and truncation rankerFind the current prod ran	0.5816153149869906
Ranker Training Pipeline Introduction for QR	Introduction to dynamic ranking Xiao WuOutlinesIntroductionRelevance MeasurementDynamic rankingRanking FeaturesRanking DataRanking modelsRelevance ExperiementIntroductionWhat is dynamic rankingRanking based on query dependent featu	0.5302889907116988
Ranker Training Pipeline Introduction for QR	FastRank--- a Decision-Tree based Ranking ModelYu SHIOutlineBackgroundAlgorithm overviewTraining implementationExperimentationChallengesReferencesBackgroundInvestigated by MSR in OsloShipped with July Tree 2010 (Denver)GoalsSpe	0.4731047403672065
Ranker Training Pipeline Introduction for QR	Metrics Pipeline & ToolsJia Liu / Xiaohui Sun / Alex SergeevASG Data Mining TeamDemo link: http://dmsql05/MetricsDefinitionTool/MetricsDefinition.aspx?DataSet=BFT&MetricName=HasCortanaChitChatsTopicsBing Live Metrics PipelineUsage and Perf	0.46760831871576786
Ranker Training Pipeline Introduction for QR	YPCutoff Selection                                                                                    -Ganesh Poomal GirirajanQuery Flow in IndexFilterSet GenerationL1 RankingL2 RankingExampleQuery: Southeast{Miami,Florida}-broward county sc	0.4467976296714474
Ranker Training Pipeline Introduction for QR	Local Category Search StudyHuanan Zhang01/03/2018OutlineStructure of PBA (Prod) rankerIntent match ranker’s role in Prod rankerIssues of intent match rankerSolutions – metastream clean upMetastream measurementPreliminary resultsPBA	0.4312146285258919
Ranker Training Pipeline Introduction for QR	Auto Category Classification PipelineHanqing Cui2012/10/25OutlinePain PointsThinkingAuto Category Classification PipelineAuto Page LabelingData SamplingTrainingFeature SelectionThresholdIterative TrainingInitial Seed Model Creati	0.4307340282351896
Ranker Training Pipeline Introduction for QR	Zh-cn Transportation Segment Optimization by Pattern EngineIntroductionThe pattern queries can cover almost 10% in all queries. We can summarize lots of patterns on Query and Document sides for different segments. We can recognize key terms, relations	0.41522080647931453
Ranker Training Pipeline Introduction for QR	QR Micro SegmentOverviewMicro Segment is way to fix corner case that main Bing ranking pipeline couldn’t fix easily by machine learning. There are many ways to do micro segment. Micro segment can be done in many layers. QR, matching, L1, L2, L3, …. To	0.4097348555774402

Query语义重要度标准	query分类—分享                     刘佳2011.6.8web query classification(query分类):	将web search query根据它的主题，分派到1个或者多个预先定义的分类中。web search query的特征：有噪声：拼写错误等长度很短：信息量少，特征少表意含糊：query可能包含多个含义,属于多个分类含义会随时间演变目标分类的特征：目标分类定义缺少语义注解一级或者多级分类分类数目：几	0.8597199867613277
Query语义重要度标准	BS代码阅读：BS基本功能：索引相关性切词成分分析offset调权query解析 （where+what）多路归并 综合调权类聚（偏离点）query分类空间调权数据来源点击调权BS代码阅读：bs_cache:map库的term cachemap库term cache操作锁where库term cachewhere库term cache操作锁init_map_term_cache: 初始化map库term cachein	0.8584788861641641
Query语义重要度标准	排序及扩展：插入排序，选择排序（冒泡排序），使用二分思想求第k大数，快速排序，非递归的快速排序，使用快排思想求第k大数，归并排序，求逆序数，自然排序算法，堆排序，最小优先级队列，计数排序，桶排序，鸽巢排序（分块排序），基数排序，外部排序：二路归并，K路归并，胜者树，败者树。  算法一：使用插入或者选择排序，得到最大的K个数，时间复杂度为：O(N*k)。 冒泡排序： void swap(int * a,int * b){            //注意	0.8539670629054736
Query语义重要度标准	克拉玛依公证处:本人因生活在国外，不能亲自到贵单位办理出生证明公证事项，兹授权委托雷春香女士全权代表我办理相关事项。对委托人在办理上述事项过程中所签署的有关文件，我均予以认可，并承担相应的法律责任。委托人：刘佳			委托人身份证号码：654301198608243929被委托人：雷春香		被委托人身份证号码：6526196207113926委托人：刘佳2018年5月24日	0.8539670629054736
Query语义重要度标准	性能升级性能升级的几个层面：系统结构：模块分解，模块交互，系统构建中的粗略估算。算法和数据结构：获得快速模块的关键：表示数据的结构，操作数据的算法：索引结构及拉链归并。代码调优：分支预测等。循环：将循环体中不改变的变量移动到循环体外；多重循环嵌套顺序。函数调用：inline函数节省函数调用开销：若makefile中不指定至少-O优化，即使声明为inline函数，编译器也不会进行函数内联。内存寻址：避免重复内存寻址。Cpu流水线的分支预测：将满足概率最高的条件放在靠前的位置。	0.8539670629054736
Query语义重要度标准	业务生成平台用户指南总体说明开发背景下一代网络是业务驱动的网络，在融合的下一代网络上高效、灵活地开发和部署各种丰富多彩的业务，从而提高网络使用率、增加收益的目标，是下一代网络的关键环节。下一代网络的发展要求呼叫与承载相分离、呼叫控制与业务相分离，使业务真正独立于网络，业务开发者不必关心与业务承载相关的底层网络知识以及具体的通信协议，只需利用业务生成平台提供的业务开发工具，就可以开发出灵活丰富且极具个性化的业务。 为了适合多种技术水平的业务开发人员的需要，现在主要有四种业务开发方式：	0.8539670629054736
Query语义重要度标准	贝叶斯分类模型：基础知识：假设	X：是数据元组，由n个属性描述；	H：是某种假设，如数据元组属于某特定类C	P(H|X)：表示给定X的属性描述，找出元组X属于类C的概率举例：X：一位35岁的顾客，收入为4w美元；H：顾客将购买计算机P(H|X)：在X的条件下，H的后验概率。当我们知道顾客的年龄和收入时，顾客X将购买计算机的概率。P(H)：H的先验概率。任意给定顾客将购买计算机的概率，独立与X。P(X|H)：在条件H下，X的后验概率。已知顾客购买了计算机，顾客是一位3	0.8539433760594433
Query语义重要度标准	K最近邻分类模型：原理：训练元组用n个属性描述，每个元组代表n维空间中的一个点，所有的训练元组存放在n维的模式空间。当给定一个未知元组时，KNN搜索该模式空间，找出最接近未知元组的k个训练元组。未知元组指派到它的k个最近邻中的多数类。“邻近性”用距离度量，如欧几里德距离。欧几里德距离：	设元组X1=(X11,X12,…X1n)，X2=(X21,X22,…X2n)，	Dist(X1,X2)=√ ∑ k= 1 n (X1i-X2i) 2 	使用上式之前，对每个属性的值规范化，以防止具有	0.8536770542713134
Query语义重要度标准	C专家编程读书笔记难点关键字的用法：关键字用法extern在函数名前，表示该函数全局可见，一般缺省。即一个文件的全局变量和函数对其他文件，具有可见性。在变量或者函数前，表示对象的定义在别处进行。由于重载，在c++中调用以C方式编译的函数时，需要加extern “c”。static隐藏：修饰的对象对其他文件不可见，防止多个文件命名冲突。持久性：修饰的对象，存储在数据段或者bss段，和程序有相同的生命周期。只有一次初始化。3、修饰的变量未初始化时，默认为“0	0.8514463350854325
Query语义重要度标准	As字符串重查优化及评估结果：背景	当bs返回的结果为空，或者返回的结果数小于30，as会进行字符串重查。即将所有的商铺名称及id建立后缀数组(suffix_name,shop_id)。字符串重查时，将检索请求的what query切词，依次取出其中的term，根据term在后缀数组中找到一系列的shop_id，进行去重及过滤，最后将所有term对应的shop_id的列表进行求交，得到结果。结果数的最大值为10000。优化方法：原实现方法：建立后缀数组：求出商铺名称的所有后缀，结构体快	0.8510812423705767

QuerySet_ARES_MC	Analyzed Query represents all information derived from all classification tasks executed on the Query. QAS supports 3 basic classifications tasks: binary classification (Domain Classification), entity extraction (Query Parse), category classification (Dom	0.41444182584267614
QuerySet_ARES_MC	Golden QueryEvery query countsImprove relevance: Relevance TechniquesWin/Loss basedGood technique has better win/loss ratioGeneric Ranker always doesn’t have good win/loss ratioWe do technique triage, and better win/loss ratio technique got sh	0.39626651117358025
QuerySet_ARES_MC	query分类—分享                     刘佳2011.6.8web query classification(query分类):	将web search query根据它的主题，分派到1个或者多个预先定义的分类中。web search query的特征：有噪声：拼写错误等长度很短：信息量少，特征少表意含糊：query可能包含多个含义,属于多个分类含义会随时间演变目标分类的特征：目标分类定义缺少语义注解一级或者多级分类分类数目：几	0.3072100511384443
QuerySet_ARES_MC	QueryString Category owner Searchvote url 寇仲最后和谁在一起 ranking  xiaopeng http://searchvote.com/default.aspx?reviewid=209877 布里斯班 ranking  xiaopeng http://searchvote.com/default.aspx?reviewid=211685 必应词典 ranking  xiaopeng http://searchvote.com/default.aspx?re	0.30239464892122697
QuerySet_ARES_MC	Debug Address Queries8/23/2013Bing Local Search RelevanceNTCG MetricsDocumentationhttps://microsoft-my.sharepoint.com/personal/aoakley_microsoft_com/Documents/2013/2013-05-22%20Maps%20metrics%20Qi.pptx?web=1Use it to identify the group of quer	0.2966735481821645
QuerySet_ARES_MC	DU items studyJia Liu2013-05-14AgendaPublication dateMain body blockDocument qualityurl static featuresPublication dateFreshness rankingYear in title, year in url, publication dateEn-us publication date coverage is ~20%Zh-cn public	0.2840445067407314
QuerySet_ARES_MC	Summary of 50 queries:QueryIssue categoryResolved促销策略案例分析Page NumberYes美丽说面膜Page NumberYes朝鲜金正恩腐化生活 图片Page NumberNo(L3 rule not cover this case: the second page is higher than the first page)智慧树2012全集Page NumberYes潘阳老公石磊P	0.27600451170271034
QuerySet_ARES_MC	Query Latitude Longitude QueryId Prod_PLDCG@3 Restcat_PLDCG@3 G_PLDCG@3 Delta ResultQuality Dolphin CRF PhonebookQuLocation LocalPivotEntity TLA Built? Result Returned? Result Good? Comment Restaurants in times square 00f0d1ee-9688-5b09-bcea-a5e860fead14 	0.2719455113715768
QuerySet_ARES_MC	Simplified Query Path SelectorSimplified query: current systemSimplified query path selectionCrf model produces a list of possible ways to place rankonly operatorQuery = “nibbana restaurant official site”nibbana restaurant rankonly:official site	0.26794453530382767
QuerySet_ARES_MC	Location and Data Services Team all hands10/08/2014AgendaCelebrate – Wei, 5minsLocal partners – Andy, 10minsLocal Data Services – Alex, 15minsGeocoder and GeoSpatial Services – Jai, 20minsLocation and Autosuggest Services – Sid, 15minsBing	0.26151988894679723

Query Understanding	Simplified Query Path SelectorSimplified query: current systemSimplified query path selectionCrf model produces a list of possible ways to place rankonly operatorQuery = “nibbana restaurant official site”nibbana restaurant rankonly:official site	0.3591573582826504
Query Understanding	Successful Feeds Query DebuggingNikita Melnichenko, 2015-03-10Feeds query debugging overviewWhen to use:Checking a new rankerChecking new augmentation before running a scrapeComparing several rankersUnderstanding feature contributionDebugg	0.3226534296522473
Query Understanding	Analyzed Query represents all information derived from all classification tasks executed on the Query. QAS supports 3 basic classifications tasks: binary classification (Domain Classification), entity extraction (Query Parse), category classification (Dom	0.3078712619632671
Query Understanding	Golden QueryEvery query countsImprove relevance: Relevance TechniquesWin/Loss basedGood technique has better win/loss ratioGeneric Ranker always doesn’t have good win/loss ratioWe do technique triage, and better win/loss ratio technique got sh	0.27713264393611237
Query Understanding	Deal UnderstandingDeals with Low Quality: (some features/rules are listed below)Features/RulesExamplesNo user used; no verified informationThe policies about return365 Day Return Policy;Free Returns on All Orders; 45 Day Return Money Back 	0.2742979808311965
Query Understanding	I’d like to explain in more details my idea of improving Dolphin, by improving its robustness of query variations and some previously unseen terms. Our rules don’t cover many query patterns. E.g., {top rated chinese restaurants} works well, but not {chi	0.25047813653415446
Query Understanding	Reading List for Natural Language Query ParsingThis is for improving our NL query parsing for entity/local triggering.By NL query parsing, our goal is to automatically extract the structured information from the query, normally by segmenting queries a	0.244661194963263
Query Understanding	QU Deep Dive 2: Query Simplification and Recurrent Neural NetworkXiaolong Li (Lead of QU Fundamentals TEAM)2/12/2015AgendaQUFun Team ResponsibilitiesRecent Deliverables Query Simplification for WebQuery Simplification for Cortana 3ARec	0.23640255255638729
Query Understanding	PBA Query Understanding MigrationTetyana Golub | Ming WuMotivationPBAvnextCurrent QU logic is complicated and hard to migrateLimitation from hard coded logicCurrent QU logic is complicated and not very flexibleHard to add new feature or adju	0.23332192333498303
Query Understanding	Deal Understanding and RankingBackgroundDeal is a very big segment in Bing Opal. We crawl store and single deals/coupons regularly from websites like groupon.com, coupons.com, restaurants.com, retailmenot.com, dealcatcher.com, dealplus.com and so on. 	0.22962347442548794

Query Formulation FY15 H2 Goals	Query Formulation Review of FY15 Goals and Silicon achievements/learningsSilicon ScorecardAreaGoalAchievementQF Relevance(Autosuggest, Related Search)SSRx+0.052Annualized Revenue+$58mRelated Search RelevanceBeat G on DO defect ra	0.48702654494265346
Query Formulation FY15 H2 Goals	Golden QueryEvery query countsImprove relevance: Relevance TechniquesWin/Loss basedGood technique has better win/loss ratioGeneric Ranker always doesn’t have good win/loss ratioWe do technique triage, and better win/loss ratio technique got sh	0.45725667689552835
Query Formulation FY15 H2 Goals	Threshold Query Formulation Deep DiveGoal of the presentation is to communicate our approach for query formulation and get feedback on whether this aligns with overall Threshold goals.OverviewGoals & MetricsQF ModelRoadmapScenariosKey Ta	0.4354134074046088
Query Formulation FY15 H2 Goals	Distance Model Updates in LDCG V2Local Relevance and Measurement TeamAgendaDistance feature in LDCG V1Why was the switch to computing distance made?First implementation of Distance feature in LDCG V2, & improvement areasProcess followed for 	0.4311526540558651
Query Formulation FY15 H2 Goals	ML Model Scorecard Analysis8/8/2019Unexpected term search movementhttps://exp.microsoft.com/xcard/?view=4e77b420-7b77-4e41-92ac-8e84f506fb01Check correctness of scorecard metric implementationCalculate term AVG rank from raw data streamsSearch	0.39946164753851304
Query Formulation FY15 H2 Goals	Translation Model APIStatus: Sodium-2, API Version 6.7OverviewThe TM API – including support for high compression - was developed as one of several architectural considerations to ship machine translation model features to production, initially for 	0.39918137871031717
Query Formulation FY15 H2 Goals	cal deepdiverelaxationdec 2017AgendaProduct GoalsQuery SimplificationMechanism/RuntimeCRF Model TrainingQS Path SelectionOffline SimulatorSmart RelaxMechanism & TrainingRelaxation: ImpactRelaxation: Product goalsImprove Rec	0.3986409503167436
Query Formulation FY15 H2 Goals	Smart Query Relaxation In Joint OptimizationA Cross-Group Collaborations Among QU/QR/CoreRanking/IS/MSR      Presented By : Xiaolong Li (Query Understanding)8/19/2013Smart Query Relaxation in JOPOutlineJOP V2 SummaryQuery Relaxation An	0.381032222449146
Query Formulation FY15 H2 Goals	Auto Category Classification PipelineHanqing Cui2012/10/25OutlinePain PointsThinkingAuto Category Classification PipelineAuto Page LabelingData SamplingTrainingFeature SelectionThresholdIterative TrainingInitial Seed Model Creati	0.3706255286966242
Query Formulation FY15 H2 Goals	AgendaAres Data Access FrameworkEntitySet Creation WorkflowMetric CalculatorQuestion & AnswerARES logical conceptsARES AssetsLogical ModelEntity/RelationRelated RVT data model ARES Data ModelUnit of ExecutionEntityJobTask	0.3696562087111725

Query Augmentation Doc (June 2011)	Debug Address Queries8/23/2013Bing Local Search RelevanceNTCG MetricsDocumentationhttps://microsoft-my.sharepoint.com/personal/aoakley_microsoft_com/Documents/2013/2013-05-22%20Maps%20metrics%20Qi.pptx?web=1Use it to identify the group of quer	0.4206547024086657
Query Augmentation Doc (June 2011)	Domain Authority CAL One PageIntroductionCurrent shipped ngram domain authority in L3 is using complete query match against an offline generated meta-stream (q, url, score), which derives (q,url) pairs from click stream and is the result of aggregatio	0.41944060004744094
Query Augmentation Doc (June 2011)	Author: Tony AngellDate: 08/01/13LocalProbe Improvements for Corrections Analysis and DebuggingTable of ContentsP0 Issues	2Issue: LocalProbe is unpredictable in the amount of time it takes to return a query and how long it takes to investigate a	0.4191630480250997
Query Augmentation Doc (June 2011)	Successful Feeds Query DebuggingNikita Melnichenko, 2015-03-10Feeds query debugging overviewWhen to use:Checking a new rankerChecking new augmentation before running a scrapeComparing several rankersUnderstanding feature contributionDebugg	0.4065156945107967
Query Augmentation Doc (June 2011)	Spam/Junk Technology Review8/8/2017 Pavel KarpovichAgendaSpam/Junk OverviewReview of current system and metricsSJRE Fishtank pipelines UrlExclusion and Defect Subranker	Blue Whale Spam Types of Fresh SpamActions to Detect Fresh	0.390119057170217
Query Augmentation Doc (June 2011)	PA Selection StackKeng-hao Chang3/8/2017AgendaQuery (offer) understandingRetail classifierCategorizerCRFSelection algorithmsRIIRNGSRanking methodsL0, L1, L1.5, L2, Attribute-awareRetail experiencePA stack via Components*RnR	0.3785736522042746
Query Augmentation Doc (June 2011)	Query AugmentationsTable of Contents1. Syntax Overview	22. Constraints	6General rules for operators	7Basic Operators	7Scoring and non-scoring constraint operators	9Stream Operators	9Literal Operators	10Meta Operators	11URL Operators	13	0.37572449096066196
Query Augmentation Doc (June 2011)	Spam/Junk Technology ReviewAgendaSpam/Junk OverviewReview of current metrics and pipelinesExample of recently shipped technologiesJunk page elimination by cross page signalsAnti-{malicious page redirection spam attack}Looking aheadSpam in 	0.369724797742436
Query Augmentation Doc (June 2011)	Analyzed Query represents all information derived from all classification tasks executed on the Query. QAS supports 3 basic classifications tasks: binary classification (Domain Classification), entity extraction (Query Parse), category classification (Dom	0.36260568380513364
Query Augmentation Doc (June 2011)	SPAM & JunkSi Planning Cheng Niu, Alex Rahin6/18/2014Agenda	Focus AreasMetricsSPAM/Junk Metrics BreakdownData Analysis and Project DefinitionFocus AreasImprove SPAM Detection (~35% of team bandwidth)Stolen ContentContent Keyword St	0.3455808070130092

QU_classifiers_20120227	Successful Feeds Query DebuggingNikita Melnichenko, 2015-03-10Feeds query debugging overviewWhen to use:Checking a new rankerChecking new augmentation before running a scrapeComparing several rankersUnderstanding feature contributionDebugg	0.42799180741951787
QU_classifiers_20120227	PA Selection StackKeng-hao Chang3/8/2017AgendaQuery (offer) understandingRetail classifierCategorizerCRFSelection algorithmsRIIRNGSRanking methodsL0, L1, L1.5, L2, Attribute-awareRetail experiencePA stack via Components*RnR	0.41664964721843034
QU_classifiers_20120227	query分类—分享                     刘佳2011.6.8web query classification(query分类):	将web search query根据它的主题，分派到1个或者多个预先定义的分类中。web search query的特征：有噪声：拼写错误等长度很短：信息量少，特征少表意含糊：query可能包含多个含义,属于多个分类含义会随时间演变目标分类的特征：目标分类定义缺少语义注解一级或者多级分类分类数目：几	0.4096968613740108
QU_classifiers_20120227	Zhcn document classification based on topicJia Liu2012.11.14agendarTraining data selection&crawl&cleanFeature selection&cleanClassifierRating Bad case analysisTrainning data	0.38220435416354653
QU_classifiers_20120227	Analyzed Query represents all information derived from all classification tasks executed on the Query. QAS supports 3 basic classifications tasks: binary classification (Domain Classification), entity extraction (Query Parse), category classification (Dom	0.36944915670697126
QU_classifiers_20120227	Summary of 50 queries:QueryIssue categoryResolved促销策略案例分析Page NumberYes美丽说面膜Page NumberYes朝鲜金正恩腐化生活 图片Page NumberNo(L3 rule not cover this case: the second page is higher than the first page)智慧树2012全集Page NumberYes潘阳老公石磊P	0.364011144757978
QU_classifiers_20120227	Multi-Query Issue and QR/Ranking Joint Optimization Bhuvan MiddhaJonas BarklundYinzhe YuYuan Wang6/26/2012AgendaPresentation TopicTime/PresenterIntroduction/QR/Ranking for Joint Optimization3:05 pm – 3:30 pm [Bhuvan/Jonas]Joint Opt	0.3599253292405227
QU_classifiers_20120227	Auto Category Classification PipelineHanqing Cui2012/10/25OutlinePain PointsThinkingAuto Category Classification PipelineAuto Page LabelingData SamplingTrainingFeature SelectionThresholdIterative TrainingInitial Seed Model Creati	0.3586284823996714
QU_classifiers_20120227	Span ClassifierSpan classifier is a general infrastructure that can be used to run a fastrank based classifier on a sequence of terms from a query.  It can be used to apply rankonly or norelax to parts of the query based on the result of the model.  Fea	0.3579391475519913
QU_classifiers_20120227	ML Model Scorecard Analysis8/8/2019Unexpected term search movementhttps://exp.microsoft.com/xcard/?view=4e77b420-7b77-4e41-92ac-8e84f506fb01Check correctness of scorecard metric implementationCalculate term AVG rank from raw data streamsSearch	0.3471455500367018

QU_PostProcessing_Migration_to_QAS	Successful Feeds Query DebuggingNikita Melnichenko, 2015-03-10Feeds query debugging overviewWhen to use:Checking a new rankerChecking new augmentation before running a scrapeComparing several rankersUnderstanding feature contributionDebugg	0.3566925131802802
QU_PostProcessing_Migration_to_QAS	Publication date optimization for Japan marketBackgroundPublication date is very important to fresh queries, outdated issues and caption date showing. Now the coverage of publication date for Japan market is very low because publication date extract	0.3556785195456979
QU_PostProcessing_Migration_to_QAS	Tiger MigrationKefeng Deng6/15/2015Microsoft ConfidentialTiger MigrationMotivationTiger IntroductionHow do we get thereCurrent statusRemaining works6/15/2015Microsoft ConfidentialMotivationSame index serve architecture as Satori 	0.3372129044049023
QU_PostProcessing_Migration_to_QAS	Analyzed Query represents all information derived from all classification tasks executed on the Query. QAS supports 3 basic classifications tasks: binary classification (Domain Classification), entity extraction (Query Parse), category classification (Dom	0.3286278856297738
QU_PostProcessing_Migration_to_QAS	Span ClassifierSpan classifier is a general infrastructure that can be used to run a fastrank based classifier on a sequence of terms from a query.  It can be used to apply rankonly or norelax to parts of the query based on the result of the model.  Fea	0.30108746477060677
QU_PostProcessing_Migration_to_QAS	Local Entity PopularityJia Liu4/23/2018Project statusStepsDetailsTime ScheduleInvestigateInvestigate old version local entity popularity:Problem define, measurement, feature extraction, training/publish pipeline, usage.12.4 – 12.18	0.297489375896059
QU_PostProcessing_Migration_to_QAS	query分类—分享                     刘佳2011.6.8web query classification(query分类):	将web search query根据它的主题，分派到1个或者多个预先定义的分类中。web search query的特征：有噪声：拼写错误等长度很短：信息量少，特征少表意含糊：query可能包含多个含义,属于多个分类含义会随时间演变目标分类的特征：目标分类定义缺少语义注解一级或者多级分类分类数目：几	0.28983542466474976
QU_PostProcessing_Migration_to_QAS	Dynamic ConflationGanesh Poomal Girirajan  Kefeng                                                    Qiang WuAcknowledgementsChiping Tang: Helped us get the UPDR judgments for Training and Evaluation.Shital Shah, Aamer Mohammed: Helped us stam	0.2796680237477208
QU_PostProcessing_Migration_to_QAS	Reading List for Natural Language Query ParsingThis is for improving our NL query parsing for entity/local triggering.By NL query parsing, our goal is to automatically extract the structured information from the query, normally by segmenting queries a	0.27756041209406584
QU_PostProcessing_Migration_to_QAS	Microsoft US Immigration PortalHow To Update Your DependentsJuly 24, 2017Step 1: Log in to your account by clicking “Log In”, either in the header or in the banner image.Step 2: Go to Your Family from the header, or by selecting “Manage Your Depen	0.2731171301616573

QU Deep Dive 3-QuerySimplifiction	QU Deep Dive 2: Query Simplification and Recurrent Neural NetworkXiaolong Li (Lead of QU Fundamentals TEAM)2/12/2015AgendaQUFun Team ResponsibilitiesRecent Deliverables Query Simplification for WebQuery Simplification for Cortana 3ARec	0.6678590953973234
QU Deep Dive 3-QuerySimplifiction	Query Simplification Deep DiveJON Fu12/11/2017AgendaQuery Simplification Motivation and TheoryQuery Simplification for WebQuery Simplification for Cortana 3ARecent Progress in Query Simplification WorkReferencesIntroductionMotiva	0.6416724360274503
QU Deep Dive 3-QuerySimplifiction	Threshold Query Formulation Deep DiveGoal of the presentation is to communicate our approach for query formulation and get feedback on whether this aligns with overall Threshold goals.OverviewGoals & MetricsQF ModelRoadmapScenariosKey Ta	0.5387689676421901
QU Deep Dive 3-QuerySimplifiction	Simplified Query Path SelectorSimplified query: current systemSimplified query path selectionCrf model produces a list of possible ways to place rankonly operatorQuery = “nibbana restaurant official site”nibbana restaurant rankonly:official site	0.5346651017729581
QU Deep Dive 3-QuerySimplifiction	Query Latitude Longitude QueryId Prod_PLDCG@3 Restcat_PLDCG@3 G_PLDCG@3 Delta ResultQuality Dolphin CRF PhonebookQuLocation LocalPivotEntity TLA Built? Result Returned? Result Good? Comment Restaurants in times square 00f0d1ee-9688-5b09-bcea-a5e860fead14 	0.49985254613747077
QU Deep Dive 3-QuerySimplifiction	Deep Dive: Query Generic Entity Extraction (GEE)Zhen Liao04/22/2016OutlineOverview of GEEFAQ for GEEArchitecture and ModelingRecent breakthrough via Deep LearningLessons we’ve learnedGeneric Entity Extraction for Queries: What is the g	0.4890779065011407
QU Deep Dive 3-QuerySimplifiction	Analyzed Query represents all information derived from all classification tasks executed on the Query. QAS supports 3 basic classifications tasks: binary classification (Domain Classification), entity extraction (Query Parse), category classification (Dom	0.47373891377042465
QU Deep Dive 3-QuerySimplifiction	I’d like to explain in more details my idea of improving Dolphin, by improving its robustness of query variations and some previously unseen terms. Our rules don’t cover many query patterns. E.g., {top rated chinese restaurants} works well, but not {chi	0.4179042857044082
QU Deep Dive 3-QuerySimplifiction	Deep Dive on Statistical Simplification Model for Hard QueriesBin Zhang (intern, University of Washington)Xiaolong Li, Ye-Yi Wang (Bing)Xiaodong He (MSR)9/11/2012OutlineHard query backgroundDeletion modelsTraining dataOnline experiment	0.4023037892204973
QU Deep Dive 3-QuerySimplifiction	Golden QueryEvery query countsImprove relevance: Relevance TechniquesWin/Loss basedGood technique has better win/loss ratioGeneric Ranker always doesn’t have good win/loss ratioWe do technique triage, and better win/loss ratio technique got sh	0.3924525385605811

QU Deep Dive 2-QuerySimplifictionAndRNN	Query Simplification Deep DiveJON Fu12/11/2017AgendaQuery Simplification Motivation and TheoryQuery Simplification for WebQuery Simplification for Cortana 3ARecent Progress in Query Simplification WorkReferencesIntroductionMotiva	0.6585944958270589
QU Deep Dive 2-QuerySimplifictionAndRNN	QU Deep Dive 2: Query Simplification and Recurrent Neural NetworkXiaolong Li (Lead of QU Fundamentals TEAM)2/12/2015AgendaQUFun Team ResponsibilitiesRecent Deliverables Query Simplification for WebQuery Simplification for Cortana 3ARec	0.6436829614952637
QU Deep Dive 2-QuerySimplifictionAndRNN	Simplified Query Path SelectorSimplified query: current systemSimplified query path selectionCrf model produces a list of possible ways to place rankonly operatorQuery = “nibbana restaurant official site”nibbana restaurant rankonly:official site	0.5396675850755809
QU Deep Dive 2-QuerySimplifictionAndRNN	Threshold Query Formulation Deep DiveGoal of the presentation is to communicate our approach for query formulation and get feedback on whether this aligns with overall Threshold goals.OverviewGoals & MetricsQF ModelRoadmapScenariosKey Ta	0.49811929998384447
QU Deep Dive 2-QuerySimplifictionAndRNN	Deep Dive: Query Generic Entity Extraction (GEE)Zhen Liao04/22/2016OutlineOverview of GEEFAQ for GEEArchitecture and ModelingRecent breakthrough via Deep LearningLessons we’ve learnedGeneric Entity Extraction for Queries: What is the g	0.4710812062217817
QU Deep Dive 2-QuerySimplifictionAndRNN	Augmented Query Parser Using Deep LearningDemi Guo (Bing Local Intern t-deguo)Manager: Leon ZhangMentor: Simona CabuzHello everyone, Today, I’m going to present my intern project: Augmented query parser using deep learning.About Me My name i	0.4571893319257361
QU Deep Dive 2-QuerySimplifictionAndRNN	Query Latitude Longitude QueryId Prod_PLDCG@3 Restcat_PLDCG@3 G_PLDCG@3 Delta ResultQuality Dolphin CRF PhonebookQuLocation LocalPivotEntity TLA Built? Result Returned? Result Good? Comment Restaurants in times square 00f0d1ee-9688-5b09-bcea-a5e860fead14 	0.4446437945632484
QU Deep Dive 2-QuerySimplifictionAndRNN	I’d like to explain in more details my idea of improving Dolphin, by improving its robustness of query variations and some previously unseen terms. Our rules don’t cover many query patterns. E.g., {top rated chinese restaurants} works well, but not {chi	0.4021262040915354
QU Deep Dive 2-QuerySimplifictionAndRNN	Site Quality ClassificationGuihong CaoDefinition of the ProblemWhat is site quality?Google’s definition includes the following dimensionsDuplicated content within the siteTrustworthyOn demand media? Quality controlSite authorityAuthor 	0.39387337060048405
QU Deep Dive 2-QuerySimplifictionAndRNN	Deep Dive on Statistical Simplification Model for Hard QueriesBin Zhang (intern, University of Washington)Xiaolong Li, Ye-Yi Wang (Bing)Xiaodong He (MSR)9/11/2012OutlineHard query backgroundDeletion modelsTraining dataOnline experiment	0.38723761177506644

QR_201701	QR FY19 LRP Planning - 23/29/18Unified Concept Tagging – Key ChallengesStructural ComplexityFor ambiguous queries and multi-concept queries, how much organization is required?  How to represent this in a linear qlf?  What about inter-concept rel	0.33894774844786585
QR_201701	QR Team ReviewJan 2017Team IntroductionConceptXDeep QRAgendaQR Team MembersDev Manager: Ciya LiaoLeads: Garrett Kaminaga, Jingwen Lu, Saekoo Lee, Gord LueckPMs: Shyam Jayasankar, Jie CaiSTC-A Speller team: Yongen Gong and his teamWha	0.28349827315218007
QR_201701	SmartRelax training and evaluation from 15%/15% flightForay scorecard: 15%+15% datagatheringUser-triggered scorecardSSRx gain of 0.12%, for 3+4 word on vs. 3+4 word off. (NOT vs. prod.)Gain is 36% from SSR, 11% from TTS, 52% from TSRSSRx gains s	0.2612950558191764
QR_201701	Microsoft ConfidentialSeptember 14, 2016Relevance Next and Artificial IntelligenceRelevance and Intent OffsiteFebruary 8thOur PrioritiesExpand our Capabilities towards a full fledged AGI Engine, with focus on Knowledge, NL/Semantic Understandi	0.24379873714116035
QR_201701	PDI Document AnnotationPDI Ranking PlatformAgendaPDI and forward indexDocument AnnotationSodium update and MG planQ&A DSAT: {books by children}Issue: Document matches the query terms, but its surrounding words may change the intent of 	0.2344432507892365
QR_201701	LDCG V3Knowledge Transfer2017-04-14Brett Clippingdale, Sean King, Vikas Mittal, Li JiangLDCG V3 OutlineLDCG V2 vs V3: High-level comparisonLDCG V3: New distance ModelV2 vs V3 OverviewLDCG V3: GeoIntent HIT appLDCG V3: Calculate distance 	0.23090994686246144
QR_201701	Microsoft ConfidentialSeptember 14, 2016AGI EngineCore Relevance PM TeamJanuary 26thHuman and Artificial IntelligenceOur Approach to an AGI EngineSolving the AGI Engine GoalsUpgrading our Search StackAgendaLets start with a conceptual 	0.2277619845904984
QR_201701	PA Selection StackKeng-hao Chang3/8/2017AgendaQuery (offer) understandingRetail classifierCategorizerCRFSelection algorithmsRIIRNGSRanking methodsL0, L1, L1.5, L2, Attribute-awareRetail experiencePA stack via Components*RnR	0.22323855897878625
QR_201701	Satori Introduction2012-09-20  yukaihAgendaOverviewMajor ModulesIngestionConflationServingGet Started in Local BoxUseful linksAppendix: Satori Local PipelineOverview - SatoriMission: build the largest, freshest, and most accurate E	0.22215698935932462
QR_201701	Local Category Search StudyHuanan Zhang01/03/2018OutlineStructure of PBA (Prod) rankerIntent match ranker’s role in Prod rankerIssues of intent match rankerSolutions – metastream clean upMetastream measurementPreliminary resultsPBA	0.21958277640259408

QR Microsegments	QR MicrosegmentsSandeep AparajitAgendaWhat are microsegments?How does microsegment work in CAL?How can I add my own microsegment?DemoQuestions/SuggestionsWhat are Microsegments?Microsegment is a technique using which you can alter the be	0.6428288428911393
QR Microsegments	QR Micro SegmentOverviewMicro Segment is way to fix corner case that main Bing ranking pipeline couldn’t fix easily by machine learning. There are many ways to do micro segment. Micro segment can be done in many layers. QR, matching, L1, L2, L3, …. To	0.38699403953830624
QR Microsegments	Query Rewriting Micro SegmentWhy QR Micro SegmentMicro Segment is way to fix corner case that main Bing ranking pipeline couldn’t fix easily by machine learningThere are many ways to do micro segment. Micro segment can be done in many layers. QR, 	0.3407281448684503
QR Microsegments	Play Book of Pattern Engine Based Micro-segment PlatformIntroductionNow, per query pattern match features (PMFs) are available for ranking. You can get PMFs of your own pattern groups (PGs) immediately after several simple steps. With these signals, r	0.28213905317699023
QR Microsegments	SmartRelax training and evaluation from 15%/15% flightForay scorecard: 15%+15% datagatheringUser-triggered scorecardSSRx gain of 0.12%, for 3+4 word on vs. 3+4 word off. (NOT vs. prod.)Gain is 36% from SSR, 11% from TTS, 52% from TSRSSRx gains s	0.24857696543092103
QR Microsegments	Integrating Knowledge Graph in Web SearchEntity Triggering and CollectionsPresenter: Ze TianKnowledge GraphEntities and RelationsEntities: celebrities, people, generic terms (e.g. light bulb)Relations: sibling, spouse, people and their works	0.2439256750189931
QR Microsegments	Translation ModelMei YangDU talk5/11/2011OutlineIntroduction to Machine Translation (MT)Introduction to phrase-based statistical machine translation (PBSMT)Translation Model @ DUFuture WorkIntroduction to MTTranslate one natural langua	0.24156268484052212
QR Microsegments	ElasticSearchInternalElasticSearch and oSearchElasticSearch  ArchitectureLucene FamilyoSearch  ArchitectureScenario and ScaleoSearchElasticSearchScope Strong structured dataImage with ANNUnstructured text Loose structured data	0.22814379486293934
QR Microsegments	[IMPORTANT]Please notify “featfun” if you want to edit this document!!!Metastream FeaturesWritten by: Tian Xia (tixia@microsoft.com)Table of Contents1. Overview	62. Basics	82.1 Metastreams	9Single instance metastream	9Multi-instance meta	0.22776488794718475
QR Microsegments	Introduction to dynamic ranking Xiao WuOutlinesIntroductionRelevance MeasurementDynamic rankingRanking FeaturesRanking DataRanking modelsRelevance ExperiementIntroductionWhat is dynamic rankingRanking based on query dependent featu	0.22506661217945917

QR Micro Segment Infrastructure	QR MicrosegmentsSandeep AparajitAgendaWhat are microsegments?How does microsegment work in CAL?How can I add my own microsegment?DemoQuestions/SuggestionsWhat are Microsegments?Microsegment is a technique using which you can alter the be	0.5918524310135267
QR Micro Segment Infrastructure	QR Micro SegmentOverviewMicro Segment is way to fix corner case that main Bing ranking pipeline couldn’t fix easily by machine learning. There are many ways to do micro segment. Micro segment can be done in many layers. QR, matching, L1, L2, L3, …. To	0.5271000006016036
QR Micro Segment Infrastructure	Play Book of Pattern Engine Based Micro-segment PlatformIntroductionNow, per query pattern match features (PMFs) are available for ranking. You can get PMFs of your own pattern groups (PGs) immediately after several simple steps. With these signals, r	0.49263962013504276
QR Micro Segment Infrastructure	Query Rewriting Micro SegmentWhy QR Micro SegmentMicro Segment is way to fix corner case that main Bing ranking pipeline couldn’t fix easily by machine learningThere are many ways to do micro segment. Micro segment can be done in many layers. QR, 	0.4875201937759013
QR Micro Segment Infrastructure	Containment and Conflation – Sprint  2Story DescriptionDone?In Demo?Implement and ship Segment Studio integration changes for Preconflation and MatchYYIdentify top K entity setYYRoot cause why entities have too many identifiersYY	0.4647092999834536
QR Micro Segment Infrastructure	Introduction to dynamic ranking Xiao WuOutlinesIntroductionRelevance MeasurementDynamic rankingRanking FeaturesRanking DataRanking modelsRelevance ExperiementIntroductionWhat is dynamic rankingRanking based on query dependent featu	0.39917140632189385
QR Micro Segment Infrastructure	Introduction to L1Xiao WuSearch Platform Tiger Team AgendaL1 goals and challengesMetrics and measurementL1 ranker and perf optimizationL1 ranking Perf optimizationDebugging tools L1 training and shippingThinking and discussionL1 	0.39702762913962236
QR Micro Segment Infrastructure	Introduction toas measurement platformOlli-Pekka TossavainenMSQ TeamSunnyvaleContentsOverviewAres AssetsData Web Store (DWS)Single HitApp core relevance exampleWhat is ARESFrom their web site:What’s been built on ARESMap Search	0.38816113182468087
QR Micro Segment Infrastructure	Tiger Index BrownbagHui ShenSearch Platform Tiger TeamAgenda	OverviewKey ideasTiger architectureTiger ++ 2/24/2012Agenda	OverviewKey ideasTiger architectureTiger ++ 2/24/2012What is Tiger IndexAn new index serve technol	0.3875593676940776
QR Micro Segment Infrastructure	Microsoft ConfidentialSeptember 14, 2016Relevance Next and Artificial IntelligenceRelevance and Intent OffsiteFebruary 8thOur PrioritiesExpand our Capabilities towards a full fledged AGI Engine, with focus on Knowledge, NL/Semantic Understandi	0.38600109199869737

QR Micro Segment Architecture	QR MicrosegmentsSandeep AparajitAgendaWhat are microsegments?How does microsegment work in CAL?How can I add my own microsegment?DemoQuestions/SuggestionsWhat are Microsegments?Microsegment is a technique using which you can alter the be	0.5573217674198039
QR Micro Segment Architecture	QR Micro SegmentOverviewMicro Segment is way to fix corner case that main Bing ranking pipeline couldn’t fix easily by machine learning. There are many ways to do micro segment. Micro segment can be done in many layers. QR, matching, L1, L2, L3, …. To	0.5184802692008862
QR Micro Segment Architecture	Query Rewriting Micro SegmentWhy QR Micro SegmentMicro Segment is way to fix corner case that main Bing ranking pipeline couldn’t fix easily by machine learningThere are many ways to do micro segment. Micro segment can be done in many layers. QR, 	0.4421482449751536
QR Micro Segment Architecture	Play Book of Pattern Engine Based Micro-segment PlatformIntroductionNow, per query pattern match features (PMFs) are available for ranking. You can get PMFs of your own pattern groups (PGs) immediately after several simple steps. With these signals, r	0.4283172398612872
QR Micro Segment Architecture	QR Team ReviewJan 2017Team IntroductionConceptXDeep QRAgendaQR Team MembersDev Manager: Ciya LiaoLeads: Garrett Kaminaga, Jingwen Lu, Saekoo Lee, Gord LueckPMs: Shyam Jayasankar, Jie CaiSTC-A Speller team: Yongen Gong and his teamWha	0.38937723100768845
QR Micro Segment Architecture	Introduction to L1Xiao WuSearch Platform Tiger Team AgendaL1 goals and challengesMetrics and measurementL1 ranker and perf optimizationL1 ranking Perf optimizationDebugging tools L1 training and shippingThinking and discussionL1 	0.38878526016744563
QR Micro Segment Architecture	Containment and Conflation – Sprint  2Story DescriptionDone?In Demo?Implement and ship Segment Studio integration changes for Preconflation and MatchYYIdentify top K entity setYYRoot cause why entities have too many identifiersYY	0.37874166039049556
QR Micro Segment Architecture	ElasticSearchInternalElasticSearch and oSearchElasticSearch  ArchitectureLucene FamilyoSearch  ArchitectureScenario and ScaleoSearchElasticSearchScope Strong structured dataImage with ANNUnstructured text Loose structured data	0.36180690368426927
QR Micro Segment Architecture	Tiger MigrationKefeng Deng6/15/2015Microsoft ConfidentialTiger MigrationMotivationTiger IntroductionHow do we get thereCurrent statusRemaining works6/15/2015Microsoft ConfidentialMotivationSame index serve architecture as Satori 	0.35291960951070206
QR Micro Segment Architecture	Tiger Index BrownbagHui ShenSearch Platform Tiger TeamAgenda	OverviewKey ideasTiger architectureTiger ++ 2/24/2012Agenda	OverviewKey ideasTiger architectureTiger ++ 2/24/2012What is Tiger IndexAn new index serve technol	0.3426310129657163

QR FY19 LRP Planning - 2	QR FY19 LRP Planning - 23/29/18Unified Concept Tagging – Key ChallengesStructural ComplexityFor ambiguous queries and multi-concept queries, how much organization is required?  How to represent this in a linear qlf?  What about inter-concept rel	0.6944708335573713
QR FY19 LRP Planning - 2	Mobile LT Discussion6/20/2014AgendaTop IssuesAd Product and Ad Quality UpdateSummarized Finding NDT Supply AnalysisSummarized Finding Google CompeteStatusFeatureWindows phoneIphone/AndroidUp to 2 adsShipped 5/20/2014Shipped more 	0.40518517025671913
QR FY19 LRP Planning - 2	PDI Document AnnotationPDI Ranking PlatformAgendaPDI and forward indexDocument AnnotationSodium update and MG planQ&A DSAT: {books by children}Issue: Document matches the query terms, but its surrounding words may change the intent of 	0.3952631875692097
QR FY19 LRP Planning - 2	FY19 Search & AI Roadmap Review: QRMay 2018Jie Cai, Garrett Kaminaga, Jingwen Lu, Momo JengMotivation – QR Query understanding and rewrite is the first opportunity for Bing to understand users’ intents;In current production, query rewrite is a	0.3831967523309497
QR FY19 LRP Planning - 2	ML Model Scorecard Analysis8/8/2019Unexpected term search movementhttps://exp.microsoft.com/xcard/?view=4e77b420-7b77-4e41-92ac-8e84f506fb01Check correctness of scorecard metric implementationCalculate term AVG rank from raw data streamsSearch	0.3830284275174883
QR FY19 LRP Planning - 2	BLU V3 Minghua Zhang      01/26/2016Next version of BLU Relevance Infrastructure​OutlineWhy BLU v3BLU v3 DesignCurrent StatusFuture WorkWhy BLU v3 (1)Limitations of current BLU infrastructureFeaturesCouldn’t utilize QAS feature	0.3793510423972465
QR FY19 LRP Planning - 2	FY18 AGI Encoder Roadmap		Nitin Sharma, Gargi Ghosh, Saurabh TiwaryAgendaIntroductionFY18 Goals and Focus AreasFocus Area Deep DiveCustomer scenariosDetailed RoadmapAGI Encoder: MotivationGoal: One general intent encoder of source 	0.35850362216567516
QR FY19 LRP Planning - 2	FY19 Search & AI Roadmap Review: Intelligent QnAMay 2018PM: Ali Alvi, Kaan Ozel, Ganga Venkatasubramanian, Oana NicolovDev: Xia Song, Doran ChakrabortyAgendaOverall QnA Opportunity and GoalsSemi-Structured DataMALTATuring for QnAAGI En	0.35061836091684556
QR FY19 LRP Planning - 2	L-1B SPECIALIZED KNOWLEDGE QUESTIONNAIREMICROSOFT POSITION IN THE U.S.Provide the following information for your current position at the Microsoft.MICROSOFT POSITION ABROADProvide the following information for your position at the Microsoft’s su	0.3349959368452255
QR FY19 LRP Planning - 2	QR Team ReviewJan 2017Team IntroductionConceptXDeep QRAgendaQR Team MembersDev Manager: Ciya LiaoLeads: Garrett Kaminaga, Jingwen Lu, Saekoo Lee, Gord LueckPMs: Shyam Jayasankar, Jie CaiSTC-A Speller team: Yongen Gong and his teamWha	0.31388349557790446

QR - FY19 Search & AI Roadmap Review	FY19 Search & AI Roadmap Review: QRMay 2018Jie Cai, Garrett Kaminaga, Jingwen Lu, Momo JengMotivation – QR Query understanding and rewrite is the first opportunity for Bing to understand users’ intents;In current production, query rewrite is a	0.665176255360329
QR - FY19 Search & AI Roadmap Review	FY19 Search & AI Roadmap Review: AGI for Web RankingMay 2018Dev: Chen Zhou, Saurabh TiwaryPM: Kiki Liu, Mir RosenbergMotivation“…But often time we have more problems about the subjects we are not familiar with and therefore even the keywords	0.6308304194153442
QR - FY19 Search & AI Roadmap Review	FY19 Search & AI Roadmap Review: Intelligent QnAMay 2018PM: Ali Alvi, Kaan Ozel, Ganga Venkatasubramanian, Oana NicolovDev: Xia Song, Doran ChakrabortyAgendaOverall QnA Opportunity and GoalsSemi-Structured DataMALTATuring for QnAAGI En	0.6169571507953867
QR - FY19 Search & AI Roadmap Review	QR FY19 LRP Planning - 23/29/18Unified Concept Tagging – Key ChallengesStructural ComplexityFor ambiguous queries and multi-concept queries, how much organization is required?  How to represent this in a linear qlf?  What about inter-concept rel	0.5297016813727576
QR - FY19 Search & AI Roadmap Review	FY18 AGI Encoder Roadmap		Nitin Sharma, Gargi Ghosh, Saurabh TiwaryAgendaIntroductionFY18 Goals and Focus AreasFocus Area Deep DiveCustomer scenariosDetailed RoadmapAGI Encoder: MotivationGoal: One general intent encoder of source 	0.48015218449271174
QR - FY19 Search & AI Roadmap Review	AGI - Web Search / Tail FY18 Roadmap 	Rohit Kapoor, Saurabh Tiwary, Gargi Ghosh, Chen Zhou,  Kushal LakhotiaFY17 RecapFY18 GoalsFY18 Focus AreasFY18 TimelineFocus Area Deep DivesAgendaFY17 RecapIn-Progress:[Fusion] Out of market [F	0.47953468325669873
QR - FY19 Search & AI Roadmap Review	CAL Problem, Vision and RoadmapContentsOverview	2Problem of today’s CAL	2Vision and Roadmap	3Start from simple but important one: infrastructure.	3Now comes core problem: Metrics	3Now comes to the interesting part: context	4Data	5Head qu	0.4158296827117423
QR - FY19 Search & AI Roadmap Review	Introduction to L1Xiao WuSearch Platform Tiger Team AgendaL1 goals and challengesMetrics and measurementL1 ranker and perf optimizationL1 ranking Perf optimizationDebugging tools L1 training and shippingThinking and discussionL1 	0.4098623966232623
QR - FY19 Search & AI Roadmap Review	SmartRelax OFE and TrainingOverviewAnalysis of smartrelax flightsOFE flight simulatorIs smartrelax ever bad?Smartrelax model training:Training method I: relax-specific targetsTraining method II: end-user targetsSmart Relax OFE and Training	0.4096792524300799
QR - FY19 Search & AI Roadmap Review	CRF Parser AnalysisBusiness category searchOverviewParser (phonebook)CRF ParserqueryLocation featuresCRF featuresQuery parsetoken[tag] token[tag] … token[tag]userBLUbusiness_namebusiness_categorylocationlocation_separatorbu	0.3990376757906353

QF Deepdive 3	Bing GC Deep DiveBingGCI 9/26/2014Introduction – Pavel, 2minsProject overview – Wei, 6minsBing GC XAP workflow – John, 10minsBing GC data pipeline and data ingestion – Florin, 7minsBing GC Offline relevance platform – Jian, 8minsSingle-poi	0.3344468198522843
QF Deepdive 3	Project-N DeepDiveAbstractSimilarity issue has been one of the biggest problems of zh-CN relevance for years but not well got solved. In this document, we will focus on one of the main problem of similarity - entity/phrase mismatch issue in query/doc 	0.27518192244521456
QF Deepdive 3	PBA Dependency and DebugMing Wu2014-01-28PBA DependenciesLocation Understanding (LES/BLU)Location info (explicit/implicit) – fulfill detailed location infoProvide location related features to phonebook CRFXapQuServiceAnswer (QAS)For most c	0.2706804817284683
QF Deepdive 3	cal deepdiverelaxationdec 2017AgendaProduct GoalsQuery SimplificationMechanism/RuntimeCRF Model TrainingQS Path SelectionOffline SimulatorSmart RelaxMechanism & TrainingRelaxation: ImpactRelaxation: Product goalsImprove Rec	0.2403311150192026
QF Deepdive 3	Speller Related Issues & SolutionsMing Wu2014-01-08Speller Related Issues – in nativePBA reads spell corrected query from Speller kif responseAssumes offsets are on raw query, which is not the caseE.g. {   piza hut} -> {pizzaiza hut}Proposed	0.20895344228812932
QF Deepdive 3	WrapStar On-Demand DesignDrafted by ZiliuContentsContext2Design Goals2Automation2Deployment Agility2High Availability2Non-Goals2Metrics2Required Changes3Orchestration3AP Migrations3Pipeline Evolution3Tools/services refactoring3	0.20287579882006754
QF Deepdive 3	Scraper overview(and more)Ofer ShterlingSean KingContentBrag.Demo (maybe)Throw some dirt.Suggest the Scraper isn’t that interesting.Recurrences tool.I hope I won’t have to show to many workflow.ScraperWe have between 500 to 1.5k sc	0.1993185241908127
QF Deepdive 3	QAS Setup & Config-Supriya HarpaleQAS ConfigurationDefines workflow of classifier executionFeature Set is the main data used as input and output of modelsModels can depend on other models output, creating dependency graphMultiple dimensions 	0.1928825629037044
QF Deepdive 3	Decision Tree Ensemble decodeAdaboost Decision tree:A forest.  One feature can be multiple nodes.Support Market checkingWord/entity classificationOne or more feature set inputMeaning[DecisionTree]Roots=90  (tree number)Nodes=630 (all n	0.18517601709260598
QF Deepdive 3	Deep Dive on Statistical Simplification Model for Hard QueriesBin Zhang (intern, University of Washington)Xiaolong Li, Ye-Yi Wang (Bing)Xiaodong He (MSR)9/11/2012OutlineHard query backgroundDeletion modelsTraining dataOnline experiment	0.1825758384689336

QASMLGFeaturizerDebug	Restaurants Features and ToolsReview SnippetXAPOSearchQueryWPOLERWPO OSCacheItemCacheIdList of YpIdsFiltersSorterEntityUpdate PostFixEntity Update OSCache IdCache ItemYpId and PostFixUXReview Snippet Data GroupCac	0.499118224327244
QASMLGFeaturizerDebug	L3 Reranking FrameworkL3 Infrastructure TeamAgendaOverviewL3 featuresL3 ranker and L3 workflowAggregatedFreeFormList-wise ranking previewL3 and L4Future WorkOverviewRank Stack in IS PlatformL4 - MergerL3 – List reorderingL2 - S	0.4518207906699497
QASMLGFeaturizerDebug	FusionByTurker KeskinpalaTuesday, May 17, 2016OverviewMotivationsWhat is Fusion?GoalsFusion ComponentsRoadmapWeb AnswerQ:“gg”Qpath1:“gg”Qpath2:“google”TLACDG FetcherL2 FetcherTLACDG FetcherL2 FetcherLL4L3L3	0.44296028409791005
QASMLGFeaturizerDebug	LEDB Transition8/6/2014ScopeLEDB serialization jobsLEDB Object Store publish jobsLEDB Odyssey Publish job for the VanueMap featureEntity Schema update and maintenanceObject Store payload size and perf SLAPartner engagement and change manag	0.43049022350660837
QASMLGFeaturizerDebug	QAS Setup & Config-Supriya HarpaleQAS ConfigurationDefines workflow of classifier executionFeature Set is the main data used as input and output of modelsModels can depend on other models output, creating dependency graphMultiple dimensions 	0.42471407240448605
QASMLGFeaturizerDebug	BusinessV3TaxonomyClassifierAugust, 2018Daniel WeinshenkerMicrosoft ConfidentialAgendaMicrosoft ConfidentialPurpose / OverviewDemoData Pipeline / Lexicon GenerationMeasurementQASChallenges / Future WorkPurpose We want to improve 	0.42029106982145664
QASMLGFeaturizerDebug	Zhcn document classification based on topicJia Liu2012.11.14agendarTraining data selection&crawl&cleanFeature selection&cleanClassifierRating Bad case analysisTrainning data	0.4196064009813629
QASMLGFeaturizerDebug	CRF Parser AnalysisBusiness category searchOverviewParser (phonebook)CRF ParserqueryLocation featuresCRF featuresQuery parsetoken[tag] token[tag] … token[tag]userBLUbusiness_namebusiness_categorylocationlocation_separatorbu	0.41938476443058115
QASMLGFeaturizerDebug	Relevance ServiceScenarioIconApplicationDoc typeCandidatesModelRun0-termWord;OutlookWin32 client.All file typesMRUReuse ContentModel 1Client0-termPower PointWin32 client.Only ppt typeLocal + MRUReuse Conte	0.4175376407043118
QASMLGFeaturizerDebug	NTCG DebuggingSteven Zittrower01/30/2015AgendaNTCGNTCG DashboardOverview of BLU Architecture (Address Specific)Address Debugging in QATNTCGNTCG (Normalized Total Cumulative Gain) is a composite metric that measures address query releva	0.4158151428078736

QAS Setup & Config	QAS Setup & Config-Supriya HarpaleQAS ConfigurationDefines workflow of classifier executionFeature Set is the main data used as input and output of modelsModels can depend on other models output, creating dependency graphMultiple dimensions 	0.5404463625125083
QAS Setup & Config	Microsoft ConfidentialSeptember 14, 2016Microsoft’s Artificial General Intelligence Effort at ASG and DLTCLi Deng, Rangan Majumder, Saurabh Tiwary, Sean Yang, Mir Rosenberg, Jianfeng GaoDefinitionsDeep learning is a class of machine learni	0.295145059083816
QAS Setup & Config	PBA Dependency and DebugMing Wu2014-01-28PBA DependenciesLocation Understanding (LES/BLU)Location info (explicit/implicit) – fulfill detailed location infoProvide location related features to phonebook CRFXapQuServiceAnswer (QAS)For most c	0.27528374611771794
QAS Setup & Config	Bing Local Search				PBA QU Post-processing in QAS Dev ownerMing WuBuddy dev(s)PM ownerContributorsFeature areaPBA Query ProcessingMilestoneAluminumTable of contents1	Overview	22	Goals/Non Goals	23	Risks/Open Issues	24	Desi	0.2663947983143359
QAS Setup & Config	Microsoft ConfidentialSeptember 14, 2016AGI EngineCore Relevance PM TeamJanuary 26thHuman and Artificial IntelligenceOur Approach to an AGI EngineSolving the AGI Engine GoalsUpgrading our Search StackAgendaLets start with a conceptual 	0.2624612407150537
QAS Setup & Config	Partner Index as ServiceWhat is the Problem? RequirementCurrent status of Bing Image StackDiscoveryClient tend to provide feed for full corpusWeb crawlerImage Content RetrievalSpecial agreement, some even behind authentication for access	0.25558191028856997
QAS Setup & Config	Run web-search-like query against my dataSame Bing Web Search Indexing and Ranking engineIndex in a secondTransparent and real time index sync, no complex index-gen pipelinePrototype in an hourFast self-onboarding with freemium account, schema-d	0.23456822690671367
QAS Setup & Config	Windows Search RS5July 9, 2018ContextCortana branded searchbox in taskbar has two key experiences:A speech first Cortana NL experienceA search first typing experience – we refer to this as Windows SearchWindows Search Key StatsUSERS: 160m mo	0.22484316798417706
QAS Setup & Config	Entity Selection ModelJia Liu2017-11-08GDP Pipeline View: local data pipelineEntity TypesEntity Types:Open/CloseHead/TailNonJunk/JunkJunk TypesGhost: Local business existed beforeJunk: General name like “Lock smith”, “ATM”Move/Br	0.2227366606093984
QAS Setup & Config	Nlp情感分析工具使用执行步骤：分词执行程序：Shenbian_exlib_segpos使用说明： 	usage: ./Shenbian_exlib_segpos  segDictPath tagDictPath inputfile outputtype      			exDictLib > outputfile具体使用举例：     ./Shenbian_exlib_segpos ../../../../lib_wordseg/worddict_1-3-4-3_PD_B	0.22065911573060193

Q3 2019 Planning	QR FY19 LRP Planning - 23/29/18Unified Concept Tagging – Key ChallengesStructural ComplexityFor ambiguous queries and multi-concept queries, how much organization is required?  How to represent this in a linear qlf?  What about inter-concept rel	0.2905863113665544
Q3 2019 Planning	ML Model Scorecard Analysis8/8/2019Unexpected term search movementhttps://exp.microsoft.com/xcard/?view=4e77b420-7b77-4e41-92ac-8e84f506fb01Check correctness of scorecard metric implementationCalculate term AVG rank from raw data streamsSearch	0.28732735343014265
Q3 2019 Planning	PDI Document AnnotationPDI Ranking PlatformAgendaPDI and forward indexDocument AnnotationSodium update and MG planQ&A DSAT: {books by children}Issue: Document matches the query terms, but its surrounding words may change the intent of 	0.2778708300780291
Q3 2019 Planning	Local Search Platform PM Onboarding GuideAuthors: Dany DaherDate: 10/18/2013Architecture OverviewHow Local Search Works Local Data Platform Architecture MetricsLocal Metrics:  http://jeffke/localMetrics/Definition of QLDCG: Local Discoun	0.2745226843433726
Q3 2019 Planning	L-1B SPECIALIZED KNOWLEDGE QUESTIONNAIREMICROSOFT POSITION IN THE U.S.Provide the following information for your current position at the Microsoft.MICROSOFT POSITION ABROADProvide the following information for your position at the Microsoft’s su	0.26439727987203976
Q3 2019 Planning	Relevance and AIBing and Information Platform GroupFY18 AGI Encoder RoadmapFeature OwnersProgram ManagersNitin SharmaDevelopersSaurabh Tiwary, Gargi GhoshResearchersMarketingPartnersYantao Li, Weihu, GuihongOverviewAGI Encoder go	0.24207082211996786
Q3 2019 Planning	SmartRelax training and evaluation from 15%/15% flightForay scorecard: 15%+15% datagatheringUser-triggered scorecardSSRx gain of 0.12%, for 3+4 word on vs. 3+4 word off. (NOT vs. prod.)Gain is 36% from SSR, 11% from TTS, 52% from TSRSSRx gains s	0.24171652286775794
Q3 2019 Planning	QR Team ReviewJan 2017Team IntroductionConceptXDeep QRAgendaQR Team MembersDev Manager: Ciya LiaoLeads: Garrett Kaminaga, Jingwen Lu, Saekoo Lee, Gord LueckPMs: Shyam Jayasankar, Jie CaiSTC-A Speller team: Yongen Gong and his teamWha	0.22188496123633614
Q3 2019 Planning	SVMT UpdateNovember 2016AgendaMorning (10:00-12:00)Overview – 15 minQnA:MALTA – 55 minInfoBot – 30 minLunch break (12:00-1:00)Afternoon (1:00-3:00)Query:Deep QR – 30 minRanking:ConceptX – 30 minFusion – 30 minNapa – 30 minO	0.21816065577481578
Q3 2019 Planning	Mobile LT Discussion6/20/2014AgendaTop IssuesAd Product and Ad Quality UpdateSummarized Finding NDT Supply AnalysisSummarized Finding Google CompeteStatusFeatureWindows phoneIphone/AndroidUp to 2 adsShipped 5/20/2014Shipped more 	0.20665074120974283

Publication date optimization for zh-cn market_byMeiCommnets_byJiaAnswer	Publication date optimization for zh-cn marketBackgroundPublication date is a very fundamental and important feature. It can help fresh ranking, whole page user experience: caption date show and freshness internal metrics, also to solve mainline out	0.6187792368119054
Publication date optimization for zh-cn market_byMeiCommnets_byJiaAnswer	Publication Date Optimization Design and Implement For zh-cn MarketReview and CommentMei Yang; Ted WildAuthorJia LiuDesignBackgroundPublication date is a very fundamental and important feature. It can help fresh ranking, solve mainline out	0.5664667610470154
Publication date optimization for zh-cn market_byMeiCommnets_byJiaAnswer	DU work items on zh-cn market　　Jia Liu2013-05-14AgendaSerp classifierWrapstar rating signalsTaobao, tmall; qna; novel; videoGeneral classiferUrl-basedTopic-basedPage number extractionName entity recognitionPerson, location, organiz	0.5556984091429438
Publication date optimization for zh-cn market_byMeiCommnets_byJiaAnswer	Zh-cn Document classification based on topicBackgroundWe want to do zh-cn document classification for better understanding the document type and topic. It can help ranking with document and  query category matching. We defined our category system: 69 	0.5354937386327915
Publication date optimization for zh-cn market_byMeiCommnets_byJiaAnswer	Zhcn document classification based on topicJia Liu2012.11.14agendarTraining data selection&crawl&cleanFeature selection&cleanClassifierRating Bad case analysisTrainning data	0.5344829817047759
Publication date optimization for zh-cn market_byMeiCommnets_byJiaAnswer	To Whom It May ConcernPage 2DATETo Whom It May Concern:Re:	Jia LiuI write to certify that Jia Liu worked as a Software Development Engineer at Microsoft (China) Company Limited (Microsoft China) in Beijing, China from March 30, 2012 to September	0.48693405209870877
Publication date optimization for zh-cn market_byMeiCommnets_byJiaAnswer	Microsoft ConfidentialSeptember 14, 2016Core Web RelevanceFY16 H2 PlanOur PrioritiesBuild a Universally Competitive Search Engine across all devicesExpand our Capabilities towards Knowledge Understanding to power Bing Next, MALTA, and great se	0.4790400643566943
Publication date optimization for zh-cn market_byMeiCommnets_byJiaAnswer	DU items studyJia Liu2013-05-14AgendaPublication dateMain body blockDocument qualityurl static featuresPublication dateFreshness rankingYear in title, year in url, publication dateEn-us publication date coverage is ~20%Zh-cn public	0.47734799246411136
Publication date optimization for zh-cn market_byMeiCommnets_byJiaAnswer	Page 23 of 26L2 General Title MatchDev: Jia Liu, Chuan Cao, Albert ZhouPM: Jin GuoDoc version: v1.0ContentsAbstract	2Project Status	2Goals	2Problem statement	3Architecture	3N-Gram Table	4Query Distribution in N-Gram Table	5Query 	0.46868115060479465
Publication date optimization for zh-cn market_byMeiCommnets_byJiaAnswer	学士学位证明BACHELOR DEGREE CERTIFICATEThis is to certify that Ms. Jia Liu, born in August 1986, with the specialty of Computer Science and Technology at Beijing University of Posts and Telecommunications from September 2005 to July 2009, has passed all req	0.46315824749345047

Publication Date Optimization For Japan Market	Publication date optimization for Japan marketBackgroundPublication date is very important to fresh queries, outdated issues and caption date showing. Now the coverage of publication date for Japan market is very low because publication date extract	0.7630062734412375
Publication Date Optimization For Japan Market	Publication date optimization for zh-cn marketBackgroundPublication date is a very fundamental and important feature. It can help fresh ranking, whole page user experience: caption date show and freshness internal metrics, also to solve mainline out	0.6294377185950155
Publication Date Optimization For Japan Market	Publication Date Optimization Design and Implement For zh-cn MarketReview and CommentMei Yang; Ted WildAuthorJia LiuDesignBackgroundPublication date is a very fundamental and important feature. It can help fresh ranking, solve mainline out	0.5522224578840711
Publication Date Optimization For Japan Market	Multi-Query Issue and QR/Ranking Joint Optimization Bhuvan MiddhaJonas BarklundYinzhe YuYuan Wang6/26/2012AgendaPresentation TopicTime/PresenterIntroduction/QR/Ranking for Joint Optimization3:05 pm – 3:30 pm [Bhuvan/Jonas]Joint Opt	0.39301233628631443
Publication Date Optimization For Japan Market	Zh-cn Publication date design docBackgroundDesignPublication date from wrapstarPublication date from URLPublication date from titlescore(c1) = w11*f1+w12*f2+w13*f3+w14*f4+w15*f5+bias1score(c2) = w21*f1+w22*f2+w23*f3+w24*f4+w25*f5+bias2Pack	0.38806579486162135
Publication Date Optimization For Japan Market	CAL MultiQuery {Matching\Ranking}		Page 3 of 4CAL MultiQuery {Matching\Ranking}DescriptionCAL is going to optimize against matching\ranking separately and will issue different queries to each tier. CAL will be leveraging several operator such as:m	0.37919705832411166
Publication Date Optimization For Japan Market	Index Quality UpdateAgendaMetrics UpdateSelection Model ImprovementRecall TierOffice ImprovementChallenges and Pain PointsHow to measure index quality?Ideally: sampling from all “good” images and see how much we covered.sampling from a	0.37433838343682396
Publication Date Optimization For Japan Market	Global relevance feature proposalFeature name: Title Match OptimizationPMJin GuoDevJia LiuTestReleaseALTeam site linkExecutive SummaryTitle is the summary/abstract of the document. Title Match is very important to SBS. Through many c	0.36733315111611914
Publication Date Optimization For Japan Market	Smart Query Relaxation In Joint OptimizationA Cross-Group Collaborations Among QU/QR/CoreRanking/IS/MSR      Presented By : Xiaolong Li (Query Understanding)8/19/2013Smart Query Relaxation in JOPOutlineJOP V2 SummaryQuery Relaxation An	0.36179024502215074
Publication Date Optimization For Japan Market	Entity Selection ModelJia Liu2017-11-08GDP Pipeline View: local data pipelineEntity TypesEntity Types:Open/CloseHead/TailNonJunk/JunkJunk TypesGhost: Local business existed beforeJunk: General name like “Lock smith”, “ATM”Move/Br	0.3606563800537106

Publication Date Optimization Design and Implement For zh-cn Market	Publication Date Optimization Design and Implement For zh-cn MarketReview and CommentMei Yang; Ted WildAuthorJia LiuDesignBackgroundPublication date is a very fundamental and important feature. It can help fresh ranking, solve mainline out	0.8350645628731633
Publication Date Optimization Design and Implement For zh-cn Market	Publication date optimization for zh-cn marketBackgroundPublication date is a very fundamental and important feature. It can help fresh ranking, whole page user experience: caption date show and freshness internal metrics, also to solve mainline out	0.8225884661184379
Publication Date Optimization Design and Implement For zh-cn Market	Publication date optimization for Japan marketBackgroundPublication date is very important to fresh queries, outdated issues and caption date showing. Now the coverage of publication date for Japan market is very low because publication date extract	0.6618926124441435
Publication Date Optimization Design and Implement For zh-cn Market	Zh-cn Publication date design docBackgroundDesignPublication date from wrapstarPublication date from URLPublication date from titlescore(c1) = w11*f1+w12*f2+w13*f3+w14*f4+w15*f5+bias1score(c2) = w21*f1+w22*f2+w23*f3+w24*f4+w25*f5+bias2Pack	0.5714825820386599
Publication Date Optimization Design and Implement For zh-cn Market	Zh-cn Document classification based on topicBackgroundWe want to do zh-cn document classification for better understanding the document type and topic. It can help ranking with document and  query category matching. We defined our category system: 69 	0.5482918646690804
Publication Date Optimization Design and Implement For zh-cn Market	Zhcn document classification based on topicJia Liu2012.11.14agendarTraining data selection&crawl&cleanFeature selection&cleanClassifierRating Bad case analysisTrainning data	0.5416351815427286
Publication Date Optimization Design and Implement For zh-cn Market	Training Data Repository v2Sourabh ChandakAgendaWhy TDR v2TDR explainedOnboarding processNext StepsSummaryDependenciesQuestionsProblemTraining data The most valuable resource for any ranker training experiment. Comprises of <quer	0.5061566097741969
Publication Date Optimization Design and Implement For zh-cn Market	DU feature usage summary about en-us and zh-cn prod ranker:<more detail please refer to the attached report>Basics:99 APF in en-us Ranker.47 APF in zh-cn Ranker.41 APF appear both in en-us Ranker and zh-cn Ranker. 58 APF only appear in  en-us 	0.4855100742262558
Publication Date Optimization Design and Implement For zh-cn Market	Smart Query Relaxation In Joint OptimizationA Cross-Group Collaborations Among QU/QR/CoreRanking/IS/MSR      Presented By : Xiaolong Li (Query Understanding)8/19/2013Smart Query Relaxation in JOPOutlineJOP V2 SummaryQuery Relaxation An	0.46080266858417995
Publication Date Optimization Design and Implement For zh-cn Market	AgendaAres Data Access FrameworkEntitySet Creation WorkflowMetric CalculatorQuestion & AnswerARES logical conceptsARES AssetsLogical ModelEntity/RelationRelated RVT data model ARES Data ModelUnit of ExecutionEntityJobTask	0.4543780372101738

Pthreads mutex vs Pthreads spinlock	Pthreads mutex vs Pthreads spinlock 锁机制(lock) 是多线程编程中最常用的同步机制,用来对多线程间共享的临界区(Critical Section) 进行保护。Pthreads提供了多种锁机制,常见的有：1) Mutex（互斥量）：pthread_mutex_***2) Spin lock（自旋锁）：pthread_spin_***3) Condition Variable（条件变量）：pthread_con_***4) Read/Write 	0.6862059491259063
Pthreads mutex vs Pthreads spinlock	Nlp情感分析工具使用执行步骤：分词执行程序：Shenbian_exlib_segpos使用说明： 	usage: ./Shenbian_exlib_segpos  segDictPath tagDictPath inputfile outputtype      			exDictLib > outputfile具体使用举例：     ./Shenbian_exlib_segpos ../../../../lib_wordseg/worddict_1-3-4-3_PD_B	0.4445981316061748
Pthreads mutex vs Pthreads spinlock	Lexical analyzer (fa_lex)Input: a buffer of textOutput: a sequence of tokens, each token is <from, to, tag>For C++:Input: “if(++i==0) {j = 0;}”Output: if/OP (/LRB ++/OP i/VAR ==/OP 0/NUM )/RBR {/LCBR j/VAR =/OP 0/NUM ;/OP }/RCBREach rule:Des	0.4056900738102491
Pthreads mutex vs Pthreads spinlock	 阿里浏览器DNS解析加速布可2010.12.31AgendaDNS解析过程DNS协议阿里浏览器DNS解析加速浏览器查找域名的IPtaobao.com浏览器缓存(2-30min)系统缓存(DNS client resolver cache)Local DNS递归查询->dns1.禁用IE的dns缓存：Start Registry Editor. Locate and click the following key in the reg	0.36117194781658124
Pthreads mutex vs Pthreads spinlock	L3 Reranking FrameworkL3 Infrastructure TeamAgendaOverviewL3 featuresL3 ranker and L3 workflowAggregatedFreeFormList-wise ranking previewL3 and L4Future WorkOverviewRank Stack in IS PlatformL4 - MergerL3 – List reorderingL2 - S	0.35796650391856344
Pthreads mutex vs Pthreads spinlock	Entity Selection Pipeline Design DocScope:This document covers the design for entity selection pipeline in GDPV3. Near-Dupe clustering is not covered in this v1 version. The goal for this pipeline is to reduce junk rate and improve NII by stamping pub	0.34730413927040193
Pthreads mutex vs Pthreads spinlock	Production Models OverviewLU annotates incoming text input with semantic information in a contextual wayWorkflow built on top of Bing production infrastructure (QAS/XAP/Object Store)Feature representation: word embedding, n-grams and lexicons matche	0.3362631046400456
Pthreads mutex vs Pthreads spinlock	Term expansion summaryGoalsVisible changes in ARDSImprove “no match” issuesImprove rank qualityLimit FPs. Pre-work neededPort names tagger to C#/C++Query timeWSD and entity taggerEntity tagging in query logs (Britney Spears bio -> <p	0.33313652355744205
Pthreads mutex vs Pthreads spinlock	libsvm的相关工具和使用方法libsvm工具：编译并能够使用 : libsvm-3.0.tarsvm的基本原理 ： libsvm-guide.pdflibsvm相关的grid工具 : [sep@ai-iknow-septest1.ai01.baidu.com auto_classifier]$ pwd grid_tools.py /home/sep/yangfan/Basic_Tools/for_lyq/auto_classifier特征筛选的相关资料和方法了解特征筛选方法	0.3271967930580518
Pthreads mutex vs Pthreads spinlock	Pattern Based Term WeightVersion 1Jia Liu2014-06-16FrameworkTerm AttributesSemantics definitionHuman understanding and knowledgeChange in different contextsLevels:KeywordAttributeRequirementStrong constraintWeak constraintVer	0.3247281157503998

Product Regex Measurement	Fast Brain – Memorization & InferenceQuery based memorization and inferenceLarge Memorization -  1B queries, clicks (Q-D) and moreDeep Brain100 - 200B Doc/Page IndexRecall, Tail and Scalability focusedLess dependency on popularity signalHeur	0.3429004015915721
Product Regex Measurement	Bing Ads Insight Track Weekly Review11/09/2015Primary KPIs  -- Product UsageCallout –NA- A memory cache mechanism was deployed last week for data platform, which benefits around half traffic and latency decreased significantly.Primary KPIs –	0.27250579420511123
Product Regex Measurement	Bing Ads Insight Track Weekly Review9/07/2015Primary KPIs  -- Product UsageCallout –NAPrimary KPIs – Platform ServiceHighlights/Lowlights: (http://adspulse/Report/61998 ) Callout – N/AUser feedbacks (Premium Tool Phase 1 release) 	0.26824882286445534
Product Regex Measurement	Run web-search-like query against my dataSame Bing Web Search Indexing and Ranking engineIndex in a secondTransparent and real time index sync, no complex index-gen pipelinePrototype in an hourFast self-onboarding with freemium account, schema-d	0.25093049505281484
Product Regex Measurement	Primary Category: What Is It, Why Is It Important, & How Do We Measure ItBing Local & Geospatial – ShruthiM, DillTellClassificationProcess in which local business entities are categorized based on the type of products and/or services that the busine	0.2418399295697319
Product Regex Measurement	Translation Model APIStatus: Sodium-2, API Version 6.7OverviewThe TM API – including support for high compression - was developed as one of several architectural considerations to ship machine translation model features to production, initially for 	0.23601144078678643
Product Regex Measurement	Files Reuse in OfficeMahaveer KothariAgendaIntroductionHigh level overviewChallengesIntegration with Ideas/SearchWhat’s NextQ & AIntroductionHistory about reuse slides in PowerPoint. Documents supported. Document gallery Archit	0.23038132477104611
Product Regex Measurement	Simplified Query Path SelectorSimplified query: current systemSimplified query path selectionCrf model produces a list of possible ways to place rankonly operatorQuery = “nibbana restaurant official site”nibbana restaurant rankonly:official site	0.22765324921219282
Product Regex Measurement	Keyword Predictor Design DocumentName: Ruchir RastogiMentor: Jia LiuManager: Leon ZhangProject overviewThe goal of this project is to design a machine-learning model that can predict keywords in a local query for improving local search relevance	0.22605700380098004
Product Regex Measurement	Measurement PlanSmoke test:We will deploy ranker model under test and service to INT and ask SKI internal users to issue whatever queries they want. In this way, we can quickly get feedback using Microsoft private data and Bing API. People can get min	0.22545497732523168

Presentation1	Word representationsMotivationWhy word representations?StructureWhy vectors?Distance and similarityBuild models that will automatically understand language for us.Vector space modelsVector space modelsCount based methodsDSM (distribu	0.3036743894875861
Presentation1	Entity Pane and Fact AnswerPresenter: Ze TianJun 25, 2013IntroductionIntroductionIntroductionProblems to SolveDoes the user search for entities or facts of entities?E.g. “who is msft ceo” (Entity: Microsoft, Fact: Chief Executive O	0.20662799423277856
Presentation1	Threshold Query Formulation Deep DiveGoal of the presentation is to communicate our approach for query formulation and get feedback on whether this aligns with overall Threshold goals.OverviewGoals & MetricsQF ModelRoadmapScenariosKey Ta	0.17782619899570665
Presentation1	Phrasal Alterations & CAL Infra 		Page 2 of 2Phrasal Alterations & CAL Infra DescriptionPhrasal Alterations is going to add CAL the functionality of doing N-to-M alterations. Given a query, CAL is going to generate multiple candidate queries without	0.15956657872821273
Presentation1		0.15489145118487777
Presentation1	Containment and Conflation – Sprint  2Story DescriptionDone?In Demo?Implement and ship Segment Studio integration changes for Preconflation and MatchYYIdentify top K entity setYYRoot cause why entities have too many identifiersYY	0.1488972683553207
Presentation1	Wind Up Impact on Existing adInsight Feature Plan03/25/2015ContextTo Enable “Wind Up for Premium” as high priority, we decide to make following resource adjustmentImpact to Existing Product/Feature AreaFocus AreaProducts/FeaturesResource	0.14212626501910514
Presentation1	Index Quality UpdateAgendaMetrics UpdateSelection Model ImprovementRecall TierOffice ImprovementChallenges and Pain PointsHow to measure index quality?Ideally: sampling from all “good” images and see how much we covered.sampling from a	0.1359115697750231
Presentation1	Zh-cn Transportation Segment Optimization by Pattern EngineIntroductionThe pattern queries can cover almost 10% in all queries. We can summarize lots of patterns on Query and Document sides for different segments. We can recognize key terms, relations	0.12352972285486756
Presentation1	Deal UnderstandingDeals with Low Quality: (some features/rules are listed below)Features/RulesExamplesNo user used; no verified informationThe policies about return365 Day Return Policy;Free Returns on All Orders; 45 Day Return Money Back 	0.12016349713645547

Presentation 1	Word representationsMotivationWhy word representations?StructureWhy vectors?Distance and similarityBuild models that will automatically understand language for us.Vector space modelsVector space modelsCount based methodsDSM (distribu	0.2766680152351651
Presentation 1		0.22479954684380032
Presentation 1	Entity Pane and Fact AnswerPresenter: Ze TianJun 25, 2013IntroductionIntroductionIntroductionProblems to SolveDoes the user search for entities or facts of entities?E.g. “who is msft ceo” (Entity: Microsoft, Fact: Chief Executive O	0.19769744761128333
Presentation 1	Threshold Query Formulation Deep DiveGoal of the presentation is to communicate our approach for query formulation and get feedback on whether this aligns with overall Threshold goals.OverviewGoals & MetricsQF ModelRoadmapScenariosKey Ta	0.14025593320405091
Presentation 1	Phrasal Alterations & CAL Infra 		Page 2 of 2Phrasal Alterations & CAL Infra DescriptionPhrasal Alterations is going to add CAL the functionality of doing N-to-M alterations. Given a query, CAL is going to generate multiple candidate queries without	0.13806037908775676
Presentation 1	Pattern Based Term Weight FrameworkIntroductionPattern based term weight recognizes the importance for part of terms or all the terms based on patterns/templates/knowledge. There are 2 differences between general and pattern based term weight.Compar	0.1254555752467379
Presentation 1	Provider Feature Measured Coverage Corrected Coverage(Exclude No Rating) Improved Coverage Estimate(Include No Rating) Note Amazon Price Amazon Availability Amazon Rating&Count >95% >92% 1. A known client issue:The current logic is to show the rating&cou	0.11668227022306511
Presentation 1	Zh-cn Transportation Segment Optimization by Pattern EngineIntroductionThe pattern queries can cover almost 10% in all queries. We can summarize lots of patterns on Query and Document sides for different segments. We can recognize key terms, relations	0.11530677615889155
Presentation 1	Wind Up Impact on Existing adInsight Feature Plan03/25/2015ContextTo Enable “Wind Up for Premium” as high priority, we decide to make following resource adjustmentImpact to Existing Product/Feature AreaFocus AreaProducts/FeaturesResource	0.10860541884352205
Presentation 1	Index Quality UpdateAgendaMetrics UpdateSelection Model ImprovementRecall TierOffice ImprovementChallenges and Pain PointsHow to measure index quality?Ideally: sampling from all “good” images and see how much we covered.sampling from a	0.10582101541147168

Presentation	Word representationsMotivationWhy word representations?StructureWhy vectors?Distance and similarityBuild models that will automatically understand language for us.Vector space modelsVector space modelsCount based methodsDSM (distribu	0.2485705061656938
Presentation		0.1840437067595763
Presentation	Threshold Query Formulation Deep DiveGoal of the presentation is to communicate our approach for query formulation and get feedback on whether this aligns with overall Threshold goals.OverviewGoals & MetricsQF ModelRoadmapScenariosKey Ta	0.14751906216053884
Presentation	Entity Pane and Fact AnswerPresenter: Ze TianJun 25, 2013IntroductionIntroductionIntroductionProblems to SolveDoes the user search for entities or facts of entities?E.g. “who is msft ceo” (Entity: Microsoft, Fact: Chief Executive O	0.1198779786607841
Presentation	Index Quality UpdateAgendaMetrics UpdateSelection Model ImprovementRecall TierOffice ImprovementChallenges and Pain PointsHow to measure index quality?Ideally: sampling from all “good” images and see how much we covered.sampling from a	0.11239064286503925
Presentation	Containment and Conflation – Sprint  2Story DescriptionDone?In Demo?Implement and ship Segment Studio integration changes for Preconflation and MatchYYIdentify top K entity setYYRoot cause why entities have too many identifiersYY	0.10593744658884793
Presentation	Zh-cn Transportation Segment Optimization by Pattern EngineIntroductionThe pattern queries can cover almost 10% in all queries. We can summarize lots of patterns on Query and Document sides for different segments. We can recognize key terms, relations	0.10580334173490853
Presentation	Wind Up Impact on Existing adInsight Feature Plan03/25/2015ContextTo Enable “Wind Up for Premium” as high priority, we decide to make following resource adjustmentImpact to Existing Product/Feature AreaFocus AreaProducts/FeaturesResource	0.10491312131695833
Presentation	Phrasal Alterations & CAL Infra 		Page 2 of 2Phrasal Alterations & CAL Infra DescriptionPhrasal Alterations is going to add CAL the functionality of doing N-to-M alterations. Given a query, CAL is going to generate multiple candidate queries without	0.09235368162245895
Presentation	Keyword predictor-Ganesh Poomal -KefengOutlineThe problem and the objective for Keyword predictorTraining Data CollectionModel and FeaturesResultsKeyword PredictorProblem    In a search engine, user expresses their need for information	0.08153605326191453

Play Book of Pattern Engine Based Micro-segment Platform	Play Book of Pattern Engine Based Micro-segment PlatformIntroductionNow, per query pattern match features (PMFs) are available for ranking. You can get PMFs of your own pattern groups (PGs) immediately after several simple steps. With these signals, r	0.8923117499808555
Play Book of Pattern Engine Based Micro-segment Platform	Pattern Based Term Weight FrameworkIntroductionPattern based term weight recognizes the importance for part of terms or all the terms based on patterns/templates/knowledge. There are 2 differences between general and pattern based term weight.Compar	0.5001898098109628
Play Book of Pattern Engine Based Micro-segment Platform	QR MicrosegmentsSandeep AparajitAgendaWhat are microsegments?How does microsegment work in CAL?How can I add my own microsegment?DemoQuestions/SuggestionsWhat are Microsegments?Microsegment is a technique using which you can alter the be	0.4850928340264052
Play Book of Pattern Engine Based Micro-segment Platform	Deep Learning: The Path ForwardTuring/AGI/WITSaurabh TiwaryGoalsStrategyDL first everywhereScaleAGI-fying building blocksNew ScenarioLight up T@W & Unified QUDL-firstWe have been hedging our effortsLet’s do (a little bit of) everyt	0.45824178361734363
Play Book of Pattern Engine Based Micro-segment Platform	QR Micro SegmentOverviewMicro Segment is way to fix corner case that main Bing ranking pipeline couldn’t fix easily by machine learning. There are many ways to do micro segment. Micro segment can be done in many layers. QR, matching, L1, L2, L3, …. To	0.4441416122976676
Play Book of Pattern Engine Based Micro-segment Platform	Microsoft Netherlands. Azure PlanPresenter nameSlide script: Thank you for taking the time today to walk through an end-to-end tour of Azure Security- the intensive and extensive work we’re doing to deliver a cloud you can trust.We’ll focus firs	0.44107853107180806
Play Book of Pattern Engine Based Micro-segment Platform	[IMPORTANT]Please notify “featfun” if you want to edit this document!!!Metastream FeaturesWritten by: Tian Xia (tixia@microsoft.com)Table of Contents1. Overview	62. Basics	82.1 Metastreams	9Single instance metastream	9Multi-instance meta	0.4309730375157901
Play Book of Pattern Engine Based Micro-segment Platform	Query Rewriting Micro SegmentWhy QR Micro SegmentMicro Segment is way to fix corner case that main Bing ranking pipeline couldn’t fix easily by machine learningThere are many ways to do micro segment. Micro segment can be done in many layers. QR, 	0.4137272233822338
Play Book of Pattern Engine Based Micro-segment Platform	PAC: Features, Usage and ProcessThis is a document on how to get document features and build metaword/metastream via Page Analyzer and Classifier (PAC ) pipeline. ContentsKinds Of Features Supported By PAC	2Url/Title Features	2Body Features: Doc	0.40979537367362545
Play Book of Pattern Engine Based Micro-segment Platform	Opal OSearch & XAP flight frameworkKevin Su & Duat Le06/22/2016OverviewOSearch basicsOpal OSearch high-level architectureProcess to onboard new feature for Opal OSearchXAP flight framework in OsearchOSearch basicsWhat's OSearch?A platf	0.4083489671611801

PhrasalAlterations	Phrasal Alterations & CAL Infra 		Page 2 of 2Phrasal Alterations & CAL Infra DescriptionPhrasal Alterations is going to add CAL the functionality of doing N-to-M alterations. Given a query, CAL is going to generate multiple candidate queries without	0.5234617535985207
PhrasalAlterations	Normalization and Parsing OverviewTypes of NormalizationLimiting to just normalization, there are actually several different types of normalization which may be interesting:WhitespaceThis is:Converting all whitespace characters to spacestrippi	0.36861389753958596
PhrasalAlterations	alterationsalterations: product goalimprove recallby adding terms (not replacing or dropping user-entered terms)using word:which are synonyms to the original terms(we are re-examining each of these for vnext)alterations: general principl	0.323874223914541
PhrasalAlterations	Bitext Alignment for Alteration Candidate GenerationJan 2018Alteration BasicsCAL alteration architecture is a big funnelCurrent mouth of the funnel is the altlist – a non-context-sensitive relation of <source, target, score>Built over time, qu	0.2739975886668492
PhrasalAlterations	Combined ALterationsNeon\sodiumAgendaNeon AchievementsBreakdownsSodiumIdeas & PlanNeonOverall ProgressExceeded Neon Commitments on CQS!NeonCQS Deep-dive-34% Bad+14% Excellent-15% Bad+13% ExcellentDRDOCQS is impr	0.2199261720591678
PhrasalAlterations	Publication Date Optimization Design and Implement For zh-cn MarketReview and CommentMei Yang; Ted WildAuthorJia LiuDesignBackgroundPublication date is a very fundamental and important feature. It can help fresh ranking, solve mainline out	0.20062011730865725
PhrasalAlterations	Entity Pane and Fact AnswerPresenter: Ze TianJun 25, 2013IntroductionIntroductionIntroductionProblems to SolveDoes the user search for entities or facts of entities?E.g. “who is msft ceo” (Entity: Microsoft, Fact: Chief Executive O	0.19554798047255537
PhrasalAlterations	Word representationsMotivationWhy word representations?StructureWhy vectors?Distance and similarityBuild models that will automatically understand language for us.Vector space modelsVector space modelsCount based methodsDSM (distribu	0.1859265182530662
PhrasalAlterations	Provider Feature Measured Coverage Corrected Coverage(Exclude No Rating) Improved Coverage Estimate(Include No Rating) Note Amazon Price Amazon Availability Amazon Rating&Count >95% >92% 1. A known client issue:The current logic is to show the rating&cou	0.17433203308327927
PhrasalAlterations	CALQuery alterationAgendaRoadmap and VisionWhere are weWhere to goPlanHow to get thereProgress and looking aheadSodium so farMagnesium and beyondDeep DiveGolden QueryRoadmap & VisionWhere are weCurrent status/problem of CAL	0.17022246735872337

Photo Requirements	InstructionS FOR obtaining photographsfor your applicationPHOTO REQUIREMENTS:Your photographs must be:2x2 inches in size Identical Taken within 30 days of filing the application(s), showing current appearance In color Full face, front view	0.3770540888012045
Photo Requirements		0.20888973287648038
Photo Requirements	alterationsalterations: product goalimprove recallby adding terms (not replacing or dropping user-entered terms)using word:which are synonyms to the original terms(we are re-examining each of these for vnext)alterations: general principl	0.10038775591009991
Photo Requirements	CALQuery alterationAgendaRoadmap and VisionWhere are weWhere to goPlanHow to get thereProgress and looking aheadSodium so farMagnesium and beyondDeep DiveGolden QueryRoadmap & VisionWhere are weCurrent status/problem of CAL	0.09321828170068497
Photo Requirements	TopChainNumber MasterId Label Type Name Phone AddressLine City Website Closed LastYearImpression LCMScore ChainId ChainName Score LPLink SparsedFeatureVector r 873x114637191399090866 0 http://maps.google.com/maps/place?cid=14233605658129796921 Ion Bank 36	0.08309730850613602
Photo Requirements	Normalization and Parsing OverviewTypes of NormalizationLimiting to just normalization, there are actually several different types of normalization which may be interesting:WhitespaceThis is:Converting all whitespace characters to spacestrippi	0.07201696270842191
Photo Requirements	Local Category Search Plan3 month StrategyData: Entity categorizationScalable, high precision/recallSegments: Food & Drink, Retail, Service, Auto, HotelMetaStream enrichmentQuery UnderstandingDolphin by defaultConsume PhoneBookQU to im	0.05300893926511245
Photo Requirements	Publication Date Optimization Design and Implement For zh-cn MarketReview and CommentMei Yang; Ted WildAuthorJia LiuDesignBackgroundPublication date is a very fundamental and important feature. It can help fresh ranking, solve mainline out	0.05163683874992504
Photo Requirements	Phrasal Alterations & CAL Infra 		Page 2 of 2Phrasal Alterations & CAL Infra DescriptionPhrasal Alterations is going to add CAL the functionality of doing N-to-M alterations. Given a query, CAL is going to generate multiple candidate queries without	0.046759956887784976
Photo Requirements	Bitext Alignment for Alteration Candidate GenerationJan 2018Alteration BasicsCAL alteration architecture is a big funnelCurrent mouth of the funnel is the altlist – a non-context-sensitive relation of <source, target, score>Built over time, qu	0.0459341231765968

PhonebookQU_and_Metadata	PhonebookQU and MetadataMing Wu2017-04-19What’s QU in PBASelect the appropriate location reference based on PBA Parser and LES response hard-coded rule based (Parser and LES result should not have conflict)Correct CRF parse based on lexicons a	0.3806748661284453
PhonebookQU_and_Metadata	Phonebook vNextDesign DiagramsPlease do not modify existing diagrams!To update a diagram, make copy of a slideand create a new version.Do not forget to update date and author.Local.Pba.MainLocal.Pba.ExecutionModeLocal.Pba.ResponseMuxMu	0.26263039506634833
PhonebookQU_and_Metadata	Tmall&Taobao Rating MetawordsBackgroundWe’ve seen in regular DSAT review meetings the DSATs that we rank too high Tmall or Taobao page with low quality(Tmall page:low sales volume; Taobao page: low sales volume or shop with poor reputation).  Zh-CN ha	0.23780005913364138
PhonebookQU_and_Metadata	Meta-stream work summaryHeyong WangClickstream exampleOverview: Click-Stream generationWeb logsLocal logsLocal clicked dataJoin with Local IndexWeb Clicked data (query, url etc.)IE ClickBing ClickIE SessionIE Tool Bar…Web Click	0.21582522573515742
PhonebookQU_and_Metadata	CALQuery alterationAgendaRoadmap and VisionWhere are weWhere to goPlanHow to get thereProgress and looking aheadSodium so farMagnesium and beyondDeep DiveGolden QueryRoadmap & VisionWhere are weCurrent status/problem of CAL	0.19997598888540738
PhonebookQU_and_Metadata	https://cosmos11.osdinfra.net/cosmos/skypedata.adhoc/local/SkypeFeedback/Mined/v2/full/ FULLActionEntity.sshttps://cosmos11.osdinfra.net/cosmos/skypedata.adhoc/local/SkypeFeedback/Mined/v2/1d/ SkypeFeedback.ssSkypeSHRComments.ssSkypeSupportSea	0.18482015172714966
PhonebookQU_and_Metadata	Crawler Tech TalkOctober 14, 2008AgendaOverview of Msnbot Internal Data FlowFlow of Chunks and Chunk MetadataReal-Time MonitoringDaily Data Reporting SubsystemPrevious Instances Requiring InterventionPotential Future ProblemsQ&AMsnbot 	0.18037086059712645
PhonebookQU_and_Metadata	Bing Local Search				Phonebook vNext Design DocumentDev ownerMickadBuddy dev(s)MichstePM ownerDabargerContributorsFeature areaMilestoneTable of contents1	Overview	32	Goals/Non Goals	53	Dependencies	64	Risks/Open Issues	75	0.17900167924457405
PhonebookQU_and_Metadata	Bing Adult FilteringNeil ZhaoSmart adult filtering GloabelSmartAdultFiltering=offSmartAdultFiltering=onStrict-category:ff000001tla:adultfilter:onModerateprefer:-category:ff000001tla:adultfilter:smartOff tla:adultfilter:off ZH	0.17753566762374465
PhonebookQU_and_Metadata	PDI Document AnnotationPDI Ranking PlatformAgendaPDI and forward indexDocument AnnotationSodium update and MG planQ&A DSAT: {books by children}Issue: Document matches the query terms, but its surrounding words may change the intent of 	0.17071086918008738

Phonebook vNext Design Document	Phonebook vNextDesign DiagramsPlease do not modify existing diagrams!To update a diagram, make copy of a slideand create a new version.Do not forget to update date and author.Local.Pba.MainLocal.Pba.ExecutionModeLocal.Pba.ResponseMuxMu	0.5961604446721896
Phonebook vNext Design Document	Bing Local Search				Phonebook vNext Design DocumentDev ownerMickadBuddy dev(s)MichstePM ownerDabargerContributorsFeature areaMilestoneTable of contents1	Overview	32	Goals/Non Goals	53	Dependencies	64	Risks/Open Issues	75	0.5196752655380195
Phonebook vNext Design Document	PhonebookQU and MetadataMing Wu2017-04-19What’s QU in PBASelect the appropriate location reference based on PBA Parser and LES response hard-coded rule based (Parser and LES result should not have conflict)Correct CRF parse based on lexicons a	0.3989804414709488
Phonebook vNext Design Document	PBAVnext and migrationFrank ZhangBenefit of vnextIt will reflect five years’ worth of local search relevance insights and lessons learned, including the relevance tuning principles we have discovered over the years.It will make it easier to suppor	0.329599144021427
Phonebook vNext Design Document	NGram Language Model based Url Breaking – Design DocumentStatusOngoingIntroductionUrl is a very important signal for ranking, particularly for tail queries and navigation queries. This signal has 100% url coverage, which really makes it different 	0.3199235293899641
Phonebook vNext Design Document	WrapStar On-Demand DesignDrafted by ZiliuContentsContext2Design Goals2Automation2Deployment Agility2High Availability2Non-Goals2Metrics2Required Changes3Orchestration3AP Migrations3Pipeline Evolution3Tools/services refactoring3	0.29040682716546784
Phonebook vNext Design Document	Brownbag:ElasticSearch ExtensibilityHeather Nakama (henakama)Azure Search09/04/14AgendaIntroductionModulesPluginsFinding extensibility pointsEnd-to-end exampleTips and tricksQ/AIntroductionHeather NakamaDeveloper with Azure S	0.2786918921375138
Phonebook vNext Design Document	Find Deals with OpalKelly You, Jia Liu, Leon Zhang7/11/2016AGENDAScenariosTechniques & ChallengesNext StepsQ&AScenariosSearch Store DealsBrowse Nearby DealsFilter Restaurants with DealsDeal Action in Entity Detail CardTechniques 	0.24846172066382843
Phonebook vNext Design Document	Text Latitude Longitude S0:Local_L3DCG3 G0:Local_L3DCG3 S1:Local_L3DCG3 S2:Local_L3DCG3 Assignment RootCause(BadMetastream,PartialMatch,Cal,BadKeyword,OtherQU,Ranker,BingNotStable,Scraping,Metrics,MicroSegment,JudgeNoise,Unknown,BadEntity) BTC CanBeResolv	0.24718932060031745
Phonebook vNext Design Document	SKI Contextual Reranking V1 design doc User ScenarioWhole page relevance of “All Tab” in the SerpletContextual relevance of “File Tab” in the Serplet DeliverablesMicrosoft search serves as an intelligence service to take user query and return be	0.2409250336114738

Pattern Based Term Weight V1	Pattern Based Term Weight FrameworkIntroductionPattern based term weight recognizes the importance for part of terms or all the terms based on patterns/templates/knowledge. There are 2 differences between general and pattern based term weight.Compar	0.7551089929877168
Pattern Based Term Weight V1	Pattern Based Term WeightJia Liu2014-05-06FrameworkTerm AttributesSemantics definitionHuman understanding and knowledgeChange in different contextsLevels:KeywordAttributeRequirementStrong constraintWeak constraintVerbUseless	0.6160646967415279
Pattern Based Term Weight V1	Pattern Based Term WeightVersion 1Jia Liu2014-06-16FrameworkTerm AttributesSemantics definitionHuman understanding and knowledgeChange in different contextsLevels:KeywordAttributeRequirementStrong constraintWeak constraintVer	0.5849225057294446
Pattern Based Term Weight V1	Play Book of Pattern Engine Based Micro-segment PlatformIntroductionNow, per query pattern match features (PMFs) are available for ranking. You can get PMFs of your own pattern groups (PGs) immediately after several simple steps. With these signals, r	0.43107001364715475
Pattern Based Term Weight V1	Abacus Query Pattern SpecThis document describes how the query GEE pattern is passing from CAL into PDR, and generate a series of features depending on the <querypattern, URL-host> level matching. Query Property of GEEHere is the query property defi	0.3761121647469357
Pattern Based Term Weight V1	Dynamic Rank FeaturesWritten by Krysta Svore (ksvore)This document is meant to give a brief overview of the features used in the dynamic ranking component of Live search.  It contains an overview of the search process followed by the definitions of cu	0.3445572024496563
Pattern Based Term Weight V1	Path Classifier FeaturesLast saved 16 March 2015 (build 3790878) by Garrett Kaminaga.NotesFeature names are composed of a group name and a feature name, separated by underscoreFeature values are always UInt32.  There are various encoding mechanism	0.3417391449179353
Pattern Based Term Weight V1	Measurement PlanSmoke test:We will deploy ranker model under test and service to INT and ask SKI internal users to issue whatever queries they want. In this way, we can quickly get feedback using Microsoft private data and Bing API. People can get min	0.3402692524036249
Pattern Based Term Weight V1	AgendaAres Data Access FrameworkEntitySet Creation WorkflowMetric CalculatorQuestion & AnswerARES logical conceptsARES AssetsLogical ModelEntity/RelationRelated RVT data model ARES Data ModelUnit of ExecutionEntityJobTask	0.30284284794303806
Pattern Based Term Weight V1	CoreCAL Improvements		Page 2 of 5CoreCAL ImprovementsDescriptionDuring Sodium, CAL Team would invest on optimizing separately for L0\L1\L2 on top of current CoreCAL improvements. Multiple Query Project will target Fidelity\SBS\SSRx while CoreCAL imp	0.3017825904639656

Pattern Based Term Weight May Planning	Pattern Based Term Weight FrameworkIntroductionPattern based term weight recognizes the importance for part of terms or all the terms based on patterns/templates/knowledge. There are 2 differences between general and pattern based term weight.Compar	0.6622501040152878
Pattern Based Term Weight May Planning	Play Book of Pattern Engine Based Micro-segment PlatformIntroductionNow, per query pattern match features (PMFs) are available for ranking. You can get PMFs of your own pattern groups (PGs) immediately after several simple steps. With these signals, r	0.5343440639568429
Pattern Based Term Weight May Planning	Pattern Based Term WeightJia Liu2014-05-06FrameworkTerm AttributesSemantics definitionHuman understanding and knowledgeChange in different contextsLevels:KeywordAttributeRequirementStrong constraintWeak constraintVerbUseless	0.4764083911816594
Pattern Based Term Weight May Planning	Pattern Based Term WeightVersion 1Jia Liu2014-06-16FrameworkTerm AttributesSemantics definitionHuman understanding and knowledgeChange in different contextsLevels:KeywordAttributeRequirementStrong constraintWeak constraintVer	0.45337468147319865
Pattern Based Term Weight May Planning	CoreCAL Improvements		Page 2 of 5CoreCAL ImprovementsDescriptionDuring Sodium, CAL Team would invest on optimizing separately for L0\L1\L2 on top of current CoreCAL improvements. Multiple Query Project will target Fidelity\SBS\SSRx while CoreCAL imp	0.3752759298968771
Pattern Based Term Weight May Planning	Measurement PlanSmoke test:We will deploy ranker model under test and service to INT and ask SKI internal users to issue whatever queries they want. In this way, we can quickly get feedback using Microsoft private data and Bing API. People can get min	0.3559537769188501
Pattern Based Term Weight May Planning	Local and mm magnesium asksCALApril 2013Microsoft ConfidentialContextWe are expanding to many international markets for Win-blueCAL/Speller impact can range from -1 to +2 points in DCG. Recent MM US DSAT analysis (Dec 2012) showed close to 1	0.3475961079515274
Pattern Based Term Weight May Planning	Path Classifier FeaturesLast saved 16 March 2015 (build 3790878) by Garrett Kaminaga.NotesFeature names are composed of a group name and a feature name, separated by underscoreFeature values are always UInt32.  There are various encoding mechanism	0.34063322450127836
Pattern Based Term Weight May Planning	PAC: Features, Usage and ProcessThis is a document on how to get document features and build metaword/metastream via Page Analyzer and Classifier (PAC ) pipeline. ContentsKinds Of Features Supported By PAC	2Url/Title Features	2Body Features: Doc	0.3174762007313496
Pattern Based Term Weight May Planning	Zh-cn Transportation Segment Optimization by Pattern EngineIntroductionThe pattern queries can cover almost 10% in all queries. We can summarize lots of patterns on Query and Document sides for different segments. We can recognize key terms, relations	0.3149437324228389

Path Classifier Features	Path Classifier FeaturesLast saved 16 March 2015 (build 3790878) by Garrett Kaminaga.NotesFeature names are composed of a group name and a feature name, separated by underscoreFeature values are always UInt32.  There are various encoding mechanism	0.6272139935412981
Path Classifier Features	Span ClassifierSpan classifier is a general infrastructure that can be used to run a fastrank based classifier on a sequence of terms from a query.  It can be used to apply rankonly or norelax to parts of the query based on the result of the model.  Fea	0.5303068268060189
Path Classifier Features	PAC: Features, Usage and ProcessThis is a document on how to get document features and build metaword/metastream via Page Analyzer and Classifier (PAC ) pipeline. ContentsKinds Of Features Supported By PAC	2Url/Title Features	2Body Features: Doc	0.4582764402974583
Path Classifier Features	Abacus Query Pattern SpecThis document describes how the query GEE pattern is passing from CAL into PDR, and generate a series of features depending on the <querypattern, URL-host> level matching. Query Property of GEEHere is the query property defi	0.4506409173909921
Path Classifier Features	Pattern Based Term Weight FrameworkIntroductionPattern based term weight recognizes the importance for part of terms or all the terms based on patterns/templates/knowledge. There are 2 differences between general and pattern based term weight.Compar	0.4276807669504656
Path Classifier Features	Restaurants Features and ToolsReview SnippetXAPOSearchQueryWPOLERWPO OSCacheItemCacheIdList of YpIdsFiltersSorterEntityUpdate PostFixEntity Update OSCache IdCache ItemYpId and PostFixUXReview Snippet Data GroupCac	0.4232490440022138
Path Classifier Features	Entity Pane and Fact AnswerPresenter: Ze TianJun 25, 2013IntroductionIntroductionIntroductionProblems to SolveDoes the user search for entities or facts of entities?E.g. “who is msft ceo” (Entity: Microsoft, Fact: Chief Executive O	0.41096189336755096
Path Classifier Features	Document classification based on urlBackgroundWe want to do document classification for better understanding the document type and document with query category match for ranking.  We will do zh-cn document classification based on url first, then docum	0.4060770034875183
Path Classifier Features	Simplified Query Path SelectorSimplified query: current systemSimplified query path selectionCrf model produces a list of possible ways to place rankonly operatorQuery = “nibbana restaurant official site”nibbana restaurant rankonly:official site	0.3986643909563891
Path Classifier Features	Play Book of Pattern Engine Based Micro-segment PlatformIntroductionNow, per query pattern match features (PMFs) are available for ranking. You can get PMFs of your own pattern groups (PGs) immediately after several simple steps. With these signals, r	0.3843284547717716

PDI Document Annotation 201307	PDI Document AnnotationPDI Ranking PlatformAgendaPDI and forward indexDocument AnnotationSodium update and MG planQ&A DSAT: {books by children}Issue: Document matches the query terms, but its surrounding words may change the intent of 	0.6922284950585224
PDI Document Annotation 201307	Restaurants Features and ToolsReview SnippetXAPOSearchQueryWPOLERWPO OSCacheItemCacheIdList of YpIdsFiltersSorterEntityUpdate PostFixEntity Update OSCache IdCache ItemYpId and PostFixUXReview Snippet Data GroupCac	0.3882537108679859
PDI Document Annotation 201307	Document classification based on urlBackgroundWe want to do document classification for better understanding the document type and document with query category match for ranking.  We will do zh-cn document classification based on url first, then docum	0.3790567875222914
PDI Document Annotation 201307	Zh-cn Transportation Segment Optimization by Pattern EngineJia Liu/Allen WangDSATsQuery: 吉林市到查干湖Relevant result title: 吉林市到查干湖怎么走近？_百度知道Irrelevant result title 1: 查干湖,中国查干湖,吉林查干湖,查干湖旅游,查干湖冬捕,国家AAAA ...Irrelevant result title 2: 查干湖_百度百科Irrel	0.3655106320956716
PDI Document Annotation 201307	Author: Tony AngellDate: 08/01/13LocalProbe Improvements for Corrections Analysis and DebuggingTable of ContentsP0 Issues	2Issue: LocalProbe is unpredictable in the amount of time it takes to return a query and how long it takes to investigate a	0.3588190814234027
PDI Document Annotation 201307	Zhcn document classification based on topicJia Liu2012.11.14agendarTraining data selection&crawl&cleanFeature selection&cleanClassifierRating Bad case analysisTrainning data	0.3539877512584807
PDI Document Annotation 201307	Online Click Labels for CAL Ranker:End – To End:aether://experiments/31148112-679c-476c-91d0-bb3ebbef81c2Continuous trained module continuously trains trees using HRS and then the ranker.OFE Ranker Training Pipeline:aether://experiments/01dbe0	0.3385791296620987
PDI Document Annotation 201307	Domain Authority CAL One PageIntroductionCurrent shipped ngram domain authority in L3 is using complete query match against an offline generated meta-stream (q, url, score), which derives (q,url) pairs from click stream and is the result of aggregatio	0.33729866584276813
PDI Document Annotation 201307	Keyword Prediction for Local SearchesRuchir RastogiMentor: Jia LiuManager: Leon ZhangOutlineProblem statementTraining data and clean-up strategiesConditional random field (CRF) modelsDeep learning modelsEnd to end measurementConclusi	0.330249447721902
PDI Document Annotation 201307	Keyword Predictor Design DocumentName: Ruchir RastogiMentor: Jia LiuManager: Leon ZhangProject overviewThe goal of this project is to design a machine-learning model that can predict keywords in a local query for improving local search relevance	0.32917034874571843

PBA_dependency_20140128	PBA Dependency and DebugMing Wu2014-01-28PBA DependenciesLocation Understanding (LES/BLU)Location info (explicit/implicit) – fulfill detailed location infoProvide location related features to phonebook CRFXapQuServiceAnswer (QAS)For most c	0.7216273181770011
PBA_dependency_20140128	Microsoft ConfidentialSeptember 14, 2016AGI EngineCore Relevance PM TeamJanuary 26thHuman and Artificial IntelligenceOur Approach to an AGI EngineSolving the AGI Engine GoalsUpgrading our Search StackAgendaLets start with a conceptual 	0.3578859187248628
PBA_dependency_20140128	QR FY19 LRP Planning - 23/29/18Unified Concept Tagging – Key ChallengesStructural ComplexityFor ambiguous queries and multi-concept queries, how much organization is required?  How to represent this in a linear qlf?  What about inter-concept rel	0.3536100466313401
PBA_dependency_20140128	Local Junk Detection and DemotionJia Liu2017-06-14GDP Pipeline View: local data pipelineTriple StoreGOALStore every entity as a set of triples.Track all changes to an entity.TripleColumnDetailsSubjectThe guid of a triple’s pa	0.35254243349223374
PBA_dependency_20140128	QR Team ReviewJan 2017Team IntroductionConceptXDeep QRAgendaQR Team MembersDev Manager: Ciya LiaoLeads: Garrett Kaminaga, Jingwen Lu, Saekoo Lee, Gord LueckPMs: Shyam Jayasankar, Jie CaiSTC-A Speller team: Yongen Gong and his teamWha	0.35169639237830735
PBA_dependency_20140128	Bing Local Search				PBA QU Post-processing in QAS Dev ownerMing WuBuddy dev(s)PM ownerContributorsFeature areaPBA Query ProcessingMilestoneAluminumTable of contents1	Overview	22	Goals/Non Goals	23	Risks/Open Issues	24	Desi	0.3480154362573335
PBA_dependency_20140128	WrapStar On-Demand DesignDrafted by ZiliuContentsContext2Design Goals2Automation2Deployment Agility2High Availability2Non-Goals2Metrics2Required Changes3Orchestration3AP Migrations3Pipeline Evolution3Tools/services refactoring3	0.34237128253584254
PBA_dependency_20140128	NTCG DebuggingSteven Zittrower01/30/2015AgendaNTCGNTCG DashboardOverview of BLU Architecture (Address Specific)Address Debugging in QATNTCGNTCG (Normalized Total Cumulative Gain) is a composite metric that measures address query releva	0.34013133242719157
PBA_dependency_20140128	PBAVnext and migrationFrank ZhangBenefit of vnextIt will reflect five years’ worth of local search relevance insights and lessons learned, including the relevance tuning principles we have discovered over the years.It will make it easier to suppor	0.33766843514534434
PBA_dependency_20140128	How DUv2 worksZehua Liu, DU GDI Team12/6/2013 Q1: How to develop a DUv2 feature?Processor + Description fileQ2: How to guarantee monthly release?Q3: Difference between the development of DUv1 and DUv2 feature?DUv1: a) ProcessorCode  	0.33047797712808874

PBA_Query_Understanding_Migration	PBA Query Understanding MigrationTetyana Golub | Ming WuMotivationPBAvnextCurrent QU logic is complicated and hard to migrateLimitation from hard coded logicCurrent QU logic is complicated and not very flexibleHard to add new feature or adju	0.6267510221127914
PBA_Query_Understanding_Migration	Successful Feeds Query DebuggingNikita Melnichenko, 2015-03-10Feeds query debugging overviewWhen to use:Checking a new rankerChecking new augmentation before running a scrapeComparing several rankersUnderstanding feature contributionDebugg	0.40324942471650155
PBA_Query_Understanding_Migration	Tiger MigrationKefeng Deng6/15/2015Microsoft ConfidentialTiger MigrationMotivationTiger IntroductionHow do we get thereCurrent statusRemaining works6/15/2015Microsoft ConfidentialMotivationSame index serve architecture as Satori 	0.3884180977124504
PBA_Query_Understanding_Migration	PBAVnext and migrationFrank ZhangBenefit of vnextIt will reflect five years’ worth of local search relevance insights and lessons learned, including the relevance tuning principles we have discovered over the years.It will make it easier to suppor	0.37223925679181125
PBA_Query_Understanding_Migration	PBA Dependency and DebugMing Wu2014-01-28PBA DependenciesLocation Understanding (LES/BLU)Location info (explicit/implicit) – fulfill detailed location infoProvide location related features to phonebook CRFXapQuServiceAnswer (QAS)For most c	0.3676270709889037
PBA_Query_Understanding_Migration	Query Rewriting Micro SegmentWhy QR Micro SegmentMicro Segment is way to fix corner case that main Bing ranking pipeline couldn’t fix easily by machine learningThere are many ways to do micro segment. Micro segment can be done in many layers. QR, 	0.3533048215772632
PBA_Query_Understanding_Migration	Leveraging Satori Knowledge in Web Ranking StackMicroSegment and Index ServeMotivationTarget at semantic queries (*defined by MALTA)Often contain more than one entity and relationSometimes involve entity inferenceTerm matching may not handle s	0.3503673944938831
PBA_Query_Understanding_Migration	Content Quality Progress & StatusFeb 23, 2012Yi Li, Guihong Cao, Santhosh Kodipaka, Cheng NiuDocument UnderstandingAgendaContent Quality Problem AreasNDCG vs. SBSSummarizationProblemWhat We DidBing StatusScraperXXXSegment Aut	0.34403714077206565
PBA_Query_Understanding_Migration	Move SBS (Learning from L3)Xiaopeng WuJunzhou WangWhat’s L3Bing ranking stackIndex selectionWorking on offline system, target recallL1Working on IFM, target recallL2Working on IFM, target precisionL3Working on TLA, target whole pag	0.33995135988913766
PBA_Query_Understanding_Migration	Index Quality UpdateAgendaMetrics UpdateSelection Model ImprovementRecall TierOffice ImprovementChallenges and Pain PointsHow to measure index quality?Ideally: sampling from all “good” images and see how much we covered.sampling from a	0.32567185256039916

PBAVnext	PBAVnext and migrationFrank ZhangBenefit of vnextIt will reflect five years’ worth of local search relevance insights and lessons learned, including the relevance tuning principles we have discovered over the years.It will make it easier to suppor	0.5170191268095253
PBAVnext	PBA Query Understanding MigrationTetyana Golub | Ming WuMotivationPBAvnextCurrent QU logic is complicated and hard to migrateLimitation from hard coded logicCurrent QU logic is complicated and not very flexibleHard to add new feature or adju	0.2799781391051529
PBAVnext	Phonebook vNextDesign DiagramsPlease do not modify existing diagrams!To update a diagram, make copy of a slideand create a new version.Do not forget to update date and author.Local.Pba.MainLocal.Pba.ExecutionModeLocal.Pba.ResponseMuxMu	0.2525618108930778
PBAVnext	PBA Dependency and DebugMing Wu2014-01-28PBA DependenciesLocation Understanding (LES/BLU)Location info (explicit/implicit) – fulfill detailed location infoProvide location related features to phonebook CRFXapQuServiceAnswer (QAS)For most c	0.24428501203763567
PBAVnext	FY18 GreenlightLocal SearchJune 14, 2017FY18 Local Search: Top GoalsInitiativeMetricFY18 GoalsTop Segments (mobile and desktop): Competitive Segment SBS (mobile and desktop)TCxSBS weak score > 5 for EN-USSegments: Hotels, Retail, Hom	0.23920724968866036
PBAVnext	PhonebookQU and MetadataMing Wu2017-04-19What’s QU in PBASelect the appropriate location reference based on PBA Parser and LES response hard-coded rule based (Parser and LES result should not have conflict)Correct CRF parse based on lexicons a	0.2177261658343944
PBAVnext	Translation ModelMei YangDU talk5/11/2011OutlineIntroduction to Machine Translation (MT)Introduction to phrase-based statistical machine translation (PBSMT)Translation Model @ DUFuture WorkIntroduction to MTTranslate one natural langua	0.20192330951766685
PBAVnext	Bing Local Search				Phonebook vNext Design DocumentDev ownerMickadBuddy dev(s)MichstePM ownerDabargerContributorsFeature areaMilestoneTable of contents1	Overview	32	Goals/Non Goals	53	Dependencies	64	Risks/Open Issues	75	0.20189573818387685
PBAVnext	Text Latitude Longitude S0:Local_L3DCG3 G0:Local_L3DCG3 S1:Local_L3DCG3 S2:Local_L3DCG3 Assignment RootCause(BadMetastream,PartialMatch,Cal,BadKeyword,OtherQU,Ranker,BingNotStable,Scraping,Metrics,MicroSegment,JudgeNoise,Unknown,BadEntity) BTC CanBeResolv	0.1949044097940439
PBAVnext	PO Box 91059Seattle, WA 98111-9159	VISION 	Member Claim Form 	for Microsoft  This form is to be used for Vision claims (routine exam and hardware) where you incurred expenses from a provider who did not bill the plan directly.For Medical or De	0.19378280794551161

PBA Feeds Geo Augmentation generation	Bing Local Search				PBA Geo Location Feeds augmentation generation Dev ownerTetyana GolubBuddy dev(s)PM ownerDave BargeronContributorsFeature areaPBA Feeds query generationMilestoneAluminumTable of contents1	Overview	22	Goal	0.49023497697463214
PBA Feeds Geo Augmentation generation	FY18 AGI Encoder Roadmap		Nitin Sharma, Gargi Ghosh, Saurabh TiwaryAgendaIntroductionFY18 Goals and Focus AreasFocus Area Deep DiveCustomer scenariosDetailed RoadmapAGI Encoder: MotivationGoal: One general intent encoder of source 	0.45496031627739514
PBA Feeds Geo Augmentation generation	AGI - Web Search / Tail FY18 Roadmap 	Rohit Kapoor, Saurabh Tiwary, Gargi Ghosh, Chen Zhou,  Kushal LakhotiaFY17 RecapFY18 GoalsFY18 Focus AreasFY18 TimelineFocus Area Deep DivesAgendaFY17 RecapIn-Progress:[Fusion] Out of market [F	0.43847141780874344
PBA Feeds Geo Augmentation generation	Dynamic Rank FeaturesWritten by Krysta Svore (ksvore)This document is meant to give a brief overview of the features used in the dynamic ranking component of Live search.  It contains an overview of the search process followed by the definitions of cu	0.4319419631019729
PBA Feeds Geo Augmentation generation	Introduction to L1Xiao WuSearch Platform Tiger Team AgendaL1 goals and challengesMetrics and measurementL1 ranker and perf optimizationL1 ranking Perf optimizationDebugging tools L1 training and shippingThinking and discussionL1 	0.38493335402133966
PBA Feeds Geo Augmentation generation	AGI UpdateDL Representation & Applications for NLU TasksSubhojit Som(Subhsom), Chen Zhou(chzho)Xia Song (xiaso), Saurabh Tiwary (satiwary)October. 2016Agenda / UpdatesMachine Reading ComprehensionLearning Generic Representation aka Semanti	0.3778319969871214
PBA Feeds Geo Augmentation generation	PBA Query Understanding MigrationTetyana Golub | Ming WuMotivationPBAvnextCurrent QU logic is complicated and hard to migrateLimitation from hard coded logicCurrent QU logic is complicated and not very flexibleHard to add new feature or adju	0.3704451317133768
PBA Feeds Geo Augmentation generation	[IMPORTANT]Please notify “featfun” if you want to edit this document!!!Metastream FeaturesWritten by: Tian Xia (tixia@microsoft.com)Table of Contents1. Overview	62. Basics	82.1 Metastreams	9Single instance metastream	9Multi-instance meta	0.3697132657612464
PBA Feeds Geo Augmentation generation	FY19 Search & AI Roadmap Review: QRMay 2018Jie Cai, Garrett Kaminaga, Jingwen Lu, Momo JengMotivation – QR Query understanding and rewrite is the first opportunity for Bing to understand users’ intents;In current production, query rewrite is a	0.3660412580240454
PBA Feeds Geo Augmentation generation	PERM Labor Certification Questionnaire:  Technical (continued)PERM Labor Certification Questionnaire (Technical)Please complete the information requested in this questionnaire carefully.  This information is necessary for the legal analysis and prepar	0.3648206714077573

PAC_Introduction_(draft)	PAC: Features, Usage and ProcessThis is a document on how to get document features and build metaword/metastream via Page Analyzer and Classifier (PAC ) pipeline. ContentsKinds Of Features Supported By PAC	2Url/Title Features	2Body Features: Doc	0.3907054333442727
PAC_Introduction_(draft)	Entity Pane and Fact AnswerPresenter: Ze TianJun 25, 2013IntroductionIntroductionIntroductionProblems to SolveDoes the user search for entities or facts of entities?E.g. “who is msft ceo” (Entity: Microsoft, Fact: Chief Executive O	0.37274728128037604
PAC_Introduction_(draft)	Ranker Training Pipeline IntroductionAgendaPipeline OverviewGCC platformExtractionData/Feature PreparationMain Ranker TrainingSegment RankersPipeline OverviewGR OctTree: gcclinkMain Steps:Metastream injection (just info here)Querys	0.3673304819982275
PAC_Introduction_(draft)	Zh-cn Transportation Segment Optimization by Pattern EngineIntroductionThe pattern queries can cover almost 10% in all queries. We can summarize lots of patterns on Query and Document sides for different segments. We can recognize key terms, relations	0.34653196833500355
PAC_Introduction_(draft)	Introduction to dynamic ranking Xiao WuOutlinesIntroductionRelevance MeasurementDynamic rankingRanking FeaturesRanking DataRanking modelsRelevance ExperiementIntroductionWhat is dynamic rankingRanking based on query dependent featu	0.3263953639411533
PAC_Introduction_(draft)	Tiger MigrationKefeng Deng6/15/2015Microsoft ConfidentialTiger MigrationMotivationTiger IntroductionHow do we get thereCurrent statusRemaining works6/15/2015Microsoft ConfidentialMotivationSame index serve architecture as Satori 	0.31076458322574096
PAC_Introduction_(draft)	Handbook of MLGProcessor AEther ModulesContents1.	Introduction	72.	MLGProcessor Modules	82.1.	Common Module Parameters	8Inputs	8Outputs	8Parameters	92.2.	BodySurfaceStream	9Inputs	9Outputs	92.3.	BoundaryView	9Examples	102.4.	Char	0.3061158618599511
PAC_Introduction_(draft)	Play Book of Pattern Engine Based Micro-segment PlatformIntroductionNow, per query pattern match features (PMFs) are available for ranking. You can get PMFs of your own pattern groups (PGs) immediately after several simple steps. With these signals, r	0.29840759085975405
PAC_Introduction_(draft)	SKI online feature extraction design docTo build ML model to detect user intent and re-rank search result from different providers, we need training data. This document mainly covers the design how to collect the training data from the real Office usage	0.29688391150823085
PAC_Introduction_(draft)	L3 in LocalKefeng DengOutlineL3 IntroductionUse L3 in localL3 exampleL3 introductionFor Local: 28 IS machines per row, about 5 million entities per machine. MinBLA = 50L3 introductionL3 featuresSet featuresFeature Statistics for top 	0.29037321625169066

PA Selection Stack - 2017	PA Selection StackKeng-hao Chang3/8/2017AgendaQuery (offer) understandingRetail classifierCategorizerCRFSelection algorithmsRIIRNGSRanking methodsL0, L1, L1.5, L2, Attribute-awareRetail experiencePA stack via Components*RnR	0.47506416878542124
PA Selection Stack - 2017	Simplified Query Path SelectorSimplified query: current systemSimplified query path selectionCrf model produces a list of possible ways to place rankonly operatorQuery = “nibbana restaurant official site”nibbana restaurant rankonly:official site	0.25253476736708713
PA Selection Stack - 2017	Abacus Query Pattern SpecThis document describes how the query GEE pattern is passing from CAL into PDR, and generate a series of features depending on the <querypattern, URL-host> level matching. Query Property of GEEHere is the query property defi	0.23305122495577799
PA Selection Stack - 2017	Entity Selection ModelJia Liu2017-11-08GDP Pipeline View: local data pipelineEntity TypesEntity Types:Open/CloseHead/TailNonJunk/JunkJunk TypesGhost: Local business existed beforeJunk: General name like “Lock smith”, “ATM”Move/Br	0.2156086274575811
PA Selection Stack - 2017	Query Automotive & Vehicle Services (90056) Banking & Finance (90111) Beauty & Spa (90353) Food & Drink (90232) Healthcare (90375) Professionals & Services (90496) Real Estate (90584) Retail (90628) Sports & Recreation (90848) Travel (90881) Other Categor	0.20843161273404204
PA Selection Stack - 2017	Restaurant segment metrics collectionObjectiveTo understand user behavior/engagement on Restaurant answers.Why this is important? The metrics will help us understand:The comparisons between different answersWhat is important to our users and w	0.20725647941549796
PA Selection Stack - 2017	Ranker Training Pipeline IntroductionAgendaPipeline OverviewGCC platformExtractionData/Feature PreparationMain Ranker TrainingSegment RankersPipeline OverviewGR OctTree: gcclinkMain Steps:Metastream injection (just info here)Querys	0.20725387199826348
PA Selection Stack - 2017	Entity Selection Pipeline Design DocScope:This document covers the design for entity selection pipeline in GDPV3. Near-Dupe clustering is not covered in this v1 version. The goal for this pipeline is to reduce junk rate and improve NII by stamping pub	0.17640742548145924
PA Selection Stack - 2017	Query Simplification Deep DiveJON Fu12/11/2017AgendaQuery Simplification Motivation and TheoryQuery Simplification for WebQuery Simplification for Cortana 3ARecent Progress in Query Simplification WorkReferencesIntroductionMotiva	0.1715040181214098
PA Selection Stack - 2017	Leveraging Satori Knowledge in Web Ranking StackMicroSegment and Index ServeMotivationTarget at semantic queries (*defined by MALTA)Often contain more than one entity and relationSometimes involve entity inferenceTerm matching may not handle s	0.17066579325206246

OpalOSearch	Find Deals with OpalKelly You, Jia Liu, Leon Zhang7/11/2016AGENDAScenariosTechniques & ChallengesNext StepsQ&AScenariosSearch Store DealsBrowse Nearby DealsFilter Restaurants with DealsDeal Action in Entity Detail CardTechniques 	0.32635551117942807
OpalOSearch	Opal OSearch & XAP flight frameworkKevin Su & Duat Le06/22/2016OverviewOSearch basicsOpal OSearch high-level architectureProcess to onboard new feature for Opal OSearchXAP flight framework in OsearchOSearch basicsWhat's OSearch?A platf	0.3081543508981104
OpalOSearch	GoldenQuery: Past Flights v1Session v1Nov, 2013Simple Explanation of GoldenQueryQuery level Explore & ExploitExplore against techniqueMemorization basedGQ service running before speller, intercept every queryContinues E&E{Microsoft off	0.22591618163380736
OpalOSearch	Golden QueryEvery query countsImprove relevance: Relevance TechniquesWin/Loss basedGood technique has better win/loss ratioGeneric Ranker always doesn’t have good win/loss ratioWe do technique triage, and better win/loss ratio technique got sh	0.20687731435507703
OpalOSearch	Combined ALterationsNeon\sodiumAgendaNeon AchievementsBreakdownsSodiumIdeas & PlanNeonOverall ProgressExceeded Neon Commitments on CQS!NeonCQS Deep-dive-34% Bad+14% Excellent-15% Bad+13% ExcellentDRDOCQS is impr	0.17586398126953653
OpalOSearch	Anchor and Click Stream RankingSteven ZittrowerBing Local Search RelevanceHypothesisConverting local search’s unstructured and raw text streams into semi-structured forms will improve ranking and offer relevance benefits.TestUsing classifiers 	0.17560540097255578
OpalOSearch	Local Category Search Plan3 month StrategyData: Entity categorizationScalable, high precision/recallSegments: Food & Drink, Retail, Service, Auto, HotelMetaStream enrichmentQuery UnderstandingDolphin by defaultConsume PhoneBookQU to im	0.17477901281593822
OpalOSearch	Relevance ServiceScenarioIconApplicationDoc typeCandidatesModelRun0-termWord;OutlookWin32 client.All file typesMRUReuse ContentModel 1Client0-termPower PointWin32 client.Only ppt typeLocal + MRUReuse Conte	0.17408124034851652
OpalOSearch	Normalization and Parsing OverviewTypes of NormalizationLimiting to just normalization, there are actually several different types of normalization which may be interesting:WhitespaceThis is:Converting all whitespace characters to spacestrippi	0.16848086749602773
OpalOSearch	Simplified Query Path SelectorSimplified query: current systemSimplified query path selectionCrf model produces a list of possible ways to place rankonly operatorQuery = “nibbana restaurant official site”nibbana restaurant rankonly:official site	0.16702646638458574

Online Click Labels	Bing Adult FilteringNeil ZhaoSmart adult filtering GloabelSmartAdultFiltering=offSmartAdultFiltering=onStrict-category:ff000001tla:adultfilter:onModerateprefer:-category:ff000001tla:adultfilter:smartOff tla:adultfilter:off ZH	0.19400545346016895
Online Click Labels	PERM Labor Certification Questionnaire:  Technical (continued)PERM Labor Certification Questionnaire (Technical)Please complete the information requested in this questionnaire carefully.  This information is necessary for the legal analysis and prepar	0.19088058353242962
Online Click Labels	Document classification based on urlBackgroundWe want to do document classification for better understanding the document type and document with query category match for ranking.  We will do zh-cn document classification based on url first, then docum	0.18852211224031734
Online Click Labels	Online Click Labels for CAL Ranker:End – To End:aether://experiments/31148112-679c-476c-91d0-bb3ebbef81c2Continuous trained module continuously trains trees using HRS and then the ranker.OFE Ranker Training Pipeline:aether://experiments/01dbe0	0.1752482140566135
Online Click Labels	I-130 Questionnaire for the Petitioner (Husband or Wife)PLEASE LEFT CLICK ON GRAY FIELDS TO ENTER DATA.  PLEASE DO NOT (A) MODIFY THE FORMAT OF THIS DOCUMENT, (B) USE ALL CAP'S; OR (C) RIGHT-CLICK ON GRAY FIELDS.  IF YOU SAVE THIS DOCUMENT, PLEASE SAVE 	0.16801970086539245
Online Click Labels	Zhcn document classification based on topicJia Liu2012.11.14agendarTraining data selection&crawl&cleanFeature selection&cleanClassifierRating Bad case analysisTrainning data	0.15416355810723498
Online Click Labels		0.14449447522230713
Online Click Labels	Click to edit Master title styleEdit Master text stylesSecond levelThird levelFourth levelFifth levelThis deck is intended for use with INTERNAL AND EXTERNAL audiences.The slides and talking points are designed to help you tell our culture s	0.14019188741837696
Online Click Labels	Meta-stream work summaryHeyong WangClickstream exampleOverview: Click-Stream generationWeb logsLocal logsLocal clicked dataJoin with Local IndexWeb Clicked data (query, url etc.)IE ClickBing ClickIE SessionIE Tool Bar…Web Click	0.13737850175176705
Online Click Labels	TopChainNumber MasterId Label Type Name Phone AddressLine City Website Closed LastYearImpression LCMScore ChainId ChainName Score LPLink SparsedFeatureVector r 873x114637191399090866 0 http://maps.google.com/maps/place?cid=14233605658129796921 Ion Bank 36	0.1273285296278981

Offline_Simulation_in_CAL	Offline Flight Simulation and JO triggering in CALMomo JengOffline Flight SimulatorOffline simulator:System for evaluation of models: What would we have seen in Foray, had we flighted this model?Used to optimize JO triggering for click metrics.	0.6095336425873386
Offline_Simulation_in_CAL	Offline Simulator in ChlorineOffline simulator in ChlorineOffline simulator in Chlorine (Jan-Jun 2016):New Query Simplification Path (QS3) in en-*European Query SimplificationRelaxcount in en-*New infrastructure in en-non-USNew triggering th	0.5562656168793025
Offline_Simulation_in_CAL	Smart relax, 3-way choiceMomo JengOffline simulationGeneral process for offline simulation:We have n choices to decide between, where n is small.Given choices A, B, and C, randomly show users A, B, or C.Randomization can be per-user (i.e. se	0.3754261385478343
Offline_Simulation_in_CAL	Global CAL Aluminum PlanJunfeng ZhouAgendaMagnesium StatusAluminum FocusProjectsMagnesium Status - ReleasesJuly: aggressive relaxation on no result queriesSept: relax count classifier, morphological alterationsOct: JO v1Nov: morphologi	0.19461181161740504
Offline_Simulation_in_CAL	CAL OFE logsOFE raw logs are cooked with the CALOFELogExtraction script, located in answers_alterations\private\OfflineDataGen\QueryAlteration\CALOFE\CALOFE.slnCooking the raw logsTo cook your logs, you need to runanswers_alterations\private\Offli	0.18138375979547355
Offline_Simulation_in_CAL	Local and mm magnesium asksCALApril 2013Microsoft ConfidentialContextWe are expanding to many international markets for Win-blueCAL/Speller impact can range from -1 to +2 points in DCG. Recent MM US DSAT analysis (Dec 2012) showed close to 1	0.17619311068434018
Offline_Simulation_in_CAL	Primary Category: What Is It, Why Is It Important, & How Do We Measure ItBing Local & Geospatial – ShruthiM, DillTellClassificationProcess in which local business entities are categorized based on the type of products and/or services that the busine	0.15772456619805553
Offline_Simulation_in_CAL	L4 Experiment PipelineDate: Aug 20th, 2013Author: Bangyong LiangMotivation:L4’s functionality is to merge results from multiple queries. L4 has two types of merging strategies. One is query level merger and the other one is document level merger. 	0.14577987265623538
Offline_Simulation_in_CAL	The follow diagram illustrates the whole pipelineThe session ranker uses the following features from four categoriesOn Session:A session is defined to be a sequence of user’s clicks and queries. In this project we refine the session to be the peri	0.13891979800967494
Offline_Simulation_in_CAL	DU Pipeline Sodium Achievements And Magnesium Plans　　Jia Liu2013-08-05OutlineSodium AchievementsMagnesium PlanMagnesium Work ItemsSodium Work ItemsAppendixSodium AchievementsWrapstar rating signalsTaobao, tmall; qna; novel; videoL3	0.13706343756744718

OfflineSimulator_Chlorine_2016	Offline Simulator in ChlorineOffline simulator in ChlorineOffline simulator in Chlorine (Jan-Jun 2016):New Query Simplification Path (QS3) in en-*European Query SimplificationRelaxcount in en-*New infrastructure in en-non-USNew triggering th	0.7371945989873308
OfflineSimulator_Chlorine_2016	Offline Flight Simulation and JO triggering in CALMomo JengOffline Flight SimulatorOffline simulator:System for evaluation of models: What would we have seen in Foray, had we flighted this model?Used to optimize JO triggering for click metrics.	0.5684847478682932
OfflineSimulator_Chlorine_2016	Smart relax, 3-way choiceMomo JengOffline simulationGeneral process for offline simulation:We have n choices to decide between, where n is small.Given choices A, B, and C, randomly show users A, B, or C.Randomization can be per-user (i.e. se	0.39054914615499225
OfflineSimulator_Chlorine_2016	Global CAL Aluminum PlanJunfeng ZhouAgendaMagnesium StatusAluminum FocusProjectsMagnesium Status - ReleasesJuly: aggressive relaxation on no result queriesSept: relax count classifier, morphological alterationsOct: JO v1Nov: morphologi	0.3036270646446165
OfflineSimulator_Chlorine_2016	DU Pipeline Sodium Achievements And Magnesium Plans　　Jia Liu2013-08-05OutlineSodium AchievementsMagnesium PlanMagnesium Work ItemsSodium Work ItemsAppendixSodium AchievementsWrapstar rating signalsTaobao, tmall; qna; novel; videoL3	0.2761139640203135
OfflineSimulator_Chlorine_2016	YPCutoff Selection                                                                                    -Ganesh Poomal GirirajanQuery Flow in IndexFilterSet GenerationL1 RankingL2 RankingExampleQuery: Southeast{Miami,Florida}-broward county sc	0.23031589636305808
OfflineSimulator_Chlorine_2016	Jia Liu2013-08-05DU Pipeline Sodium Achievements And Magnesium Plans For CJK　　OutlineSodium AchievementsMagnesium PlanMagnesium Work ItemsSodium Work ItemsAppendixSodium AchievementsWrapstar rating signalsTaobao, tmall; qna; novel; v	0.22396264994690374
OfflineSimulator_Chlorine_2016	DU Pipeline V2Bram Gruneir, Ted Wild and Connie YangDocument Understanding Dev Talk6/27/2013DU Pipeline V2: frequency demoIntroduce the demo featureDevelopmentDeploymentDU Pipeline V2: frequency demoIntroduce the demo featureDevelopmen	0.22380890306992365
OfflineSimulator_Chlorine_2016	Index Quality Team’s Deep Learning ExperienceLuke ChenOutlineMotivationsCNTK/Phily ExperienceIQ team DL projects highlightsResourcesMotivationsRecent progress in deep neural net provides inspirations to upgrade Bing’s machine learning stac	0.21177530090105998
OfflineSimulator_Chlorine_2016	InstructionS FOR obtaining photographsfor your applicationPHOTO REQUIREMENTS:Your photographs must be:2x2 inches in size Identical Taken within 30 days of filing the application(s), showing current appearance In color Full face, front view	0.20069056695222046

Office Shredding Service (Brownbag)	Office Shredding ServiceSKI Tech Talk – 3/29What do we shred?Office documents into reusable piecesService powering Add From Files in Word, Reuse slides in PPT, Files tab in Microsoft SearchAPIsGoLocalSearchShredding APIs (Document Manifest	0.6216588728092369
Office Shredding Service (Brownbag)	Tiger Index BrownbagHui ShenSearch Platform Tiger TeamAgenda	OverviewKey ideasTiger architectureTiger ++ 2/24/2012Agenda	OverviewKey ideasTiger architectureTiger ++ 2/24/2012What is Tiger IndexAn new index serve technol	0.35655898229013977
Office Shredding Service (Brownbag)	Bing Adult FilteringNeil ZhaoSmart adult filtering GloabelSmartAdultFiltering=offSmartAdultFiltering=onStrict-category:ff000001tla:adultfilter:onModerateprefer:-category:ff000001tla:adultfilter:smartOff tla:adultfilter:off ZH	0.3065157498619909
Office Shredding Service (Brownbag)	Bing Local Search				Phonebook vNext Design DocumentDev ownerMickadBuddy dev(s)MichstePM ownerDabargerContributorsFeature areaMilestoneTable of contents1	Overview	32	Goals/Non Goals	53	Dependencies	64	Risks/Open Issues	75	0.2948476284777354
Office Shredding Service (Brownbag)	Blue-Whale Multimedia Rank Data-FlowEugene Jian Huangjianhua@microsoft.com2012-03-13MM Page Static RankMedia LinkExpress RankMM Page Express RankMM PageSuper-Fresh RankMM PageSubmission RankMM PageEffective Rank Media Entit	0.27677473057171303
Office Shredding Service (Brownbag)	NTCG DebuggingSteven Zittrower01/30/2015AgendaNTCGNTCG DashboardOverview of BLU Architecture (Address Specific)Address Debugging in QATNTCGNTCG (Normalized Total Cumulative Gain) is a composite metric that measures address query releva	0.2748230280679885
Office Shredding Service (Brownbag)	LEDB Transition8/6/2014ScopeLEDB serialization jobsLEDB Object Store publish jobsLEDB Odyssey Publish job for the VanueMap featureEntity Schema update and maintenanceObject Store payload size and perf SLAPartner engagement and change manag	0.27356339384646167
Office Shredding Service (Brownbag)	After Action Report TellMeService, Shredder, AugmentationService, Enrichment, UCIService (Insights), Entity Service<<insert Service Name>>	 [Technology /Service Name]Disaster Recovery Plan (DRP)	 						Office Group Name : After Action Report 	0.266848782643109
Office Shredding Service (Brownbag)	Debug Address Queries8/23/2013Bing Local Search RelevanceNTCG MetricsDocumentationhttps://microsoft-my.sharepoint.com/personal/aoakley_microsoft_com/Documents/2013/2013-05-22%20Maps%20metrics%20Qi.pptx?web=1Use it to identify the group of quer	0.26066485401418127
Office Shredding Service (Brownbag)	Brownbag:ElasticSearch ExtensibilityHeather Nakama (henakama)Azure Search09/04/14AgendaIntroductionModulesPluginsFinding extensibility pointsEnd-to-end exampleTips and tricksQ/AIntroductionHeather NakamaDeveloper with Azure S	0.2606264223308018

Office Relevance Service	WPO Local Relevance Tech TalkWPO Local Relevance TeamOverviewWPO’s role in local relevance pipelineLocal ExperienceArchitecture overviewMetricsWPO Local Relevance Model IntroductionWPO Query understanding and Location understandingWhy do	0.34030408139477836
Office Relevance Service	File Relevance Experimentation Design DocRecall AnalysisTest the search quality of external services like OLS, 3S, QF and SPO Search.Search scenarios: 0-term search, term search, 3S (Insert File and Attach File).Compare the recall: diff of returne	0.2898776917367417
Office Relevance Service	Whole Page RelevanceShip Meeting 08/14/2012AgendaSummary of IssuesSpecial TopicsWhole Page Relevance - IssuesTeamIssue Description StatusOwnerDue Action UpdateINTL Mon-GsheldonNo major issuesCaptions MetricsSBS – Monthly 	0.24078220164919356
Office Relevance Service	Relevance Debug InfrastructureProblemFrequent  daily metric fluctuationRelevance gain negated by regressions from Sep to Oct 2013Painful to investigateChallengeLocal stack is complex with lots of componentsVarious relevance events mixed toge	0.22128515958038827
Office Relevance Service	After Action Report TellMeService, Shredder, AugmentationService, Enrichment, UCIService (Insights), Entity Service<<insert Service Name>>	 [Technology /Service Name]Disaster Recovery Plan (DRP)	 						Office Group Name : After Action Report 	0.22002952245660712
Office Relevance Service	Core Web RelevanceFY16 H2 PlanCore Web RelevanceFY16 H2 PlanCore Web RelevanceFY16 H2 PlanCore Web RelevanceFY16 H2 Plan	0.21605344174611252
Office Relevance Service	WPO Local RelevancePing Yin2017-03-21OverviewWPO’s role in local relevance pipelineLocal Entity StampingArchitecture overviewWPO Local Relevance Models.Query: exton mall, User location: Wallingford, PAWPO RolesExtract/detect all entity	0.21468314724917642
Office Relevance Service	Distance Model, LDS, L3Knowledge SharingNikita Melnichenko, Bing Local2017-04-21Overview of PBA relevance flow in FeedsL1Keyword matchWPOL2 levelRankerTruncationCategory matchName matchLogical DistanceUI sortingGIMXIMGDM	0.21343196797941452
Office Relevance Service	Debug Address Queries8/23/2013Bing Local Search RelevanceNTCG MetricsDocumentationhttps://microsoft-my.sharepoint.com/personal/aoakley_microsoft_com/Documents/2013/2013-05-22%20Maps%20metrics%20Qi.pptx?web=1Use it to identify the group of quer	0.20570460097598428
Office Relevance Service	Relevance Experimentation with DUOverviewThe ideal end state for any relevance improvement would consist of having one or more DU features shipped in the index that is then leveraged by the latest production ranker. This would achieve the highest leve	0.19308159313753107

Offer of Jia Liu	To whom it may concern,  We are Jia Liu and her husband, Edward Wild.  The bearers of this letter are Jia's mother, Chunxiang Lei, and father, Xinbao Liu.  Jia is a software engineer working at Microsoft on an L1 visa valid until 2020, and Edward is a	0.4722467708528712
Offer of Jia Liu	6/8/2016To Whom It May Concern:Re:	Jia LiuThis letter is to confirm that Jia Liu was employed at Microsoft (China) Company Limited in Beijing, China from March 30, 2012 to June 21, 2015.  She worked full time, 40 hours per week.  Sincerely,Xue B	0.4630365262426805
Offer of Jia Liu	To whom it may concern,The bearer of this letter is my sister, Yan Liu. My name is Jia Liu, and I am a software engineer employed by Microsoft. I am working here on an L1 visa valid until 2019. I have invited my parents, my sister, and her son to come v	0.4581744216234907
Offer of Jia Liu	To Whom It May ConcernPage 2DATETo Whom It May Concern:Re:	Jia LiuI write to certify that Jia Liu worked as a Software Development Engineer at Microsoft (China) Company Limited (Microsoft China) in Beijing, China from March 30, 2012 to September	0.45122001744098256
Offer of Jia Liu	To whom it may concern,The bearers of this letter are my parents and nephew.  My name is Jia Liu, and I am a software engineer employed by Microsoft.  I am working here on an L1 visa valid until 2019.  I have invited my parents, my sister, and her son t	0.41974747004679913
Offer of Jia Liu	To whom it may concern,We are Xinbao Liu and Chunxiang Lei, a married couple.  We are citizens of China visiting our daughter and son-in-law in Bothell, Washington on valid US B-2 visas.  Our daughter, Jia Liu is a citizen of China residing in the Unite	0.4154523341415974
Offer of Jia Liu	Jia Liu2013-08-05DU Pipeline Sodium Achievements And Magnesium Plans For CJK　　OutlineSodium AchievementsMagnesium PlanMagnesium Work ItemsSodium Work ItemsAppendixSodium AchievementsWrapstar rating signalsTaobao, tmall; qna; novel; v	0.3695796652309727
Offer of Jia Liu	Local Popularity V2Xiaohui Liu, Dave Bargeron, Fengxia PanAgendaProblem and motivationSolutionTechnique deep diveFeature MeasurementPipeline GDI marketsFuture workMotivationEnable LDCG v2Improve local search relevanceRelated 	0.330187294617546
Offer of Jia Liu	Page 23 of 26L2 General Title MatchDev: Jia Liu, Chuan Cao, Albert ZhouPM: Jin GuoDoc version: v1.0ContentsAbstract	2Project Status	2Goals	2Problem statement	3Architecture	3N-Gram Table	4Query Distribution in N-Gram Table	5Query 	0.3219632062672617
Offer of Jia Liu	学士学位证明BACHELOR DEGREE CERTIFICATEThis is to certify that Ms. Jia Liu, born in August 1986, with the specialty of Computer Science and Technology at Beijing University of Posts and Telecommunications from September 2005 to July 2009, has passed all req	0.32109482601664685

ODP Classification	ODP Classification: Summarizing Pages as a Topic DistributionNov 17, 2010Paul Bennett (pauben), MSR CLUESJoint work with Max Chickering & Susan Dumais© 2006 Microsoft Corporation. All rights reserved. Microsoft, Windows, Windows Vista and ot	0.5519592372432764
ODP Classification	Zhcn document classification based on topicJia Liu2012.11.14agendarTraining data selection&crawl&cleanFeature selection&cleanClassifierRating Bad case analysisTrainning data	0.4845194332766429
ODP Classification	Zh-cn Document classification based on topicBackgroundWe want to do zh-cn document classification for better understanding the document type and topic. It can help ranking with document and  query category matching. We defined our category system: 69 	0.4068726087707999
ODP Classification	Document classification based on urlBackgroundWe want to do document classification for better understanding the document type and document with query category match for ranking.  We will do zh-cn document classification based on url first, then docum	0.3814842988038724
ODP Classification	Ranker Training Pipeline IntroductionAgendaPipeline OverviewGCC platformExtractionData/Feature PreparationMain Ranker TrainingSegment RankersPipeline OverviewGR OctTree: gcclinkMain Steps:Metastream injection (just info here)Querys	0.35909346970524136
ODP Classification	Auto Category Classification PipelineHanqing Cui2012/10/25OutlinePain PointsThinkingAuto Category Classification PipelineAuto Page LabelingData SamplingTrainingFeature SelectionThresholdIterative TrainingInitial Seed Model Creati	0.34231258881898496
ODP Classification	ML Model Scorecard Analysis8/8/2019Unexpected term search movementhttps://exp.microsoft.com/xcard/?view=4e77b420-7b77-4e41-92ac-8e84f506fb01Check correctness of scorecard metric implementationCalculate term AVG rank from raw data streamsSearch	0.3345409802163086
ODP Classification	Competitive Query-Entity ClickMicrosoft ConfidentialMicrosoft ConfidentialGoalCreate a dataset that is readily available to utilize and analyze query-entity click patterns on competitive dataCompetitive Engine: GoogleMicrosoft ConfidentialCo	0.3320931966507877
ODP Classification	Zh-cn Transportation Segment Optimization by Pattern EngineJia Liu/Allen WangDSATsQuery: 吉林市到查干湖Relevant result title: 吉林市到查干湖怎么走近？_百度知道Irrelevant result title 1: 查干湖,中国查干湖,吉林查干湖,查干湖旅游,查干湖冬捕,国家AAAA ...Irrelevant result title 2: 查干湖_百度百科Irrel	0.329222220830758
ODP Classification	Publication date optimization for zh-cn marketBackgroundPublication date is a very fundamental and important feature. It can help fresh ranking, whole page user experience: caption date show and freshness internal metrics, also to solve mainline out	0.32497554827792247

O365Brownbag_Session2_MetricsPipeline	NTCG DebuggingSteven Zittrower01/30/2015AgendaNTCGNTCG DashboardOverview of BLU Architecture (Address Specific)Address Debugging in QATNTCGNTCG (Normalized Total Cumulative Gain) is a composite metric that measures address query releva	0.4984549118889426
O365Brownbag_Session2_MetricsPipeline	IQ Team RecapH1 2016FY16H1 AccomplishmentsTeamSSRxen-* Desktop SBSen-* Mobile SBSen-* Semantic SBSCore Web Relevance0.55/0.62.46/3.02.65/3.01.88/2.0Adult LeakageSpamJunkCQDCGMPCMALTABing@WorkSubstrate0.02/0.01	0.4876197883239469
O365Brownbag_Session2_MetricsPipeline	Microsoft ConfidentialSeptember 14, 2016DRAFTSearch and AI PM Team MeetingApril 14th 2017Our MissionWho are we?Thoughts on PMQ&AAgendaThe 5 Priorities for Artificial Intelligence and Research Bing becomes 10 billion dollar business	0.47497483422105774
O365Brownbag_Session2_MetricsPipeline	Home TeamLocal Brown Baghttp://aka.ms/gethometeam ADContactsBusiness cardsAppsEmailsWeb searchThe opportunity For consumers: Most people prefer to use referrals, or “word of mouth” Competition doesn’t embrace thisAmazon – anony	0.4728136566953159
O365Brownbag_Session2_MetricsPipeline	FusionByTurker KeskinpalaTuesday, May 17, 2016OverviewMotivationsWhat is Fusion?GoalsFusion ComponentsRoadmapWeb AnswerQ:“gg”Qpath1:“gg”Qpath2:“google”TLACDG FetcherL2 FetcherTLACDG FetcherL2 FetcherLL4L3L3	0.45299582779425135
O365Brownbag_Session2_MetricsPipeline	Tiger Index BrownbagHui ShenSearch Platform Tiger TeamAgenda	OverviewKey ideasTiger architectureTiger ++ 2/24/2012Agenda	OverviewKey ideasTiger architectureTiger ++ 2/24/2012What is Tiger IndexAn new index serve technol	0.4313494041371341
O365Brownbag_Session2_MetricsPipeline	Online Click Labels for CAL Ranker:End – To End:aether://experiments/31148112-679c-476c-91d0-bb3ebbef81c2Continuous trained module continuously trains trees using HRS and then the ranker.OFE Ranker Training Pipeline:aether://experiments/01dbe0	0.4164820239141809
O365Brownbag_Session2_MetricsPipeline	FY18 GreenlightLocal SearchJune 14, 2017FY18 Local Search: Top GoalsInitiativeMetricFY18 GoalsTop Segments (mobile and desktop): Competitive Segment SBS (mobile and desktop)TCxSBS weak score > 5 for EN-USSegments: Hotels, Retail, Hom	0.4112094948276449
O365Brownbag_Session2_MetricsPipeline	Pthreads mutex vs Pthreads spinlock 锁机制(lock) 是多线程编程中最常用的同步机制,用来对多线程间共享的临界区(Critical Section) 进行保护。Pthreads提供了多种锁机制,常见的有：1) Mutex（互斥量）：pthread_mutex_***2) Spin lock（自旋锁）：pthread_spin_***3) Condition Variable（条件变量）：pthread_con_***4) Read/Write 	0.41024330141974696
O365Brownbag_Session2_MetricsPipeline	Debug Address Queries8/23/2013Bing Local Search RelevanceNTCG MetricsDocumentationhttps://microsoft-my.sharepoint.com/personal/aoakley_microsoft_com/Documents/2013/2013-05-22%20Maps%20metrics%20Qi.pptx?web=1Use it to identify the group of quer	0.4037187666038813

November 2016 Harry - SVMT Relevance and Platform	PDI Document AnnotationPDI Ranking PlatformAgendaPDI and forward indexDocument AnnotationSodium update and MG planQ&A DSAT: {books by children}Issue: Document matches the query terms, but its surrounding words may change the intent of 	0.4438491380956147
November 2016 Harry - SVMT Relevance and Platform	BLU V3 Minghua Zhang      01/26/2016Next version of BLU Relevance Infrastructure​OutlineWhy BLU v3BLU v3 DesignCurrent StatusFuture WorkWhy BLU v3 (1)Limitations of current BLU infrastructureFeaturesCouldn’t utilize QAS feature	0.4299274465385777
November 2016 Harry - SVMT Relevance and Platform	Dynamic Rank FeaturesWritten by Krysta Svore (ksvore)This document is meant to give a brief overview of the features used in the dynamic ranking component of Live search.  It contains an overview of the search process followed by the definitions of cu	0.3920546322469787
November 2016 Harry - SVMT Relevance and Platform	Distance Model, LDS, L3Knowledge SharingNikita Melnichenko, Bing Local2017-04-21Overview of PBA relevance flow in FeedsL1Keyword matchWPOL2 levelRankerTruncationCategory matchName matchLogical DistanceUI sortingGIMXIMGDM	0.3587013304815713
November 2016 Harry - SVMT Relevance and Platform	Restaurants Features and ToolsReview SnippetXAPOSearchQueryWPOLERWPO OSCacheItemCacheIdList of YpIdsFiltersSorterEntityUpdate PostFixEntity Update OSCache IdCache ItemYpId and PostFixUXReview Snippet Data GroupCac	0.3321429161020517
November 2016 Harry - SVMT Relevance and Platform	Progress in BLU Relevance  Marta Penas Centeno (mapena)Minghua Zhang (minghuaz)Jian Wu (jianwu)OutlineBLU as a service is the goal of our relevance improvementsBLU v3 is the relevance platform for BLU as a serviceRelevance improvements del	0.32582763593100306
November 2016 Harry - SVMT Relevance and Platform	CJK RELEVANCE ALL HANDS03/06/201401Qi ASG Memo02MS Poll	03USBS MeasurementAGENDA04Win in USBSVideoEbookMemo DocWatch the VideoVideoIntroductionWho We AreOur VisionClosingDiscussion and QnA01Qi ASG Memo02	0.32214014780001354
November 2016 Harry - SVMT Relevance and Platform	Bing Location Understanding (BLU)Marta Penas CentenoBoot camp (03/30/2016)BLU overviewLocation candidate extractionFeature extractionRankingTruncationLocation candidate extractionLocation candidate extractionFeature extractionRan	0.31813252695280364
November 2016 Harry - SVMT Relevance and Platform	Summary and HighlightsIn April the metrics/measurement team released local AutoSuggest metric and shared initial transit measurement results; BLU team shipped CL 1.0 ontology and deployed BLU v3 to all markets; PBA team shipped a new L2 ranker and refre	0.3173219595164051
November 2016 Harry - SVMT Relevance and Platform	PBAVnext and migrationFrank ZhangBenefit of vnextIt will reflect five years’ worth of local search relevance insights and lessons learned, including the relevance tuning principles we have discovered over the years.It will make it easier to suppor	0.31722909562267315

Normalization and Parsing Overview	Normalization and Parsing OverviewTypes of NormalizationLimiting to just normalization, there are actually several different types of normalization which may be interesting:WhitespaceThis is:Converting all whitespace characters to spacestrippi	0.7621741698503922
Normalization and Parsing Overview	Span ClassifierSpan classifier is a general infrastructure that can be used to run a fastrank based classifier on a sequence of terms from a query.  It can be used to apply rankonly or norelax to parts of the query based on the result of the model.  Fea	0.33471021452879035
Normalization and Parsing Overview	Provider Feature Measured Coverage Corrected Coverage(Exclude No Rating) Improved Coverage Estimate(Include No Rating) Note Amazon Price Amazon Availability Amazon Rating&Count >95% >92% 1. A known client issue:The current logic is to show the rating&cou	0.33293183660968134
Normalization and Parsing Overview	Document classification based on urlBackgroundWe want to do document classification for better understanding the document type and document with query category match for ranking.  We will do zh-cn document classification based on url first, then docum	0.31284914534982716
Normalization and Parsing Overview	Zh-cn Document classification based on topicBackgroundWe want to do zh-cn document classification for better understanding the document type and topic. It can help ranking with document and  query category matching. We defined our category system: 69 	0.30614026980490966
Normalization and Parsing Overview	No Results Workflow ImprovementsBackgroundToday’s No Results workflow looks at the number of documents returned by WebAnswer, and if it is exactly zero, will make a second call to alterations for aggressive treatment, and a second call to WebAnswer wi	0.3041376403317942
Normalization and Parsing Overview	Phrasal Alterations & CAL Infra 		Page 2 of 2Phrasal Alterations & CAL Infra DescriptionPhrasal Alterations is going to add CAL the functionality of doing N-to-M alterations. Given a query, CAL is going to generate multiple candidate queries without	0.29912577509001015
Normalization and Parsing Overview	Relevance Experimentation with DUOverviewThe ideal end state for any relevance improvement would consist of having one or more DU features shipped in the index that is then leveraged by the latest production ranker. This would achieve the highest leve	0.2745662813498114
Normalization and Parsing Overview	Project-N DeepDiveAbstractSimilarity issue has been one of the biggest problems of zh-CN relevance for years but not well got solved. In this document, we will focus on one of the main problem of similarity - entity/phrase mismatch issue in query/doc 	0.25058789907611095
Normalization and Parsing Overview	Site Quality ClassificationGuihong CaoDefinition of the ProblemWhat is site quality?Google’s definition includes the following dimensionsDuplicated content within the siteTrustworthyOn demand media? Quality controlSite authorityAuthor 	0.24329672346356535

No Results Workflow Improvements	No Results Workflow ImprovementsBackgroundToday’s No Results workflow looks at the number of documents returned by WebAnswer, and if it is exactly zero, will make a second call to alterations for aggressive treatment, and a second call to WebAnswer wi	0.788089441186733
No Results Workflow Improvements	AgendaAres Data Access FrameworkEntitySet Creation WorkflowMetric CalculatorQuestion & AnswerARES logical conceptsARES AssetsLogical ModelEntity/RelationRelated RVT data model ARES Data ModelUnit of ExecutionEntityJobTask	0.4104429631591494
No Results Workflow Improvements	Analyzed Query represents all information derived from all classification tasks executed on the Query. QAS supports 3 basic classifications tasks: binary classification (Domain Classification), entity extraction (Query Parse), category classification (Dom	0.39865861895094984
No Results Workflow Improvements	CoreCAL Improvements		Page 2 of 5CoreCAL ImprovementsDescriptionDuring Sodium, CAL Team would invest on optimizing separately for L0\L1\L2 on top of current CoreCAL improvements. Multiple Query Project will target Fidelity\SBS\SSRx while CoreCAL imp	0.39816503053570146
No Results Workflow Improvements	Production Models OverviewLU annotates incoming text input with semantic information in a contextual wayWorkflow built on top of Bing production infrastructure (QAS/XAP/Object Store)Feature representation: word embedding, n-grams and lexicons matche	0.38348505561138246
No Results Workflow Improvements	L3 Reranking FrameworkL3 Infrastructure TeamAgendaOverviewL3 featuresL3 ranker and L3 workflowAggregatedFreeFormList-wise ranking previewL3 and L4Future WorkOverviewRank Stack in IS PlatformL4 - MergerL3 – List reorderingL2 - S	0.37190928968890724
No Results Workflow Improvements	Term expansion summaryGoalsVisible changes in ARDSImprove “no match” issuesImprove rank qualityLimit FPs. Pre-work neededPort names tagger to C#/C++Query timeWSD and entity taggerEntity tagging in query logs (Britney Spears bio -> <p	0.37123171310707054
No Results Workflow Improvements	Normalization and Parsing OverviewTypes of NormalizationLimiting to just normalization, there are actually several different types of normalization which may be interesting:WhitespaceThis is:Converting all whitespace characters to spacestrippi	0.3572922848476077
No Results Workflow Improvements	Publication Date Optimization Design and Implement For zh-cn MarketReview and CommentMei Yang; Ted WildAuthorJia LiuDesignBackgroundPublication date is a very fundamental and important feature. It can help fresh ranking, solve mainline out	0.3536869472930686
No Results Workflow Improvements	Publication date optimization for zh-cn marketBackgroundPublication date is a very fundamental and important feature. It can help fresh ranking, whole page user experience: caption date show and freshness internal metrics, also to solve mainline out	0.3436400072301786

News Categorization	Local Category Search Plan3 month StrategyData: Entity categorizationScalable, high precision/recallSegments: Food & Drink, Retail, Service, Auto, HotelMetaStream enrichmentQuery UnderstandingDolphin by defaultConsume PhoneBookQU to im	0.4230953093127931
News Categorization	Entity Categorization Using Convolutional Neural NetworkWeiwu Zhu8/23/2018AgendaMotivationCNN introductionCNN in NLPCNN based entity categorizationMeasurementMotivationTaxonomy mapping is not scalable (Feature Normalization)Nee	0.41402142428086214
News Categorization	Machine Learning Categorization & Popularity2012-08-30 | Nicolas NicolovGoalsShow how categorization and popularity systems work.Introduce important ML concepts.Illustrate ML techniques through examples.(aiming to be self-contained)Categoriz	0.3389892557320419
News Categorization	Training data distributionContain categories as many as possible : 36 categies. The data of category in the same amountContain hudong data and  host dataPositive : negative = 1:7  ~ 1:10 categoryhudonghostpositivenegativeNegative_total	0.3251868352833186
News Categorization	Auto Category Classification PipelineHanqing Cui2012/10/25OutlinePain PointsThinkingAuto Category Classification PipelineAuto Page LabelingData SamplingTrainingFeature SelectionThresholdIterative TrainingInitial Seed Model Creati	0.29246074671965583
News Categorization	Publication date optimization for zh-cn marketBackgroundPublication date is a very fundamental and important feature. It can help fresh ranking, whole page user experience: caption date show and freshness internal metrics, also to solve mainline out	0.26827892014420096
News Categorization	Primary Category: What Is It, Why Is It Important, & How Do We Measure ItBing Local & Geospatial – ShruthiM, DillTellClassificationProcess in which local business entities are categorized based on the type of products and/or services that the busine	0.2581544105429404
News Categorization	Restaurants Features and ToolsReview SnippetXAPOSearchQueryWPOLERWPO OSCacheItemCacheIdList of YpIdsFiltersSorterEntityUpdate PostFixEntity Update OSCache IdCache ItemYpId and PostFixUXReview Snippet Data GroupCac	0.23817019572809758
News Categorization	QueryString Category owner Searchvote url 寇仲最后和谁在一起 ranking  xiaopeng http://searchvote.com/default.aspx?reviewid=209877 布里斯班 ranking  xiaopeng http://searchvote.com/default.aspx?reviewid=211685 必应词典 ranking  xiaopeng http://searchvote.com/default.aspx?re	0.23657899212103517
News Categorization	Local Search Platform PM Onboarding GuideAuthors: Dany DaherDate: 10/18/2013Architecture OverviewHow Local Search Works Local Data Platform Architecture MetricsLocal Metrics:  http://jeffke/localMetrics/Definition of QLDCG: Local Discoun	0.2312850867965009

NamedEntityRecognizer	Named Entity RecognizerTao Peng and Kang LiEntity names recognitionRecognize person, location and organization namesBOSTON, April  16 - Kevin Garnett helped the Boston Celtics beat the L. A. Lakers in last year's NBA final. ( Tony Gutierrez / Asso	0.5568117354602047
NamedEntityRecognizer	Name Entity Recognition based on Perceptron modelBackgroundWe have many name entity DSATs like user searched name “XYZ”, and the results may be “XY”,”YZ” or “XYW” related. We have done QU name entity recognition for zh-cn market already. So we want to	0.5458874637026724
NamedEntityRecognizer	Relevance ServiceScenarioIconApplicationDoc typeCandidatesModelRun0-termWord;OutlookWin32 client.All file typesMRUReuse ContentModel 1Client0-termPower PointWin32 client.Only ppt typeLocal + MRUReuse Conte	0.35779643962319574
NamedEntityRecognizer	Competitive Query-Entity ClickMicrosoft ConfidentialMicrosoft ConfidentialGoalCreate a dataset that is readily available to utilize and analyze query-entity click patterns on competitive dataCompetitive Engine: GoogleMicrosoft ConfidentialCo	0.350338140774662
NamedEntityRecognizer	Restaurants Features and ToolsReview SnippetXAPOSearchQueryWPOLERWPO OSCacheItemCacheIdList of YpIdsFiltersSorterEntityUpdate PostFixEntity Update OSCache IdCache ItemYpId and PostFixUXReview Snippet Data GroupCac	0.28243855607313667
NamedEntityRecognizer	Normalization and Parsing OverviewTypes of NormalizationLimiting to just normalization, there are actually several different types of normalization which may be interesting:WhitespaceThis is:Converting all whitespace characters to spacestrippi	0.27929667020847665
NamedEntityRecognizer	ElasticSearchInternalElasticSearch and oSearchElasticSearch  ArchitectureLucene FamilyoSearch  ArchitectureScenario and ScaleoSearchElasticSearchScope Strong structured dataImage with ANNUnstructured text Loose structured data	0.26344535920607476
NamedEntityRecognizer	Document classification based on urlBackgroundWe want to do document classification for better understanding the document type and document with query category match for ranking.  We will do zh-cn document classification based on url first, then docum	0.25570535222047536
NamedEntityRecognizer	Country Level Market FY13 Goal Delivered - Neon Speller Delivered - Neon CAL Delivered - Neon Delivered - Sodium CAL Delivered - Sodium Speller Delivered - Sodium FY13 Remaining Metric Australia Very Deep en-AU NDCG - Overall Brazil Very Deep pt-BR 0 NDCG	0.23949834374882578
NamedEntityRecognizer	BusinessV3TaxonomyClassifierAugust, 2018Daniel WeinshenkerMicrosoft ConfidentialAgendaMicrosoft ConfidentialPurpose / OverviewDemoData Pipeline / Lexicon GenerationMeasurementQASChallenges / Future WorkPurpose We want to improve 	0.22935171170141816

Name Entity Recognition based on Perceptron model	Name Entity Recognition based on Perceptron modelBackgroundWe have many name entity DSATs like user searched name “XYZ”, and the results may be “XY”,”YZ” or “XYW” related. We have done QU name entity recognition for zh-cn market already. So we want to	0.8241892258223408
Name Entity Recognition based on Perceptron model	Named Entity RecognizerTao Peng and Kang LiEntity names recognitionRecognize person, location and organization namesBOSTON, April  16 - Kevin Garnett helped the Boston Celtics beat the L. A. Lakers in last year's NBA final. ( Tony Gutierrez / Asso	0.6350996815558863
Name Entity Recognition based on Perceptron model	Local Search Entity Schema for RelationShips (Entity Containment, Affinities) Short blurb of what this spec is aboutMilestone:  MagnesiumSpec StatusDraftTFS Feature IDPM/Doc OwnerSandhya GuntreddyContributors Scott, Bruno,Andrew,Prajakta	0.40444001937747354
Name Entity Recognition based on Perceptron model	NGram Language Model based Url Breaking – Design DocumentStatusOngoingIntroductionUrl is a very important signal for ranking, particularly for tail queries and navigation queries. This signal has 100% url coverage, which really makes it different 	0.3982004689797541
Name Entity Recognition based on Perceptron model	Google-Bing Entity MatchingIn 75,563 Google scrape entities those with a non-empty name are 12,507: Mapped to Bing entities: 𝟖𝟒.𝟖𝟗% (=(10,162+455)/12,507). Missing data.Among entities in            and            1.07%(=83+51) have Lat/Lon	0.3967029816469298
Name Entity Recognition based on Perceptron model	Entity Categorization Using Convolutional Neural NetworkWeiwu Zhu8/23/2018AgendaMotivationCNN introductionCNN in NLPCNN based entity categorizationMeasurementMotivationTaxonomy mapping is not scalable (Feature Normalization)Nee	0.3907527044143655
Name Entity Recognition based on Perceptron model	Competitive Query-Entity ClickMicrosoft ConfidentialMicrosoft ConfidentialGoalCreate a dataset that is readily available to utilize and analyze query-entity click patterns on competitive dataCompetitive Engine: GoogleMicrosoft ConfidentialCo	0.38541896657281627
Name Entity Recognition based on Perceptron model	Local Category Search Plan3 month StrategyData: Entity categorizationScalable, high precision/recallSegments: Food & Drink, Retail, Service, Auto, HotelMetaStream enrichmentQuery UnderstandingDolphin by defaultConsume PhoneBookQU to im	0.38074639225788764
Name Entity Recognition based on Perceptron model	Fast Brain – Memorization & InferenceQuery based memorization and inferenceLarge Memorization -  1B queries, clicks (Q-D) and moreDeep Brain100 - 200B Doc/Page IndexRecall, Tail and Scalability focusedLess dependency on popularity signalHeur	0.38053676873667397
Name Entity Recognition based on Perceptron model	Project-N DeepDiveAbstractSimilarity issue has been one of the biggest problems of zh-CN relevance for years but not well got solved. In this document, we will focus on one of the main problem of similarity - entity/phrase mismatch issue in query/doc 	0.36548808128526666

NTCG Debugging	NTCG DebuggingSteven Zittrower01/30/2015AgendaNTCGNTCG DashboardOverview of BLU Architecture (Address Specific)Address Debugging in QATNTCGNTCG (Normalized Total Cumulative Gain) is a composite metric that measures address query releva	0.5529832940188206
NTCG Debugging	PBA Dependency and DebugMing Wu2014-01-28PBA DependenciesLocation Understanding (LES/BLU)Location info (explicit/implicit) – fulfill detailed location infoProvide location related features to phonebook CRFXapQuServiceAnswer (QAS)For most c	0.5129110301767039
NTCG Debugging	Successful Feeds Query DebuggingNikita Melnichenko, 2015-03-10Feeds query debugging overviewWhen to use:Checking a new rankerChecking new augmentation before running a scrapeComparing several rankersUnderstanding feature contributionDebugg	0.4565380134386644
NTCG Debugging	WrapStar On-Demand DesignDrafted by ZiliuContentsContext2Design Goals2Automation2Deployment Agility2High Availability2Non-Goals2Metrics2Required Changes3Orchestration3AP Migrations3Pipeline Evolution3Tools/services refactoring3	0.3929450008649449
NTCG Debugging	LEDB Transition8/6/2014ScopeLEDB serialization jobsLEDB Object Store publish jobsLEDB Odyssey Publish job for the VanueMap featureEntity Schema update and maintenanceObject Store payload size and perf SLAPartner engagement and change manag	0.372329198273597
NTCG Debugging	Bing Local Search				PBA QU Post-processing in QAS Dev ownerMing WuBuddy dev(s)PM ownerContributorsFeature areaPBA Query ProcessingMilestoneAluminumTable of contents1	Overview	22	Goals/Non Goals	23	Risks/Open Issues	24	Desi	0.3410510821869762
NTCG Debugging	How DUv2 worksZehua Liu, DU GDI Team12/6/2013 Q1: How to develop a DUv2 feature?Processor + Description fileQ2: How to guarantee monthly release?Q3: Difference between the development of DUv1 and DUv2 feature?DUv1: a) ProcessorCode  	0.33659628104296385
NTCG Debugging	Debug Address Queries8/23/2013Bing Local Search RelevanceNTCG MetricsDocumentationhttps://microsoft-my.sharepoint.com/personal/aoakley_microsoft_com/Documents/2013/2013-05-22%20Maps%20metrics%20Qi.pptx?web=1Use it to identify the group of quer	0.32045196408147303
NTCG Debugging	Zh-cn Transportation Segment Optimization by Pattern EngineJia Liu/Allen WangDSATsQuery: 吉林市到查干湖Relevant result title: 吉林市到查干湖怎么走近？_百度知道Irrelevant result title 1: 查干湖,中国查干湖,吉林查干湖,查干湖旅游,查干湖冬捕,国家AAAA ...Irrelevant result title 2: 查干湖_百度百科Irrel	0.3137234019167372
NTCG Debugging	Bing Local Search				Phonebook vNext Design DocumentDev ownerMickadBuddy dev(s)MichstePM ownerDabargerContributorsFeature areaMilestoneTable of contents1	Overview	32	Goals/Non Goals	53	Dependencies	64	Risks/Open Issues	75	0.3037605863094283

NLP情感分析工具的使用	BS代码阅读：BS基本功能：索引相关性切词成分分析offset调权query解析 （where+what）多路归并 综合调权类聚（偏离点）query分类空间调权数据来源点击调权BS代码阅读：bs_cache:map库的term cachemap库term cache操作锁where库term cachewhere库term cache操作锁init_map_term_cache: 初始化map库term cachein	0.8855955124047051
NLP情感分析工具的使用	贝叶斯分类模型：基础知识：假设	X：是数据元组，由n个属性描述；	H：是某种假设，如数据元组属于某特定类C	P(H|X)：表示给定X的属性描述，找出元组X属于类C的概率举例：X：一位35岁的顾客，收入为4w美元；H：顾客将购买计算机P(H|X)：在X的条件下，H的后验概率。当我们知道顾客的年龄和收入时，顾客X将购买计算机的概率。P(H)：H的先验概率。任意给定顾客将购买计算机的概率，独立与X。P(X|H)：在条件H下，X的后验概率。已知顾客购买了计算机，顾客是一位3	0.883170609784926
NLP情感分析工具的使用	K最近邻分类模型：原理：训练元组用n个属性描述，每个元组代表n维空间中的一个点，所有的训练元组存放在n维的模式空间。当给定一个未知元组时，KNN搜索该模式空间，找出最接近未知元组的k个训练元组。未知元组指派到它的k个最近邻中的多数类。“邻近性”用距离度量，如欧几里德距离。欧几里德距离：	设元组X1=(X11,X12,…X1n)，X2=(X21,X22,…X2n)，	Dist(X1,X2)=√ ∑ k= 1 n (X1i-X2i) 2 	使用上式之前，对每个属性的值规范化，以防止具有	0.8792418828754979
NLP情感分析工具的使用	Svm分类模型：基本原理：将所有待分类的点映射到“高维空间”，然后在高维空间中找到一个能将这些点分开的“超平面”，这在理论上是被完全证明了是成立的，而且在实际计算中也是可行的。满足条件的“超平面”的个数不是唯一的。SVM需要的是利用这些超平面，找到这两类点之间的“最大间隔”。并非所有的数据都线性可分，将非线性映射到更高维的特征空间变成线性可分。（低维空间向量集通常难于划分，解决的方法是将它们映射到高维空间。）但这个办法带来的困难就是计算复杂度的增加，而核函数正好巧妙地解决了这个问题。也就是说，只要选用	0.8787418824847248
NLP情感分析工具的使用	排序及扩展：插入排序，选择排序（冒泡排序），使用二分思想求第k大数，快速排序，非递归的快速排序，使用快排思想求第k大数，归并排序，求逆序数，自然排序算法，堆排序，最小优先级队列，计数排序，桶排序，鸽巢排序（分块排序），基数排序，外部排序：二路归并，K路归并，胜者树，败者树。  算法一：使用插入或者选择排序，得到最大的K个数，时间复杂度为：O(N*k)。 冒泡排序： void swap(int * a,int * b){            //注意	0.8786137640920164
NLP情感分析工具的使用	克拉玛依公证处:本人因生活在国外，不能亲自到贵单位办理出生证明公证事项，兹授权委托雷春香女士全权代表我办理相关事项。对委托人在办理上述事项过程中所签署的有关文件，我均予以认可，并承担相应的法律责任。委托人：刘佳			委托人身份证号码：654301198608243929被委托人：雷春香		被委托人身份证号码：6526196207113926委托人：刘佳2018年5月24日	0.8786137640920164
NLP情感分析工具的使用	性能升级性能升级的几个层面：系统结构：模块分解，模块交互，系统构建中的粗略估算。算法和数据结构：获得快速模块的关键：表示数据的结构，操作数据的算法：索引结构及拉链归并。代码调优：分支预测等。循环：将循环体中不改变的变量移动到循环体外；多重循环嵌套顺序。函数调用：inline函数节省函数调用开销：若makefile中不指定至少-O优化，即使声明为inline函数，编译器也不会进行函数内联。内存寻址：避免重复内存寻址。Cpu流水线的分支预测：将满足概率最高的条件放在靠前的位置。	0.8786137640920164
NLP情感分析工具的使用	业务生成平台用户指南总体说明开发背景下一代网络是业务驱动的网络，在融合的下一代网络上高效、灵活地开发和部署各种丰富多彩的业务，从而提高网络使用率、增加收益的目标，是下一代网络的关键环节。下一代网络的发展要求呼叫与承载相分离、呼叫控制与业务相分离，使业务真正独立于网络，业务开发者不必关心与业务承载相关的底层网络知识以及具体的通信协议，只需利用业务生成平台提供的业务开发工具，就可以开发出灵活丰富且极具个性化的业务。 为了适合多种技术水平的业务开发人员的需要，现在主要有四种业务开发方式：	0.8786137640920164
NLP情感分析工具的使用	SVM分类内容概要流程图预处理SVM分类器组合分类结果流程图内容概要流程图预处理SVM分类器组合分类结果特征选择特征，以文本行业分类来说，切词term特征的重要性“北京”是个没用的特征“速8”是个有用的特征“轻度”这个词呢？信息增益（Information Gain）   熵H是一个分布是否分散的表征，与信息相反概率估计P(ci) = ci类别的样本数 / 样本总数P(ci|t)  = t出现的属于ci	0.8777706047149377
NLP情感分析工具的使用	海量数据库的设计和实现淘宝海量数据库之一：来自业务的挑战(2010-11-24 11:34:38) 作为一个电子商务企业，从一开始，数据库及其事务能力在淘宝一直扮演着十分关键的角色，淘宝积累了丰富的数据库的架构和规划等方面的经验，产生了众多优秀的DBA。 淘宝是一家迅速发展的公司。全球网站排名公司Alexa提供的数据显示，2010年4月27日，Amazon、Ebay的用户占全球互联网用户的百分比分别为3.47%和2.68%，而淘宝的用户占全球互联网用户的百分比则达到了4.1%，淘宝网日	0.8768928128929595

NL Azure Plan V2 - Edit EJ	ML Model Scorecard Analysis8/8/2019Unexpected term search movementhttps://exp.microsoft.com/xcard/?view=4e77b420-7b77-4e41-92ac-8e84f506fb01Check correctness of scorecard metric implementationCalculate term AVG rank from raw data streamsSearch	0.4721973185021337
NL Azure Plan V2 - Edit EJ	Microsoft Netherlands. Azure PlanPresenter nameSlide script: Thank you for taking the time today to walk through an end-to-end tour of Azure Security- the intensive and extensive work we’re doing to deliver a cloud you can trust.We’ll focus firs	0.42900348131156496
NL Azure Plan V2 - Edit EJ	Bing Local Search				PBA QU Post-processing in QAS Dev ownerMing WuBuddy dev(s)PM ownerContributorsFeature areaPBA Query ProcessingMilestoneAluminumTable of contents1	Overview	22	Goals/Non Goals	23	Risks/Open Issues	24	Desi	0.3799273538798204
NL Azure Plan V2 - Edit EJ	Translation Model APIStatus: Sodium-2, API Version 6.7OverviewThe TM API – including support for high compression - was developed as one of several architectural considerations to ship machine translation model features to production, initially for 	0.37348189993413805
NL Azure Plan V2 - Edit EJ	IQ Team RecapH1 2016FY16H1 AccomplishmentsTeamSSRxen-* Desktop SBSen-* Mobile SBSen-* Semantic SBSCore Web Relevance0.55/0.62.46/3.02.65/3.01.88/2.0Adult LeakageSpamJunkCQDCGMPCMALTABing@WorkSubstrate0.02/0.01	0.3647604866232383
NL Azure Plan V2 - Edit EJ	Online Click Labels for CAL Ranker:End – To End:aether://experiments/31148112-679c-476c-91d0-bb3ebbef81c2Continuous trained module continuously trains trees using HRS and then the ranker.OFE Ranker Training Pipeline:aether://experiments/01dbe0	0.36111170893512295
NL Azure Plan V2 - Edit EJ	Distance Model, LDS, L3Knowledge SharingNikita Melnichenko, Bing Local2017-04-21Overview of PBA relevance flow in FeedsL1Keyword matchWPOL2 levelRankerTruncationCategory matchName matchLogical DistanceUI sortingGIMXIMGDM	0.3554473479294544
NL Azure Plan V2 - Edit EJ	NTCG DebuggingSteven Zittrower01/30/2015AgendaNTCGNTCG DashboardOverview of BLU Architecture (Address Specific)Address Debugging in QATNTCGNTCG (Normalized Total Cumulative Gain) is a composite metric that measures address query releva	0.35443346478919274
NL Azure Plan V2 - Edit EJ	FY19 Search & AI Roadmap Review: Intelligent QnAMay 2018PM: Ali Alvi, Kaan Ozel, Ganga Venkatasubramanian, Oana NicolovDev: Xia Song, Doran ChakrabortyAgendaOverall QnA Opportunity and GoalsSemi-Structured DataMALTATuring for QnAAGI En	0.35438269959786756
NL Azure Plan V2 - Edit EJ	FY19 Search & AI Roadmap Review: AGI for Web RankingMay 2018Dev: Chen Zhou, Saurabh TiwaryPM: Kiki Liu, Mir RosenbergMotivation“…But often time we have more problems about the subjects we are not familiar with and therefore even the keywords	0.34783142872886674

NGram Language Model based Url Breaking	NGram Language Model based Url Breaking – Design DocumentStatusOngoingIntroductionUrl is a very important signal for ranking, particularly for tail queries and navigation queries. This signal has 100% url coverage, which really makes it different 	0.7899626496991686
NGram Language Model based Url Breaking	Phonebook vNextDesign DiagramsPlease do not modify existing diagrams!To update a diagram, make copy of a slideand create a new version.Do not forget to update date and author.Local.Pba.MainLocal.Pba.ExecutionModeLocal.Pba.ResponseMuxMu	0.47128541591488116
NGram Language Model based Url Breaking	Document classification based on urlBackgroundWe want to do document classification for better understanding the document type and document with query category match for ranking.  We will do zh-cn document classification based on url first, then docum	0.389601676279242
NGram Language Model based Url Breaking	SPAM & JunkSi Planning Cheng Niu, Alex Rahin6/18/2014Agenda	Focus AreasMetricsSPAM/Junk Metrics BreakdownData Analysis and Project DefinitionFocus AreasImprove SPAM Detection (~35% of team bandwidth)Stolen ContentContent Keyword St	0.37783458162416345
NGram Language Model based Url Breaking	Production Models OverviewLU annotates incoming text input with semantic information in a contextual wayWorkflow built on top of Bing production infrastructure (QAS/XAP/Object Store)Feature representation: word embedding, n-grams and lexicons matche	0.37529687479307666
NGram Language Model based Url Breaking	RelaxCount Classifier in JO V3By: Gord Lueck, 2013.09.04BackgroundCAL now has the ability to ship with a relaxcount classifier.  That is, a trained decision tree that is designed to predict the relaxcount decision on a query.  The classifier can be 	0.3694585229490743
NGram Language Model based Url Breaking	QueryString Category owner Searchvote url 寇仲最后和谁在一起 ranking  xiaopeng http://searchvote.com/default.aspx?reviewid=209877 布里斯班 ranking  xiaopeng http://searchvote.com/default.aspx?reviewid=211685 必应词典 ranking  xiaopeng http://searchvote.com/default.aspx?re	0.3619788119106856
NGram Language Model based Url Breaking	CRF Parser AnalysisBusiness category searchOverviewParser (phonebook)CRF ParserqueryLocation featuresCRF featuresQuery parsetoken[tag] token[tag] … token[tag]userBLUbusiness_namebusiness_categorylocationlocation_separatorbu	0.3604004564608255
NGram Language Model based Url Breaking	Zh-cn Publication date design docBackgroundDesignPublication date from wrapstarPublication date from URLPublication date from titlescore(c1) = w11*f1+w12*f2+w13*f3+w14*f4+w15*f5+bias1score(c2) = w21*f1+w22*f2+w23*f3+w24*f4+w25*f5+bias2Pack	0.3505419400761271
NGram Language Model based Url Breaking	Name Entity Recognition based on Perceptron modelBackgroundWe have many name entity DSATs like user searched name “XYZ”, and the results may be “XY”,”YZ” or “XYW” related. We have done QU name entity recognition for zh-cn market already. So we want to	0.3417795838788212

MultiQueryCAL	CAL MultiQuery {Matching\Ranking}		Page 3 of 4CAL MultiQuery {Matching\Ranking}DescriptionCAL is going to optimize against matching\ranking separately and will issue different queries to each tier. CAL will be leveraging several operator such as:m	0.41656020095590524
MultiQueryCAL	CALQuery alterationAgendaRoadmap and VisionWhere are weWhere to goPlanHow to get thereProgress and looking aheadSodium so farMagnesium and beyondDeep DiveGolden QueryRoadmap & VisionWhere are weCurrent status/problem of CAL	0.2678107278961457
MultiQueryCAL	Simplified Query Path SelectorSimplified query: current systemSimplified query path selectionCrf model produces a list of possible ways to place rankonly operatorQuery = “nibbana restaurant official site”nibbana restaurant rankonly:official site	0.1946938387503533
MultiQueryCAL	Summary of 50 queries:QueryIssue categoryResolved促销策略案例分析Page NumberYes美丽说面膜Page NumberYes朝鲜金正恩腐化生活 图片Page NumberNo(L3 rule not cover this case: the second page is higher than the first page)智慧树2012全集Page NumberYes潘阳老公石磊P	0.18236709914692295
MultiQueryCAL	Local Category Search Plan3 month StrategyData: Entity categorizationScalable, high precision/recallSegments: Food & Drink, Retail, Service, Auto, HotelMetaStream enrichmentQuery UnderstandingDolphin by defaultConsume PhoneBookQU to im	0.17677557771797442
MultiQueryCAL	BingGC Multi-Pointer Stack11/4/2014BingGCI@microsoft.comMulti-Pointer ResolutionUsing a tiling system, we first find the correct Tile, then search inside to find matching entities:	 Chipotle Mission St 2nd StQuery: Chipotle Mission St 2nd St	0.17615808440422873
MultiQueryCAL	Span ClassifierSpan classifier is a general infrastructure that can be used to run a fastrank based classifier on a sequence of terms from a query.  It can be used to apply rankonly or norelax to parts of the query based on the result of the model.  Fea	0.172268653318599
MultiQueryCAL	Meta-stream work summaryHeyong WangClickstream exampleOverview: Click-Stream generationWeb logsLocal logsLocal clicked dataJoin with Local IndexWeb Clicked data (query, url etc.)IE ClickBing ClickIE SessionIE Tool Bar…Web Click	0.1593493993990863
MultiQueryCAL	MQ for CALOverviewSpellerQASMQTriggerMQSingleQueryChainChainChainAugmentAugmentAugmentTailQuerySimplifiedSPCombSP1SP2Sp3AugmentAugmentPropertyBag - SQQueryAlterationListQueryAlterationSetQueryAlterationType	0.15198797354888657
MultiQueryCAL	Training data distributionContain categories as many as possible : 36 categies. The data of category in the same amountContain hudong data and  host dataPositive : negative = 1:7  ~ 1:10 categoryhudonghostpositivenegativeNegative_total	0.14976870229081

Move SBS via L3	Distance Model, LDS, L3Knowledge SharingNikita Melnichenko, Bing Local2017-04-21Overview of PBA relevance flow in FeedsL1Keyword matchWPOL2 levelRankerTruncationCategory matchName matchLogical DistanceUI sortingGIMXIMGDM	0.3774493564534569
Move SBS via L3	Move SBS (Learning from L3)Xiaopeng WuJunzhou WangWhat’s L3Bing ranking stackIndex selectionWorking on offline system, target recallL1Working on IFM, target recallL2Working on IFM, target precisionL3Working on TLA, target whole pag	0.3169714749242593
Move SBS via L3	Distance Model Updates in LDCG V2Local Relevance and Measurement TeamAgendaDistance feature in LDCG V1Why was the switch to computing distance made?First implementation of Distance feature in LDCG V2, & improvement areasProcess followed for 	0.3099150948020659
Move SBS via L3	ML Model Scorecard Analysis8/8/2019Unexpected term search movementhttps://exp.microsoft.com/xcard/?view=4e77b420-7b77-4e41-92ac-8e84f506fb01Check correctness of scorecard metric implementationCalculate term AVG rank from raw data streamsSearch	0.2928353413786966
Move SBS via L3	IQ Team RecapH1 2016FY16H1 AccomplishmentsTeamSSRxen-* Desktop SBSen-* Mobile SBSen-* Semantic SBSCore Web Relevance0.55/0.62.46/3.02.65/3.01.88/2.0Adult LeakageSpamJunkCQDCGMPCMALTABing@WorkSubstrate0.02/0.01	0.2764990922950933
Move SBS via L3	BLU V3 Minghua Zhang      01/26/2016Next version of BLU Relevance Infrastructure​OutlineWhy BLU v3BLU v3 DesignCurrent StatusFuture WorkWhy BLU v3 (1)Limitations of current BLU infrastructureFeaturesCouldn’t utilize QAS feature	0.2762543074563879
Move SBS via L3	PBAVnext and migrationFrank ZhangBenefit of vnextIt will reflect five years’ worth of local search relevance insights and lessons learned, including the relevance tuning principles we have discovered over the years.It will make it easier to suppor	0.2740856491846656
Move SBS via L3	Mobile 100k Compete Data analysis with G - Simulation Report6/6/2014Mobile Simulation AnalysisThis analysis compares Google and Bing on iOS for 3 querysets.REPORTS GENERATED FOR **: Overall Metrics Coverage (WP, ML and Bot)IY (WP, ML and Bot	0.24142764887620005
Move SBS via L3	LDCG V3Knowledge Transfer2017-04-14Brett Clippingdale, Sean King, Vikas Mittal, Li JiangLDCG V3 OutlineLDCG V2 vs V3: High-level comparisonLDCG V3: New distance ModelV2 vs V3 OverviewLDCG V3: GeoIntent HIT appLDCG V3: Calculate distance 	0.2318402724758976
Move SBS via L3	Mobile LT Discussion6/20/2014AgendaTop IssuesAd Product and Ad Quality UpdateSummarized Finding NDT Supply AnalysisSummarized Finding Google CompeteStatusFeatureWindows phoneIphone/AndroidUp to 2 adsShipped 5/20/2014Shipped more 	0.22719344661269605

Mobile LT Discussion 07142014	Mobile LT Discussion6/20/2014AgendaTop IssuesAd Product and Ad Quality UpdateSummarized Finding NDT Supply AnalysisSummarized Finding Google CompeteStatusFeatureWindows phoneIphone/AndroidUp to 2 adsShipped 5/20/2014Shipped more 	0.5266881473665765
Mobile LT Discussion 07142014	L3 Distance Model for LocalNikita Melnichenko, Bing Local2016-04-12AgendaIntroduction to the Distance problemPrevious workA new approach: experiments and designResultsFuture developmentIntroduction to the Distance problemWe say “it’s a	0.41179984410633447
Mobile LT Discussion 07142014	Mobile 100k Compete Data analysis with G - Simulation Report6/6/2014Mobile Simulation AnalysisThis analysis compares Google and Bing on iOS for 3 querysets.REPORTS GENERATED FOR **: Overall Metrics Coverage (WP, ML and Bot)IY (WP, ML and Bot	0.40387190285480823
Mobile LT Discussion 07142014	Distance Model, LDS, L3Knowledge SharingNikita Melnichenko, Bing Local2017-04-21Overview of PBA relevance flow in FeedsL1Keyword matchWPOL2 levelRankerTruncationCategory matchName matchLogical DistanceUI sortingGIMXIMGDM	0.37735226762260227
Mobile LT Discussion 07142014	ML Model Scorecard Analysis8/8/2019Unexpected term search movementhttps://exp.microsoft.com/xcard/?view=4e77b420-7b77-4e41-92ac-8e84f506fb01Check correctness of scorecard metric implementationCalculate term AVG rank from raw data streamsSearch	0.3388610597284385
Mobile LT Discussion 07142014	Move SBS (Learning from L3)Xiaopeng WuJunzhou WangWhat’s L3Bing ranking stackIndex selectionWorking on offline system, target recallL1Working on IFM, target recallL2Working on IFM, target precisionL3Working on TLA, target whole pag	0.3245247501997105
Mobile LT Discussion 07142014	PBAVnext and migrationFrank ZhangBenefit of vnextIt will reflect five years’ worth of local search relevance insights and lessons learned, including the relevance tuning principles we have discovered over the years.It will make it easier to suppor	0.3010607358722146
Mobile LT Discussion 07142014	Author: Tony AngellDate: 08/01/13LocalProbe Improvements for Corrections Analysis and DebuggingTable of ContentsP0 Issues	2Issue: LocalProbe is unpredictable in the amount of time it takes to return a query and how long it takes to investigate a	0.29629200535519135
Mobile LT Discussion 07142014	Google Mobile vs Desktop RankDiff StudyNov 2017GoalsUnderstand what Google does differently on Mobile, if anythingDrive product ideas & shape ranking improvements on MobileUnderstand any possible impact to Algo scrapes & metricsDrive scrapin	0.2929511285089821
Mobile LT Discussion 07142014	IQ Team RecapH1 2016FY16H1 AccomplishmentsTeamSSRxen-* Desktop SBSen-* Mobile SBSen-* Semantic SBSCore Web Relevance0.55/0.62.46/3.02.65/3.01.88/2.0Adult LeakageSpamJunkCQDCGMPCMALTABing@WorkSubstrate0.02/0.01	0.2864540492024259

MetastreamFidelityAnalysis	Meta-stream work summaryHeyong WangClickstream exampleOverview: Click-Stream generationWeb logsLocal logsLocal clicked dataJoin with Local IndexWeb Clicked data (query, url etc.)IE ClickBing ClickIE SessionIE Tool Bar…Web Click	0.453340293084234
MetastreamFidelityAnalysis	Country Level Market FY13 Goal Delivered - Neon Speller Delivered - Neon CAL Delivered - Neon Delivered - Sodium CAL Delivered - Sodium Speller Delivered - Sodium FY13 Remaining Metric Australia Very Deep en-AU NDCG - Overall Brazil Very Deep pt-BR 0 NDCG	0.349966373429486
MetastreamFidelityAnalysis	 Core Web RelevanceInformation Platform GroupBing Spam & JunkFeature OwnersProgram ManagersMichael AbboudDevelopersPavel Karpovich, Lidong Zhao, Gregory Minasyants, Ashok Ponnuswami,  Eugene Remizov, Mikhail BorbotDev ManagerLuke ChenM	0.34198022815333295
MetastreamFidelityAnalysis	FusionByTurker KeskinpalaTuesday, May 17, 2016OverviewMotivationsWhat is Fusion?GoalsFusion ComponentsRoadmapWeb AnswerQ:“gg”Qpath1:“gg”Qpath2:“google”TLACDG FetcherL2 FetcherTLACDG FetcherL2 FetcherLL4L3L3	0.3385444639385565
MetastreamFidelityAnalysis	Metrics Pipeline & ToolsJia Liu / Xiaohui Sun / Alex SergeevASG Data Mining TeamDemo link: http://dmsql05/MetricsDefinitionTool/MetricsDefinition.aspx?DataSet=BFT&MetricName=HasCortanaChitChatsTopicsBing Live Metrics PipelineUsage and Perf	0.3339560608877729
MetastreamFidelityAnalysis	QR Team ReviewJan 2017Team IntroductionConceptXDeep QRAgendaQR Team MembersDev Manager: Ciya LiaoLeads: Garrett Kaminaga, Jingwen Lu, Saekoo Lee, Gord LueckPMs: Shyam Jayasankar, Jie CaiSTC-A Speller team: Yongen Gong and his teamWha	0.32644925201839364
MetastreamFidelityAnalysis	Restaurant segment metrics collectionObjectiveTo understand user behavior/engagement on Restaurant answers.Why this is important? The metrics will help us understand:The comparisons between different answersWhat is important to our users and w	0.3206128201226034
MetastreamFidelityAnalysis	WPO Local RelevancePing Yin2017-03-21OverviewWPO’s role in local relevance pipelineLocal Entity StampingArchitecture overviewWPO Local Relevance Models.Query: exton mall, User location: Wallingford, PAWPO RolesExtract/detect all entity	0.31595967040229966
MetastreamFidelityAnalysis	Ranker Training Pipeline IntroductionAgendaPipeline OverviewGCC platformExtractionData/Feature PreparationMain Ranker TrainingSegment RankersPipeline OverviewGR OctTree: gcclinkMain Steps:Metastream injection (just info here)Querys	0.3151866024612296
MetastreamFidelityAnalysis	Local Category Search Plan3 month StrategyData: Entity categorizationScalable, high precision/recallSegments: Food & Drink, Retail, Service, Auto, HotelMetaStream enrichmentQuery UnderstandingDolphin by defaultConsume PhoneBookQU to im	0.3138134338699868

Measurement For Deal Ranking Algorithm	Deal Ranking Improvement & MeasurementBackgroundAfter we shipped deal understanding, bad deals filtering, deal ranking for the entity search deals and popular deals nearby. We want to measure and improve our deal ranking based on user behaviors. We ca	0.6168091811980615
Measurement For Deal Ranking Algorithm	Deal Understanding and RankingBackgroundDeal is a very big segment in Bing Opal. We crawl store and single deals/coupons regularly from websites like groupon.com, coupons.com, restaurants.com, retailmenot.com, dealcatcher.com, dealplus.com and so on. 	0.5524554072189155
Measurement For Deal Ranking Algorithm	Deal Ranking ImprovementsDeal Understanding ImprovementsGoal: Increase general deal coverage (deal product type from specific to general).Solution: Identify the prefix and suffix of title by punctuations and prep. Remove the prefix and suffix from t	0.5031192345235063
Measurement For Deal Ranking Algorithm	CAL MultiQuery {Matching\Ranking}		Page 3 of 4CAL MultiQuery {Matching\Ranking}DescriptionCAL is going to optimize against matching\ranking separately and will issue different queries to each tier. CAL will be leveraging several operator such as:m	0.48196689486496885
Measurement For Deal Ranking Algorithm	FastRank--- a Decision-Tree based Ranking ModelYu SHIOutlineBackgroundAlgorithm overviewTraining implementationExperimentationChallengesReferencesBackgroundInvestigated by MSR in OsloShipped with July Tree 2010 (Denver)GoalsSpe	0.47353439071031267
Measurement For Deal Ranking Algorithm	alterationsalterations: product goalimprove recallby adding terms (not replacing or dropping user-entered terms)using word:which are synonyms to the original terms(we are re-examining each of these for vnext)alterations: general principl	0.4344508848586676
Measurement For Deal Ranking Algorithm	Summary and HighlightsIn April the metrics/measurement team released local AutoSuggest metric and shared initial transit measurement results; BLU team shipped CL 1.0 ontology and deployed BLU v3 to all markets; PBA team shipped a new L2 ranker and refre	0.4340828710861361
Measurement For Deal Ranking Algorithm	Measurement PlanSmoke test:We will deploy ranker model under test and service to INT and ask SKI internal users to issue whatever queries they want. In this way, we can quickly get feedback using Microsoft private data and Bing API. People can get min	0.428088471818664
Measurement For Deal Ranking Algorithm	Country Level Market FY13 Goal Delivered - Neon Speller Delivered - Neon CAL Delivered - Neon Delivered - Sodium CAL Delivered - Sodium Speller Delivered - Sodium FY13 Remaining Metric Australia Very Deep en-AU NDCG - Overall Brazil Very Deep pt-BR 0 NDCG	0.4066499503984248
Measurement For Deal Ranking Algorithm	Phrasal Alterations & CAL Infra 		Page 2 of 2Phrasal Alterations & CAL Infra DescriptionPhrasal Alterations is going to add CAL the functionality of doing N-to-M alterations. Given a query, CAL is going to generate multiple candidate queries without	0.3972233109070862

ML Model Scorecard analysis	ML Model Scorecard Analysis8/8/2019Unexpected term search movementhttps://exp.microsoft.com/xcard/?view=4e77b420-7b77-4e41-92ac-8e84f506fb01Check correctness of scorecard metric implementationCalculate term AVG rank from raw data streamsSearch	0.7101130832806285
ML Model Scorecard analysis	Handbook of MLGProcessor AEther ModulesContents1.	Introduction	72.	MLGProcessor Modules	82.1.	Common Module Parameters	8Inputs	8Outputs	8Parameters	92.2.	BodySurfaceStream	9Inputs	9Outputs	92.3.	BoundaryView	9Examples	102.4.	Char	0.43094400028550617
ML Model Scorecard analysis	SmartRelax training and evaluation from 15%/15% flightForay scorecard: 15%+15% datagatheringUser-triggered scorecardSSRx gain of 0.12%, for 3+4 word on vs. 3+4 word off. (NOT vs. prod.)Gain is 36% from SSR, 11% from TTS, 52% from TSRSSRx gains s	0.39807608358898205
ML Model Scorecard analysis	Mobile 100k Compete Data analysis with G - Simulation Report6/6/2014Mobile Simulation AnalysisThis analysis compares Google and Bing on iOS for 3 querysets.REPORTS GENERATED FOR **: Overall Metrics Coverage (WP, ML and Bot)IY (WP, ML and Bot	0.3959939267504175
ML Model Scorecard analysis	CoreCAL Improvements		Page 2 of 5CoreCAL ImprovementsDescriptionDuring Sodium, CAL Team would invest on optimizing separately for L0\L1\L2 on top of current CoreCAL improvements. Multiple Query Project will target Fidelity\SBS\SSRx while CoreCAL imp	0.3666764117962114
ML Model Scorecard analysis	Mobile LT Discussion6/20/2014AgendaTop IssuesAd Product and Ad Quality UpdateSummarized Finding NDT Supply AnalysisSummarized Finding Google CompeteStatusFeatureWindows phoneIphone/AndroidUp to 2 adsShipped 5/20/2014Shipped more 	0.3451241389171149
ML Model Scorecard analysis	Query Formulation Review of FY15 Goals and Silicon achievements/learningsSilicon ScorecardAreaGoalAchievementQF Relevance(Autosuggest, Related Search)SSRx+0.052Annualized Revenue+$58mRelated Search RelevanceBeat G on DO defect ra	0.3320744071782336
ML Model Scorecard analysis	Name Entity Recognition based on Perceptron modelBackgroundWe have many name entity DSATs like user searched name “XYZ”, and the results may be “XY”,”YZ” or “XYW” related. We have done QU name entity recognition for zh-cn market already. So we want to	0.3273098471929204
ML Model Scorecard analysis	Smart Query Relaxation In Joint OptimizationA Cross-Group Collaborations Among QU/QR/CoreRanking/IS/MSR      Presented By : Xiaolong Li (Query Understanding)8/19/2013Smart Query Relaxation in JOPOutlineJOP V2 SummaryQuery Relaxation An	0.3210680116908427
ML Model Scorecard analysis	Google Mobile vs Desktop RankDiff StudyNov 2017GoalsUnderstand what Google does differently on Mobile, if anythingDrive product ideas & shape ranking improvements on MobileUnderstand any possible impact to Algo scrapes & metricsDrive scrapin	0.31628737974600846

M02-Deployment Considerations - Edited, see remarks	Module 2:Deployment Considerations© 2014 Microsoft Corporation. All rights reserved. MICROSOFT MAKES NO WARRANTIES, EXPRESS, IMPLIED OR STATUTORY, AS TO THE INFORMATION IN THIS PRESENTATION.11/28/2016 8:58 PMMicrosoft ServicesConditions and Te	0.4813888348153494
M02-Deployment Considerations - Edited, see remarks	Measurement PlanSmoke test:We will deploy ranker model under test and service to INT and ask SKI internal users to issue whatever queries they want. In this way, we can quickly get feedback using Microsoft private data and Bing API. People can get min	0.4277928053503113
M02-Deployment Considerations - Edited, see remarks	PBA Dependency and DebugMing Wu2014-01-28PBA DependenciesLocation Understanding (LES/BLU)Location info (explicit/implicit) – fulfill detailed location infoProvide location related features to phonebook CRFXapQuServiceAnswer (QAS)For most c	0.40552420588474264
M02-Deployment Considerations - Edited, see remarks	Decision Tree Ensemble decodeAdaboost Decision tree:A forest.  One feature can be multiple nodes.Support Market checkingWord/entity classificationOne or more feature set inputMeaning[DecisionTree]Roots=90  (tree number)Nodes=630 (all n	0.35271530398026024
M02-Deployment Considerations - Edited, see remarks	Index Serve in Bing SearchContents1	Introduction	81.1	Overview	81.2	Goals and constraints	82	IndexServe Stats at a glance	93	IndexServe Architecture Overview	93.1	Logical Query flow	93.2	Machine Functions	124	Runtime Services	124.1	FCS	0.34470976262683467
M02-Deployment Considerations - Edited, see remarks	Run web-search-like query against my dataSame Bing Web Search Indexing and Ranking engineIndex in a secondTransparent and real time index sync, no complex index-gen pipelinePrototype in an hourFast self-onboarding with freemium account, schema-d	0.33794722930896365
M02-Deployment Considerations - Edited, see remarks	Bing GC Deep DiveBingGCI 9/26/2014Introduction – Pavel, 2minsProject overview – Wei, 6minsBing GC XAP workflow – John, 10minsBing GC data pipeline and data ingestion – Florin, 7minsBing GC Offline relevance platform – Jian, 8minsSingle-poi	0.33725752715446966
M02-Deployment Considerations - Edited, see remarks	Deal Ranking Improvement & MeasurementBackgroundAfter we shipped deal understanding, bad deals filtering, deal ranking for the entity search deals and popular deals nearby. We want to measure and improve our deal ranking based on user behaviors. We ca	0.33311619663360803
M02-Deployment Considerations - Edited, see remarks	AGI Intent EncoderGavin YingWeb Intelligence Team(Tail Ranking team)7/29/2016What is Intent EncoderGiven a text like query, question, short sentence, get a vector represent in a high dimension space. The vector should capture semantic meanin	0.3321704232654727
M02-Deployment Considerations - Edited, see remarks	L3 Reranking FrameworkL3 Infrastructure TeamAgendaOverviewL3 featuresL3 ranker and L3 workflowAggregatedFreeFormList-wise ranking previewL3 and L4Future WorkOverviewRank Stack in IS PlatformL4 - MergerL3 – List reorderingL2 - S	0.3113666894820452

Logistic regression 读书笔记	Logistic regression读书笔记基本概念1 线性回归线性回归：因变量和自变量之前存在线性关系。一般模型如下：从一般模型可以看出Y和X(X1,X2,X3...)之间存在线性关系。线性回归的目的就是为了确定因变量和自变量的关系程度，即求回归模型的参数。2 逻辑回归(1) 线性回归的缺点，主要难以处理以下两个问题a. 因变量Y如果不是数值型b. 因变量与自变量不存在线性关系 (2) 逻辑回归的一般形式 P是概率，是某个事件发生的概率，比如文档	0.5571686374259801
Logistic regression 读书笔记	hypertable介绍-1一 Hypertable 是什么：Hypertable 是一个正在进行中的开源项目，以google的bigtable论文为基础指导，使用c++语言实现。目的是为了解决大并发，大数据量的数据库需求。目前 只支持最基本的查询功能，对于事物，关联查询等都不支持。对单条查询的响应时间可能也不如传统数据库（要看数据量，量越大，对hypertable越有 力）。好处是，可以处理大量并发请求，和管理大量数据。可扩缩性好，扩容只需要增加集群中的机器就ok了。任何节点失效，既不会造成系统	0.4601023388853989
Logistic regression 读书笔记	BS代码阅读：BS基本功能：索引相关性切词成分分析offset调权query解析 （where+what）多路归并 综合调权类聚（偏离点）query分类空间调权数据来源点击调权BS代码阅读：bs_cache:map库的term cachemap库term cache操作锁where库term cachewhere库term cache操作锁init_map_term_cache: 初始化map库term cachein	0.4382500356401435
Logistic regression 读书笔记	query分类—分享                     刘佳2011.6.8web query classification(query分类):	将web search query根据它的主题，分派到1个或者多个预先定义的分类中。web search query的特征：有噪声：拼写错误等长度很短：信息量少，特征少表意含糊：query可能包含多个含义,属于多个分类含义会随时间演变目标分类的特征：目标分类定义缺少语义注解一级或者多级分类分类数目：几	0.42756967620576153
Logistic regression 读书笔记	Localbs性能优化使用gprof分析程序性能瓶颈：Gprof原理：在内存中分配一些内存，存储程序执行期间的统计数据。在GCC使用-pg选项编译后，gcc会在程序的入口处(main 函数之前)调用：void monstartup(lowpc, highpc)；在每个函数的入口处调用：void _mcount()；在程序退出时(在 atexit () 里)调用：void _mcleanup()。monstartup：负责初始化profile环境，分配内存空间；_mcount：记录每个函数代	0.4215041458449701
Logistic regression 读书笔记	SVM分类内容概要流程图预处理SVM分类器组合分类结果流程图内容概要流程图预处理SVM分类器组合分类结果特征选择特征，以文本行业分类来说，切词term特征的重要性“北京”是个没用的特征“速8”是个有用的特征“轻度”这个词呢？信息增益（Information Gain）   熵H是一个分布是否分散的表征，与信息相反概率估计P(ci) = ci类别的样本数 / 样本总数P(ci|t)  = t出现的属于ci	0.42006657370131206
Logistic regression 读书笔记	Svm分类模型：基本原理：将所有待分类的点映射到“高维空间”，然后在高维空间中找到一个能将这些点分开的“超平面”，这在理论上是被完全证明了是成立的，而且在实际计算中也是可行的。满足条件的“超平面”的个数不是唯一的。SVM需要的是利用这些超平面，找到这两类点之间的“最大间隔”。并非所有的数据都线性可分，将非线性映射到更高维的特征空间变成线性可分。（低维空间向量集通常难于划分，解决的方法是将它们映射到高维空间。）但这个办法带来的困难就是计算复杂度的增加，而核函数正好巧妙地解决了这个问题。也就是说，只要选用	0.41851376352752956
Logistic regression 读书笔记	Summary of 50 queries:QueryIssue categoryResolved促销策略案例分析Page NumberYes美丽说面膜Page NumberYes朝鲜金正恩腐化生活 图片Page NumberNo(L3 rule not cover this case: the second page is higher than the first page)智慧树2012全集Page NumberYes潘阳老公石磊P	0.41510639062540966
Logistic regression 读书笔记	Adaboost算法总结Adaboost原理AdaBoost是英文"Adaptive Boosting"（自适应增强）的缩写，由Yoav Freund和Robert Schapire在1995年提出。AdaBoost 是一种迭代算法，其核心思想是针对同一个训练集训练不同的分类器，即弱分类器，然后把这些弱分类器集合起来，构造一个更强的最终分类器。算法本身是改变数据分布实现的，它根据每次训练集之中的每个样本的分类是否正确，以及上次的总体分类的准确率，来确定每个样本的权值。将修改权值的新数据送给下层分类	0.4141375452057961
Logistic regression 读书笔记	资源区confilter升级之词表匹配算法调研分析词表匹配贴吧confilter词表匹配算法介绍贴吧confilter词表匹配算法的分析trie树介绍trie树进行词表匹配的分析ac自动机介绍ac自动机进行词表匹配的分析改进内存的ac自动机介绍tst（ternary-search- tree）介绍tst（ternary-search- tree）进行词表匹配的分析资源confilter词表统计分析总结词表匹配confilter为内容过滤模块，词表匹配	0.41185013154833006

LocalSearchRelevanceImprovement	Debug Address Queries8/23/2013Bing Local Search RelevanceNTCG MetricsDocumentationhttps://microsoft-my.sharepoint.com/personal/aoakley_microsoft_com/Documents/2013/2013-05-22%20Maps%20metrics%20Qi.pptx?web=1Use it to identify the group of quer	0.4320700457004544
LocalSearchRelevanceImprovement	WPO Local RelevancePing Yin2017-03-21OverviewWPO’s role in local relevance pipelineLocal Entity StampingArchitecture overviewWPO Local Relevance Models.Query: exton mall, User location: Wallingford, PAWPO RolesExtract/detect all entity	0.41588877327197715
LocalSearchRelevanceImprovement	Local Search Popularity V2 DesignBing Local SearchDevXiaohui Liu, Fengxia PanPMDave BargeronMilestoneAl. M1ContributorsFeature Bug IDSignoffPM Spec Linkhttps://microsoft.sharepoint.com/teams/localsearch/_layouts/15/WopiFrame.aspx?s	0.40042552084543953
LocalSearchRelevanceImprovement	Index Quality UpdateAgendaMetrics UpdateSelection Model ImprovementRecall TierOffice ImprovementChallenges and Pain PointsHow to measure index quality?Ideally: sampling from all “good” images and see how much we covered.sampling from a	0.3970751744019962
LocalSearchRelevanceImprovement	WPO Local Relevance Tech TalkWPO Local Relevance TeamOverviewWPO’s role in local relevance pipelineLocal ExperienceArchitecture overviewMetricsWPO Local Relevance Model IntroductionWPO Query understanding and Location understandingWhy do	0.3922340543475022
LocalSearchRelevanceImprovement	Anchor and Click Stream RankingSteven ZittrowerBing Local Search RelevanceHypothesisConverting local search’s unstructured and raw text streams into semi-structured forms will improve ranking and offer relevance benefits.TestUsing classifiers 	0.3859979050988799
LocalSearchRelevanceImprovement	Local Search Platform PM Onboarding GuideAuthors: Dany DaherDate: 10/18/2013Architecture OverviewHow Local Search Works Local Data Platform Architecture MetricsLocal Metrics:  http://jeffke/localMetrics/Definition of QLDCG: Local Discoun	0.3821492595458332
LocalSearchRelevanceImprovement	Leveraging Satori Knowledge in Web Ranking StackMicroSegment and Index ServeMotivationTarget at semantic queries (*defined by MALTA)Often contain more than one entity and relationSometimes involve entity inferenceTerm matching may not handle s	0.3772272331189228
LocalSearchRelevanceImprovement	Local Search Online Learning Lihong LiFengxia PanAgendaOnline LearningBiased user engagement dataLocal results positional bias estimation method & ExperimentOffline click evaluatorL2 ranker improvement using online click dataExperiment &	0.3731853569374242
LocalSearchRelevanceImprovement	MQ for CALOverviewSpellerQASMQTriggerMQSingleQueryChainChainChainAugmentAugmentAugmentTailQuerySimplifiedSPCombSP1SP2Sp3AugmentAugmentPropertyBag - SQQueryAlterationListQueryAlterationSetQueryAlterationType	0.3641198478308069

LocalProbe - WinPhoneApp	Text Latitude Longitude S0:Local_L3DCG3 G0:Local_L3DCG3 S1:Local_L3DCG3 S2:Local_L3DCG3 Assignment RootCause(BadMetastream,PartialMatch,Cal,BadKeyword,OtherQU,Ranker,BingNotStable,Scraping,Metrics,MicroSegment,JudgeNoise,Unknown,BadEntity) BTC CanBeResolv	0.31268963362013996
LocalProbe - WinPhoneApp	Meta-stream work summaryHeyong WangClickstream exampleOverview: Click-Stream generationWeb logsLocal logsLocal clicked dataJoin with Local IndexWeb Clicked data (query, url etc.)IE ClickBing ClickIE SessionIE Tool Bar…Web Click	0.3055545004718159
LocalProbe - WinPhoneApp	Bing Local Search				Phonebook vNext Design DocumentDev ownerMickadBuddy dev(s)MichstePM ownerDabargerContributorsFeature areaMilestoneTable of contents1	Overview	32	Goals/Non Goals	53	Dependencies	64	Risks/Open Issues	75	0.24684038264521974
LocalProbe - WinPhoneApp	Normalization and Parsing OverviewTypes of NormalizationLimiting to just normalization, there are actually several different types of normalization which may be interesting:WhitespaceThis is:Converting all whitespace characters to spacestrippi	0.23901345771796506
LocalProbe - WinPhoneApp	Relevance ServiceScenarioIconApplicationDoc typeCandidatesModelRun0-termWord;OutlookWin32 client.All file typesMRUReuse ContentModel 1Client0-termPower PointWin32 client.Only ppt typeLocal + MRUReuse Conte	0.2216070009042507
LocalProbe - WinPhoneApp	Local Probe WinPhone AppPrint Date: 0000-00-00Spec StatusDraftTFS Feature IDRelease[Release]PMJacob Haynes Florian VossDesign[Design]Milestone[Milestone]Dev[Dev]User Research[User Research]Feature Team[Feature Team]Test	0.2200872549679767
LocalProbe - WinPhoneApp	CALQuery alterationAgendaRoadmap and VisionWhere are weWhere to goPlanHow to get thereProgress and looking aheadSodium so farMagnesium and beyondDeep DiveGolden QueryRoadmap & VisionWhere are weCurrent status/problem of CAL	0.2191168017423137
LocalProbe - WinPhoneApp	Local Probe bugsContents1.	Phone number format replacement	22.	Data on the Live Site does not correspond to data in the Local Probe	43.	Second time corrections	54.	Cuisine Selection	65.	Market settings affecting cuisine output	76.	Ranking is	0.21852775626867332
LocalProbe - WinPhoneApp	Local Search Popularity V2 DesignBing Local SearchDevXiaohui Liu, Fengxia PanPMDave BargeronMilestoneAl. M1ContributorsFeature Bug IDSignoffPM Spec Linkhttps://microsoft.sharepoint.com/teams/localsearch/_layouts/15/WopiFrame.aspx?s	0.1911298408553076
LocalProbe - WinPhoneApp	Uses Of Clicks Logs In LocalRelevance	serajago, pingyin, dzpotashOverviewCUV LogsIntent Model ImprovementsTop Links Mining'sGoogle Directions/Maps ClicksDistance Ranking ImprovementsLocation ApproximationPer Category Distance Distributio	0.1613523555677479

LocalCategorySearchPlan	Local Search Platform PM Onboarding GuideAuthors: Dany DaherDate: 10/18/2013Architecture OverviewHow Local Search Works Local Data Platform Architecture MetricsLocal Metrics:  http://jeffke/localMetrics/Definition of QLDCG: Local Discoun	0.48193415891472946
LocalCategorySearchPlan	Local Category Search Plan3 month StrategyData: Entity categorizationScalable, high precision/recallSegments: Food & Drink, Retail, Service, Auto, HotelMetaStream enrichmentQuery UnderstandingDolphin by defaultConsume PhoneBookQU to im	0.4718095764861916
LocalCategorySearchPlan	Keyword Prediction for Local SearchesRuchir RastogiMentor: Jia LiuManager: Leon ZhangOutlineProblem statementTraining data and clean-up strategiesConditional random field (CRF) modelsDeep learning modelsEnd to end measurementConclusi	0.42628709577379476
LocalCategorySearchPlan	Local Search Popularity V2 DesignBing Local SearchDevXiaohui Liu, Fengxia PanPMDave BargeronMilestoneAl. M1ContributorsFeature Bug IDSignoffPM Spec Linkhttps://microsoft.sharepoint.com/teams/localsearch/_layouts/15/WopiFrame.aspx?s	0.42241516884046215
LocalCategorySearchPlan	CALQuery alterationAgendaRoadmap and VisionWhere are weWhere to goPlanHow to get thereProgress and looking aheadSodium so farMagnesium and beyondDeep DiveGolden QueryRoadmap & VisionWhere are weCurrent status/problem of CAL	0.418192377415247
LocalCategorySearchPlan	Anchor and Click Stream RankingSteven ZittrowerBing Local Search RelevanceHypothesisConverting local search’s unstructured and raw text streams into semi-structured forms will improve ranking and offer relevance benefits.TestUsing classifiers 	0.34815175405017984
LocalCategorySearchPlan	Meta-stream work summaryHeyong WangClickstream exampleOverview: Click-Stream generationWeb logsLocal logsLocal clicked dataJoin with Local IndexWeb Clicked data (query, url etc.)IE ClickBing ClickIE SessionIE Tool Bar…Web Click	0.343464961095848
LocalCategorySearchPlan	Restaurants Features and ToolsReview SnippetXAPOSearchQueryWPOLERWPO OSCacheItemCacheIdList of YpIdsFiltersSorterEntityUpdate PostFixEntity Update OSCache IdCache ItemYpId and PostFixUXReview Snippet Data GroupCac	0.3401465854350787
LocalCategorySearchPlan	Local DCG11/02/2012AgendaGoals of Local DCGHow Local DCG is calculatedComparison of Local DCG versus sNDCGOperationalization for scalePlan for international rolloutPlan for Local DCG enhancementsGoals of Local DCGGoalsActions take to	0.33708881414687053
LocalCategorySearchPlan	QueryString Category owner Searchvote url 寇仲最后和谁在一起 ranking  xiaopeng http://searchvote.com/default.aspx?reviewid=209877 布里斯班 ranking  xiaopeng http://searchvote.com/default.aspx?reviewid=211685 必应词典 ranking  xiaopeng http://searchvote.com/default.aspx?re	0.32893693549706754

Local.Pba.Main	PBA Query Understanding MigrationTetyana Golub | Ming WuMotivationPBAvnextCurrent QU logic is complicated and hard to migrateLimitation from hard coded logicCurrent QU logic is complicated and not very flexibleHard to add new feature or adju	0.2753561388324081
Local.Pba.Main	Local DCG11/02/2012AgendaGoals of Local DCGHow Local DCG is calculatedComparison of Local DCG versus sNDCGOperationalization for scalePlan for international rolloutPlan for Local DCG enhancementsGoals of Local DCGGoalsActions take to	0.25300914417304116
Local.Pba.Main	L3 in LocalKefeng DengOutlineL3 IntroductionUse L3 in localL3 exampleL3 introductionFor Local: 28 IS machines per row, about 5 million entities per machine. MinBLA = 50L3 introductionL3 featuresSet featuresFeature Statistics for top 	0.22623205759065884
Local.Pba.Main	Bing Local Search				PBA Geo Location Feeds augmentation generation Dev ownerTetyana GolubBuddy dev(s)PM ownerDave BargeronContributorsFeature areaPBA Feeds query generationMilestoneAluminumTable of contents1	Overview	22	Goal	0.22014079066741402
Local.Pba.Main	Location and Data Services Team all hands10/08/2014AgendaCelebrate – Wei, 5minsLocal partners – Andy, 10minsLocal Data Services – Alex, 15minsGeocoder and GeoSpatial Services – Jai, 20minsLocation and Autosuggest Services – Sid, 15minsBing	0.20903460136528
Local.Pba.Main	Text Latitude Longitude S0:Local_L3DCG3 G0:Local_L3DCG3 S1:Local_L3DCG3 S2:Local_L3DCG3 Assignment RootCause(BadMetastream,PartialMatch,Cal,BadKeyword,OtherQU,Ranker,BingNotStable,Scraping,Metrics,MicroSegment,JudgeNoise,Unknown,BadEntity) BTC CanBeResolv	0.20165811819158566
Local.Pba.Main	Local Category Search StudyHuanan Zhang01/03/2018OutlineStructure of PBA (Prod) rankerIntent match ranker’s role in Prod rankerIssues of intent match rankerSolutions – metastream clean upMetastream measurementPreliminary resultsPBA	0.19425766658371033
Local.Pba.Main	Local and mm magnesium asksCALApril 2013Microsoft ConfidentialContextWe are expanding to many international markets for Win-blueCAL/Speller impact can range from -1 to +2 points in DCG. Recent MM US DSAT analysis (Dec 2012) showed close to 1	0.19253943951302244
Local.Pba.Main	PBAVnext and migrationFrank ZhangBenefit of vnextIt will reflect five years’ worth of local search relevance insights and lessons learned, including the relevance tuning principles we have discovered over the years.It will make it easier to suppor	0.19151848058636992
Local.Pba.Main	Progress in BLU Relevance  Marta Penas Centeno (mapena)Minghua Zhang (minghuaz)Jian Wu (jianwu)OutlineBLU as a service is the goal of our relevance improvementsBLU v3 is the relevance platform for BLU as a serviceRelevance improvements del	0.1913606314801613

Local US-Feed-List	US Privoder List 7/21/2016 internal/external  licensed/crawled Job scheduled isSeed comments for KAG whitelist for KAG? commetns for Feed en-US-FTWMissingEntityCorrection  Internal Internal allowed Y Dsats admin added reported missing business internally 	0.25232644749047606
Local US-Feed-List	CALQuery alterationAgendaRoadmap and VisionWhere are weWhere to goPlanHow to get thereProgress and looking aheadSodium so farMagnesium and beyondDeep DiveGolden QueryRoadmap & VisionWhere are weCurrent status/problem of CAL	0.2470241735258025
Local US-Feed-List	Local DCG11/02/2012AgendaGoals of Local DCGHow Local DCG is calculatedComparison of Local DCG versus sNDCGOperationalization for scalePlan for international rolloutPlan for Local DCG enhancementsGoals of Local DCGGoalsActions take to	0.22014302788332185
Local US-Feed-List	L3 in LocalKefeng DengOutlineL3 IntroductionUse L3 in localL3 exampleL3 introductionFor Local: 28 IS machines per row, about 5 million entities per machine. MinBLA = 50L3 introductionL3 featuresSet featuresFeature Statistics for top 	0.18341959000686878
Local US-Feed-List	Deal UnderstandingDeals with Low Quality: (some features/rules are listed below)Features/RulesExamplesNo user used; no verified informationThe policies about return365 Day Return Policy;Free Returns on All Orders; 45 Day Return Money Back 	0.16937956817036903
Local US-Feed-List	Local Search Popularity V2 DesignBing Local SearchDevXiaohui Liu, Fengxia PanPMDave BargeronMilestoneAl. M1ContributorsFeature Bug IDSignoffPM Spec Linkhttps://microsoft.sharepoint.com/teams/localsearch/_layouts/15/WopiFrame.aspx?s	0.1596765744933289
Local US-Feed-List	PAC: Features, Usage and ProcessThis is a document on how to get document features and build metaword/metastream via Page Analyzer and Classifier (PAC ) pipeline. ContentsKinds Of Features Supported By PAC	2Url/Title Features	2Body Features: Doc	0.15681534766908492
Local US-Feed-List	CAL OFE logsOFE raw logs are cooked with the CALOFELogExtraction script, located in answers_alterations\private\OfflineDataGen\QueryAlteration\CALOFE\CALOFE.slnCooking the raw logsTo cook your logs, you need to runanswers_alterations\private\Offli	0.15507906642135488
Local US-Feed-List	Local Search – Entity Containment Short blurb of what this spec is aboutMilestone:  MG,ALSpec StatusDraftTFS Feature IDPMSandhya GuntreddyContributorsRajesh Srivastava, Prajakta Joshi,Kanad, PrashantSpec Location:https://microsoft.sh	0.14606949554240053
Local US-Feed-List	Local Search Online Learning Lihong LiFengxia PanAgendaOnline LearningBiased user engagement dataLocal results positional bias estimation method & ExperimentOffline click evaluatorL2 ranker improvement using online click dataExperiment &	0.12447103274192119

Local Search and Entity Containment V2	Local Search Entity Schema for RelationShips (Entity Containment, Affinities) Short blurb of what this spec is aboutMilestone:  MagnesiumSpec StatusDraftTFS Feature IDPM/Doc OwnerSandhya GuntreddyContributors Scott, Bruno,Andrew,Prajakta	0.6317024612186041
Local Search and Entity Containment V2	Local Search – Entity Containment Short blurb of what this spec is aboutMilestone:  MG,ALSpec StatusDraftTFS Feature IDPMSandhya GuntreddyContributorsRajesh Srivastava, Prajakta Joshi,Kanad, PrashantSpec Location:https://microsoft.sh	0.6045745380256736
Local Search and Entity Containment V2	Local Search Popularity V2 DesignBing Local SearchDevXiaohui Liu, Fengxia PanPMDave BargeronMilestoneAl. M1ContributorsFeature Bug IDSignoffPM Spec Linkhttps://microsoft.sharepoint.com/teams/localsearch/_layouts/15/WopiFrame.aspx?s	0.43219313125874026
Local Search and Entity Containment V2	Entity Selection Pipeline Design DocScope:This document covers the design for entity selection pipeline in GDPV3. Near-Dupe clustering is not covered in this v1 version. The goal for this pipeline is to reduce junk rate and improve NII by stamping pub	0.42553920001176104
Local Search and Entity Containment V2	Bing Local Search				Phonebook vNext Design DocumentDev ownerMickadBuddy dev(s)MichstePM ownerDabargerContributorsFeature areaMilestoneTable of contents1	Overview	32	Goals/Non Goals	53	Dependencies	64	Risks/Open Issues	75	0.41566092270318344
Local Search and Entity Containment V2	Local Search Platform PM Onboarding GuideAuthors: Dany DaherDate: 10/18/2013Architecture OverviewHow Local Search Works Local Data Platform Architecture MetricsLocal Metrics:  http://jeffke/localMetrics/Definition of QLDCG: Local Discoun	0.40047253443393943
Local Search and Entity Containment V2	Local Relevance SQR (en-us + en-ca)March 14, 2017AgendaContext & Scope:EN-US & EN-CA, Mobile and SERP relevance focusedPBA (pre-web) relevance focusedQuality measurements DSAT examplesGeneral issuesKey Segments (Restaurants, Hotels, Re	0.3991919089218801
Local Search and Entity Containment V2	Bing Local Functional DetailsDocument StatusDate Created6/25/2013Last Updated2/28/2014Current StatusDraft Key StakeholdersProgram ManagementDany Daher; Tony Angell; Sumitra Sheth; Product ManagementTBD;Executive SponsorsEric Ca	0.3871081305050351
Local Search and Entity Containment V2	Named Entity RecognizerTao Peng and Kang LiEntity names recognitionRecognize person, location and organization namesBOSTON, April  16 - Kevin Garnett helped the Boston Celtics beat the L. A. Lakers in last year's NBA final. ( Tony Gutierrez / Asso	0.3850888711994134
Local Search and Entity Containment V2	Google-Bing Entity MatchingIn 75,563 Google scrape entities those with a non-empty name are 12,507: Mapped to Bing entities: 𝟖𝟒.𝟖𝟗% (=(10,162+455)/12,507). Missing data.Among entities in            and            1.07%(=83+51) have Lat/Lon	0.380200503707814

Local Search Schema for Entity Containment	Local Search Entity Schema for RelationShips (Entity Containment, Affinities) Short blurb of what this spec is aboutMilestone:  MagnesiumSpec StatusDraftTFS Feature IDPM/Doc OwnerSandhya GuntreddyContributors Scott, Bruno,Andrew,Prajakta	0.6654001661676385
Local Search Schema for Entity Containment	Google-Bing Entity MatchingIn 75,563 Google scrape entities those with a non-empty name are 12,507: Mapped to Bing entities: 𝟖𝟒.𝟖𝟗% (=(10,162+455)/12,507). Missing data.Among entities in            and            1.07%(=83+51) have Lat/Lon	0.43599102683468577
Local Search Schema for Entity Containment	Local Search Platform PM Onboarding GuideAuthors: Dany DaherDate: 10/18/2013Architecture OverviewHow Local Search Works Local Data Platform Architecture MetricsLocal Metrics:  http://jeffke/localMetrics/Definition of QLDCG: Local Discoun	0.4230948316733208
Local Search Schema for Entity Containment	Named Entity RecognizerTao Peng and Kang LiEntity names recognitionRecognize person, location and organization namesBOSTON, April  16 - Kevin Garnett helped the Boston Celtics beat the L. A. Lakers in last year's NBA final. ( Tony Gutierrez / Asso	0.4222791407462519
Local Search Schema for Entity Containment	Bing Local Functional DetailsDocument StatusDate Created6/25/2013Last Updated2/28/2014Current StatusDraft Key StakeholdersProgram ManagementDany Daher; Tony Angell; Sumitra Sheth; Product ManagementTBD;Executive SponsorsEric Ca	0.41547684525476625
Local Search Schema for Entity Containment	Local Search – Entity Containment Short blurb of what this spec is aboutMilestone:  MG,ALSpec StatusDraftTFS Feature IDPMSandhya GuntreddyContributorsRajesh Srivastava, Prajakta Joshi,Kanad, PrashantSpec Location:https://microsoft.sh	0.40517789922709474
Local Search Schema for Entity Containment	Local Search Popularity V2 DesignBing Local SearchDevXiaohui Liu, Fengxia PanPMDave BargeronMilestoneAl. M1ContributorsFeature Bug IDSignoffPM Spec Linkhttps://microsoft.sharepoint.com/teams/localsearch/_layouts/15/WopiFrame.aspx?s	0.39738632441567695
Local Search Schema for Entity Containment	Run web-search-like query against my dataSame Bing Web Search Indexing and Ranking engineIndex in a secondTransparent and real time index sync, no complex index-gen pipelinePrototype in an hourFast self-onboarding with freemium account, schema-d	0.38605286107796744
Local Search Schema for Entity Containment	Bing Local Search				Phonebook vNext Design DocumentDev ownerMickadBuddy dev(s)MichstePM ownerDabargerContributorsFeature areaMilestoneTable of contents1	Overview	32	Goals/Non Goals	53	Dependencies	64	Risks/Open Issues	75	0.3857040809940368
Local Search Schema for Entity Containment	Debug Address Queries8/23/2013Bing Local Search RelevanceNTCG MetricsDocumentationhttps://microsoft-my.sharepoint.com/personal/aoakley_microsoft_com/Documents/2013/2013-05-22%20Maps%20metrics%20Qi.pptx?web=1Use it to identify the group of quer	0.3740453526629228

Local Search Relevance SQR March-2017	Local Relevance SQR (en-us + en-ca)March 14, 2017AgendaContext & Scope:EN-US & EN-CA, Mobile and SERP relevance focusedPBA (pre-web) relevance focusedQuality measurements DSAT examplesGeneral issuesKey Segments (Restaurants, Hotels, Re	0.48325689924754683
Local Search Relevance SQR March-2017	Local Search Platform PM Onboarding GuideAuthors: Dany DaherDate: 10/18/2013Architecture OverviewHow Local Search Works Local Data Platform Architecture MetricsLocal Metrics:  http://jeffke/localMetrics/Definition of QLDCG: Local Discoun	0.48309960961099624
Local Search Relevance SQR March-2017	WPO Local RelevancePing Yin2017-03-21OverviewWPO’s role in local relevance pipelineLocal Entity StampingArchitecture overviewWPO Local Relevance Models.Query: exton mall, User location: Wallingford, PAWPO RolesExtract/detect all entity	0.39510528917119103
Local Search Relevance SQR March-2017	Local Junk Detection and DemotionJia Liu2017-06-14GDP Pipeline View: local data pipelineTriple StoreGOALStore every entity as a set of triples.Track all changes to an entity.TripleColumnDetailsSubjectThe guid of a triple’s pa	0.39131406713371675
Local Search Relevance SQR March-2017	GoldenQuery: Past Flights v1Session v1Nov, 2013Simple Explanation of GoldenQueryQuery level Explore & ExploitExplore against techniqueMemorization basedGQ service running before speller, intercept every queryContinues E&E{Microsoft off	0.37886861787356557
Local Search Relevance SQR March-2017	WPO Local Relevance Tech TalkWPO Local Relevance TeamOverviewWPO’s role in local relevance pipelineLocal ExperienceArchitecture overviewMetricsWPO Local Relevance Model IntroductionWPO Query understanding and Location understandingWhy do	0.3748474358903679
Local Search Relevance SQR March-2017	Local Category Search Plan3 month StrategyData: Entity categorizationScalable, high precision/recallSegments: Food & Drink, Retail, Service, Auto, HotelMetaStream enrichmentQuery UnderstandingDolphin by defaultConsume PhoneBookQU to im	0.3717430011028713
Local Search Relevance SQR March-2017	Debug Address Queries8/23/2013Bing Local Search RelevanceNTCG MetricsDocumentationhttps://microsoft-my.sharepoint.com/personal/aoakley_microsoft_com/Documents/2013/2013-05-22%20Maps%20metrics%20Qi.pptx?web=1Use it to identify the group of quer	0.36734211453079735
Local Search Relevance SQR March-2017	Location and Data Services Team all hands10/08/2014AgendaCelebrate – Wei, 5minsLocal partners – Andy, 10minsLocal Data Services – Alex, 15minsGeocoder and GeoSpatial Services – Jai, 20minsLocation and Autosuggest Services – Sid, 15minsBing	0.3582570278830789
Local Search Relevance SQR March-2017	Whole Page RelevanceShip Meeting 08/14/2012AgendaSummary of IssuesSpecial TopicsWhole Page Relevance - IssuesTeamIssue Description StatusOwnerDue Action UpdateINTL Mon-GsheldonNo major issuesCaptions MetricsSBS – Monthly 	0.35656705509562436

Local Search Platform PM Onboarding Guide	Local Search Platform PM Onboarding GuideAuthors: Dany DaherDate: 10/18/2013Architecture OverviewHow Local Search Works Local Data Platform Architecture MetricsLocal Metrics:  http://jeffke/localMetrics/Definition of QLDCG: Local Discoun	0.7841265878656839
Local Search Platform PM Onboarding Guide	Local Search Popularity V2 DesignBing Local SearchDevXiaohui Liu, Fengxia PanPMDave BargeronMilestoneAl. M1ContributorsFeature Bug IDSignoffPM Spec Linkhttps://microsoft.sharepoint.com/teams/localsearch/_layouts/15/WopiFrame.aspx?s	0.5274664502461313
Local Search Platform PM Onboarding Guide	Local Search – Entity Containment Short blurb of what this spec is aboutMilestone:  MG,ALSpec StatusDraftTFS Feature IDPMSandhya GuntreddyContributorsRajesh Srivastava, Prajakta Joshi,Kanad, PrashantSpec Location:https://microsoft.sh	0.4668695285894543
Local Search Platform PM Onboarding Guide	Bing Local Search				Phonebook vNext Design DocumentDev ownerMickadBuddy dev(s)MichstePM ownerDabargerContributorsFeature areaMilestoneTable of contents1	Overview	32	Goals/Non Goals	53	Dependencies	64	Risks/Open Issues	75	0.449775465178306
Local Search Platform PM Onboarding Guide	Local Category Search Plan3 month StrategyData: Entity categorizationScalable, high precision/recallSegments: Food & Drink, Retail, Service, Auto, HotelMetaStream enrichmentQuery UnderstandingDolphin by defaultConsume PhoneBookQU to im	0.4483161104190942
Local Search Platform PM Onboarding Guide	Bing Local Search				PBA Geo Location Feeds augmentation generation Dev ownerTetyana GolubBuddy dev(s)PM ownerDave BargeronContributorsFeature areaPBA Feeds query generationMilestoneAluminumTable of contents1	Overview	22	Goal	0.43479027586196656
Local Search Platform PM Onboarding Guide	Bing Local Search				PBA QU Post-processing in QAS Dev ownerMing WuBuddy dev(s)PM ownerContributorsFeature areaPBA Query ProcessingMilestoneAluminumTable of contents1	Overview	22	Goals/Non Goals	23	Risks/Open Issues	24	Desi	0.43438462924345533
Local Search Platform PM Onboarding Guide	Keyword Prediction for Local SearchesRuchir RastogiMentor: Jia LiuManager: Leon ZhangOutlineProblem statementTraining data and clean-up strategiesConditional random field (CRF) modelsDeep learning modelsEnd to end measurementConclusi	0.4166548763801729
Local Search Platform PM Onboarding Guide	Deep Learning: The Path ForwardTuring/AGI/WITSaurabh TiwaryGoalsStrategyDL first everywhereScaleAGI-fying building blocksNew ScenarioLight up T@W & Unified QUDL-firstWe have been hedging our effortsLet’s do (a little bit of) everyt	0.4000975968862174
Local Search Platform PM Onboarding Guide	Local Search Online Learning Lihong LiFengxia PanAgendaOnline LearningBiased user engagement dataLocal results positional bias estimation method & ExperimentOffline click evaluatorL2 ranker improvement using online click dataExperiment &	0.3797443677171368

Local Probe bugs v2	Local Probe bugsContents1.	Phone number format replacement	22.	Data on the Live Site does not correspond to data in the Local Probe	43.	Second time corrections	54.	Cuisine Selection	65.	Market settings affecting cuisine output	76.	Ranking is	0.4155922150616032
Local Probe bugs v2	Uses Of Clicks Logs In LocalRelevance	serajago, pingyin, dzpotashOverviewCUV LogsIntent Model ImprovementsTop Links Mining'sGoogle Directions/Maps ClicksDistance Ranking ImprovementsLocation ApproximationPer Category Distance Distributio	0.3221315694511776
Local Probe bugs v2	Local DCG11/02/2012AgendaGoals of Local DCGHow Local DCG is calculatedComparison of Local DCG versus sNDCGOperationalization for scalePlan for international rolloutPlan for Local DCG enhancementsGoals of Local DCGGoalsActions take to	0.2520684491408452
Local Probe bugs v2	Bing Local Search				PBA QU Post-processing in QAS Dev ownerMing WuBuddy dev(s)PM ownerContributorsFeature areaPBA Query ProcessingMilestoneAluminumTable of contents1	Overview	22	Goals/Non Goals	23	Risks/Open Issues	24	Desi	0.24447599237522458
Local Probe bugs v2	US Privoder List 7/21/2016 internal/external  licensed/crawled Job scheduled isSeed comments for KAG whitelist for KAG? commetns for Feed en-US-FTWMissingEntityCorrection  Internal Internal allowed Y Dsats admin added reported missing business internally 	0.24247188746972567
Local Probe bugs v2	WPO Local RelevancePing Yin2017-03-21OverviewWPO’s role in local relevance pipelineLocal Entity StampingArchitecture overviewWPO Local Relevance Models.Query: exton mall, User location: Wallingford, PAWPO RolesExtract/detect all entity	0.23118712778943748
Local Probe bugs v2	Page | 2                                 <Si-09.1> Cross Page Junk Detection – V2Feature One-PagerDocument Version:0.9Authors:arahin, lidonzDocument Status:1.0Date:7/20/2014Feature OverviewDescription:Use new Main Body signal	0.22830037522579152
Local Probe bugs v2	Bing Local Search				Phonebook vNext Design DocumentDev ownerMickadBuddy dev(s)MichstePM ownerDabargerContributorsFeature areaMilestoneTable of contents1	Overview	32	Goals/Non Goals	53	Dependencies	64	Risks/Open Issues	75	0.2273608468016987
Local Probe bugs v2	The Data Skew ProblemFei Xu2/27/2018The Scheduled TalksMarch 18th Dave Maltz – OSD future network March 25th Pat – TBD April 1st Pat – TBDApril 8th Brad – Terasort in 12 minutesApril 15th Eric – The Global Scheduler April 22nd Brian – 	0.22209129234934205
Local Probe bugs v2	Local Junk Detection and DemotionJia Liu2017-06-14GDP Pipeline View: local data pipelineTriple StoreGOALStore every entity as a set of triples.Track all changes to an entity.TripleColumnDetailsSubjectThe guid of a triple’s pa	0.21882570797506018

Local Probe Improvements for Corrections Analysis and Debugging	Publication Date Optimization Design and Implement For zh-cn MarketReview and CommentMei Yang; Ted WildAuthorJia LiuDesignBackgroundPublication date is a very fundamental and important feature. It can help fresh ranking, solve mainline out	0.5351918726920879
Local Probe Improvements for Corrections Analysis and Debugging	Publication date optimization for Japan marketBackgroundPublication date is very important to fresh queries, outdated issues and caption date showing. Now the coverage of publication date for Japan market is very low because publication date extract	0.5269751975166908
Local Probe Improvements for Corrections Analysis and Debugging	Local Search Entity Schema for RelationShips (Entity Containment, Affinities) Short blurb of what this spec is aboutMilestone:  MagnesiumSpec StatusDraftTFS Feature IDPM/Doc OwnerSandhya GuntreddyContributors Scott, Bruno,Andrew,Prajakta	0.5268283720488431
Local Probe Improvements for Corrections Analysis and Debugging	Publication date optimization for zh-cn marketBackgroundPublication date is a very fundamental and important feature. It can help fresh ranking, whole page user experience: caption date show and freshness internal metrics, also to solve mainline out	0.512853741746782
Local Probe Improvements for Corrections Analysis and Debugging	CoreCAL Improvements		Page 2 of 5CoreCAL ImprovementsDescriptionDuring Sodium, CAL Team would invest on optimizing separately for L0\L1\L2 on top of current CoreCAL improvements. Multiple Query Project will target Fidelity\SBS\SSRx while CoreCAL imp	0.5068132990429144
Local Probe Improvements for Corrections Analysis and Debugging	Deal Ranking ImprovementsDeal Understanding ImprovementsGoal: Increase general deal coverage (deal product type from specific to general).Solution: Identify the prefix and suffix of title by punctuations and prep. Remove the prefix and suffix from t	0.4976989568492507
Local Probe Improvements for Corrections Analysis and Debugging	Author: Tony AngellDate: 08/01/13LocalProbe Improvements for Corrections Analysis and DebuggingTable of ContentsP0 Issues	2Issue: LocalProbe is unpredictable in the amount of time it takes to return a query and how long it takes to investigate a	0.48976572451145406
Local Probe Improvements for Corrections Analysis and Debugging	I’d like to explain in more details my idea of improving Dolphin, by improving its robustness of query variations and some previously unseen terms. Our rules don’t cover many query patterns. E.g., {top rated chinese restaurants} works well, but not {chi	0.4866322759311166
Local Probe Improvements for Corrections Analysis and Debugging	Training Data Repository v2Sourabh ChandakAgendaWhy TDR v2TDR explainedOnboarding processNext StepsSummaryDependenciesQuestionsProblemTraining data The most valuable resource for any ranker training experiment. Comprises of <quer	0.47684440611601897
Local Probe Improvements for Corrections Analysis and Debugging	Term expansion summaryGoalsVisible changes in ARDSImprove “no match” issuesImprove rank qualityLimit FPs. Pre-work neededPort names tagger to C#/C++Query timeWSD and entity taggerEntity tagging in query logs (Britney Spears bio -> <p	0.46750080527066523

Local Probe Functional Details	Bing Local Functional DetailsDocument StatusDate Created6/25/2013Last Updated2/28/2014Current StatusDraft Key StakeholdersProgram ManagementDany Daher; Tony Angell; Sumitra Sheth; Product ManagementTBD;Executive SponsorsEric Ca	0.43093343763853054
Local Probe Functional Details	Local Search Entity Schema for RelationShips (Entity Containment, Affinities) Short blurb of what this spec is aboutMilestone:  MagnesiumSpec StatusDraftTFS Feature IDPM/Doc OwnerSandhya GuntreddyContributors Scott, Bruno,Andrew,Prajakta	0.35335781540490896
Local Probe Functional Details	Site Quality ClassificationGuihong CaoDefinition of the ProblemWhat is site quality?Google’s definition includes the following dimensionsDuplicated content within the siteTrustworthyOn demand media? Quality controlSite authorityAuthor 	0.3485422456837565
Local Probe Functional Details	Named Entity RecognizerTao Peng and Kang LiEntity names recognitionRecognize person, location and organization namesBOSTON, April  16 - Kevin Garnett helped the Boston Celtics beat the L. A. Lakers in last year's NBA final. ( Tony Gutierrez / Asso	0.3345146545419169
Local Probe Functional Details	CAL OFE logsOFE raw logs are cooked with the CALOFELogExtraction script, located in answers_alterations\private\OfflineDataGen\QueryAlteration\CALOFE\CALOFE.slnCooking the raw logsTo cook your logs, you need to runanswers_alterations\private\Offli	0.3212385696772371
Local Probe Functional Details	Partner Index as ServiceWhat is the Problem? RequirementCurrent status of Bing Image StackDiscoveryClient tend to provide feed for full corpusWeb crawlerImage Content RetrievalSpecial agreement, some even behind authentication for access	0.32065484784785214
Local Probe Functional Details	Local Category Search Plan3 month StrategyData: Entity categorizationScalable, high precision/recallSegments: Food & Drink, Retail, Service, Auto, HotelMetaStream enrichmentQuery UnderstandingDolphin by defaultConsume PhoneBookQU to im	0.3201955597541784
Local Probe Functional Details	Entity Selection Pipeline Design DocScope:This document covers the design for entity selection pipeline in GDPV3. Near-Dupe clustering is not covered in this v1 version. The goal for this pipeline is to reduce junk rate and improve NII by stamping pub	0.29528039865943645
Local Probe Functional Details	Publication date optimization for zh-cn marketBackgroundPublication date is a very fundamental and important feature. It can help fresh ranking, whole page user experience: caption date show and freshness internal metrics, also to solve mainline out	0.2936647294354468
Local Probe Functional Details	Publication date optimization for Japan marketBackgroundPublication date is very important to fresh queries, outdated issues and caption date showing. Now the coverage of publication date for Japan market is very low because publication date extract	0.27914797783860956

Local Popularity V2 Design	Local Search Popularity V2 DesignBing Local SearchDevXiaohui Liu, Fengxia PanPMDave BargeronMilestoneAl. M1ContributorsFeature Bug IDSignoffPM Spec Linkhttps://microsoft.sharepoint.com/teams/localsearch/_layouts/15/WopiFrame.aspx?s	0.4940869862594356
Local Popularity V2 Design	Local Entity PopularityJia Liu4/23/2018Project statusStepsDetailsTime ScheduleInvestigateInvestigate old version local entity popularity:Problem define, measurement, feature extraction, training/publish pipeline, usage.12.4 – 12.18	0.36396049969184263
Local Popularity V2 Design	Local Popularity V2Xiaohui Liu, Dave Bargeron, Fengxia PanAgendaProblem and motivationSolutionTechnique deep diveFeature MeasurementPipeline GDI marketsFuture workMotivationEnable LDCG v2Improve local search relevanceRelated 	0.3607604064925758
Local Popularity V2 Design	Microsoft US Immigration PortalHow To Update Your DependentsJuly 24, 2017Step 1: Log in to your account by clicking “Log In”, either in the header or in the banner image.Step 2: Go to Your Family from the header, or by selecting “Manage Your Depen	0.35940158232697156
Local Popularity V2 Design	Deal UnderstandingDeals with Low Quality: (some features/rules are listed below)Features/RulesExamplesNo user used; no verified informationThe policies about return365 Day Return Policy;Free Returns on All Orders; 45 Day Return Money Back 	0.3542137008680826
Local Popularity V2 Design	Bing Local Functional DetailsDocument StatusDate Created6/25/2013Last Updated2/28/2014Current StatusDraft Key StakeholdersProgram ManagementDany Daher; Tony Angell; Sumitra Sheth; Product ManagementTBD;Executive SponsorsEric Ca	0.34705709353849346
Local Popularity V2 Design	Local Search – Entity Containment Short blurb of what this spec is aboutMilestone:  MG,ALSpec StatusDraftTFS Feature IDPMSandhya GuntreddyContributorsRajesh Srivastava, Prajakta Joshi,Kanad, PrashantSpec Location:https://microsoft.sh	0.3371121032974794
Local Popularity V2 Design	Bing Local Search				PBA QU Post-processing in QAS Dev ownerMing WuBuddy dev(s)PM ownerContributorsFeature areaPBA Query ProcessingMilestoneAluminumTable of contents1	Overview	22	Goals/Non Goals	23	Risks/Open Issues	24	Desi	0.32778504729944524
Local Popularity V2 Design	Local Junk Detection and DemotionJia Liu2017-06-14GDP Pipeline View: local data pipelineTriple StoreGOALStore every entity as a set of triples.Track all changes to an entity.TripleColumnDetailsSubjectThe guid of a triple’s pa	0.3227297811257738
Local Popularity V2 Design	Uses Of Clicks Logs In LocalRelevance	serajago, pingyin, dzpotashOverviewCUV LogsIntent Model ImprovementsTop Links Mining'sGoogle Directions/Maps ClicksDistance Ranking ImprovementsLocation ApproximationPer Category Distance Distributio	0.3133088747955822

Local Popularity V2	Local Search Popularity V2 DesignBing Local SearchDevXiaohui Liu, Fengxia PanPMDave BargeronMilestoneAl. M1ContributorsFeature Bug IDSignoffPM Spec Linkhttps://microsoft.sharepoint.com/teams/localsearch/_layouts/15/WopiFrame.aspx?s	0.38061562024152246
Local Popularity V2	Local Popularity V2Xiaohui Liu, Dave Bargeron, Fengxia PanAgendaProblem and motivationSolutionTechnique deep diveFeature MeasurementPipeline GDI marketsFuture workMotivationEnable LDCG v2Improve local search relevanceRelated 	0.2697313284504077
Local Popularity V2	Local Entity PopularityJia Liu4/23/2018Project statusStepsDetailsTime ScheduleInvestigateInvestigate old version local entity popularity:Problem define, measurement, feature extraction, training/publish pipeline, usage.12.4 – 12.18	0.2637567678938392
Local Popularity V2	Bing Local Functional DetailsDocument StatusDate Created6/25/2013Last Updated2/28/2014Current StatusDraft Key StakeholdersProgram ManagementDany Daher; Tony Angell; Sumitra Sheth; Product ManagementTBD;Executive SponsorsEric Ca	0.2494289409763526
Local Popularity V2	Microsoft US Immigration PortalHow To Update Your DependentsJuly 24, 2017Step 1: Log in to your account by clicking “Log In”, either in the header or in the banner image.Step 2: Go to Your Family from the header, or by selecting “Manage Your Depen	0.24138483331364824
Local Popularity V2	Text Latitude Longitude S0:Local_L3DCG3 G0:Local_L3DCG3 S1:Local_L3DCG3 S2:Local_L3DCG3 Assignment RootCause(BadMetastream,PartialMatch,Cal,BadKeyword,OtherQU,Ranker,BingNotStable,Scraping,Metrics,MicroSegment,JudgeNoise,Unknown,BadEntity) BTC CanBeResolv	0.21351254393556393
Local Popularity V2	L3 in LocalKefeng DengOutlineL3 IntroductionUse L3 in localL3 exampleL3 introductionFor Local: 28 IS machines per row, about 5 million entities per machine. MinBLA = 50L3 introductionL3 featuresSet featuresFeature Statistics for top 	0.20782287233171554
Local Popularity V2	Machine Learning Categorization & Popularity2012-08-30 | Nicolas NicolovGoalsShow how categorization and popularity systems work.Introduce important ML concepts.Illustrate ML techniques through examples.(aiming to be self-contained)Categoriz	0.20723713244774145
Local Popularity V2	Location and Data Services Team all hands10/08/2014AgendaCelebrate – Wei, 5minsLocal partners – Andy, 10minsLocal Data Services – Alex, 15minsGeocoder and GeoSpatial Services – Jai, 20minsLocation and Autosuggest Services – Sid, 15minsBing	0.20290494828149966
Local Popularity V2	Local Search Entity Schema for RelationShips (Entity Containment, Affinities) Short blurb of what this spec is aboutMilestone:  MagnesiumSpec StatusDraftTFS Feature IDPM/Doc OwnerSandhya GuntreddyContributors Scott, Bruno,Andrew,Prajakta	0.1938855396235014

Local DCG v1	Local DCG11/02/2012AgendaGoals of Local DCGHow Local DCG is calculatedComparison of Local DCG versus sNDCGOperationalization for scalePlan for international rolloutPlan for Local DCG enhancementsGoals of Local DCGGoalsActions take to	0.6252743815955057
Local DCG v1	Text Latitude Longitude S0:Local_L3DCG3 G0:Local_L3DCG3 S1:Local_L3DCG3 S2:Local_L3DCG3 Assignment RootCause(BadMetastream,PartialMatch,Cal,BadKeyword,OtherQU,Ranker,BingNotStable,Scraping,Metrics,MicroSegment,JudgeNoise,Unknown,BadEntity) BTC CanBeResolv	0.31015218737335204
Local DCG v1	Distance Model Updates in LDCG V2Local Relevance and Measurement TeamAgendaDistance feature in LDCG V1Why was the switch to computing distance made?First implementation of Distance feature in LDCG V2, & improvement areasProcess followed for 	0.2932872632640995
Local DCG v1	Bing Local Search				PBA Geo Location Feeds augmentation generation Dev ownerTetyana GolubBuddy dev(s)PM ownerDave BargeronContributorsFeature areaPBA Feeds query generationMilestoneAluminumTable of contents1	Overview	22	Goal	0.28025752277232485
Local DCG v1	After Action Report TellMeService, Shredder, AugmentationService, Enrichment, UCIService (Insights), Entity Service<<insert Service Name>>	 [Technology /Service Name]Disaster Recovery Plan (DRP)	 						Office Group Name : After Action Report 	0.27248179521170723
Local DCG v1	Location and Data Services Team all hands10/08/2014AgendaCelebrate – Wei, 5minsLocal partners – Andy, 10minsLocal Data Services – Alex, 15minsGeocoder and GeoSpatial Services – Jai, 20minsLocation and Autosuggest Services – Sid, 15minsBing	0.27218011423727506
Local DCG v1	WPO Local Relevance Tech TalkWPO Local Relevance TeamOverviewWPO’s role in local relevance pipelineLocal ExperienceArchitecture overviewMetricsWPO Local Relevance Model IntroductionWPO Query understanding and Location understandingWhy do	0.26049672918608135
Local DCG v1	PO Box 91059Seattle, WA 98111-9159	VISION 	Member Claim Form 	for Microsoft  This form is to be used for Vision claims (routine exam and hardware) where you incurred expenses from a provider who did not bill the plan directly.For Medical or De	0.25707337050681983
Local DCG v1	LDCG V3Knowledge Transfer2017-04-14Brett Clippingdale, Sean King, Vikas Mittal, Li JiangLDCG V3 OutlineLDCG V2 vs V3: High-level comparisonLDCG V3: New distance ModelV2 vs V3 OverviewLDCG V3: GeoIntent HIT appLDCG V3: Calculate distance 	0.25475569041003815
Local DCG v1	FY18 AGI Encoder Roadmap		Nitin Sharma, Gargi Ghosh, Saurabh TiwaryAgendaIntroductionFY18 Goals and Focus AreasFocus Area Deep DiveCustomer scenariosDetailed RoadmapAGI Encoder: MotivationGoal: One general intent encoder of source 	0.24952597362373652

Lexical analyzer	Lexical analyzer (fa_lex)Input: a buffer of textOutput: a sequence of tokens, each token is <from, to, tag>For C++:Input: “if(++i==0) {j = 0;}”Output: if/OP (/LRB ++/OP i/VAR ==/OP 0/NUM )/RBR {/LCBR j/VAR =/OP 0/NUM ;/OP }/RCBREach rule:Des	0.38373150327747113
Lexical analyzer	Local Search Online Learning Lihong LiFengxia PanAgendaOnline LearningBiased user engagement dataLocal results positional bias estimation method & ExperimentOffline click evaluatorL2 ranker improvement using online click dataExperiment &	0.29017317942857124
Lexical analyzer	Keyword Predictor Design DocumentName: Ruchir RastogiMentor: Jia LiuManager: Leon ZhangProject overviewThe goal of this project is to design a machine-learning model that can predict keywords in a local query for improving local search relevance	0.24368187640479536
Lexical analyzer	CALQuery alterationAgendaRoadmap and VisionWhere are weWhere to goPlanHow to get thereProgress and looking aheadSodium so farMagnesium and beyondDeep DiveGolden QueryRoadmap & VisionWhere are weCurrent status/problem of CAL	0.24066324174113335
Lexical analyzer	Mobile 100k Compete Data analysis with G - Simulation Report6/6/2014Mobile Simulation AnalysisThis analysis compares Google and Bing on iOS for 3 querysets.REPORTS GENERATED FOR **: Overall Metrics Coverage (WP, ML and Bot)IY (WP, ML and Bot	0.2336591548971562
Lexical analyzer	Query Formulation Review of FY15 Goals and Silicon achievements/learningsSilicon ScorecardAreaGoalAchievementQF Relevance(Autosuggest, Related Search)SSRx+0.052Annualized Revenue+$58mRelated Search RelevanceBeat G on DO defect ra	0.2284523466748656
Lexical analyzer	Named Entity RecognizerTao Peng and Kang LiEntity names recognitionRecognize person, location and organization namesBOSTON, April  16 - Kevin Garnett helped the Boston Celtics beat the L. A. Lakers in last year's NBA final. ( Tony Gutierrez / Asso	0.228106291983202
Lexical analyzer	Mobile LT Discussion6/20/2014AgendaTop IssuesAd Product and Ad Quality UpdateSummarized Finding NDT Supply AnalysisSummarized Finding Google CompeteStatusFeatureWindows phoneIphone/AndroidUp to 2 adsShipped 5/20/2014Shipped more 	0.22674392951103248
Lexical analyzer	Leveraging Satori Knowledge Graph in Web Ranking StackMicroSegment and Index ServeThe demo is about how to leverage Satori Knowledge Graph in Web ranking. It is joint work among relevance microsegment, Satori and index serve teams.MotivationSome	0.22040115029545307
Lexical analyzer	Production Models OverviewLU annotates incoming text input with semantic information in a contextual wayWorkflow built on top of Bing production infrastructure (QAS/XAP/Object Store)Feature representation: word embedding, n-grams and lexicons matche	0.2143536681721838

Leveraging Satori Knowledge in Web Ranking Stack	Leveraging Satori Knowledge Graph in Web Ranking StackMicroSegment and Index ServeThe demo is about how to leverage Satori Knowledge Graph in Web ranking. It is joint work among relevance microsegment, Satori and index serve teams.MotivationSome	0.7813978134190078
Leveraging Satori Knowledge in Web Ranking Stack	Leveraging Satori Knowledge in Web Ranking StackMicroSegment and Index ServeMotivationTarget at semantic queries (*defined by MALTA)Often contain more than one entity and relationSometimes involve entity inferenceTerm matching may not handle s	0.6981503143515967
Leveraging Satori Knowledge in Web Ranking Stack	Content Quality Classification & RankingGuihong Cao, Cheng NiuContent Quality for RankingContent quality = originality + trustworthy + information satisfaction + freshnessSpam sites, junk site, link farm, content farm, ….Search users are interes	0.45696027705745257
Leveraging Satori Knowledge in Web Ranking Stack	Local Search Online Learning Lihong LiFengxia PanAgendaOnline LearningBiased user engagement dataLocal results positional bias estimation method & ExperimentOffline click evaluatorL2 ranker improvement using online click dataExperiment &	0.42866269043639266
Leveraging Satori Knowledge in Web Ranking Stack	Local Category Search StudyHuanan Zhang01/03/2018OutlineStructure of PBA (Prod) rankerIntent match ranker’s role in Prod rankerIssues of intent match rankerSolutions – metastream clean upMetastream measurementPreliminary resultsPBA	0.3833657285654456
Leveraging Satori Knowledge in Web Ranking Stack	Move SBS (Learning from L3)Xiaopeng WuJunzhou WangWhat’s L3Bing ranking stackIndex selectionWorking on offline system, target recallL1Working on IFM, target recallL2Working on IFM, target precisionL3Working on TLA, target whole pag	0.3575900768362599
Leveraging Satori Knowledge in Web Ranking Stack	Partner Index as ServiceWhat is the Problem? RequirementCurrent status of Bing Image StackDiscoveryClient tend to provide feed for full corpusWeb crawlerImage Content RetrievalSpecial agreement, some even behind authentication for access	0.35660375274716
Leveraging Satori Knowledge in Web Ranking Stack	L2 Ranker Training and Feature Management						-- Shu HuangOutlineL2 ranker and truncation rankerFeature extractionFake L2 rankerFeature extraction pipelineMutiple ideal querysetsL2 ranker and truncation rankerFind the current prod ran	0.35554949441760103
Leveraging Satori Knowledge in Web Ranking Stack	Bing Local Functional DetailsDocument StatusDate Created6/25/2013Last Updated2/28/2014Current StatusDraft Key StakeholdersProgram ManagementDany Daher; Tony Angell; Sumitra Sheth; Product ManagementTBD;Executive SponsorsEric Ca	0.34065160682736656
Leveraging Satori Knowledge in Web Ranking Stack	Tmall&Taobao Rating MetawordsBackgroundWe’ve seen in regular DSAT review meetings the DSATs that we rank too high Tmall or Taobao page with low quality(Tmall page:low sales volume; Taobao page: low sales volume or shop with poor reputation).  Zh-CN ha	0.33065691775368555

LES with Speller in BFPR	LES with Speller in BFPRAnton AmirovBenefitsSupport for misspelled location, metrics improvementAlignment with web resultsCurrent statusHybridLESRaw QuerySpell Corrected QuerySpellerFLEFLEWithSpellerSome answers (AmberAlerts, Electio	0.5627983080100919
LES with Speller in BFPR	Speller Related Issues & SolutionsMing Wu2014-01-08Speller Related Issues – in nativePBA reads spell corrected query from Speller kif responseAssumes offsets are on raw query, which is not the caseE.g. {   piza hut} -> {pizzaiza hut}Proposed	0.41178498667413393
LES with Speller in BFPR	Introduction to XAP“The world is indeed full of peril and in it there are many dark places.”- J. R. R. Tolkien, The Lord of the RingsAlex Bakulin (albakuli)2/16/2016How online Bing worksHow online Bing worksXAP’s role in BingHost a	0.32358296344117504
LES with Speller in BFPR	Files Reuse in OfficeMahaveer KothariAgendaIntroductionHigh level overviewChallengesIntegration with Ideas/SearchWhat’s NextQ & AIntroductionHistory about reuse slides in PowerPoint. Documents supported. Document gallery Archit	0.32286458615751545
LES with Speller in BFPR	Dynamic Rank FeaturesWritten by Krysta Svore (ksvore)This document is meant to give a brief overview of the features used in the dynamic ranking component of Live search.  It contains an overview of the search process followed by the definitions of cu	0.3220114063981418
LES with Speller in BFPR	L-1B SPECIALIZED KNOWLEDGE QUESTIONNAIREMICROSOFT POSITION IN THE U.S.Provide the following information for your current position at the Microsoft.MICROSOFT POSITION ABROADProvide the following information for your position at the Microsoft’s su	0.28360081439044393
LES with Speller in BFPR	Augmented Query Parser Using Deep LearningDemi Guo (Bing Local Intern t-deguo)Manager: Leon ZhangMentor: Simona CabuzHello everyone, Today, I’m going to present my intern project: Augmented query parser using deep learning.About Me My name i	0.27916685946881825
LES with Speller in BFPR	Deal UnderstandingDeals with Low Quality: (some features/rules are listed below)Features/RulesExamplesNo user used; no verified informationThe policies about return365 Day Return Policy;Free Returns on All Orders; 45 Day Return Money Back 	0.2766597757099856
LES with Speller in BFPR	To whom it may concern,  We are Jia Liu and her husband, Edward Wild.  The bearers of this letter are Jia's mother, Chunxiang Lei, and father, Xinbao Liu.  Jia is a software engineer working at Microsoft on an L1 visa valid until 2020, and Edward is a	0.26789427367930857
LES with Speller in BFPR	Relevance Experimentation with DUOverviewThe ideal end state for any relevance improvement would consist of having one or more DU features shipped in the index that is then leveraged by the latest production ranker. This would achieve the highest leve	0.2600251750222402

LEDB Transition	LEDB Transition8/6/2014ScopeLEDB serialization jobsLEDB Object Store publish jobsLEDB Odyssey Publish job for the VanueMap featureEntity Schema update and maintenanceObject Store payload size and perf SLAPartner engagement and change manag	0.3836820617582734
LEDB Transition	Lexical analyzer (fa_lex)Input: a buffer of textOutput: a sequence of tokens, each token is <from, to, tag>For C++:Input: “if(++i==0) {j = 0;}”Output: if/OP (/LRB ++/OP i/VAR ==/OP 0/NUM )/RBR {/LCBR j/VAR =/OP 0/NUM ;/OP }/RCBREach rule:Des	0.29562043585915987
LEDB Transition	L2 Ranker Training and Feature Management						-- Shu HuangOutlineL2 ranker and truncation rankerFeature extractionFake L2 rankerFeature extraction pipelineMutiple ideal querysetsL2 ranker and truncation rankerFind the current prod ran	0.2951492931293795
LEDB Transition	FastRank--- a Decision-Tree based Ranking ModelYu SHIOutlineBackgroundAlgorithm overviewTraining implementationExperimentationChallengesReferencesBackgroundInvestigated by MSR in OsloShipped with July Tree 2010 (Denver)GoalsSpe	0.29410731679148544
LEDB Transition	Zh-cn Transportation Segment Optimization by Pattern EngineIntroductionThe pattern queries can cover almost 10% in all queries. We can summarize lots of patterns on Query and Document sides for different segments. We can recognize key terms, relations	0.2855311636083579
LEDB Transition	Zh-cn Transportation Segment Optimization by Pattern EngineJia Liu/Allen WangDSATsQuery: 吉林市到查干湖Relevant result title: 吉林市到查干湖怎么走近？_百度知道Irrelevant result title 1: 查干湖,中国查干湖,吉林查干湖,查干湖旅游,查干湖冬捕,国家AAAA ...Irrelevant result title 2: 查干湖_百度百科Irrel	0.2735325805688626
LEDB Transition	File Relevance Experimentation Design DocRecall AnalysisTest the search quality of external services like OLS, 3S, QF and SPO Search.Search scenarios: 0-term search, term search, 3S (Insert File and Attach File).Compare the recall: diff of returne	0.25869829182530324
LEDB Transition	Publication date optimization for Japan marketBackgroundPublication date is very important to fresh queries, outdated issues and caption date showing. Now the coverage of publication date for Japan market is very low because publication date extract	0.2517213771246992
LEDB Transition	Leveraging Satori Knowledge Graph in Web Ranking StackMicroSegment and Index ServeThe demo is about how to leverage Satori Knowledge Graph in Web ranking. It is joint work among relevance microsegment, Satori and index serve teams.MotivationSome	0.24678771745989544
LEDB Transition	Golden QueryEvery query countsImprove relevance: Relevance TechniquesWin/Loss basedGood technique has better win/loss ratioGeneric Ranker always doesn’t have good win/loss ratioWe do technique triage, and better win/loss ratio technique got sh	0.24140871187501683

LDCGv3	Distance Model Updates in LDCG V2Local Relevance and Measurement TeamAgendaDistance feature in LDCG V1Why was the switch to computing distance made?First implementation of Distance feature in LDCG V2, & improvement areasProcess followed for 	0.47156105755495165
LDCGv3	成交日期 买卖标志 成交价格 成交数量 成交金额 20160106 买入 100 1702 20160113 买入 100 1532 20160325 卖出 100 1695 20160708 卖出 100 1570 20160725 卖出 500 10700 20160802 卖出 300 6660 20160802 卖出 200 4430 20160803 卖出 200 4672 20160908 卖出 100 2695 成交日期 买卖标志 成交价格 成交数量 成交金额 20160112 买入 100	0.45204028110799416
LDCGv3	成交日期 买卖标志 成交价格 成交数量 成交金额 20160105 买入 100 897 20160108 卖出 8 200 1600 成交日期 买卖标志 成交价格 成交数量 成交金额 20160106 买入 100 1702 20160113 买入 100 1532 20160325 卖出 100 1695 20160708 卖出 100 1570 20160725 卖出 500 10700 20160802 卖出 300 6660 20160802 卖出 200 4430 20160803 卖出 20	0.4450310695617159
LDCGv3	成交日期 买卖标志 成交价格 成交数量 成交金额 2016年亏319 2015及2016年已完结 20160105 买入 100 897 20160108 卖出 8 200 1600 20150615 买入 100 1889 20150615 买入 100 1840 20150624 卖出 100 1585 20150720 买入 100 1073 20150721 买入 100 1098 20150721 买入 100 1086 20150723 买入 100 1110 20150818 卖出 500 	0.443584571613565
LDCGv3	Nlp情感分析工具使用执行步骤：分词执行程序：Shenbian_exlib_segpos使用说明： 	usage: ./Shenbian_exlib_segpos  segDictPath tagDictPath inputfile outputtype      			exDictLib > outputfile具体使用举例：     ./Shenbian_exlib_segpos ../../../../lib_wordseg/worddict_1-3-4-3_PD_B	0.43526887844539064
LDCGv3	Distance Model, LDS, L3Knowledge SharingNikita Melnichenko, Bing Local2017-04-21Overview of PBA relevance flow in FeedsL1Keyword matchWPOL2 levelRankerTruncationCategory matchName matchLogical DistanceUI sortingGIMXIMGDM	0.42442287736044926
LDCGv3	常用Linux命令：统计当前目录下所有.h文件的个数：find . -name "*.h" | wc -l统计当前目录下所有.h文件的总代码行数：find . -name "*.h" | xargs wc -l传输大文件时rz -be解压tar.gz文件tar zxvf x.tar.gz	0.42409278957648705
LDCGv3	成交日期 买卖标志 成交价格 成交数量 成交金额 20160105 买入 100 897 20160108 卖出 8 200 1600 成交日期 买卖标志 成交价格 成交数量 成交金额 20160106 买入 100 1702 成交日期 买卖标志 成交价格 成交数量 成交金额 20160105 买入 100 897 20160108 卖出 8 200 1600 	0.42293723724523424
LDCGv3	 阿里浏览器DNS解析加速布可2010.12.31AgendaDNS解析过程DNS协议阿里浏览器DNS解析加速浏览器查找域名的IPtaobao.com浏览器缓存(2-30min)系统缓存(DNS client resolver cache)Local DNS递归查询->dns1.禁用IE的dns缓存：Start Registry Editor. Locate and click the following key in the reg	0.4185344616312235
LDCGv3	资源区confilter升级之词表匹配算法调研分析词表匹配贴吧confilter词表匹配算法介绍贴吧confilter词表匹配算法的分析trie树介绍trie树进行词表匹配的分析ac自动机介绍ac自动机进行词表匹配的分析改进内存的ac自动机介绍tst（ternary-search- tree）介绍tst（ternary-search- tree）进行词表匹配的分析资源confilter词表统计分析总结词表匹配confilter为内容过滤模块，词表匹配	0.41772576475789674

LDCGV2_NewDistanceFormula_v4	Distance Model Updates in LDCG V2Local Relevance and Measurement TeamAgendaDistance feature in LDCG V1Why was the switch to computing distance made?First implementation of Distance feature in LDCG V2, & improvement areasProcess followed for 	0.5174354363309124
LDCGV2_NewDistanceFormula_v4	Distance Model, LDS, L3Knowledge SharingNikita Melnichenko, Bing Local2017-04-21Overview of PBA relevance flow in FeedsL1Keyword matchWPOL2 levelRankerTruncationCategory matchName matchLogical DistanceUI sortingGIMXIMGDM	0.50344784879721
LDCGV2_NewDistanceFormula_v4	Local DCG11/02/2012AgendaGoals of Local DCGHow Local DCG is calculatedComparison of Local DCG versus sNDCGOperationalization for scalePlan for international rolloutPlan for Local DCG enhancementsGoals of Local DCGGoalsActions take to	0.4745114907780727
LDCGV2_NewDistanceFormula_v4	Nlp情感分析工具使用执行步骤：分词执行程序：Shenbian_exlib_segpos使用说明： 	usage: ./Shenbian_exlib_segpos  segDictPath tagDictPath inputfile outputtype      			exDictLib > outputfile具体使用举例：     ./Shenbian_exlib_segpos ../../../../lib_wordseg/worddict_1-3-4-3_PD_B	0.4688723585750528
LDCGV2_NewDistanceFormula_v4	 阿里浏览器DNS解析加速布可2010.12.31AgendaDNS解析过程DNS协议阿里浏览器DNS解析加速浏览器查找域名的IPtaobao.com浏览器缓存(2-30min)系统缓存(DNS client resolver cache)Local DNS递归查询->dns1.禁用IE的dns缓存：Start Registry Editor. Locate and click the following key in the reg	0.439398720331536
LDCGV2_NewDistanceFormula_v4	Unix高级环境编程读书笔记第七章 进程环境C程序总是从main函数开始执行，main函数的原型：int main(int argc,  char* argv[]);argc:命令行参数个数argv:指向各个命令参数的指针 测试main函数参数： 测试结果： 使用size命令查看可执行文件的正文段、数据段、bss段的长度：dec：十进制表示三个段的总长度hex：十六进制表示三个段的总长度 共享库使得可执行文件不再需要包含公用的库例程，	0.4320287260747781
LDCGV2_NewDistanceFormula_v4	HIVE介绍简介是什么hive是一个基于hadoop的数据仓库。使用hadoop-hdfs作为数据存储层；提供类似SQL的语言（HQL），通过hadoop-mapreduce完成数据计算；通过HQL语言提供使用者部分传统RDBMS一样的表格查询特性和分布式存储计算特性。类似的系统有yahoo的pig[1] ，google的sawzall[2]，microsoft的DryadLINQ[3]。架构图表 1 hive架构图[4]操作界面：CLI，Web，Thriftdrive	0.4296050620814332
LDCGV2_NewDistanceFormula_v4	根据clientip和wideip获得最佳访问pool设计和实现架构设计数据库操作相关数据表结构region2cidrs(5283)：说明：将region2cidrs表中的所有记录select出来，得到[region,cidr]，将cidr使用 perl中的Net::CIDR ::cidr2range($cidr)将$cidr转化为[low_ip,high_ip]的形式，再利用ip到unsigned int的转换函数，最终转化为[low_uint,high_uint	0.4194272601381116
LDCGV2_NewDistanceFormula_v4	浅谈Redis的原理与应用tianzhedong（董天喆）大纲What is RedisWhy RedisHow To Use RedisWhat Is RedisWhat is RedisWhat is Rediskey value store可以持久化的cacheHashTableMemory DB它的高性能都是基于内存操作的基础data structure serverRedis支持复杂的数据特性，比如List, Set等Redis	0.41922945675424766
LDCGV2_NewDistanceFormula_v4	成交日期 买卖标志 成交价格 成交数量 成交金额 2016年亏319 2015及2016年已完结 20160105 买入 100 897 20160108 卖出 8 200 1600 20150615 买入 100 1889 20150615 买入 100 1840 20150624 卖出 100 1585 20150720 买入 100 1073 20150721 买入 100 1098 20150721 买入 100 1086 20150723 买入 100 1110 20150818 卖出 500 	0.41854268312702875

L4 Experiment Pipeline	L4 Experiment PipelineDate: Aug 20th, 2013Author: Bangyong LiangMotivation:L4’s functionality is to merge results from multiple queries. L4 has two types of merging strategies. One is query level merger and the other one is document level merger. 	0.6261780876504183
L4 Experiment Pipeline	DU Pipeline Sodium Achievements And Magnesium Plans　　Jia Liu2013-08-05OutlineSodium AchievementsMagnesium PlanMagnesium Work ItemsSodium Work ItemsAppendixSodium AchievementsWrapstar rating signalsTaobao, tmall; qna; novel; videoL3	0.48734884474197504
L4 Experiment Pipeline	Ranker Training Pipeline IntroductionAgendaPipeline OverviewGCC platformExtractionData/Feature PreparationMain Ranker TrainingSegment RankersPipeline OverviewGR OctTree: gcclinkMain Steps:Metastream injection (just info here)Querys	0.4573852578127813
L4 Experiment Pipeline	DU Pipeline V2Bram Gruneir, Ted Wild and Connie YangDocument Understanding Dev Talk6/27/2013DU Pipeline V2: frequency demoIntroduce the demo featureDevelopmentDeploymentDU Pipeline V2: frequency demoIntroduce the demo featureDevelopmen	0.43775900768111425
L4 Experiment Pipeline	Jia Liu2013-08-05DU Pipeline Sodium Achievements And Magnesium Plans For CJK　　OutlineSodium AchievementsMagnesium PlanMagnesium Work ItemsSodium Work ItemsAppendixSodium AchievementsWrapstar rating signalsTaobao, tmall; qna; novel; v	0.4135833680618922
L4 Experiment Pipeline	Entity Selection Pipeline Design DocScope:This document covers the design for entity selection pipeline in GDPV3. Near-Dupe clustering is not covered in this v1 version. The goal for this pipeline is to reduce junk rate and improve NII by stamping pub	0.38400659206665094
L4 Experiment Pipeline	Auto Category Classification PipelineHanqing Cui2012/10/25OutlinePain PointsThinkingAuto Category Classification PipelineAuto Page LabelingData SamplingTrainingFeature SelectionThresholdIterative TrainingInitial Seed Model Creati	0.34536532576785994
L4 Experiment Pipeline	YPCutoff Selection                                                                                    -Ganesh Poomal GirirajanQuery Flow in IndexFilterSet GenerationL1 RankingL2 RankingExampleQuery: Southeast{Miami,Florida}-broward county sc	0.3451307769343154
L4 Experiment Pipeline	LES with Speller in BFPRAnton AmirovBenefitsSupport for misspelled location, metrics improvementAlignment with web resultsCurrent statusHybridLESRaw QuerySpell Corrected QuerySpellerFLEFLEWithSpellerSome answers (AmberAlerts, Electio	0.3212649515688292
L4 Experiment Pipeline	File Relevance Experimentation Design DocRecall AnalysisTest the search quality of external services like OLS, 3S, QF and SPO Search.Search scenarios: 0-term search, term search, 3S (Insert File and Attach File).Compare the recall: diff of returne	0.316889802864438

L3 in Local	L3 in LocalKefeng DengOutlineL3 IntroductionUse L3 in localL3 exampleL3 introductionFor Local: 28 IS machines per row, about 5 million entities per machine. MinBLA = 50L3 introductionL3 featuresSet featuresFeature Statistics for top 	0.3423718521042388
L3 in Local	Text Latitude Longitude S0:Local_L3DCG3 G0:Local_L3DCG3 S1:Local_L3DCG3 S2:Local_L3DCG3 Assignment RootCause(BadMetastream,PartialMatch,Cal,BadKeyword,OtherQU,Ranker,BingNotStable,Scraping,Metrics,MicroSegment,JudgeNoise,Unknown,BadEntity) BTC CanBeResolv	0.28641426691290944
L3 in Local	L3 Distance Model for LocalNikita Melnichenko, Bing Local2016-04-12AgendaIntroduction to the Distance problemPrevious workA new approach: experiments and designResultsFuture developmentIntroduction to the Distance problemWe say “it’s a	0.2519837314230513
L3 in Local	WPO Local Relevance Tech TalkWPO Local Relevance TeamOverviewWPO’s role in local relevance pipelineLocal ExperienceArchitecture overviewMetricsWPO Local Relevance Model IntroductionWPO Query understanding and Location understandingWhy do	0.19890903568633428
L3 in Local	Distance Model Updates in LDCG V2Local Relevance and Measurement TeamAgendaDistance feature in LDCG V1Why was the switch to computing distance made?First implementation of Distance feature in LDCG V2, & improvement areasProcess followed for 	0.17273124812297372
L3 in Local		0.16600954286061959
L3 in Local	Local and mm magnesium asksCALApril 2013Microsoft ConfidentialContextWe are expanding to many international markets for Win-blueCAL/Speller impact can range from -1 to +2 points in DCG. Recent MM US DSAT analysis (Dec 2012) showed close to 1	0.14325433795135817
L3 in Local	WPO Local RelevancePing Yin2017-03-21OverviewWPO’s role in local relevance pipelineLocal Entity StampingArchitecture overviewWPO Local Relevance Models.Query: exton mall, User location: Wallingford, PAWPO RolesExtract/detect all entity	0.13580277878306907
L3 in Local	Local Search Platform PM Onboarding GuideAuthors: Dany DaherDate: 10/18/2013Architecture OverviewHow Local Search Works Local Data Platform Architecture MetricsLocal Metrics:  http://jeffke/localMetrics/Definition of QLDCG: Local Discoun	0.1251426850994507
L3 in Local	Move SBS (Learning from L3)Xiaopeng WuJunzhou WangWhat’s L3Bing ranking stackIndex selectionWorking on offline system, target recallL1Working on IFM, target recallL2Working on IFM, target precisionL3Working on TLA, target whole pag	0.11761592163282683

L3 Reranking Framework	L3 Reranking FrameworkL3 Infrastructure TeamAgendaOverviewL3 featuresL3 ranker and L3 workflowAggregatedFreeFormList-wise ranking previewL3 and L4Future WorkOverviewRank Stack in IS PlatformL4 - MergerL3 – List reorderingL2 - S	0.5089076571616585
L3 Reranking Framework	PBAVnext and migrationFrank ZhangBenefit of vnextIt will reflect five years’ worth of local search relevance insights and lessons learned, including the relevance tuning principles we have discovered over the years.It will make it easier to suppor	0.3292052180133146
L3 Reranking Framework	Anchor and Click Stream RankingSteven ZittrowerBing Local Search RelevanceHypothesisConverting local search’s unstructured and raw text streams into semi-structured forms will improve ranking and offer relevance benefits.TestUsing classifiers 	0.2926237276279213
L3 Reranking Framework	Move SBS (Learning from L3)Xiaopeng WuJunzhou WangWhat’s L3Bing ranking stackIndex selectionWorking on offline system, target recallL1Working on IFM, target recallL2Working on IFM, target precisionL3Working on TLA, target whole pag	0.2921851178563096
L3 Reranking Framework	Introduction to dynamic ranking Xiao WuOutlinesIntroductionRelevance MeasurementDynamic rankingRanking FeaturesRanking DataRanking modelsRelevance ExperiementIntroductionWhat is dynamic rankingRanking based on query dependent featu	0.2590746389484967
L3 Reranking Framework	FastRank--- a Decision-Tree based Ranking ModelYu SHIOutlineBackgroundAlgorithm overviewTraining implementationExperimentationChallengesReferencesBackgroundInvestigated by MSR in OsloShipped with July Tree 2010 (Denver)GoalsSpe	0.2553334324228259
L3 Reranking Framework	L3 Distance Model for LocalNikita Melnichenko, Bing Local2016-04-12AgendaIntroduction to the Distance problemPrevious workA new approach: experiments and designResultsFuture developmentIntroduction to the Distance problemWe say “it’s a	0.25511114788900446
L3 Reranking Framework	SKI Contextual Reranking V1 design doc User ScenarioWhole page relevance of “All Tab” in the SerpletContextual relevance of “File Tab” in the Serplet DeliverablesMicrosoft search serves as an intelligence service to take user query and return be	0.24841733700521032
L3 Reranking Framework	Content Quality Classification & RankingGuihong Cao, Cheng NiuContent Quality for RankingContent quality = originality + trustworthy + information satisfaction + freshnessSpam sites, junk site, link farm, content farm, ….Search users are interes	0.23709884753665103
L3 Reranking Framework	Partner Index as ServiceWhat is the Problem? RequirementCurrent status of Bing Image StackDiscoveryClient tend to provide feed for full corpusWeb crawlerImage Content RetrievalSpecial agreement, some even behind authentication for access	0.236732369589887

L2 page from L1 click through	 阿里浏览器DNS解析加速布可2010.12.31AgendaDNS解析过程DNS协议阿里浏览器DNS解析加速浏览器查找域名的IPtaobao.com浏览器缓存(2-30min)系统缓存(DNS client resolver cache)Local DNS递归查询->dns1.禁用IE的dns缓存：Start Registry Editor. Locate and click the following key in the reg	0.3259083360737871
L2 page from L1 click through	Pthreads mutex vs Pthreads spinlock 锁机制(lock) 是多线程编程中最常用的同步机制,用来对多线程间共享的临界区(Critical Section) 进行保护。Pthreads提供了多种锁机制,常见的有：1) Mutex（互斥量）：pthread_mutex_***2) Spin lock（自旋锁）：pthread_spin_***3) Condition Variable（条件变量）：pthread_con_***4) Read/Write 	0.32551944921444786
L2 page from L1 click through	SVMT UpdateNovember 2016AgendaMorning (10:00-12:00)Overview – 15 minQnA:MALTA – 55 minInfoBot – 30 minLunch break (12:00-1:00)Afternoon (1:00-3:00)Query:Deep QR – 30 minRanking:ConceptX – 30 minFusion – 30 minNapa – 30 minO	0.30656287174529906
L2 page from L1 click through	浅谈Redis的原理与应用tianzhedong（董天喆）大纲What is RedisWhy RedisHow To Use RedisWhat Is RedisWhat is RedisWhat is Rediskey value store可以持久化的cacheHashTableMemory DB它的高性能都是基于内存操作的基础data structure serverRedis支持复杂的数据特性，比如List, Set等Redis	0.2965380123477012
L2 page from L1 click through	Nlp情感分析工具使用执行步骤：分词执行程序：Shenbian_exlib_segpos使用说明： 	usage: ./Shenbian_exlib_segpos  segDictPath tagDictPath inputfile outputtype      			exDictLib > outputfile具体使用举例：     ./Shenbian_exlib_segpos ../../../../lib_wordseg/worddict_1-3-4-3_PD_B	0.2959714888485517
L2 page from L1 click through	Zh-cn Transportation Segment Optimization by Pattern EngineJia Liu/Allen WangDSATsQuery: 吉林市到查干湖Relevant result title: 吉林市到查干湖怎么走近？_百度知道Irrelevant result title 1: 查干湖,中国查干湖,吉林查干湖,查干湖旅游,查干湖冬捕,国家AAAA ...Irrelevant result title 2: 查干湖_百度百科Irrel	0.29008961245352294
L2 page from L1 click through	客户价值模型分享和讨论WHY/WHAT/HOWECom ASEA  ——  Advertisement Search Analysis2010-12-29为什么要做客户模型客户价值度模型客户关注点模型客户忠诚度模型……常用的客户价值模型RFM模型R(Recency)表示客户最近一次购买的时间有多远；F(Frequency)表示客户在最近一段时间内购买的次数；M (Monetary)表示最近一段时间内购买的金额2维RFM（消除购买次数与购买额之间的多重	0.2898942111925645
L2 page from L1 click through	Hbase分析报告本文基于环境hadoop-0.16.4 和 hbase-0.1.3 编写Hbase是一个分布式开源数据库，基于Hadoop分布式文件系统，模仿并提供了基于Google文件系统的Bigtable数据库的所有功能。Hbaes的目标是处理非常庞大的表，可以用普通的计算机处理超过10亿行数据，并且有数百万列元素组成的数据表。Hbase可以直接使用本地文件系统或者Hadoop作为数据存储方式，不过为了提高数据可靠性和系统的健壮性，发挥Hbase处理大数据量等功能，需要使用Hadoo	0.2889181094352812
L2 page from L1 click through	Click through handling & Organic search on One Map and Mobile L2. Challenge & problemsCurrently we have a lot of issues with click through experience.  For example, click see more results link on local listing experience get single entity pane experie	0.28579184209685093
L2 page from L1 click through	常用Linux命令：统计当前目录下所有.h文件的个数：find . -name "*.h" | wc -l统计当前目录下所有.h文件的总代码行数：find . -name "*.h" | xargs wc -l传输大文件时rz -be解压tar.gz文件tar zxvf x.tar.gz	0.28047958776812504

L2 General Title Match	L2 General Title MatchJia Liu2/25/2014N-Gram Table6B Documents TitleN-Gram is continually builtTitle: A B C D3-Gram: A B C, B C D1-Gram to 10-Gram, N is in [1…10]Format: N-gram \t Len \t FrequencyTable Guid:3ce6e18c-ad7e-47e0-94ec-dfd6	0.5718722833330159
L2 General Title Match	Page 23 of 26L2 General Title MatchDev: Jia Liu, Chuan Cao, Albert ZhouPM: Jin GuoDoc version: v1.0ContentsAbstract	2Project Status	2Goals	2Problem statement	3Architecture	3N-Gram Table	4Query Distribution in N-Gram Table	5Query 	0.3396975036661159
L2 General Title Match	Deep Dive: Query Generic Entity Extraction (GEE)Zhen Liao04/22/2016OutlineOverview of GEEFAQ for GEEArchitecture and ModelingRecent breakthrough via Deep LearningLessons we’ve learnedGeneric Entity Extraction for Queries: What is the g	0.31843258948775727
L2 General Title Match	Pthreads mutex vs Pthreads spinlock 锁机制(lock) 是多线程编程中最常用的同步机制,用来对多线程间共享的临界区(Critical Section) 进行保护。Pthreads提供了多种锁机制,常见的有：1) Mutex（互斥量）：pthread_mutex_***2) Spin lock（自旋锁）：pthread_spin_***3) Condition Variable（条件变量）：pthread_con_***4) Read/Write 	0.22747581365094263
L2 General Title Match	Click to edit Master title styleEdit Master text stylesSecond levelThird levelFourth levelFifth levelThis deck is intended for use with INTERNAL AND EXTERNAL audiences.The slides and talking points are designed to help you tell our culture s	0.22130369435894734
L2 General Title Match	libsvm的相关工具和使用方法libsvm工具：编译并能够使用 : libsvm-3.0.tarsvm的基本原理 ： libsvm-guide.pdflibsvm相关的grid工具 : [sep@ai-iknow-septest1.ai01.baidu.com auto_classifier]$ pwd grid_tools.py /home/sep/yangfan/Basic_Tools/for_lyq/auto_classifier特征筛选的相关资料和方法了解特征筛选方法	0.2163198272526312
L2 General Title Match	query分类—分享                     刘佳2011.6.8web query classification(query分类):	将web search query根据它的主题，分派到1个或者多个预先定义的分类中。web search query的特征：有噪声：拼写错误等长度很短：信息量少，特征少表意含糊：query可能包含多个含义,属于多个分类含义会随时间演变目标分类的特征：目标分类定义缺少语义注解一级或者多级分类分类数目：几	0.2117404199849242
L2 General Title Match	贴吧FRS重构介绍卢红波 luhongbo@baidu.com何戬　hejian01@baidu.com提纲整体方案概述Frsdi设计Frslogic设计整体方案概述	什么是frsFrs现状与问题重构的目标重构的设计数据拆分与冗余FrslogicFrsdi什么是frs数据量：吧总数：　300万主题总数：　10亿浏览量（天）：2亿pv提交量 (天)：发帖量：1350万新增主题：100万投票:  3000设	0.2082542554000569
L2 General Title Match	Nlp情感分析工具使用执行步骤：分词执行程序：Shenbian_exlib_segpos使用说明： 	usage: ./Shenbian_exlib_segpos  segDictPath tagDictPath inputfile outputtype      			exDictLib > outputfile具体使用举例：     ./Shenbian_exlib_segpos ../../../../lib_wordseg/worddict_1-3-4-3_PD_B	0.20317411079887202
L2 General Title Match	Microsoft ConfidentialClick to edit Master title styleEdit Master text stylesSecond levelThird levelFourth levelFifth levelMicrosoft ConfidentialMicrosoft ConfidentialMicrosoft ConfidentialGISELLI PANONTINIDEEPANKAR DUBEYSubstrate 	0.19828630738283143

L1 Brownbag	Brownbag:ElasticSearch ExtensibilityHeather Nakama (henakama)Azure Search09/04/14AgendaIntroductionModulesPluginsFinding extensibility pointsEnd-to-end exampleTips and tricksQ/AIntroductionHeather NakamaDeveloper with Azure S	0.4882281898074035
L1 Brownbag	Tiger Index BrownbagHui ShenSearch Platform Tiger TeamAgenda	OverviewKey ideasTiger architectureTiger ++ 2/24/2012Agenda	OverviewKey ideasTiger architectureTiger ++ 2/24/2012What is Tiger IndexAn new index serve technol	0.3072168934540644
L1 Brownbag	SVMT UpdateNovember 2016AgendaMorning (10:00-12:00)Overview – 15 minQnA:MALTA – 55 minInfoBot – 30 minLunch break (12:00-1:00)Afternoon (1:00-3:00)Query:Deep QR – 30 minRanking:ConceptX – 30 minFusion – 30 minNapa – 30 minO	0.22554021629413085
L1 Brownbag	[PLEASE REMOVE THIS TEXT AND BRACKETSANDPRINT ON COMPANY LETTERHEAD]INSERT DATETo Whom It May Concern:Re:	Jia LiuThis letter is to confirm that Jia Liu was employed at Microsoft (China) Company Limited in Beijing, China from March 30, 2012 to 	0.21522531674800788
L1 Brownbag	NTCG DebuggingSteven Zittrower01/30/2015AgendaNTCGNTCG DashboardOverview of BLU Architecture (Address Specific)Address Debugging in QATNTCGNTCG (Normalized Total Cumulative Gain) is a composite metric that measures address query releva	0.20551898562189705
L1 Brownbag	QR FY19 LRP Planning - 23/29/18Unified Concept Tagging – Key ChallengesStructural ComplexityFor ambiguous queries and multi-concept queries, how much organization is required?  How to represent this in a linear qlf?  What about inter-concept rel	0.20533171770686182
L1 Brownbag	Phonebook vNextDesign DiagramsPlease do not modify existing diagrams!To update a diagram, make copy of a slideand create a new version.Do not forget to update date and author.Local.Pba.MainLocal.Pba.ExecutionModeLocal.Pba.ResponseMuxMu	0.18569018122309675
L1 Brownbag	Home TeamLocal Brown Baghttp://aka.ms/gethometeam ADContactsBusiness cardsAppsEmailsWeb searchThe opportunity For consumers: Most people prefer to use referrals, or “word of mouth” Competition doesn’t embrace thisAmazon – anony	0.18419900674212172
L1 Brownbag	Relevance and AIBing and Information Platform GroupFY18 AGI Encoder RoadmapFeature OwnersProgram ManagersNitin SharmaDevelopersSaurabh Tiwary, Gargi GhoshResearchersMarketingPartnersYantao Li, Weihu, GuihongOverviewAGI Encoder go	0.18240673212764477
L1 Brownbag	Scraper overview(and more)Ofer ShterlingSean KingContentBrag.Demo (maybe)Throw some dirt.Suggest the Scraper isn’t that interesting.Recurrences tool.I hope I won’t have to show to many workflow.ScraperWe have between 500 to 1.5k sc	0.1765692999043905

L-1B Specialized Knowledge Questionnaire_Jia liu	L-1B SPECIALIZED KNOWLEDGE QUESTIONNAIREMICROSOFT POSITION IN THE U.S.Provide the following information for your current position at the Microsoft.MICROSOFT POSITION ABROADProvide the following information for your position at the Microsoft’s su	0.6877043946926945
L-1B Specialized Knowledge Questionnaire_Jia liu	DU items studyJia Liu2013-05-14AgendaPublication dateMain body blockDocument qualityurl static featuresPublication dateFreshness rankingYear in title, year in url, publication dateEn-us publication date coverage is ~20%Zh-cn public	0.5077353077281571
L-1B Specialized Knowledge Questionnaire_Jia liu	LDCG V3Knowledge Transfer2017-04-14Brett Clippingdale, Sean King, Vikas Mittal, Li JiangLDCG V3 OutlineLDCG V2 vs V3: High-level comparisonLDCG V3: New distance ModelV2 vs V3 OverviewLDCG V3: GeoIntent HIT appLDCG V3: Calculate distance 	0.47169155702402743
L-1B Specialized Knowledge Questionnaire_Jia liu	Query Latitude Longitude QueryId Prod_PLDCG@3 Restcat_PLDCG@3 G_PLDCG@3 Delta ResultQuality Dolphin CRF PhonebookQuLocation LocalPivotEntity TLA Built? Result Returned? Result Good? Comment Restaurants in times square 00f0d1ee-9688-5b09-bcea-a5e860fead14 	0.4715027003481317
L-1B Specialized Knowledge Questionnaire_Jia liu	DU Pipeline V2Bram Gruneir, Ted Wild and Connie YangDocument Understanding Dev Talk6/27/2013DU Pipeline V2: frequency demoIntroduce the demo featureDevelopmentDeploymentDU Pipeline V2: frequency demoIntroduce the demo featureDevelopmen	0.45238188589326456
L-1B Specialized Knowledge Questionnaire_Jia liu	Page 23 of 26L2 General Title MatchDev: Jia Liu, Chuan Cao, Albert ZhouPM: Jin GuoDoc version: v1.0ContentsAbstract	2Project Status	2Goals	2Problem statement	3Architecture	3N-Gram Table	4Query Distribution in N-Gram Table	5Query 	0.44450010427017767
L-1B Specialized Knowledge Questionnaire_Jia liu	Find Deals with OpalKelly You, Jia Liu, Leon Zhang7/11/2016AGENDAScenariosTechniques & ChallengesNext StepsQ&AScenariosSearch Store DealsBrowse Nearby DealsFilter Restaurants with DealsDeal Action in Entity Detail CardTechniques 	0.4280452725746828
L-1B Specialized Knowledge Questionnaire_Jia liu	1/29 AGI ReviewAttendees: Harry Shum, Yi-Min Wang, David Ku, Steven Yao, Jianfeng Gao, Saurabh Tiwary, JJ Liu, Mir RosenbergTask Oriented Dialog AgentsJianfengShare the “Hail Caesar” slide (rule-based vs. RL dialog)Write what we discussed on Cor	0.4205082357888402
L-1B Specialized Knowledge Questionnaire_Jia liu	BLU V3 Minghua Zhang      01/26/2016Next version of BLU Relevance Infrastructure​OutlineWhy BLU v3BLU v3 DesignCurrent StatusFuture WorkWhy BLU v3 (1)Limitations of current BLU infrastructureFeaturesCouldn’t utilize QAS feature	0.4126988987214261
L-1B Specialized Knowledge Questionnaire_Jia liu	Local Popularity V2Xiaohui Liu, Dave Bargeron, Fengxia PanAgendaProblem and motivationSolutionTechnique deep diveFeature MeasurementPipeline GDI marketsFuture workMotivationEnable LDCG v2Improve local search relevanceRelated 	0.4070617561690072

L-1B Specialized Knowledge Questionnaire	L-1B SPECIALIZED KNOWLEDGE QUESTIONNAIREMICROSOFT POSITION IN THE U.S.Provide the following information for your current position at the Microsoft.MICROSOFT POSITION ABROADProvide the following information for your position at the Microsoft’s su	0.776468224616732
L-1B Specialized Knowledge Questionnaire	I-130 Questionnaire for the Petitioner (Husband or Wife)PLEASE LEFT CLICK ON GRAY FIELDS TO ENTER DATA.  PLEASE DO NOT (A) MODIFY THE FORMAT OF THIS DOCUMENT, (B) USE ALL CAP'S; OR (C) RIGHT-CLICK ON GRAY FIELDS.  IF YOU SAVE THIS DOCUMENT, PLEASE SAVE 	0.4187231983176862
L-1B Specialized Knowledge Questionnaire	DU items studyJia Liu2013-05-14AgendaPublication dateMain body blockDocument qualityurl static featuresPublication dateFreshness rankingYear in title, year in url, publication dateEn-us publication date coverage is ~20%Zh-cn public	0.4055795372138877
L-1B Specialized Knowledge Questionnaire	LDCG V3Knowledge Transfer2017-04-14Brett Clippingdale, Sean King, Vikas Mittal, Li JiangLDCG V3 OutlineLDCG V2 vs V3: High-level comparisonLDCG V3: New distance ModelV2 vs V3 OverviewLDCG V3: GeoIntent HIT appLDCG V3: Calculate distance 	0.3994074785713553
L-1B Specialized Knowledge Questionnaire	Query Latitude Longitude QueryId Prod_PLDCG@3 Restcat_PLDCG@3 G_PLDCG@3 Delta ResultQuality Dolphin CRF PhonebookQuLocation LocalPivotEntity TLA Built? Result Returned? Result Good? Comment Restaurants in times square 00f0d1ee-9688-5b09-bcea-a5e860fead14 	0.387684284659824
L-1B Specialized Knowledge Questionnaire	DU Pipeline V2Bram Gruneir, Ted Wild and Connie YangDocument Understanding Dev Talk6/27/2013DU Pipeline V2: frequency demoIntroduce the demo featureDevelopmentDeploymentDU Pipeline V2: frequency demoIntroduce the demo featureDevelopmen	0.3809255586263664
L-1B Specialized Knowledge Questionnaire	Speller Related Issues & SolutionsMing Wu2014-01-08Speller Related Issues – in nativePBA reads spell corrected query from Speller kif responseAssumes offsets are on raw query, which is not the caseE.g. {   piza hut} -> {pizzaiza hut}Proposed	0.3783372684399158
L-1B Specialized Knowledge Questionnaire	WPO Local Relevance Tech TalkWPO Local Relevance TeamOverviewWPO’s role in local relevance pipelineLocal ExperienceArchitecture overviewMetricsWPO Local Relevance Model IntroductionWPO Query understanding and Location understandingWhy do	0.37665874517225884
L-1B Specialized Knowledge Questionnaire	PERM Labor Certification Questionnaire:  Technical (continued)PERM Labor Certification Questionnaire (Technical)Please complete the information requested in this questionnaire carefully.  This information is necessary for the legal analysis and prepar	0.3652479598756161
L-1B Specialized Knowledge Questionnaire	QR Team ReviewJan 2017Team IntroductionConceptXDeep QRAgendaQR Team MembersDev Manager: Ciya LiaoLeads: Garrett Kaminaga, Jingwen Lu, Saekoo Lee, Gord LueckPMs: Shyam Jayasankar, Jie CaiSTC-A Speller team: Yongen Gong and his teamWha	0.35648512544657385

K最近邻分类模型	贝叶斯分类模型：基础知识：假设	X：是数据元组，由n个属性描述；	H：是某种假设，如数据元组属于某特定类C	P(H|X)：表示给定X的属性描述，找出元组X属于类C的概率举例：X：一位35岁的顾客，收入为4w美元；H：顾客将购买计算机P(H|X)：在X的条件下，H的后验概率。当我们知道顾客的年龄和收入时，顾客X将购买计算机的概率。P(H)：H的先验概率。任意给定顾客将购买计算机的概率，独立与X。P(X|H)：在条件H下，X的后验概率。已知顾客购买了计算机，顾客是一位3	0.9020860628137524
K最近邻分类模型	排序及扩展：插入排序，选择排序（冒泡排序），使用二分思想求第k大数，快速排序，非递归的快速排序，使用快排思想求第k大数，归并排序，求逆序数，自然排序算法，堆排序，最小优先级队列，计数排序，桶排序，鸽巢排序（分块排序），基数排序，外部排序：二路归并，K路归并，胜者树，败者树。  算法一：使用插入或者选择排序，得到最大的K个数，时间复杂度为：O(N*k)。 冒泡排序： void swap(int * a,int * b){            //注意	0.8978399594857066
K最近邻分类模型	克拉玛依公证处:本人因生活在国外，不能亲自到贵单位办理出生证明公证事项，兹授权委托雷春香女士全权代表我办理相关事项。对委托人在办理上述事项过程中所签署的有关文件，我均予以认可，并承担相应的法律责任。委托人：刘佳			委托人身份证号码：654301198608243929被委托人：雷春香		被委托人身份证号码：6526196207113926委托人：刘佳2018年5月24日	0.8978399594857066
K最近邻分类模型	性能升级性能升级的几个层面：系统结构：模块分解，模块交互，系统构建中的粗略估算。算法和数据结构：获得快速模块的关键：表示数据的结构，操作数据的算法：索引结构及拉链归并。代码调优：分支预测等。循环：将循环体中不改变的变量移动到循环体外；多重循环嵌套顺序。函数调用：inline函数节省函数调用开销：若makefile中不指定至少-O优化，即使声明为inline函数，编译器也不会进行函数内联。内存寻址：避免重复内存寻址。Cpu流水线的分支预测：将满足概率最高的条件放在靠前的位置。	0.8978399594857066
K最近邻分类模型	业务生成平台用户指南总体说明开发背景下一代网络是业务驱动的网络，在融合的下一代网络上高效、灵活地开发和部署各种丰富多彩的业务，从而提高网络使用率、增加收益的目标，是下一代网络的关键环节。下一代网络的发展要求呼叫与承载相分离、呼叫控制与业务相分离，使业务真正独立于网络，业务开发者不必关心与业务承载相关的底层网络知识以及具体的通信协议，只需利用业务生成平台提供的业务开发工具，就可以开发出灵活丰富且极具个性化的业务。 为了适合多种技术水平的业务开发人员的需要，现在主要有四种业务开发方式：	0.8978399594857066
K最近邻分类模型	K最近邻分类模型：原理：训练元组用n个属性描述，每个元组代表n维空间中的一个点，所有的训练元组存放在n维的模式空间。当给定一个未知元组时，KNN搜索该模式空间，找出最接近未知元组的k个训练元组。未知元组指派到它的k个最近邻中的多数类。“邻近性”用距离度量，如欧几里德距离。欧几里德距离：	设元组X1=(X11,X12,…X1n)，X2=(X21,X22,…X2n)，	Dist(X1,X2)=√ ∑ k= 1 n (X1i-X2i) 2 	使用上式之前，对每个属性的值规范化，以防止具有	0.8977903140602628
K最近邻分类模型	工作6周年5个月小记今天是中国时间8/24/2018，也就是我32岁的生日，这是一个不老也不再年轻的年纪。最近总是因为工作而郁郁寡欢，心中不快，所以决定记录总结一下，希望自己能有所释怀、转变、确立新的目标。从2012年3月31到现在，我已在微软Bing工作6年5个月。在此之前，我在百度实习9个月，在阿里巴巴实习2个月，在搜狗实习1个月。在微软北京CJK relevance组勤恳的工作2年6个月，从级别59升到61，做了1年半的DU, 1年的relevance。总体来说，老板们的风格是相关性主导基础	0.8969169015172169
K最近邻分类模型	海量数据库的设计和实现淘宝海量数据库之一：来自业务的挑战(2010-11-24 11:34:38) 作为一个电子商务企业，从一开始，数据库及其事务能力在淘宝一直扮演着十分关键的角色，淘宝积累了丰富的数据库的架构和规划等方面的经验，产生了众多优秀的DBA。 淘宝是一家迅速发展的公司。全球网站排名公司Alexa提供的数据显示，2010年4月27日，Amazon、Ebay的用户占全球互联网用户的百分比分别为3.47%和2.68%，而淘宝的用户占全球互联网用户的百分比则达到了4.1%，淘宝网日	0.8966745463613783
K最近邻分类模型	C专家编程读书笔记难点关键字的用法：关键字用法extern在函数名前，表示该函数全局可见，一般缺省。即一个文件的全局变量和函数对其他文件，具有可见性。在变量或者函数前，表示对象的定义在别处进行。由于重载，在c++中调用以C方式编译的函数时，需要加extern “c”。static隐藏：修饰的对象对其他文件不可见，防止多个文件命名冲突。持久性：修饰的对象，存储在数据段或者bss段，和程序有相同的生命周期。只有一次初始化。3、修饰的变量未初始化时，默认为“0	0.8952665597776505
K最近邻分类模型	BS代码阅读：BS基本功能：索引相关性切词成分分析offset调权query解析 （where+what）多路归并 综合调权类聚（偏离点）query分类空间调权数据来源点击调权BS代码阅读：bs_cache:map库的term cachemap库term cache操作锁where库term cachewhere库term cache操作锁init_map_term_cache: 初始化map库term cachein	0.8936426286735205

KeywordsAndMetaStreamwithSegment_FeedsMulti9_CalvsStem	MQ for CALOverviewSpellerQASMQTriggerMQSingleQueryChainChainChainAugmentAugmentAugmentTailQuerySimplifiedSPCombSP1SP2Sp3AugmentAugmentPropertyBag - SQQueryAlterationListQueryAlterationSetQueryAlterationType	0.4969470116712173
KeywordsAndMetaStreamwithSegment_FeedsMulti9_CalvsStem	Keyword Prediction for Local SearchesRuchir RastogiMentor: Jia LiuManager: Leon ZhangOutlineProblem statementTraining data and clean-up strategiesConditional random field (CRF) modelsDeep learning modelsEnd to end measurementConclusi	0.4660132511220313
KeywordsAndMetaStreamwithSegment_FeedsMulti9_CalvsStem	Lexical analyzer (fa_lex)Input: a buffer of textOutput: a sequence of tokens, each token is <from, to, tag>For C++:Input: “if(++i==0) {j = 0;}”Output: if/OP (/LRB ++/OP i/VAR ==/OP 0/NUM )/RBR {/LCBR j/VAR =/OP 0/NUM ;/OP }/RCBREach rule:Des	0.46506042993701285
KeywordsAndMetaStreamwithSegment_FeedsMulti9_CalvsStem	Keyword Predictor Design DocumentName: Ruchir RastogiMentor: Jia LiuManager: Leon ZhangProject overviewThe goal of this project is to design a machine-learning model that can predict keywords in a local query for improving local search relevance	0.4622265780527959
KeywordsAndMetaStreamwithSegment_FeedsMulti9_CalvsStem	BusinessV3TaxonomyClassifierAugust, 2018Daniel WeinshenkerMicrosoft ConfidentialAgendaMicrosoft ConfidentialPurpose / OverviewDemoData Pipeline / Lexicon GenerationMeasurementQASChallenges / Future WorkPurpose We want to improve 	0.45737148630075203
KeywordsAndMetaStreamwithSegment_FeedsMulti9_CalvsStem	Keyword predictor-Ganesh Poomal -KefengOutlineThe problem and the objective for Keyword predictorTraining Data CollectionModel and FeaturesResultsKeyword PredictorProblem    In a search engine, user expresses their need for information	0.4515538145106757
KeywordsAndMetaStreamwithSegment_FeedsMulti9_CalvsStem	Query AugmentationsTable of Contents1. Syntax Overview	22. Constraints	6General rules for operators	7Basic Operators	7Scoring and non-scoring constraint operators	9Stream Operators	9Literal Operators	10Meta Operators	11URL Operators	13	0.435592288595165
KeywordsAndMetaStreamwithSegment_FeedsMulti9_CalvsStem	Local Category Search StudyHuanan Zhang01/03/2018OutlineStructure of PBA (Prod) rankerIntent match ranker’s role in Prod rankerIssues of intent match rankerSolutions – metastream clean upMetastream measurementPreliminary resultsPBA	0.43407650243888407
KeywordsAndMetaStreamwithSegment_FeedsMulti9_CalvsStem	Domain Authority CAL One PageIntroductionCurrent shipped ngram domain authority in L3 is using complete query match against an offline generated meta-stream (q, url, score), which derives (q,url) pairs from click stream and is the result of aggregatio	0.4328430189382328
KeywordsAndMetaStreamwithSegment_FeedsMulti9_CalvsStem	LES with Speller in BFPRAnton AmirovBenefitsSupport for misspelled location, metrics improvementAlignment with web resultsCurrent statusHybridLESRaw QuerySpell Corrected QuerySpellerFLEFLEWithSpellerSome answers (AmberAlerts, Electio	0.43094907141140554

KeywordsAndMetaStreamwithSegment_FeedsMulti9_CalONandOFF	Keyword predictor-Ganesh Poomal -KefengOutlineThe problem and the objective for Keyword predictorTraining Data CollectionModel and FeaturesResultsKeyword PredictorProblem    In a search engine, user expresses their need for information	0.5021107667237279
KeywordsAndMetaStreamwithSegment_FeedsMulti9_CalONandOFF	Keyword Prediction for Local SearchesRuchir RastogiMentor: Jia LiuManager: Leon ZhangOutlineProblem statementTraining data and clean-up strategiesConditional random field (CRF) modelsDeep learning modelsEnd to end measurementConclusi	0.48660137223064986
KeywordsAndMetaStreamwithSegment_FeedsMulti9_CalONandOFF	Keyword Predictor Design DocumentName: Ruchir RastogiMentor: Jia LiuManager: Leon ZhangProject overviewThe goal of this project is to design a machine-learning model that can predict keywords in a local query for improving local search relevance	0.47558837830004175
KeywordsAndMetaStreamwithSegment_FeedsMulti9_CalONandOFF	Lexical analyzer (fa_lex)Input: a buffer of textOutput: a sequence of tokens, each token is <from, to, tag>For C++:Input: “if(++i==0) {j = 0;}”Output: if/OP (/LRB ++/OP i/VAR ==/OP 0/NUM )/RBR {/LCBR j/VAR =/OP 0/NUM ;/OP }/RCBREach rule:Des	0.45062588460834724
KeywordsAndMetaStreamwithSegment_FeedsMulti9_CalONandOFF	MQ for CALOverviewSpellerQASMQTriggerMQSingleQueryChainChainChainAugmentAugmentAugmentTailQuerySimplifiedSPCombSP1SP2Sp3AugmentAugmentPropertyBag - SQQueryAlterationListQueryAlterationSetQueryAlterationType	0.45035010664372654
KeywordsAndMetaStreamwithSegment_FeedsMulti9_CalONandOFF	Query AugmentationsTable of Contents1. Syntax Overview	22. Constraints	6General rules for operators	7Basic Operators	7Scoring and non-scoring constraint operators	9Stream Operators	9Literal Operators	10Meta Operators	11URL Operators	13	0.4364368146415006
KeywordsAndMetaStreamwithSegment_FeedsMulti9_CalONandOFF	BusinessV3TaxonomyClassifierAugust, 2018Daniel WeinshenkerMicrosoft ConfidentialAgendaMicrosoft ConfidentialPurpose / OverviewDemoData Pipeline / Lexicon GenerationMeasurementQASChallenges / Future WorkPurpose We want to improve 	0.4271410258005833
KeywordsAndMetaStreamwithSegment_FeedsMulti9_CalONandOFF	Local Category Search StudyHuanan Zhang01/03/2018OutlineStructure of PBA (Prod) rankerIntent match ranker’s role in Prod rankerIssues of intent match rankerSolutions – metastream clean upMetastream measurementPreliminary resultsPBA	0.3976751316308989
KeywordsAndMetaStreamwithSegment_FeedsMulti9_CalONandOFF	Keyword Predictor Summer 2018 SummaryIntern: Ruchir Rastogi (rrastogi@stanford.edu)Mentor: Jia LiuThe Aether ID’s listed in this document are more up to date than the one’s listed in the PowerPoint.PipelinesTraining data clean-up pipelineAethe	0.39730492183382243
KeywordsAndMetaStreamwithSegment_FeedsMulti9_CalONandOFF	Domain Authority CAL One PageIntroductionCurrent shipped ngram domain authority in L3 is using complete query match against an offline generated meta-stream (q, url, score), which derives (q,url) pairs from click stream and is the result of aggregatio	0.38524083378729096

Keyword predictor	Keyword predictor-Ganesh Poomal -KefengOutlineThe problem and the objective for Keyword predictorTraining Data CollectionModel and FeaturesResultsKeyword PredictorProblem    In a search engine, user expresses their need for information	0.5885827305265301
Keyword predictor	Keyword Predictor Design DocumentName: Ruchir RastogiMentor: Jia LiuManager: Leon ZhangProject overviewThe goal of this project is to design a machine-learning model that can predict keywords in a local query for improving local search relevance	0.4041104855294618
Keyword predictor	Keyword Prediction for Local SearchesRuchir RastogiMentor: Jia LiuManager: Leon ZhangOutlineProblem statementTraining data and clean-up strategiesConditional random field (CRF) modelsDeep learning modelsEnd to end measurementConclusi	0.39943290109116786
Keyword predictor	Keyword Predictor Summer 2018 SummaryIntern: Ruchir Rastogi (rrastogi@stanford.edu)Mentor: Jia LiuThe Aether ID’s listed in this document are more up to date than the one’s listed in the PowerPoint.PipelinesTraining data clean-up pipelineAethe	0.27963412313889074
Keyword predictor	This workbook contains Parent Child Relationship matrix of provider given relationships. Currently only navteq provides this information and that is the only one which is included here. Parent Category Parent Count Child Count 11579 Hospitals And Medical 	0.17885764994655323
Keyword predictor	浅谈Redis的原理与应用tianzhedong（董天喆）大纲What is RedisWhy RedisHow To Use RedisWhat Is RedisWhat is RedisWhat is Rediskey value store可以持久化的cacheHashTableMemory DB它的高性能都是基于内存操作的基础data structure serverRedis支持复杂的数据特性，比如List, Set等Redis	0.1734356346215295
Keyword predictor	Translation Model in Local Search- Shu HuangIntroductionTranslation model in web searchOdpTitle translation model in local searchData preparationModel trainingGenerate new metastreamIntroductionTranslation model used in web searchLea	0.15416821750635873
Keyword predictor	Word representationsMotivationWhy word representations?StructureWhy vectors?Distance and similarityBuild models that will automatically understand language for us.Vector space modelsVector space modelsCount based methodsDSM (distribu	0.14809304049172195
Keyword predictor	Entity Pane and Fact AnswerPresenter: Ze TianJun 25, 2013IntroductionIntroductionIntroductionProblems to SolveDoes the user search for entities or facts of entities?E.g. “who is msft ceo” (Entity: Microsoft, Fact: Chief Executive O	0.14777631781038694
Keyword predictor	Nlp情感分析工具使用执行步骤：分词执行程序：Shenbian_exlib_segpos使用说明： 	usage: ./Shenbian_exlib_segpos  segDictPath tagDictPath inputfile outputtype      			exDictLib > outputfile具体使用举例：     ./Shenbian_exlib_segpos ../../../../lib_wordseg/worddict_1-3-4-3_PD_B	0.14658481274756807

Keyword Prediction Design Document v2	Keyword Predictor Design DocumentName: Ruchir RastogiMentor: Jia LiuManager: Leon ZhangProject overviewThe goal of this project is to design a machine-learning model that can predict keywords in a local query for improving local search relevance	0.6035315116827269
Keyword Prediction Design Document v2	Keyword predictor-Ganesh Poomal -KefengOutlineThe problem and the objective for Keyword predictorTraining Data CollectionModel and FeaturesResultsKeyword PredictorProblem    In a search engine, user expresses their need for information	0.5821413536797239
Keyword Prediction Design Document v2	Keyword Prediction for Local SearchesRuchir RastogiMentor: Jia LiuManager: Leon ZhangOutlineProblem statementTraining data and clean-up strategiesConditional random field (CRF) modelsDeep learning modelsEnd to end measurementConclusi	0.5005762949170508
Keyword Prediction Design Document v2	Training Data Repository v2Sourabh ChandakAgendaWhy TDR v2TDR explainedOnboarding processNext StepsSummaryDependenciesQuestionsProblemTraining data The most valuable resource for any ranker training experiment. Comprises of <quer	0.39094277120728277
Keyword Prediction Design Document v2	Zhcn document classification based on topicJia Liu2012.11.14agendarTraining data selection&crawl&cleanFeature selection&cleanClassifierRating Bad case analysisTrainning data	0.38538867387075953
Keyword Prediction Design Document v2	This workbook contains Parent Child Relationship matrix of provider given relationships. Currently only navteq provides this information and that is the only one which is included here. Parent Category Parent Count Child Count 11579 Hospitals And Medical 	0.37551819387187024
Keyword Prediction Design Document v2	TermX TrainingLast saved by Gord Lueck, 8/17/2015 2:15 PMContentsTermX Training	1Overview	1Prerequisites	1Inputs	1Translation Model Generation	2TermX_GenerateTrainingData	2TermX_GenerateTM	2TermX Trim Model	3TermX_PostProcess TM	3C	0.373770482612602
Keyword Prediction Design Document v2	Zh-cn Document classification based on topicBackgroundWe want to do zh-cn document classification for better understanding the document type and topic. It can help ranking with document and  query category matching. We defined our category system: 69 	0.3630423650930233
Keyword Prediction Design Document v2	Document classification based on urlBackgroundWe want to do document classification for better understanding the document type and document with query category match for ranking.  We will do zh-cn document classification based on url first, then docum	0.36182177852368863
Keyword Prediction Design Document v2	Publication Date Optimization Design and Implement For zh-cn MarketReview and CommentMei Yang; Ted WildAuthorJia LiuDesignBackgroundPublication date is a very fundamental and important feature. It can help fresh ranking, solve mainline out	0.33716276489973207

KWP Summary - Summer 2018	Keyword Predictor Summer 2018 SummaryIntern: Ruchir Rastogi (rrastogi@stanford.edu)Mentor: Jia LiuThe Aether ID’s listed in this document are more up to date than the one’s listed in the PowerPoint.PipelinesTraining data clean-up pipelineAethe	0.3286304095035117
KWP Summary - Summer 2018	Summary and HighlightsIn April the metrics/measurement team released local AutoSuggest metric and shared initial transit measurement results; BLU team shipped CL 1.0 ontology and deployed BLU v3 to all markets; PBA team shipped a new L2 ranker and refre	0.3082274198016162
KWP Summary - Summer 2018	PDI Document AnnotationPDI Ranking PlatformAgendaPDI and forward indexDocument AnnotationSodium update and MG planQ&A DSAT: {books by children}Issue: Document matches the query terms, but its surrounding words may change the intent of 	0.26850511891466694
KWP Summary - Summer 2018	Discover More – RestaurantsJune, 2018Daniel WeinshenkerMicrosoft ConfidentialOverview Suggests cuisines, dishes, amenities, and nearby POIs to users searching for restaurants Top 50 cities in the USA suggest the followingWell-known dishes 	0.2680342109764625
KWP Summary - Summer 2018	DU work items on zh-cn market　　Jia Liu2013-05-14AgendaSerp classifierWrapstar rating signalsTaobao, tmall; qna; novel; videoGeneral classiferUrl-basedTopic-basedPage number extractionName entity recognitionPerson, location, organiz	0.24708932267946512
KWP Summary - Summer 2018	CNTK Junk Classifier PrototypeAnton Savin and Gilbert Wong6/3/2016Overall Plan and PrioritiesLearn Deep Learning and Neural NetworkLearn CNTK (Computational Network Toolkit) by walking through the examplesBuild a junk classifier using CNTKEv	0.22886222290598737
KWP Summary - Summer 2018	Jia Liu2013-08-05DU Pipeline Sodium Achievements And Magnesium Plans For CJK　　OutlineSodium AchievementsMagnesium PlanMagnesium Work ItemsSodium Work ItemsAppendixSodium AchievementsWrapstar rating signalsTaobao, tmall; qna; novel; v	0.22719854420867275
KWP Summary - Summer 2018	TermX TrainingLast saved by Gord Lueck, 8/17/2015 2:15 PMContentsTermX Training	1Overview	1Prerequisites	1Inputs	1Translation Model Generation	2TermX_GenerateTrainingData	2TermX_GenerateTM	2TermX Trim Model	3TermX_PostProcess TM	3C	0.22193520301578407
KWP Summary - Summer 2018	MQ for CALOverviewSpellerQASMQTriggerMQSingleQueryChainChainChainAugmentAugmentAugmentTailQuerySimplifiedSPCombSP1SP2Sp3AugmentAugmentPropertyBag - SQQueryAlterationListQueryAlterationSetQueryAlterationType	0.2180783474589174
KWP Summary - Summer 2018	SVMT UpdateNovember 2016AgendaMorning (10:00-12:00)Overview – 15 minQnA:MALTA – 55 minInfoBot – 30 minLunch break (12:00-1:00)Afternoon (1:00-3:00)Query:Deep QR – 30 minRanking:ConceptX – 30 minFusion – 30 minNapa – 30 minO	0.20739505781269196

Junk Detection and Demotion [Autosaved]	Spam/Junk Technology Review8/8/2017 Pavel KarpovichAgendaSpam/Junk OverviewReview of current system and metricsSJRE Fishtank pipelines UrlExclusion and Defect Subranker	Blue Whale Spam Types of Fresh SpamActions to Detect Fresh	0.44635349490359727
Junk Detection and Demotion [Autosaved]	Local Junk Detection and DemotionJia Liu2017-06-14GDP Pipeline View: local data pipelineTriple StoreGOALStore every entity as a set of triples.Track all changes to an entity.TripleColumnDetailsSubjectThe guid of a triple’s pa	0.4279673400758167
Junk Detection and Demotion [Autosaved]	Spam/Junk Technology ReviewAgendaSpam/Junk OverviewReview of current metrics and pipelinesExample of recently shipped technologiesJunk page elimination by cross page signalsAnti-{malicious page redirection spam attack}Looking aheadSpam in 	0.4111078602980223
Junk Detection and Demotion [Autosaved]	SPAM & JunkSi Planning Cheng Niu, Alex Rahin6/18/2014Agenda	Focus AreasMetricsSPAM/Junk Metrics BreakdownData Analysis and Project DefinitionFocus AreasImprove SPAM Detection (~35% of team bandwidth)Stolen ContentContent Keyword St	0.3651813354150068
Junk Detection and Demotion [Autosaved]	WrapStar On-Demand DesignDrafted by ZiliuContentsContext2Design Goals2Automation2Deployment Agility2High Availability2Non-Goals2Metrics2Required Changes3Orchestration3AP Migrations3Pipeline Evolution3Tools/services refactoring3	0.3511791009537594
Junk Detection and Demotion [Autosaved]	Local Relevance SQR (en-us + en-ca)March 14, 2017AgendaContext & Scope:EN-US & EN-CA, Mobile and SERP relevance focusedPBA (pre-web) relevance focusedQuality measurements DSAT examplesGeneral issuesKey Segments (Restaurants, Hotels, Re	0.30246353865581327
Junk Detection and Demotion [Autosaved]	Phrasal Alterations & CAL Infra 		Page 2 of 2Phrasal Alterations & CAL Infra DescriptionPhrasal Alterations is going to add CAL the functionality of doing N-to-M alterations. Given a query, CAL is going to generate multiple candidate queries without	0.2857822920302047
Junk Detection and Demotion [Autosaved]	cal deepdiverelaxationdec 2017AgendaProduct GoalsQuery SimplificationMechanism/RuntimeCRF Model TrainingQS Path SelectionOffline SimulatorSmart RelaxMechanism & TrainingRelaxation: ImpactRelaxation: Product goalsImprove Rec	0.28570168466932616
Junk Detection and Demotion [Autosaved]	Deal Ranking Improvement & MeasurementBackgroundAfter we shipped deal understanding, bad deals filtering, deal ranking for the entity search deals and popular deals nearby. We want to measure and improve our deal ranking based on user behaviors. We ca	0.27234315063711406
Junk Detection and Demotion [Autosaved]	SKI Contextual Reranking V1 design doc User ScenarioWhole page relevance of “All Tab” in the SerpletContextual relevance of “File Tab” in the Serplet DeliverablesMicrosoft search serves as an intelligence service to take user query and return be	0.2690765706021224

JointOptimization_Deepdive	OPG- Business Continuity PlanTellMeService, Shredder, AugmentationService, Enrichment, UCIService (Insights), Entity ServiceDocument Revision HistoryDateAuthorChange NotesLeader Sign off4/30/2018alyanInitial document5/10/2019alyanU	0.2925210479930408
JointOptimization_Deepdive	Multi-Query Issue and QR/Ranking Joint Optimization Bhuvan MiddhaJonas BarklundYinzhe YuYuan Wang6/26/2012AgendaPresentation TopicTime/PresenterIntroduction/QR/Ranking for Joint Optimization3:05 pm – 3:30 pm [Bhuvan/Jonas]Joint Opt	0.28185572873807324
JointOptimization_Deepdive	Deal Ranking Improvement & MeasurementBackgroundAfter we shipped deal understanding, bad deals filtering, deal ranking for the entity search deals and popular deals nearby. We want to measure and improve our deal ranking based on user behaviors. We ca	0.2592228852171715
JointOptimization_Deepdive	11/17 AGI review with HarryCES: cover AI for OfficeCo-market with NvidiaMPQnA Keep in Jordi’s demo in the Dec AI eventAbortion query is very controversial	Not our responsibility to make the decision for the user but it’s the search engine’s re	0.25059700733457757
JointOptimization_Deepdive	Query Simplification Deep DiveJON Fu12/11/2017AgendaQuery Simplification Motivation and TheoryQuery Simplification for WebQuery Simplification for Cortana 3ARecent Progress in Query Simplification WorkReferencesIntroductionMotiva	0.2498994049722123
JointOptimization_Deepdive	CAL MultiQuery {Matching\Ranking}		Page 3 of 4CAL MultiQuery {Matching\Ranking}DescriptionCAL is going to optimize against matching\ranking separately and will issue different queries to each tier. CAL will be leveraging several operator such as:m	0.24418440498768013
JointOptimization_Deepdive	cal deepdiverelaxationdec 2017AgendaProduct GoalsQuery SimplificationMechanism/RuntimeCRF Model TrainingQS Path SelectionOffline SimulatorSmart RelaxMechanism & TrainingRelaxation: ImpactRelaxation: Product goalsImprove Rec	0.24257087115292458
JointOptimization_Deepdive	Publication Date Optimization Design and Implement For zh-cn MarketReview and CommentMei Yang; Ted WildAuthorJia LiuDesignBackgroundPublication date is a very fundamental and important feature. It can help fresh ranking, solve mainline out	0.24011074668850602
JointOptimization_Deepdive	Deep RelaxQuery Relaxation and L1 FidelityQuery Relaxation{printable iphone 7 user guide}rankonly:printable iphone 7 rankonly:user guiderankonly:printable iphone 7 user guideDeep Relax and vector similarity Encode query without each toke	0.23743676299908228
JointOptimization_Deepdive	Interactive BingGoalSolving hard queryOverview Search engine is helping people solving problem. A lot of cases, search engine couldn’t solve problem at first shot. At this point, search engine need take more information to narrow down the user int	0.2372344837729813

Jia Liu of MSFT PERM Labor Certification Questionnaire - Technical 10 9 2012	PERM Labor Certification Questionnaire:  Technical (continued)PERM Labor Certification Questionnaire (Technical)Please complete the information requested in this questionnaire carefully.  This information is necessary for the legal analysis and prepar	0.6598123495108817
Jia Liu of MSFT PERM Labor Certification Questionnaire - Technical 10 9 2012	学士学位证明BACHELOR DEGREE CERTIFICATEThis is to certify that Ms. Jia Liu, born in August 1986, with the specialty of Computer Science and Technology at Beijing University of Posts and Telecommunications from September 2005 to July 2009, has passed all req	0.6081040128458391
Jia Liu of MSFT PERM Labor Certification Questionnaire - Technical 10 9 2012	DU items studyJia Liu2013-05-14AgendaPublication dateMain body blockDocument qualityurl static featuresPublication dateFreshness rankingYear in title, year in url, publication dateEn-us publication date coverage is ~20%Zh-cn public	0.47197359524062116
Jia Liu of MSFT PERM Labor Certification Questionnaire - Technical 10 9 2012	Distance-Aware Local SearchZhao Zhout-zhazho@microsoft.comOutlineProject Goal and MotivationMethodologyExperimental ResultsConclusionBackgroundEntities having LatLonNew York City (40.7127,-74.0059) Facing East Restaurant (47.619905, 	0.4324030534957907
Jia Liu of MSFT PERM Labor Certification Questionnaire - Technical 10 9 2012	Opal OSearch & XAP flight frameworkKevin Su & Duat Le06/22/2016OverviewOSearch basicsOpal OSearch high-level architectureProcess to onboard new feature for Opal OSearchXAP flight framework in OsearchOSearch basicsWhat's OSearch?A platf	0.42579260590975104
Jia Liu of MSFT PERM Labor Certification Questionnaire - Technical 10 9 2012	Jia Liu2013-08-05DU Pipeline Sodium Achievements And Magnesium Plans For CJK　　OutlineSodium AchievementsMagnesium PlanMagnesium Work ItemsSodium Work ItemsAppendixSodium AchievementsWrapstar rating signalsTaobao, tmall; qna; novel; v	0.4143022428866036
Jia Liu of MSFT PERM Labor Certification Questionnaire - Technical 10 9 2012	To Whom It May ConcernPage 2DATETo Whom It May Concern:Re:	Jia LiuI write to certify that Jia Liu worked as a Software Development Engineer at Microsoft (China) Company Limited (Microsoft China) in Beijing, China from March 30, 2012 to September	0.4136994283028629
Jia Liu of MSFT PERM Labor Certification Questionnaire - Technical 10 9 2012	Metrics Pipeline & ToolsJia Liu / Xiaohui Sun / Alex SergeevASG Data Mining TeamDemo link: http://dmsql05/MetricsDefinitionTool/MetricsDefinition.aspx?DataSet=BFT&MetricName=HasCortanaChitChatsTopicsBing Live Metrics PipelineUsage and Perf	0.41306535632962116
Jia Liu of MSFT PERM Labor Certification Questionnaire - Technical 10 9 2012	Office Shredding ServiceSKI Tech Talk – 3/29What do we shred?Office documents into reusable piecesService powering Add From Files in Word, Reuse slides in PPT, Files tab in Microsoft SearchAPIsGoLocalSearchShredding APIs (Document Manifest	0.41186246780685154
Jia Liu of MSFT PERM Labor Certification Questionnaire - Technical 10 9 2012	Find Deals with OpalKelly You, Jia Liu, Leon Zhang7/11/2016AGENDAScenariosTechniques & ChallengesNext StepsQ&AScenariosSearch Store DealsBrowse Nearby DealsFilter Restaurants with DealsDeal Action in Entity Detail CardTechniques 	0.411045514117011

Jia Liu Birth Certificate	To Whom It May ConcernPage 2DATETo Whom It May Concern:Re:	Jia LiuI write to certify that Jia Liu worked as a Software Development Engineer at Microsoft (China) Company Limited (Microsoft China) in Beijing, China from March 30, 2012 to September	0.4518675171477814
Jia Liu Birth Certificate	学士学位证明BACHELOR DEGREE CERTIFICATEThis is to certify that Ms. Jia Liu, born in August 1986, with the specialty of Computer Science and Technology at Beijing University of Posts and Telecommunications from September 2005 to July 2009, has passed all req	0.4479205895575011
Jia Liu Birth Certificate	To whom it may concern,  We are Jia Liu and her husband, Edward Wild.  The bearers of this letter are Jia's mother, Chunxiang Lei, and father, Xinbao Liu.  Jia is a software engineer working at Microsoft on an L1 visa valid until 2020, and Edward is a	0.40856702446691945
Jia Liu Birth Certificate	6/8/2016To Whom It May Concern:Re:	Jia LiuThis letter is to confirm that Jia Liu was employed at Microsoft (China) Company Limited in Beijing, China from March 30, 2012 to June 21, 2015.  She worked full time, 40 hours per week.  Sincerely,Xue B	0.37510665003286003
Jia Liu Birth Certificate	To whom it may concern,We are Xinbao Liu and Chunxiang Lei, a married couple.  We are citizens of China visiting our daughter and son-in-law in Bothell, Washington on valid US B-2 visas.  Our daughter, Jia Liu is a citizen of China residing in the Unite	0.3365215397161216
Jia Liu Birth Certificate	To whom it may concern,The bearers of this letter are my parents and nephew.  My name is Jia Liu, and I am a software engineer employed by Microsoft.  I am working here on an L1 visa valid until 2019.  I have invited my parents, my sister, and her son t	0.30111499325141317
Jia Liu Birth Certificate	Jia Liu2013-08-05DU Pipeline Sodium Achievements And Magnesium Plans For CJK　　OutlineSodium AchievementsMagnesium PlanMagnesium Work ItemsSodium Work ItemsAppendixSodium AchievementsWrapstar rating signalsTaobao, tmall; qna; novel; v	0.29509097186833017
Jia Liu Birth Certificate	DU work items on zh-cn market　　Jia Liu2013-05-14AgendaSerp classifierWrapstar rating signalsTaobao, tmall; qna; novel; videoGeneral classiferUrl-basedTopic-basedPage number extractionName entity recognitionPerson, location, organiz	0.29126286731590356
Jia Liu Birth Certificate	DU items studyJia Liu2013-05-14AgendaPublication dateMain body blockDocument qualityurl static featuresPublication dateFreshness rankingYear in title, year in url, publication dateEn-us publication date coverage is ~20%Zh-cn public	0.27888307189447376
Jia Liu Birth Certificate	To whom it may concern,The bearer of this letter is my sister, Yan Liu. My name is Jia Liu, and I am a software engineer employed by Microsoft. I am working here on an L1 visa valid until 2019. I have invited my parents, my sister, and her son to come v	0.2777668228148188

Jia Liu	6/8/2016To Whom It May Concern:Re:	Jia LiuThis letter is to confirm that Jia Liu was employed at Microsoft (China) Company Limited in Beijing, China from March 30, 2012 to June 21, 2015.  She worked full time, 40 hours per week.  Sincerely,Xue B	0.4642407360769148
Jia Liu	To Whom It May ConcernPage 2DATETo Whom It May Concern:Re:	Jia LiuI write to certify that Jia Liu worked as a Software Development Engineer at Microsoft (China) Company Limited (Microsoft China) in Beijing, China from March 30, 2012 to September	0.4045356829101142
Jia Liu	To whom it may concern,  We are Jia Liu and her husband, Edward Wild.  The bearers of this letter are Jia's mother, Chunxiang Lei, and father, Xinbao Liu.  Jia is a software engineer working at Microsoft on an L1 visa valid until 2020, and Edward is a	0.3905167172883241
Jia Liu	Jia Liu2013-08-05DU Pipeline Sodium Achievements And Magnesium Plans For CJK　　OutlineSodium AchievementsMagnesium PlanMagnesium Work ItemsSodium Work ItemsAppendixSodium AchievementsWrapstar rating signalsTaobao, tmall; qna; novel; v	0.3671937085985024
Jia Liu	To whom it may concern,The bearer of this letter is my sister, Yan Liu. My name is Jia Liu, and I am a software engineer employed by Microsoft. I am working here on an L1 visa valid until 2019. I have invited my parents, my sister, and her son to come v	0.3482583521213067
Jia Liu	To whom it may concern,We are Xinbao Liu and Chunxiang Lei, a married couple.  We are citizens of China visiting our daughter and son-in-law in Bothell, Washington on valid US B-2 visas.  Our daughter, Jia Liu is a citizen of China residing in the Unite	0.3419460966061223
Jia Liu	学士学位证明BACHELOR DEGREE CERTIFICATEThis is to certify that Ms. Jia Liu, born in August 1986, with the specialty of Computer Science and Technology at Beijing University of Posts and Telecommunications from September 2005 to July 2009, has passed all req	0.3152088449225729
Jia Liu	To whom it may concern,The bearers of this letter are my parents and nephew.  My name is Jia Liu, and I am a software engineer employed by Microsoft.  I am working here on an L1 visa valid until 2019.  I have invited my parents, my sister, and her son t	0.3132701059352211
Jia Liu	DU work items on zh-cn market　　Jia Liu2013-05-14AgendaSerp classifierWrapstar rating signalsTaobao, tmall; qna; novel; videoGeneral classiferUrl-basedTopic-basedPage number extractionName entity recognitionPerson, location, organiz	0.2931960205877249
Jia Liu	DU items studyJia Liu2013-05-14AgendaPublication dateMain body blockDocument qualityurl static featuresPublication dateFreshness rankingYear in title, year in url, publication dateEn-us publication date coverage is ~20%Zh-cn public	0.28091549277455186

Invitationletter	PDI Document AnnotationPDI Ranking PlatformAgendaPDI and forward indexDocument AnnotationSodium update and MG planQ&A DSAT: {books by children}Issue: Document matches the query terms, but its surrounding words may change the intent of 	0.2380888476483749
Invitationletter	Fusion: Next Gen Web Intelligence Review with David KuJune 2016Goals:Power Bing and Bing Next with web open knowledgeNew post L2 ranking platform with MQ and contextual capability inherently Integrated ranking process provides jointly opti	0.21987265265012648
Invitationletter	Integrating Knowledge Graph in Web SearchEntity Triggering and CollectionsPresenter: Ze TianKnowledge GraphEntities and RelationsEntities: celebrities, people, generic terms (e.g. light bulb)Relations: sibling, spouse, people and their works	0.20321816099712492
Invitationletter	Fusion: Next Gen Web IntelligenceDeep Dive with Steven 1/6/2017Goals:Power Bing & Bing Next with web open knowledgeNew post L2 ranking platformImproved agility and scalabilityInherent MQ + contextual capability Integrated ranking process: 	0.20244354779800677
Invitationletter	Partner Index as ServiceWhat is the Problem? RequirementCurrent status of Bing Image StackDiscoveryClient tend to provide feed for full corpusWeb crawlerImage Content RetrievalSpecial agreement, some even behind authentication for access	0.20181192244200621
Invitationletter	QR Team ReviewJan 2017Team IntroductionConceptXDeep QRAgendaQR Team MembersDev Manager: Ciya LiaoLeads: Garrett Kaminaga, Jingwen Lu, Saekoo Lee, Gord LueckPMs: Shyam Jayasankar, Jie CaiSTC-A Speller team: Yongen Gong and his teamWha	0.18859064805226738
Invitationletter	Introduction toas measurement platformOlli-Pekka TossavainenMSQ TeamSunnyvaleContentsOverviewAres AssetsData Web Store (DWS)Single HitApp core relevance exampleWhat is ARESFrom their web site:What’s been built on ARESMap Search	0.18585751901255093
Invitationletter	Index Quality UpdateAgendaMetrics UpdateSelection Model ImprovementRecall TierOffice ImprovementChallenges and Pain PointsHow to measure index quality?Ideally: sampling from all “good” images and see how much we covered.sampling from a	0.18311790086740903
Invitationletter	Author: Tony AngellDate: 08/01/13LocalProbe Improvements for Corrections Analysis and DebuggingTable of ContentsP0 Issues	2Issue: LocalProbe is unpredictable in the amount of time it takes to return a query and how long it takes to investigate a	0.17505536193492005
Invitationletter	Ranker Training Pipeline IntroductionAgendaPipeline OverviewGCC platformExtractionData/Feature PreparationMain Ranker TrainingSegment RankersPipeline OverviewGR OctTree: gcclinkMain Steps:Metastream injection (just info here)Querys	0.15676340545548614

InvitationLetter2018	PDI Document AnnotationPDI Ranking PlatformAgendaPDI and forward indexDocument AnnotationSodium update and MG planQ&A DSAT: {books by children}Issue: Document matches the query terms, but its surrounding words may change the intent of 	0.3320903784312646
InvitationLetter2018	QR Team ReviewJan 2017Team IntroductionConceptXDeep QRAgendaQR Team MembersDev Manager: Ciya LiaoLeads: Garrett Kaminaga, Jingwen Lu, Saekoo Lee, Gord LueckPMs: Shyam Jayasankar, Jie CaiSTC-A Speller team: Yongen Gong and his teamWha	0.2821295170724639
InvitationLetter2018	Author: Tony AngellDate: 08/01/13LocalProbe Improvements for Corrections Analysis and DebuggingTable of ContentsP0 Issues	2Issue: LocalProbe is unpredictable in the amount of time it takes to return a query and how long it takes to investigate a	0.26644882967816935
InvitationLetter2018	Introduction toas measurement platformOlli-Pekka TossavainenMSQ TeamSunnyvaleContentsOverviewAres AssetsData Web Store (DWS)Single HitApp core relevance exampleWhat is ARESFrom their web site:What’s been built on ARESMap Search	0.2609712764317898
InvitationLetter2018	Fusion: Next Gen Web Intelligence Review with David KuJune 2016Goals:Power Bing and Bing Next with web open knowledgeNew post L2 ranking platform with MQ and contextual capability inherently Integrated ranking process provides jointly opti	0.24484252640144688
InvitationLetter2018	Index Quality UpdateAgendaMetrics UpdateSelection Model ImprovementRecall TierOffice ImprovementChallenges and Pain PointsHow to measure index quality?Ideally: sampling from all “good” images and see how much we covered.sampling from a	0.2411259775155573
InvitationLetter2018	Introduction to dynamic ranking Xiao WuOutlinesIntroductionRelevance MeasurementDynamic rankingRanking FeaturesRanking DataRanking modelsRelevance ExperiementIntroductionWhat is dynamic rankingRanking based on query dependent featu	0.2408579236822583
InvitationLetter2018	Ranker Training Pipeline IntroductionAgendaPipeline OverviewGCC platformExtractionData/Feature PreparationMain Ranker TrainingSegment RankersPipeline OverviewGR OctTree: gcclinkMain Steps:Metastream injection (just info here)Querys	0.22017576203581163
InvitationLetter2018	FusionByTurker KeskinpalaTuesday, May 17, 2016OverviewMotivationsWhat is Fusion?GoalsFusion ComponentsRoadmapWeb AnswerQ:“gg”Qpath1:“gg”Qpath2:“google”TLACDG FetcherL2 FetcherTLACDG FetcherL2 FetcherLL4L3L3	0.2067311870892144
InvitationLetter2018	Integrating Knowledge Graph in Web SearchEntity Triggering and CollectionsPresenter: Ze TianKnowledge GraphEntities and RelationsEntities: celebrities, people, generic terms (e.g. light bulb)Relations: sibling, spouse, people and their works	0.20546926366154677

InvitationLetter	PDI Document AnnotationPDI Ranking PlatformAgendaPDI and forward indexDocument AnnotationSodium update and MG planQ&A DSAT: {books by children}Issue: Document matches the query terms, but its surrounding words may change the intent of 	0.2380888476483749
InvitationLetter	Fusion: Next Gen Web Intelligence Review with David KuJune 2016Goals:Power Bing and Bing Next with web open knowledgeNew post L2 ranking platform with MQ and contextual capability inherently Integrated ranking process provides jointly opti	0.21987265265012648
InvitationLetter	Integrating Knowledge Graph in Web SearchEntity Triggering and CollectionsPresenter: Ze TianKnowledge GraphEntities and RelationsEntities: celebrities, people, generic terms (e.g. light bulb)Relations: sibling, spouse, people and their works	0.20321816099712492
InvitationLetter	Fusion: Next Gen Web IntelligenceDeep Dive with Steven 1/6/2017Goals:Power Bing & Bing Next with web open knowledgeNew post L2 ranking platformImproved agility and scalabilityInherent MQ + contextual capability Integrated ranking process: 	0.20244354779800677
InvitationLetter	Partner Index as ServiceWhat is the Problem? RequirementCurrent status of Bing Image StackDiscoveryClient tend to provide feed for full corpusWeb crawlerImage Content RetrievalSpecial agreement, some even behind authentication for access	0.20181192244200621
InvitationLetter	QR Team ReviewJan 2017Team IntroductionConceptXDeep QRAgendaQR Team MembersDev Manager: Ciya LiaoLeads: Garrett Kaminaga, Jingwen Lu, Saekoo Lee, Gord LueckPMs: Shyam Jayasankar, Jie CaiSTC-A Speller team: Yongen Gong and his teamWha	0.18859064805226738
InvitationLetter	Introduction toas measurement platformOlli-Pekka TossavainenMSQ TeamSunnyvaleContentsOverviewAres AssetsData Web Store (DWS)Single HitApp core relevance exampleWhat is ARESFrom their web site:What’s been built on ARESMap Search	0.18585751901255093
InvitationLetter	Index Quality UpdateAgendaMetrics UpdateSelection Model ImprovementRecall TierOffice ImprovementChallenges and Pain PointsHow to measure index quality?Ideally: sampling from all “good” images and see how much we covered.sampling from a	0.18311790086740903
InvitationLetter	Author: Tony AngellDate: 08/01/13LocalProbe Improvements for Corrections Analysis and DebuggingTable of ContentsP0 Issues	2Issue: LocalProbe is unpredictable in the amount of time it takes to return a query and how long it takes to investigate a	0.17505536193492005
InvitationLetter	Ranker Training Pipeline IntroductionAgendaPipeline OverviewGCC platformExtractionData/Feature PreparationMain Ranker TrainingSegment RankersPipeline OverviewGR OctTree: gcclinkMain Steps:Metastream injection (just info here)Querys	0.15676340545548614

Investigating Job Performance Issues Using SCOPEStudio	Investigating Job Performance Issues Using SCOPEStudio Author: Xiaoyong ZhuSupport: Client Tools Customer SupportContentsIntroduction	2Investigating Data Skew Problem	2Confirm data skew problem via SCOPEStudio	3Whether the data skew problem 	0.7379044982128797
Investigating Job Performance Issues Using SCOPEStudio	Interactive BingGoalSolving hard queryOverview Search engine is helping people solving problem. A lot of cases, search engine couldn’t solve problem at first shot. At this point, search engine need take more information to narrow down the user int	0.5100584376306668
Investigating Job Performance Issues Using SCOPEStudio	Thoughts on Interest Graph – Experience, Business and TechnologyPersonalized recommendation that you don’t want to miss Author: Ting Cai Contributors: AC Surendran, Xiaodong Fan, Chuanxin Hu, Yan Ke, Tony Chor, Richard Qian1.	What is Interest Graph?	0.4449760038935079
Investigating Job Performance Issues Using SCOPEStudio	FusionByTurker KeskinpalaTuesday, May 17, 2016OverviewMotivationsWhat is Fusion?GoalsFusion ComponentsRoadmapWeb AnswerQ:“gg”Qpath1:“gg”Qpath2:“google”TLACDG FetcherL2 FetcherTLACDG FetcherL2 FetcherLL4L3L3	0.44098834533785436
Investigating Job Performance Issues Using SCOPEStudio	cal deepdiverelaxationdec 2017AgendaProduct GoalsQuery SimplificationMechanism/RuntimeCRF Model TrainingQS Path SelectionOffline SimulatorSmart RelaxMechanism & TrainingRelaxation: ImpactRelaxation: Product goalsImprove Rec	0.4314137436602734
Investigating Job Performance Issues Using SCOPEStudio	Introduction to L1Xiao WuSearch Platform Tiger Team AgendaL1 goals and challengesMetrics and measurementL1 ranker and perf optimizationL1 ranking Perf optimizationDebugging tools L1 training and shippingThinking and discussionL1 	0.4265680182545739
Investigating Job Performance Issues Using SCOPEStudio	Entity Categorization Using Convolutional Neural NetworkWeiwu Zhu8/23/2018AgendaMotivationCNN introductionCNN in NLPCNN based entity categorizationMeasurementMotivationTaxonomy mapping is not scalable (Feature Normalization)Nee	0.4221540897076526
Investigating Job Performance Issues Using SCOPEStudio	Query Formulation Review of FY15 Goals and Silicon achievements/learningsSilicon ScorecardAreaGoalAchievementQF Relevance(Autosuggest, Related Search)SSRx+0.052Annualized Revenue+$58mRelated Search RelevanceBeat G on DO defect ra	0.4187961790426117
Investigating Job Performance Issues Using SCOPEStudio	Tiger Index BrownbagHui ShenSearch Platform Tiger TeamAgenda	OverviewKey ideasTiger architectureTiger ++ 2/24/2012Agenda	OverviewKey ideasTiger architectureTiger ++ 2/24/2012What is Tiger IndexAn new index serve technol	0.41870082086220034
Investigating Job Performance Issues Using SCOPEStudio	Threshold Query Formulation Deep DiveGoal of the presentation is to communicate our approach for query formulation and get feedback on whether this aligns with overall Threshold goals.OverviewGoals & MetricsQF ModelRoadmapScenariosKey Ta	0.4158556101110643

Introducing Substrate - Samim Erdogan	Paul LuberPrincipal Group PMSamim ErdoganPrincipal Pm ManagerIntroducing Substrate 	MICROSOFT CONFIDENTIALSubstrate Day 2018A cloud platform for compliant, scalable apps that offer intelligent experiences built on rich user data.What is Su	0.4985537059318025
Introducing Substrate - Samim Erdogan	Introduction to dynamic ranking Xiao WuOutlinesIntroductionRelevance MeasurementDynamic rankingRanking FeaturesRanking DataRanking modelsRelevance ExperiementIntroductionWhat is dynamic rankingRanking based on query dependent featu	0.4280694446783845
Introducing Substrate - Samim Erdogan	Satori Introduction2012-09-20  yukaihAgendaOverviewMajor ModulesIngestionConflationServingGet Started in Local BoxUseful linksAppendix: Satori Local PipelineOverview - SatoriMission: build the largest, freshest, and most accurate E	0.4075307906415384
Introducing Substrate - Samim Erdogan	Auto Category Classification PipelineHanqing Cui2012/10/25OutlinePain PointsThinkingAuto Category Classification PipelineAuto Page LabelingData SamplingTrainingFeature SelectionThresholdIterative TrainingInitial Seed Model Creati	0.3786750411682741
Introducing Substrate - Samim Erdogan	Relevance Debug InfrastructureProblemFrequent  daily metric fluctuationRelevance gain negated by regressions from Sep to Oct 2013Painful to investigateChallengeLocal stack is complex with lots of componentsVarious relevance events mixed toge	0.3732770149261747
Introducing Substrate - Samim Erdogan	Ranker Training Pipeline IntroductionAgendaPipeline OverviewGCC platformExtractionData/Feature PreparationMain Ranker TrainingSegment RankersPipeline OverviewGR OctTree: gcclinkMain Steps:Metastream injection (just info here)Querys	0.3625961004057955
Introducing Substrate - Samim Erdogan	Relevance Experimentation with DUOverviewThe ideal end state for any relevance improvement would consist of having one or more DU features shipped in the index that is then leveraged by the latest production ranker. This would achieve the highest leve	0.3617983168852312
Introducing Substrate - Samim Erdogan	NGram Language Model based Url Breaking – Design DocumentStatusOngoingIntroductionUrl is a very important signal for ranking, particularly for tail queries and navigation queries. This signal has 100% url coverage, which really makes it different 	0.3415982587230003
Introducing Substrate - Samim Erdogan	Introduction to XAP“The world is indeed full of peril and in it there are many dark places.”- J. R. R. Tolkien, The Lord of the RingsAlex Bakulin (albakuli)2/16/2016How online Bing worksHow online Bing worksXAP’s role in BingHost a	0.32983292330907094
Introducing Substrate - Samim Erdogan	Generic Entity Extraction in Sodium Owner: Chuanxin HuContributors: Kang Li, Yi LiOverviewThe understanding of entities and their relationship is a one of the key pillars supporting the Bing’s strategic bet on the knowledge graph. Today, Satori ca	0.32334433155569076

Interactive Bing	ID Phrase Should be removed? 1 all of y 2 bing 3 bing can you 4 bing could you 5 bing could you please 6 bing i d like to 7 bing i d like you to 8 bing i need to 9 bing i need you to 10 bing i wanna 11 bing i want to 12 bing i want you to 13 bing i would 	0.3754367584697033
Interactive Bing	Bing GC Deep DiveBingGCI 9/26/2014Introduction – Pavel, 2minsProject overview – Wei, 6minsBing GC XAP workflow – John, 10minsBing GC data pipeline and data ingestion – Florin, 7minsBing GC Offline relevance platform – Jian, 8minsSingle-poi	0.3540417600510353
Interactive Bing	BingGC Multi-Pointer Stack11/4/2014BingGCI@microsoft.comMulti-Pointer ResolutionUsing a tiling system, we first find the correct Tile, then search inside to find matching entities:	 Chipotle Mission St 2nd StQuery: Chipotle Mission St 2nd St	0.3378702168909657
Interactive Bing	Index Serve in Bing SearchContents1	Introduction	81.1	Overview	81.2	Goals and constraints	82	IndexServe Stats at a glance	93	IndexServe Architecture Overview	93.1	Logical Query flow	93.2	Machine Functions	124	Runtime Services	124.1	FCS	0.2973741395631281
Interactive Bing	Fusion: Next Gen Web IntelligenceDeep Dive with Steven 1/6/2017Goals:Power Bing & Bing Next with web open knowledgeNew post L2 ranking platformImproved agility and scalabilityInherent MQ + contextual capability Integrated ranking process: 	0.2844048614112781
Interactive Bing	Partner Index as ServiceWhat is the Problem? RequirementCurrent status of Bing Image StackDiscoveryClient tend to provide feed for full corpusWeb crawlerImage Content RetrievalSpecial agreement, some even behind authentication for access	0.2810667148741566
Interactive Bing	Integrating Knowledge Graph in Web SearchEntity Triggering and CollectionsPresenter: Ze TianKnowledge GraphEntities and RelationsEntities: celebrities, people, generic terms (e.g. light bulb)Relations: sibling, spouse, people and their works	0.27983066699670756
Interactive Bing	Interactive BingGoalSolving hard queryOverview Search engine is helping people solving problem. A lot of cases, search engine couldn’t solve problem at first shot. At this point, search engine need take more information to narrow down the user int	0.2788901574037347
Interactive Bing	Fusion: Next Gen Web Intelligence Review with David KuJune 2016Goals:Power Bing and Bing Next with web open knowledgeNew post L2 ranking platform with MQ and contextual capability inherently Integrated ranking process provides jointly opti	0.2740932501670256
Interactive Bing	Stateful Query Intent RefinementFeature OverviewStateful Query Intent Refinement is a Bing QR service that can be leveraged to guide users to their specific intent. Queries that have ambiguous intent or multiple intents/sub-intents can be refined usin	0.2374717715489851

Index Quality Update	Index Quality UpdateAgendaMetrics UpdateSelection Model ImprovementRecall TierOffice ImprovementChallenges and Pain PointsHow to measure index quality?Ideally: sampling from all “good” images and see how much we covered.sampling from a	0.5705154499593051
Index Quality Update	Index Quality Team’s Deep Learning ExperienceLuke ChenOutlineMotivationsCNTK/Phily ExperienceIQ team DL projects highlightsResourcesMotivationsRecent progress in deep neural net provides inspirations to upgrade Bing’s machine learning stac	0.3534501732454814
Index Quality Update	Index Serve in Bing SearchContents1	Introduction	81.1	Overview	81.2	Goals and constraints	82	IndexServe Stats at a glance	93	IndexServe Architecture Overview	93.1	Logical Query flow	93.2	Machine Functions	124	Runtime Services	124.1	FCS	0.34044915228425154
Index Quality Update	L-1B SPECIALIZED KNOWLEDGE QUESTIONNAIREMICROSOFT POSITION IN THE U.S.Provide the following information for your current position at the Microsoft.MICROSOFT POSITION ABROADProvide the following information for your position at the Microsoft’s su	0.288239760263335
Index Quality Update	Partner Index as ServiceWhat is the Problem? RequirementCurrent status of Bing Image StackDiscoveryClient tend to provide feed for full corpusWeb crawlerImage Content RetrievalSpecial agreement, some even behind authentication for access	0.2755985798757951
Index Quality Update	Content Quality Classification & RankingGuihong Cao, Cheng NiuContent Quality for RankingContent quality = originality + trustworthy + information satisfaction + freshnessSpam sites, junk site, link farm, content farm, ….Search users are interes	0.2592792656166972
Index Quality Update	Local Search Platform PM Onboarding GuideAuthors: Dany DaherDate: 10/18/2013Architecture OverviewHow Local Search Works Local Data Platform Architecture MetricsLocal Metrics:  http://jeffke/localMetrics/Definition of QLDCG: Local Discoun	0.25886069446058196
Index Quality Update	Run web-search-like query against my dataSame Bing Web Search Indexing and Ranking engineIndex in a secondTransparent and real time index sync, no complex index-gen pipelinePrototype in an hourFast self-onboarding with freemium account, schema-d	0.2570991746317749
Index Quality Update	Competitive Query-Entity ClickMicrosoft ConfidentialMicrosoft ConfidentialGoalCreate a dataset that is readily available to utilize and analyze query-entity click patterns on competitive dataCompetitive Engine: GoogleMicrosoft ConfidentialCo	0.24577498481011542
Index Quality Update	Lexical analyzer (fa_lex)Input: a buffer of textOutput: a sequence of tokens, each token is <from, to, tag>For C++:Input: “if(++i==0) {j = 0;}”Output: if/OP (/LRB ++/OP i/VAR ==/OP 0/NUM )/RBR {/LCBR j/VAR =/OP 0/NUM ;/OP }/RCBREach rule:Des	0.24403949579132023

Index Quality Team’s Deep Learning Experience	Index Quality Team’s Deep Learning ExperienceLuke ChenOutlineMotivationsCNTK/Phily ExperienceIQ team DL projects highlightsResourcesMotivationsRecent progress in deep neural net provides inspirations to upgrade Bing’s machine learning stac	0.7719386533119414
Index Quality Team’s Deep Learning Experience	QR Team ReviewJan 2017Team IntroductionConceptXDeep QRAgendaQR Team MembersDev Manager: Ciya LiaoLeads: Garrett Kaminaga, Jingwen Lu, Saekoo Lee, Gord LueckPMs: Shyam Jayasankar, Jie CaiSTC-A Speller team: Yongen Gong and his teamWha	0.5229639098963952
Index Quality Team’s Deep Learning Experience	Index Quality UpdateAgendaMetrics UpdateSelection Model ImprovementRecall TierOffice ImprovementChallenges and Pain PointsHow to measure index quality?Ideally: sampling from all “good” images and see how much we covered.sampling from a	0.4672724686428965
Index Quality Team’s Deep Learning Experience	Term expansion summaryGoalsVisible changes in ARDSImprove “no match” issuesImprove rank qualityLimit FPs. Pre-work neededPort names tagger to C#/C++Query timeWSD and entity taggerEntity tagging in query logs (Britney Spears bio -> <p	0.42733999466583805
Index Quality Team’s Deep Learning Experience	Deal Ranking ImprovementsDeal Understanding ImprovementsGoal: Increase general deal coverage (deal product type from specific to general).Solution: Identify the prefix and suffix of title by punctuations and prep. Remove the prefix and suffix from t	0.41801361405434656
Index Quality Team’s Deep Learning Experience	Query Formulation Review of FY15 Goals and Silicon achievements/learningsSilicon ScorecardAreaGoalAchievementQF Relevance(Autosuggest, Related Search)SSRx+0.052Annualized Revenue+$58mRelated Search RelevanceBeat G on DO defect ra	0.4166735751081999
Index Quality Team’s Deep Learning Experience	Index Serve in Bing SearchContents1	Introduction	81.1	Overview	81.2	Goals and constraints	82	IndexServe Stats at a glance	93	IndexServe Architecture Overview	93.1	Logical Query flow	93.2	Machine Functions	124	Runtime Services	124.1	FCS	0.4095313470444993
Index Quality Team’s Deep Learning Experience	Augmented Query Parser Using Deep LearningDemi Guo (Bing Local Intern t-deguo)Manager: Leon ZhangMentor: Simona CabuzHello everyone, Today, I’m going to present my intern project: Augmented query parser using deep learning.About Me My name i	0.40050197640877017
Index Quality Team’s Deep Learning Experience	Site Quality ClassificationGuihong CaoDefinition of the ProblemWhat is site quality?Google’s definition includes the following dimensionsDuplicated content within the siteTrustworthyOn demand media? Quality controlSite authorityAuthor 	0.4004270750412445
Index Quality Team’s Deep Learning Experience	Deal Ranking Improvement & MeasurementBackgroundAfter we shipped deal understanding, bad deals filtering, deal ranking for the entity search deals and popular deals nearby. We want to measure and improve our deal ranking based on user behaviors. We ca	0.39821040275091046

Improving Cortana Personalization Through Finances	OSG Threshold[Cortana/Improving Cortana Personalization Through Finances]functional specification[Shell/CAST]CONTACTSROLEName; AliasProgram ManagerColleen Hamilton; chamiltDeveloperQualityDesignPartner(s)ONE PAGE SPEC - Guideline	0.7095623783767075
Improving Cortana Personalization Through Finances	Provider Feature Measured Coverage Corrected Coverage(Exclude No Rating) Improved Coverage Estimate(Include No Rating) Note Amazon Price Amazon Availability Amazon Rating&Count >95% >92% 1. A known client issue:The current logic is to show the rating&cou	0.3830800755226789
Improving Cortana Personalization Through Finances	CoreCAL Improvements		Page 2 of 5CoreCAL ImprovementsDescriptionDuring Sodium, CAL Team would invest on optimizing separately for L0\L1\L2 on top of current CoreCAL improvements. Multiple Query Project will target Fidelity\SBS\SSRx while CoreCAL imp	0.36751304229133286
Improving Cortana Personalization Through Finances	Named Entity RecognizerTao Peng and Kang LiEntity names recognitionRecognize person, location and organization namesBOSTON, April  16 - Kevin Garnett helped the Boston Celtics beat the L. A. Lakers in last year's NBA final. ( Tony Gutierrez / Asso	0.3537113263071018
Improving Cortana Personalization Through Finances	Local Search – Entity Containment Short blurb of what this spec is aboutMilestone:  MG,ALSpec StatusDraftTFS Feature IDPMSandhya GuntreddyContributorsRajesh Srivastava, Prajakta Joshi,Kanad, PrashantSpec Location:https://microsoft.sh	0.3373776016425095
Improving Cortana Personalization Through Finances	Local Search Entity Schema for RelationShips (Entity Containment, Affinities) Short blurb of what this spec is aboutMilestone:  MagnesiumSpec StatusDraftTFS Feature IDPM/Doc OwnerSandhya GuntreddyContributors Scott, Bruno,Andrew,Prajakta	0.3191882077427175
Improving Cortana Personalization Through Finances	Thoughts on Interest Graph – Experience, Business and TechnologyPersonalized recommendation that you don’t want to miss Author: Ting Cai Contributors: AC Surendran, Xiaodong Fan, Chuanxin Hu, Yan Ke, Tony Chor, Richard Qian1.	What is Interest Graph?	0.31693431803466987
Improving Cortana Personalization Through Finances	Normalization and Parsing OverviewTypes of NormalizationLimiting to just normalization, there are actually several different types of normalization which may be interesting:WhitespaceThis is:Converting all whitespace characters to spacestrippi	0.31507514049993524
Improving Cortana Personalization Through Finances	Threshold Query Formulation Deep DiveGoal of the presentation is to communicate our approach for query formulation and get feedback on whether this aligns with overall Threshold goals.OverviewGoals & MetricsQF ModelRoadmapScenariosKey Ta	0.31399419800846257
Improving Cortana Personalization Through Finances	Site Quality ClassificationGuihong CaoDefinition of the ProblemWhat is site quality?Google’s definition includes the following dimensionsDuplicated content within the siteTrustworthyOn demand media? Quality controlSite authorityAuthor 	0.30384108535254856

IT Tech Talk Intro and Close Template	Microsoft IT Technology AdoptionSee past and upcoming  talks at http://aka.ms/ITTechTalksSubscribe to IT Tech Talks DL @IT Tech Talk Invitethere’s a link on the Tech Talks siteQuestions about Tech Talks? Ask Justin Lane or Susan Sims.IT Tech T	0.5036468530934204
IT Tech Talk Intro and Close Template	Crawler Tech TalkOctober 14, 2008AgendaOverview of Msnbot Internal Data FlowFlow of Chunks and Chunk MetadataReal-Time MonitoringDaily Data Reporting SubsystemPrevious Instances Requiring InterventionPotential Future ProblemsQ&AMsnbot 	0.4119751482526639
IT Tech Talk Intro and Close Template	QR Team ReviewJan 2017Team IntroductionConceptXDeep QRAgendaQR Team MembersDev Manager: Ciya LiaoLeads: Garrett Kaminaga, Jingwen Lu, Saekoo Lee, Gord LueckPMs: Shyam Jayasankar, Jie CaiSTC-A Speller team: Yongen Gong and his teamWha	0.36125062877474134
IT Tech Talk Intro and Close Template	WPO Local Relevance Tech TalkWPO Local Relevance TeamOverviewWPO’s role in local relevance pipelineLocal ExperienceArchitecture overviewMetricsWPO Local Relevance Model IntroductionWPO Query understanding and Location understandingWhy do	0.32304141520574653
IT Tech Talk Intro and Close Template	QR MicrosegmentsSandeep AparajitAgendaWhat are microsegments?How does microsegment work in CAL?How can I add my own microsegment?DemoQuestions/SuggestionsWhat are Microsegments?Microsegment is a technique using which you can alter the be	0.31179640364086547
IT Tech Talk Intro and Close Template	Pattern Based Term Weight FrameworkIntroductionPattern based term weight recognizes the importance for part of terms or all the terms based on patterns/templates/knowledge. There are 2 differences between general and pattern based term weight.Compar	0.3060322427307666
IT Tech Talk Intro and Close Template	Thoughts on Interest Graph – Experience, Business and TechnologyPersonalized recommendation that you don’t want to miss Author: Ting Cai Contributors: AC Surendran, Xiaodong Fan, Chuanxin Hu, Yan Ke, Tony Chor, Richard Qian1.	What is Interest Graph?	0.3057537438486251
IT Tech Talk Intro and Close Template	Measurement PlanSmoke test:We will deploy ranker model under test and service to INT and ask SKI internal users to issue whatever queries they want. In this way, we can quickly get feedback using Microsoft private data and Bing API. People can get min	0.29783273988265174
IT Tech Talk Intro and Close Template	Fusion: Next Gen Web IntelligenceDeep Dive with Steven 1/6/2017Goals:Power Bing & Bing Next with web open knowledgeNew post L2 ranking platformImproved agility and scalabilityInherent MQ + contextual capability Integrated ranking process: 	0.2820443358848446
IT Tech Talk Intro and Close Template	Fusion: Next Gen Web Intelligence Review with David KuJune 2016Goals:Power Bing and Bing Next with web open knowledgeNew post L2 ranking platform with MQ and contextual capability inherently Integrated ranking process provides jointly opti	0.28190830549925305

IQ Team Recap H1 2016	IQ Team RecapH1 2016FY16H1 AccomplishmentsTeamSSRxen-* Desktop SBSen-* Mobile SBSen-* Semantic SBSCore Web Relevance0.55/0.62.46/3.02.65/3.01.88/2.0Adult LeakageSpamJunkCQDCGMPCMALTABing@WorkSubstrate0.02/0.01	0.6092224143500719
IQ Team Recap H1 2016	Location and Data Services Team all hands10/08/2014AgendaCelebrate – Wei, 5minsLocal partners – Andy, 10minsLocal Data Services – Alex, 15minsGeocoder and GeoSpatial Services – Jai, 20minsLocation and Autosuggest Services – Sid, 15minsBing	0.3766267852529543
IQ Team Recap H1 2016	TermX: the Query Rewriting Engine for BingCore Relevance PM Meeting | Shu Zheng | Jan 5th, 2016AgendaWhat is TermX? Technique DeepdiveCurrent StateFuture WorksWhat is TermX? TermX = TermExp = Term ExpansionThe query rewriting engine for 	0.3684854722683962
IQ Team Recap H1 2016	QR Team ReviewJan 2017Team IntroductionConceptXDeep QRAgendaQR Team MembersDev Manager: Ciya LiaoLeads: Garrett Kaminaga, Jingwen Lu, Saekoo Lee, Gord LueckPMs: Shyam Jayasankar, Jie CaiSTC-A Speller team: Yongen Gong and his teamWha	0.36539819699714216
IQ Team Recap H1 2016	WPO Local RelevancePing Yin2017-03-21OverviewWPO’s role in local relevance pipelineLocal Entity StampingArchitecture overviewWPO Local Relevance Models.Query: exton mall, User location: Wallingford, PAWPO RolesExtract/detect all entity	0.32601894121236275
IQ Team Recap H1 2016	How do we train SM-CRF for APN?AgendaOverviewGeneration of Lexicons (in aether)Generation of RegEx FeaturesCRF Training Pipeline (in aether)CRF Eval Pipeline (in aether)Debugging ToolsQuestions?OverviewCRF is responsible for entity e	0.32486053928064035
IQ Team Recap H1 2016	CoreCAL Improvements		Page 2 of 5CoreCAL ImprovementsDescriptionDuring Sodium, CAL Team would invest on optimizing separately for L0\L1\L2 on top of current CoreCAL improvements. Multiple Query Project will target Fidelity\SBS\SSRx while CoreCAL imp	0.32051307309225696
IQ Team Recap H1 2016	ML Model Scorecard Analysis8/8/2019Unexpected term search movementhttps://exp.microsoft.com/xcard/?view=4e77b420-7b77-4e41-92ac-8e84f506fb01Check correctness of scorecard metric implementationCalculate term AVG rank from raw data streamsSearch	0.3202415713802502
IQ Team Recap H1 2016	WPO Local Relevance Tech TalkWPO Local Relevance TeamOverviewWPO’s role in local relevance pipelineLocal ExperienceArchitecture overviewMetricsWPO Local Relevance Model IntroductionWPO Query understanding and Location understandingWhy do	0.3132621596729406
IQ Team Recap H1 2016	Microsoft ConfidentialSeptember 14, 2016AGI EngineCore Relevance PM TeamJanuary 26thHuman and Artificial IntelligenceOur Approach to an AGI EngineSolving the AGI Engine GoalsUpgrading our Search StackAgendaLets start with a conceptual 	0.31239308637403357

I130 Questionnaire for USC Petitioner_Ted Wild	I-130 Questionnaire for the Petitioner (Husband or Wife)PLEASE LEFT CLICK ON GRAY FIELDS TO ENTER DATA.  PLEASE DO NOT (A) MODIFY THE FORMAT OF THIS DOCUMENT, (B) USE ALL CAP'S; OR (C) RIGHT-CLICK ON GRAY FIELDS.  IF YOU SAVE THIS DOCUMENT, PLEASE SAVE 	0.4799074998729853
I130 Questionnaire for USC Petitioner_Ted Wild	L-1B SPECIALIZED KNOWLEDGE QUESTIONNAIREMICROSOFT POSITION IN THE U.S.Provide the following information for your current position at the Microsoft.MICROSOFT POSITION ABROADProvide the following information for your position at the Microsoft’s su	0.4098700699424936
I130 Questionnaire for USC Petitioner_Ted Wild	PERM Labor Certification Questionnaire:  Technical (continued)PERM Labor Certification Questionnaire (Technical)Please complete the information requested in this questionnaire carefully.  This information is necessary for the legal analysis and prepar	0.39139934707837604
I130 Questionnaire for USC Petitioner_Ted Wild	QR FY19 LRP Planning - 23/29/18Unified Concept Tagging – Key ChallengesStructural ComplexityFor ambiguous queries and multi-concept queries, how much organization is required?  How to represent this in a linear qlf?  What about inter-concept rel	0.3498281420273006
I130 Questionnaire for USC Petitioner_Ted Wild	Measurement PlanSmoke test:We will deploy ranker model under test and service to INT and ask SKI internal users to issue whatever queries they want. In this way, we can quickly get feedback using Microsoft private data and Bing API. People can get min	0.340144935336659
I130 Questionnaire for USC Petitioner_Ted Wild	LDCG V3Knowledge Transfer2017-04-14Brett Clippingdale, Sean King, Vikas Mittal, Li JiangLDCG V3 OutlineLDCG V2 vs V3: High-level comparisonLDCG V3: New distance ModelV2 vs V3 OverviewLDCG V3: GeoIntent HIT appLDCG V3: Calculate distance 	0.3166113518605635
I130 Questionnaire for USC Petitioner_Ted Wild	Investigating Job Performance Issues Using SCOPEStudio Author: Xiaoyong ZhuSupport: Client Tools Customer SupportContentsIntroduction	2Investigating Data Skew Problem	2Confirm data skew problem via SCOPEStudio	3Whether the data skew problem 	0.30393793397016333
I130 Questionnaire for USC Petitioner_Ted Wild	Query Automotive & Vehicle Services (90056) Banking & Finance (90111) Beauty & Spa (90353) Food & Drink (90232) Healthcare (90375) Professionals & Services (90496) Real Estate (90584) Retail (90628) Sports & Recreation (90848) Travel (90881) Other Categor	0.30147025815449574
I130 Questionnaire for USC Petitioner_Ted Wild	Zh-cn Transportation Segment Optimization by Pattern EngineIntroductionThe pattern queries can cover almost 10% in all queries. We can summarize lots of patterns on Query and Document sides for different segments. We can recognize key terms, relations	0.2909025507758804
I130 Questionnaire for USC Petitioner_Ted Wild	BusinessV3TaxonomyClassifierAugust, 2018Daniel WeinshenkerMicrosoft ConfidentialAgendaMicrosoft ConfidentialPurpose / OverviewDemoData Pipeline / Lexicon GenerationMeasurementQASChallenges / Future WorkPurpose We want to improve 	0.28892127468578543

I130 Questionnaire for USC Petitioner_Edward Wild	I-130 Questionnaire for the Petitioner (Husband or Wife)PLEASE LEFT CLICK ON GRAY FIELDS TO ENTER DATA.  PLEASE DO NOT (A) MODIFY THE FORMAT OF THIS DOCUMENT, (B) USE ALL CAP'S; OR (C) RIGHT-CLICK ON GRAY FIELDS.  IF YOU SAVE THIS DOCUMENT, PLEASE SAVE 	0.4237683150610389
I130 Questionnaire for USC Petitioner_Edward Wild	L-1B SPECIALIZED KNOWLEDGE QUESTIONNAIREMICROSOFT POSITION IN THE U.S.Provide the following information for your current position at the Microsoft.MICROSOFT POSITION ABROADProvide the following information for your position at the Microsoft’s su	0.3929501497173039
I130 Questionnaire for USC Petitioner_Edward Wild	QR FY19 LRP Planning - 23/29/18Unified Concept Tagging – Key ChallengesStructural ComplexityFor ambiguous queries and multi-concept queries, how much organization is required?  How to represent this in a linear qlf?  What about inter-concept rel	0.33900272826926425
I130 Questionnaire for USC Petitioner_Edward Wild	Introduction toas measurement platformOlli-Pekka TossavainenMSQ TeamSunnyvaleContentsOverviewAres AssetsData Web Store (DWS)Single HitApp core relevance exampleWhat is ARESFrom their web site:What’s been built on ARESMap Search	0.33821495728341155
I130 Questionnaire for USC Petitioner_Edward Wild	AGI Intent EncoderGavin YingWeb Intelligence Team(Tail Ranking team)7/29/2016What is Intent EncoderGiven a text like query, question, short sentence, get a vector represent in a high dimension space. The vector should capture semantic meanin	0.33379315280571326
I130 Questionnaire for USC Petitioner_Edward Wild	PO Box 91059Seattle, WA 98111-9159	VISION 	Member Claim Form 	for Microsoft  This form is to be used for Vision claims (routine exam and hardware) where you incurred expenses from a provider who did not bill the plan directly.For Medical or De	0.331086654824496
I130 Questionnaire for USC Petitioner_Edward Wild	LDCG V3Knowledge Transfer2017-04-14Brett Clippingdale, Sean King, Vikas Mittal, Li JiangLDCG V3 OutlineLDCG V2 vs V3: High-level comparisonLDCG V3: New distance ModelV2 vs V3 OverviewLDCG V3: GeoIntent HIT appLDCG V3: Calculate distance 	0.3288111247445946
I130 Questionnaire for USC Petitioner_Edward Wild	Dynamic Rank FeaturesWritten by Krysta Svore (ksvore)This document is meant to give a brief overview of the features used in the dynamic ranking component of Live search.  It contains an overview of the search process followed by the definitions of cu	0.3220928397032884
I130 Questionnaire for USC Petitioner_Edward Wild	Measurement PlanSmoke test:We will deploy ranker model under test and service to INT and ask SKI internal users to issue whatever queries they want. In this way, we can quickly get feedback using Microsoft private data and Bing API. People can get min	0.3188736034029451
I130 Questionnaire for USC Petitioner_Edward Wild	DU Pipeline V2Bram Gruneir, Ted Wild and Connie YangDocument Understanding Dev Talk6/27/2013DU Pipeline V2: frequency demoIntroduce the demo featureDevelopmentDeploymentDU Pipeline V2: frequency demoIntroduce the demo featureDevelopmen	0.3129476333114489

I130 Questionnaire for USC Petitioner	I-130 Questionnaire for the Petitioner (Husband or Wife)PLEASE LEFT CLICK ON GRAY FIELDS TO ENTER DATA.  PLEASE DO NOT (A) MODIFY THE FORMAT OF THIS DOCUMENT, (B) USE ALL CAP'S; OR (C) RIGHT-CLICK ON GRAY FIELDS.  IF YOU SAVE THIS DOCUMENT, PLEASE SAVE 	0.4137097601179869
I130 Questionnaire for USC Petitioner	L-1B SPECIALIZED KNOWLEDGE QUESTIONNAIREMICROSOFT POSITION IN THE U.S.Provide the following information for your current position at the Microsoft.MICROSOFT POSITION ABROADProvide the following information for your position at the Microsoft’s su	0.40153452932414413
I130 Questionnaire for USC Petitioner	PERM Labor Certification Questionnaire:  Technical (continued)PERM Labor Certification Questionnaire (Technical)Please complete the information requested in this questionnaire carefully.  This information is necessary for the legal analysis and prepar	0.3812408852255027
I130 Questionnaire for USC Petitioner	Query Automotive & Vehicle Services (90056) Banking & Finance (90111) Beauty & Spa (90353) Food & Drink (90232) Healthcare (90375) Professionals & Services (90496) Real Estate (90584) Retail (90628) Sports & Recreation (90848) Travel (90881) Other Categor	0.33397426758636983
I130 Questionnaire for USC Petitioner	QR FY19 LRP Planning - 23/29/18Unified Concept Tagging – Key ChallengesStructural ComplexityFor ambiguous queries and multi-concept queries, how much organization is required?  How to represent this in a linear qlf?  What about inter-concept rel	0.32531619885434204
I130 Questionnaire for USC Petitioner	Speller Related Issues & SolutionsMing Wu2014-01-08Speller Related Issues – in nativePBA reads spell corrected query from Speller kif responseAssumes offsets are on raw query, which is not the caseE.g. {   piza hut} -> {pizzaiza hut}Proposed	0.3251531097212683
I130 Questionnaire for USC Petitioner	query分类—分享                     刘佳2011.6.8web query classification(query分类):	将web search query根据它的主题，分派到1个或者多个预先定义的分类中。web search query的特征：有噪声：拼写错误等长度很短：信息量少，特征少表意含糊：query可能包含多个含义,属于多个分类含义会随时间演变目标分类的特征：目标分类定义缺少语义注解一级或者多级分类分类数目：几	0.3193051969654248
I130 Questionnaire for USC Petitioner	BusinessV3TaxonomyClassifierAugust, 2018Daniel WeinshenkerMicrosoft ConfidentialAgendaMicrosoft ConfidentialPurpose / OverviewDemoData Pipeline / Lexicon GenerationMeasurementQASChallenges / Future WorkPurpose We want to improve 	0.3147892980907352
I130 Questionnaire for USC Petitioner	Investigating Job Performance Issues Using SCOPEStudio Author: Xiaoyong ZhuSupport: Client Tools Customer SupportContentsIntroduction	2Investigating Data Skew Problem	2Confirm data skew problem via SCOPEStudio	3Whether the data skew problem 	0.3114809216079789
I130 Questionnaire for USC Petitioner	贴吧大数据存储luhongbo@baidu.com2011-8-7/31目录概述和现状设计原则pbFrs负载均衡发展方向2011-8-7/31贴吧数据概述2011-8-7/31贴吧存储现状按照功能做模块水平拆分各模块均为数据单机模式镜像抗压力2011-8-7/31设计要求和原则性能（更新、浏览）访问模式决定设计最优化内存使用有效利用磁盘特性硬盘？Flash？顺序io还是随机读写？区别对待高峰期和	0.30461311501657484

How do we train SM-CRF	How do we train SM-CRF for APN?AgendaOverviewGeneration of Lexicons (in aether)Generation of RegEx FeaturesCRF Training Pipeline (in aether)CRF Eval Pipeline (in aether)Debugging ToolsQuestions?OverviewCRF is responsible for entity e	0.5029158694745323
How do we train SM-CRF	CRF Parser AnalysisBusiness category searchOverviewParser (phonebook)CRF ParserqueryLocation featuresCRF featuresQuery parsetoken[tag] token[tag] … token[tag]userBLUbusiness_namebusiness_categorylocationlocation_separatorbu	0.22044565955143505
How do we train SM-CRF	Crawler Tech TalkOctober 14, 2008AgendaOverview of Msnbot Internal Data FlowFlow of Chunks and Chunk MetadataReal-Time MonitoringDaily Data Reporting SubsystemPrevious Instances Requiring InterventionPotential Future ProblemsQ&AMsnbot 	0.22009259301541068
How do we train SM-CRF	A Step by step guide to Creating a new Block in the DU V2 PipelineThis document will demonstrate how to create a new block, including the testing and deployment for the new DU Pipeline.  To begin, if you do not yet have a block name, please send an em	0.197960825786256
How do we train SM-CRF	FY19 Search & AI Roadmap Review: AGI for Web RankingMay 2018Dev: Chen Zhou, Saurabh TiwaryPM: Kiki Liu, Mir RosenbergMotivation“…But often time we have more problems about the subjects we are not familiar with and therefore even the keywords	0.1948342291553459
How do we train SM-CRF	SKI online feature extraction design docTo build ML model to detect user intent and re-rank search result from different providers, we need training data. This document mainly covers the design how to collect the training data from the real Office usage	0.19082706756573475
How do we train SM-CRF	Thoughts on Interest Graph – Experience, Business and TechnologyPersonalized recommendation that you don’t want to miss Author: Ting Cai Contributors: AC Surendran, Xiaodong Fan, Chuanxin Hu, Yan Ke, Tony Chor, Richard Qian1.	What is Interest Graph?	0.18871173491730395
How do we train SM-CRF	To whom it may concern,We are Xinbao Liu and Chunxiang Lei, a married couple.  We are citizens of China visiting our daughter and son-in-law in Bothell, Washington on valid US B-2 visas.  Our daughter, Jia Liu is a citizen of China residing in the Unite	0.18515053025842262
How do we train SM-CRF	Introduction to L1Xiao WuSearch Platform Tiger Team AgendaL1 goals and challengesMetrics and measurementL1 ranker and perf optimizationL1 ranking Perf optimizationDebugging tools L1 training and shippingThinking and discussionL1 	0.18468705003079933
How do we train SM-CRF	IQ Team RecapH1 2016FY16H1 AccomplishmentsTeamSSRxen-* Desktop SBSen-* Mobile SBSen-* Semantic SBSCore Web Relevance0.55/0.62.46/3.02.65/3.01.88/2.0Adult LeakageSpamJunkCQDCGMPCMALTABing@WorkSubstrate0.02/0.01	0.18390188331989715

How DUv2 Works	How DUv2 worksZehua Liu, DU GDI Team12/6/2013 Q1: How to develop a DUv2 feature?Processor + Description fileQ2: How to guarantee monthly release?Q3: Difference between the development of DUv1 and DUv2 feature?DUv1: a) ProcessorCode  	0.4601091913341507
How DUv2 Works	DU work items on zh-cn market　　Jia Liu2013-05-14AgendaSerp classifierWrapstar rating signalsTaobao, tmall; qna; novel; videoGeneral classiferUrl-basedTopic-basedPage number extractionName entity recognitionPerson, location, organiz	0.241045923649011
How DUv2 Works	Deep Dive: Query Generic Entity Extraction (GEE)Zhen Liao04/22/2016OutlineOverview of GEEFAQ for GEEArchitecture and ModelingRecent breakthrough via Deep LearningLessons we’ve learnedGeneric Entity Extraction for Queries: What is the g	0.22687377972079736
How DUv2 Works	DU items studyJia Liu2013-05-14AgendaPublication dateMain body blockDocument qualityurl static featuresPublication dateFreshness rankingYear in title, year in url, publication dateEn-us publication date coverage is ~20%Zh-cn public	0.20968332035707107
How DUv2 Works	A Step by step guide to Creating a new Block in the DU V2 PipelineThis document will demonstrate how to create a new block, including the testing and deployment for the new DU Pipeline.  To begin, if you do not yet have a block name, please send an em	0.20026168015646026
How DUv2 Works	DU Pipeline V2Bram Gruneir, Ted Wild and Connie YangDocument Understanding Dev Talk6/27/2013DU Pipeline V2: frequency demoIntroduce the demo featureDevelopmentDeploymentDU Pipeline V2: frequency demoIntroduce the demo featureDevelopmen	0.19907235797253256
How DUv2 Works	Spam/Junk Technology Review8/8/2017 Pavel KarpovichAgendaSpam/Junk OverviewReview of current system and metricsSJRE Fishtank pipelines UrlExclusion and Defect Subranker	Blue Whale Spam Types of Fresh SpamActions to Detect Fresh	0.13600988232849867
How DUv2 Works	DU feature usage summary about en-us and zh-cn prod ranker:<more detail please refer to the attached report>Basics:99 APF in en-us Ranker.47 APF in zh-cn Ranker.41 APF appear both in en-us Ranker and zh-cn Ranker. 58 APF only appear in  en-us 	0.12910921272981316
How DUv2 Works	AGI Intent EncoderGavin YingWeb Intelligence Team(Tail Ranking team)7/29/2016What is Intent EncoderGiven a text like query, question, short sentence, get a vector represent in a high dimension space. The vector should capture semantic meanin	0.12467786529691448
How DUv2 Works	Ranker Training Pipeline IntroductionAgendaPipeline OverviewGCC platformExtractionData/Feature PreparationMain Ranker TrainingSegment RankersPipeline OverviewGR OctTree: gcclinkMain Steps:Metastream injection (just info here)Querys	0.122856590894915

Home Team - Local Brown Bag	Home TeamLocal Brown Baghttp://aka.ms/gethometeam ADContactsBusiness cardsAppsEmailsWeb searchThe opportunity For consumers: Most people prefer to use referrals, or “word of mouth” Competition doesn’t embrace thisAmazon – anony	0.49322058377290046
Home Team - Local Brown Bag	QR Team ReviewJan 2017Team IntroductionConceptXDeep QRAgendaQR Team MembersDev Manager: Ciya LiaoLeads: Garrett Kaminaga, Jingwen Lu, Saekoo Lee, Gord LueckPMs: Shyam Jayasankar, Jie CaiSTC-A Speller team: Yongen Gong and his teamWha	0.26874470872689604
Home Team - Local Brown Bag	To Whom It May ConcernPage 2DATETo Whom It May Concern:Re:	Jia LiuI write to certify that Jia Liu worked as a Software Development Engineer at Microsoft (China) Company Limited (Microsoft China) in Beijing, China from March 30, 2012 to September	0.23666617277403545
Home Team - Local Brown Bag	Tiger Index BrownbagHui ShenSearch Platform Tiger TeamAgenda	OverviewKey ideasTiger architectureTiger ++ 2/24/2012Agenda	OverviewKey ideasTiger architectureTiger ++ 2/24/2012What is Tiger IndexAn new index serve technol	0.2268162173246284
Home Team - Local Brown Bag	Who Am I?Name: Jefferson WangClass: Rising CS SeniorUniversity: Georgia TechTeam: Bing Local RelevanceMentor: Supriya HarpaleManager: Jian WuProject SummaryTitle: QAS MLG Featurizer DebuggerDescription: Minimize the time it takes for a	0.20045775427273094
Home Team - Local Brown Bag	6/8/2016To Whom It May Concern:Re:	Jia LiuThis letter is to confirm that Jia Liu was employed at Microsoft (China) Company Limited in Beijing, China from March 30, 2012 to June 21, 2015.  She worked full time, 40 hours per week.  Sincerely,Xue B	0.18514290802217048
Home Team - Local Brown Bag	To Whom It May ConcernPage 2[PLEASE REMOVE THIS TEXT AND BRACKETSANDPRINT ON COMPANY LETTERHEAD]DATETo Whom It May Concern:Re:	Jia LiuI write to certify that Jia Liu worked as a Software Development Engineer at Microsoft (China) Company Li	0.16894670231196574
Home Team - Local Brown Bag	WPO Local Relevance Tech TalkWPO Local Relevance TeamOverviewWPO’s role in local relevance pipelineLocal ExperienceArchitecture overviewMetricsWPO Local Relevance Model IntroductionWPO Query understanding and Location understandingWhy do	0.16729853976603487
Home Team - Local Brown Bag	Text Latitude Longitude S0:Local_L3DCG3 G0:Local_L3DCG3 S1:Local_L3DCG3 S2:Local_L3DCG3 Assignment RootCause(BadMetastream,PartialMatch,Cal,BadKeyword,OtherQU,Ranker,BingNotStable,Scraping,Metrics,MicroSegment,JudgeNoise,Unknown,BadEntity) BTC CanBeResolv	0.15943001826335468
Home Team - Local Brown Bag	IQ Team RecapH1 2016FY16H1 AccomplishmentsTeamSSRxen-* Desktop SBSen-* Mobile SBSen-* Semantic SBSCore Web Relevance0.55/0.62.46/3.02.65/3.01.88/2.0Adult LeakageSpamJunkCQDCGMPCMALTABing@WorkSubstrate0.02/0.01	0.15286029166437684

Handbook of MLGProcessor AEthor Modules	Handbook of MLGProcessor AEther ModulesContents1.	Introduction	72.	MLGProcessor Modules	82.1.	Common Module Parameters	8Inputs	8Outputs	8Parameters	92.2.	BodySurfaceStream	9Inputs	9Outputs	92.3.	BoundaryView	9Examples	102.4.	Char	0.8113701236487887
Handbook of MLGProcessor AEthor Modules	ML Model Scorecard Analysis8/8/2019Unexpected term search movementhttps://exp.microsoft.com/xcard/?view=4e77b420-7b77-4e41-92ac-8e84f506fb01Check correctness of scorecard metric implementationCalculate term AVG rank from raw data streamsSearch	0.4709938235850313
Handbook of MLGProcessor AEthor Modules	Move SBS (Learning from L3)Xiaopeng WuJunzhou WangWhat’s L3Bing ranking stackIndex selectionWorking on offline system, target recallL1Working on IFM, target recallL2Working on IFM, target precisionL3Working on TLA, target whole pag	0.42959742264190054
Handbook of MLGProcessor AEthor Modules	Opal OSearch & XAP flight frameworkKevin Su & Duat Le06/22/2016OverviewOSearch basicsOpal OSearch high-level architectureProcess to onboard new feature for Opal OSearchXAP flight framework in OsearchOSearch basicsWhat's OSearch?A platf	0.4025071570578178
Handbook of MLGProcessor AEthor Modules	FusionByTurker KeskinpalaTuesday, May 17, 2016OverviewMotivationsWhat is Fusion?GoalsFusion ComponentsRoadmapWeb AnswerQ:“gg”Qpath1:“gg”Qpath2:“google”TLACDG FetcherL2 FetcherTLACDG FetcherL2 FetcherLL4L3L3	0.4000637200664529
Handbook of MLGProcessor AEthor Modules	Distance-Aware Local SearchZhao Zhout-zhazho@microsoft.comOutlineProject Goal and MotivationMethodologyExperimental ResultsConclusionBackgroundEntities having LatLonNew York City (40.7127,-74.0059) Facing East Restaurant (47.619905, 	0.3977328774037387
Handbook of MLGProcessor AEthor Modules	CJK RELEVANCE ALL HANDS03/06/201401Qi ASG Memo02MS Poll	03USBS MeasurementAGENDA04Win in USBSVideoEbookMemo DocWatch the VideoVideoIntroductionWho We AreOur VisionClosingDiscussion and QnA01Qi ASG Memo02	0.3954706008740273
Handbook of MLGProcessor AEthor Modules	PBA Query Understanding MigrationTetyana Golub | Ming WuMotivationPBAvnextCurrent QU logic is complicated and hard to migrateLimitation from hard coded logicCurrent QU logic is complicated and not very flexibleHard to add new feature or adju	0.39294957457734775
Handbook of MLGProcessor AEthor Modules	FY18 AGI Encoder Roadmap		Nitin Sharma, Gargi Ghosh, Saurabh TiwaryAgendaIntroductionFY18 Goals and Focus AreasFocus Area Deep DiveCustomer scenariosDetailed RoadmapAGI Encoder: MotivationGoal: One general intent encoder of source 	0.3918152486983834
Handbook of MLGProcessor AEthor Modules	DU feature usage summary about en-us and zh-cn prod ranker:<more detail please refer to the attached report>Basics:99 APF in en-us Ranker.47 APF in zh-cn Ranker.41 APF appear both in en-us Ranker and zh-cn Ranker. 58 APF only appear in  en-us 	0.3792748727988908

Google-Bing-Entity-Matching	Google-Bing Entity MatchingIn 75,563 Google scrape entities those with a non-empty name are 12,507: Mapped to Bing entities: 𝟖𝟒.𝟖𝟗% (=(10,162+455)/12,507). Missing data.Among entities in            and            1.07%(=83+51) have Lat/Lon	0.7175806876066566
Google-Bing-Entity-Matching	ID Phrase Should be removed? 1 all of y 2 bing 3 bing can you 4 bing could you 5 bing could you please 6 bing i d like to 7 bing i d like you to 8 bing i need to 9 bing i need you to 10 bing i wanna 11 bing i want to 12 bing i want you to 13 bing i would 	0.4006137474124306
Google-Bing-Entity-Matching	Bing GC Deep DiveBingGCI 9/26/2014Introduction – Pavel, 2minsProject overview – Wei, 6minsBing GC XAP workflow – John, 10minsBing GC data pipeline and data ingestion – Florin, 7minsBing GC Offline relevance platform – Jian, 8minsSingle-poi	0.39264127692784645
Google-Bing-Entity-Matching	Local Search Entity Schema for RelationShips (Entity Containment, Affinities) Short blurb of what this spec is aboutMilestone:  MagnesiumSpec StatusDraftTFS Feature IDPM/Doc OwnerSandhya GuntreddyContributors Scott, Bruno,Andrew,Prajakta	0.3882267647726671
Google-Bing-Entity-Matching	Bing Local Search				PBA Geo Location Feeds augmentation generation Dev ownerTetyana GolubBuddy dev(s)PM ownerDave BargeronContributorsFeature areaPBA Feeds query generationMilestoneAluminumTable of contents1	Overview	22	Goal	0.35752937915250094
Google-Bing-Entity-Matching	Bing Local Search				Phonebook vNext Design DocumentDev ownerMickadBuddy dev(s)MichstePM ownerDabargerContributorsFeature areaMilestoneTable of contents1	Overview	32	Goals/Non Goals	53	Dependencies	64	Risks/Open Issues	75	0.3396424389332037
Google-Bing-Entity-Matching	CAL MultiQuery {Matching\Ranking}		Page 3 of 4CAL MultiQuery {Matching\Ranking}DescriptionCAL is going to optimize against matching\ranking separately and will issue different queries to each tier. CAL will be leveraging several operator such as:m	0.32863084133801657
Google-Bing-Entity-Matching	Run web-search-like query against my dataSame Bing Web Search Indexing and Ranking engineIndex in a secondTransparent and real time index sync, no complex index-gen pipelinePrototype in an hourFast self-onboarding with freemium account, schema-d	0.29628378410488104
Google-Bing-Entity-Matching	Bing Local Functional DetailsDocument StatusDate Created6/25/2013Last Updated2/28/2014Current StatusDraft Key StakeholdersProgram ManagementDany Daher; Tony Angell; Sumitra Sheth; Product ManagementTBD;Executive SponsorsEric Ca	0.2828829889465482
Google-Bing-Entity-Matching	Bing Local Search				PBA QU Post-processing in QAS Dev ownerMing WuBuddy dev(s)PM ownerContributorsFeature areaPBA Query ProcessingMilestoneAluminumTable of contents1	Overview	22	Goals/Non Goals	23	Risks/Open Issues	24	Desi	0.2772015502745838

Google Mobile vs Desktop RankDiff Study	Google Mobile vs Desktop RankDiff StudyNov 2017GoalsUnderstand what Google does differently on Mobile, if anythingDrive product ideas & shape ranking improvements on MobileUnderstand any possible impact to Algo scrapes & metricsDrive scrapin	0.8574286859212642
Google Mobile vs Desktop RankDiff Study	Deal Understanding and RankingBackgroundDeal is a very big segment in Bing Opal. We crawl store and single deals/coupons regularly from websites like groupon.com, coupons.com, restaurants.com, retailmenot.com, dealcatcher.com, dealplus.com and so on. 	0.4189782590416101
Google Mobile vs Desktop RankDiff Study	Deal Ranking Improvement & MeasurementBackgroundAfter we shipped deal understanding, bad deals filtering, deal ranking for the entity search deals and popular deals nearby. We want to measure and improve our deal ranking based on user behaviors. We ca	0.4107365025568378
Google Mobile vs Desktop RankDiff Study	Mobile 100k Compete Data analysis with G - Simulation Report6/6/2014Mobile Simulation AnalysisThis analysis compares Google and Bing on iOS for 3 querysets.REPORTS GENERATED FOR **: Overall Metrics Coverage (WP, ML and Bot)IY (WP, ML and Bot	0.3939860628025855
Google Mobile vs Desktop RankDiff Study	CAL MultiQuery {Matching\Ranking}		Page 3 of 4CAL MultiQuery {Matching\Ranking}DescriptionCAL is going to optimize against matching\ranking separately and will issue different queries to each tier. CAL will be leveraging several operator such as:m	0.3544487853246703
Google Mobile vs Desktop RankDiff Study	Tmall&Taobao Rating MetawordsBackgroundWe’ve seen in regular DSAT review meetings the DSATs that we rank too high Tmall or Taobao page with low quality(Tmall page:low sales volume; Taobao page: low sales volume or shop with poor reputation).  Zh-CN ha	0.3366800291280681
Google Mobile vs Desktop RankDiff Study	Wrapstar rating signalsfor zh-cn documentsJia LiuWrapstar rating signals for rankingWrapstar Taobao ratingWrapstar Tmall ratingWrapstar Qna ratingWrapstar Book ratingWrapstar Video ratingDsats examplesTaobao examplesQuery=“蓝色休闲裤	淘宝”	0.3150239625769381
Google Mobile vs Desktop RankDiff Study	FastRank--- a Decision-Tree based Ranking ModelYu SHIOutlineBackgroundAlgorithm overviewTraining implementationExperimentationChallengesReferencesBackgroundInvestigated by MSR in OsloShipped with July Tree 2010 (Denver)GoalsSpe	0.3120853291914525
Google Mobile vs Desktop RankDiff Study	Deal Ranking ImprovementsDeal Understanding ImprovementsGoal: Increase general deal coverage (deal product type from specific to general).Solution: Identify the prefix and suffix of title by punctuations and prep. Remove the prefix and suffix from t	0.3076709722847104
Google Mobile vs Desktop RankDiff Study	CosmosSearch RESTful APIsWe now provide the cosmos search REST APIs to enable users to get more insights of their historical SCOPE jobs. This document walks through the basic steps to try out this API.If you have any questions for this document or wan	0.29234496895275364

GoldenQuery-sessionv1-allurls	GoldenQuery: Past Flights v1Session v1Nov, 2013Simple Explanation of GoldenQueryQuery level Explore & ExploitExplore against techniqueMemorization basedGQ service running before speller, intercept every queryContinues E&E{Microsoft off	0.6126633335104117
GoldenQuery-sessionv1-allurls	Golden QueryEvery query countsImprove relevance: Relevance TechniquesWin/Loss basedGood technique has better win/loss ratioGeneric Ranker always doesn’t have good win/loss ratioWe do technique triage, and better win/loss ratio technique got sh	0.40167440108141006
GoldenQuery-sessionv1-allurls	SPAM & JunkSi Planning Cheng Niu, Alex Rahin6/18/2014Agenda	Focus AreasMetricsSPAM/Junk Metrics BreakdownData Analysis and Project DefinitionFocus AreasImprove SPAM Detection (~35% of team bandwidth)Stolen ContentContent Keyword St	0.36411298975268763
GoldenQuery-sessionv1-allurls	Bing Adult FilteringNeil ZhaoSmart adult filtering GloabelSmartAdultFiltering=offSmartAdultFiltering=onStrict-category:ff000001tla:adultfilter:onModerateprefer:-category:ff000001tla:adultfilter:smartOff tla:adultfilter:off ZH	0.33190101375263065
GoldenQuery-sessionv1-allurls	FY19 Search & AI Roadmap Review: Intelligent QnAMay 2018PM: Ali Alvi, Kaan Ozel, Ganga Venkatasubramanian, Oana NicolovDev: Xia Song, Doran ChakrabortyAgendaOverall QnA Opportunity and GoalsSemi-Structured DataMALTATuring for QnAAGI En	0.32903649290525355
GoldenQuery-sessionv1-allurls	Domain Authority CAL One PageIntroductionCurrent shipped ngram domain authority in L3 is using complete query match against an offline generated meta-stream (q, url, score), which derives (q,url) pairs from click stream and is the result of aggregatio	0.3200948752043195
GoldenQuery-sessionv1-allurls	Local Junk Detection and DemotionJia Liu2017-06-14GDP Pipeline View: local data pipelineTriple StoreGOALStore every entity as a set of triples.Track all changes to an entity.TripleColumnDetailsSubjectThe guid of a triple’s pa	0.31358115747793613
GoldenQuery-sessionv1-allurls	Run web-search-like query against my dataSame Bing Web Search Indexing and Ranking engineIndex in a secondTransparent and real time index sync, no complex index-gen pipelinePrototype in an hourFast self-onboarding with freemium account, schema-d	0.30963385794734155
GoldenQuery-sessionv1-allurls	Leveraging Satori Knowledge in Web Ranking StackMicroSegment and Index ServeMotivationTarget at semantic queries (*defined by MALTA)Often contain more than one entity and relationSometimes involve entity inferenceTerm matching may not handle s	0.30876209021634665
GoldenQuery-sessionv1-allurls	Abacus Query Pattern SpecThis document describes how the query GEE pattern is passing from CAL into PDR, and generate a series of features depending on the <querypattern, URL-host> level matching. Query Property of GEEHere is the query property defi	0.3081065716208856

GoldenQuery-SessionFeature	GoldenQuery: Past Flights v1Session v1Nov, 2013Simple Explanation of GoldenQueryQuery level Explore & ExploitExplore against techniqueMemorization basedGQ service running before speller, intercept every queryContinues E&E{Microsoft off	0.6267597949597308
GoldenQuery-SessionFeature	Golden QueryEvery query countsImprove relevance: Relevance TechniquesWin/Loss basedGood technique has better win/loss ratioGeneric Ranker always doesn’t have good win/loss ratioWe do technique triage, and better win/loss ratio technique got sh	0.41003976956855354
GoldenQuery-SessionFeature	Leveraging Satori Knowledge in Web Ranking StackMicroSegment and Index ServeMotivationTarget at semantic queries (*defined by MALTA)Often contain more than one entity and relationSometimes involve entity inferenceTerm matching may not handle s	0.38435637348854923
GoldenQuery-SessionFeature	Local Search Platform PM Onboarding GuideAuthors: Dany DaherDate: 10/18/2013Architecture OverviewHow Local Search Works Local Data Platform Architecture MetricsLocal Metrics:  http://jeffke/localMetrics/Definition of QLDCG: Local Discoun	0.3673089915693552
GoldenQuery-SessionFeature	Run web-search-like query against my dataSame Bing Web Search Indexing and Ranking engineIndex in a secondTransparent and real time index sync, no complex index-gen pipelinePrototype in an hourFast self-onboarding with freemium account, schema-d	0.3330148454989685
GoldenQuery-SessionFeature	Restaurants Features and ToolsReview SnippetXAPOSearchQueryWPOLERWPO OSCacheItemCacheIdList of YpIdsFiltersSorterEntityUpdate PostFixEntity Update OSCache IdCache ItemYpId and PostFixUXReview Snippet Data GroupCac	0.33147130682356085
GoldenQuery-SessionFeature	Bing Local Search				PBA Geo Location Feeds augmentation generation Dev ownerTetyana GolubBuddy dev(s)PM ownerDave BargeronContributorsFeature areaPBA Feeds query generationMilestoneAluminumTable of contents1	Overview	22	Goal	0.3278429411709633
GoldenQuery-SessionFeature	Global relevance feature proposalFeature name: Title Match OptimizationPMJin GuoDevJia LiuTestReleaseALTeam site linkExecutive SummaryTitle is the summary/abstract of the document. Title Match is very important to SBS. Through many c	0.32776994641417057
GoldenQuery-SessionFeature	Index Quality UpdateAgendaMetrics UpdateSelection Model ImprovementRecall TierOffice ImprovementChallenges and Pain PointsHow to measure index quality?Ideally: sampling from all “good” images and see how much we covered.sampling from a	0.3184636861954658
GoldenQuery-SessionFeature	Debug Address Queries8/23/2013Bing Local Search RelevanceNTCG MetricsDocumentationhttps://microsoft-my.sharepoint.com/personal/aoakley_microsoft_com/Documents/2013/2013-05-22%20Maps%20metrics%20Qi.pptx?web=1Use it to identify the group of quer	0.3112953017664631

Golden Query	Golden QueryEvery query countsImprove relevance: Relevance TechniquesWin/Loss basedGood technique has better win/loss ratioGeneric Ranker always doesn’t have good win/loss ratioWe do technique triage, and better win/loss ratio technique got sh	0.5337457934026262
Golden Query	GoldenQuery: Past Flights v1Session v1Nov, 2013Simple Explanation of GoldenQueryQuery level Explore & ExploitExplore against techniqueMemorization basedGQ service running before speller, intercept every queryContinues E&E{Microsoft off	0.38599190959321505
Golden Query	Abacus Query Pattern SpecThis document describes how the query GEE pattern is passing from CAL into PDR, and generate a series of features depending on the <querypattern, URL-host> level matching. Query Property of GEEHere is the query property defi	0.2436580111775793
Golden Query	Debug Address Queries8/23/2013Bing Local Search RelevanceNTCG MetricsDocumentationhttps://microsoft-my.sharepoint.com/personal/aoakley_microsoft_com/Documents/2013/2013-05-22%20Maps%20metrics%20Qi.pptx?web=1Use it to identify the group of quer	0.21557179267297136
Golden Query	Run web-search-like query against my dataSame Bing Web Search Indexing and Ranking engineIndex in a secondTransparent and real time index sync, no complex index-gen pipelinePrototype in an hourFast self-onboarding with freemium account, schema-d	0.20683503978004628
Golden Query	Successful Feeds Query DebuggingNikita Melnichenko, 2015-03-10Feeds query debugging overviewWhen to use:Checking a new rankerChecking new augmentation before running a scrapeComparing several rankersUnderstanding feature contributionDebugg	0.20603816321858426
Golden Query	Local Relevance SQR (en-us + en-ca)March 14, 2017AgendaContext & Scope:EN-US & EN-CA, Mobile and SERP relevance focusedPBA (pre-web) relevance focusedQuality measurements DSAT examplesGeneral issuesKey Segments (Restaurants, Hotels, Re	0.2039404555848673
Golden Query	Tiger Index BrownbagHui ShenSearch Platform Tiger TeamAgenda	OverviewKey ideasTiger architectureTiger ++ 2/24/2012Agenda	OverviewKey ideasTiger architectureTiger ++ 2/24/2012What is Tiger IndexAn new index serve technol	0.19810740555301873
Golden Query	query分类—分享                     刘佳2011.6.8web query classification(query分类):	将web search query根据它的主题，分派到1个或者多个预先定义的分类中。web search query的特征：有噪声：拼写错误等长度很短：信息量少，特征少表意含糊：query可能包含多个含义,属于多个分类含义会随时间演变目标分类的特征：目标分类定义缺少语义注解一级或者多级分类分类数目：几	0.19538827713010362
Golden Query	SPAM & JunkSi Planning Cheng Niu, Alex Rahin6/18/2014Agenda	Focus AreasMetricsSPAM/Junk Metrics BreakdownData Analysis and Project DefinitionFocus AreasImprove SPAM Detection (~35% of team bandwidth)Stolen ContentContent Keyword St	0.19212697419926322

Global CAL Aluminum Plan	Global CAL Aluminum PlanJunfeng ZhouAgendaMagnesium StatusAluminum FocusProjectsMagnesium Status - ReleasesJuly: aggressive relaxation on no result queriesSept: relax count classifier, morphological alterationsOct: JO v1Nov: morphologi	0.5325829799558556
Global CAL Aluminum Plan	Local Category Search Plan3 month StrategyData: Entity categorizationScalable, high precision/recallSegments: Food & Drink, Retail, Service, Auto, HotelMetaStream enrichmentQuery UnderstandingDolphin by defaultConsume PhoneBookQU to im	0.3585943119804066
Global CAL Aluminum Plan	Bitext Alignment for Alteration Candidate GenerationJan 2018Alteration BasicsCAL alteration architecture is a big funnelCurrent mouth of the funnel is the altlist – a non-context-sensitive relation of <source, target, score>Built over time, qu	0.3491047989572565
Global CAL Aluminum Plan	alterationsalterations: product goalimprove recallby adding terms (not replacing or dropping user-entered terms)using word:which are synonyms to the original terms(we are re-examining each of these for vnext)alterations: general principl	0.2937423913037486
Global CAL Aluminum Plan	CNTK Junk Classifier PrototypeAnton Savin and Gilbert Wong6/3/2016Overall Plan and PrioritiesLearn Deep Learning and Neural NetworkLearn CNTK (Computational Network Toolkit) by walking through the examplesBuild a junk classifier using CNTKEv	0.28902047798236674
Global CAL Aluminum Plan	Cosmos Scope Aluminum M3 Release Announcement Cosmos Scope Aluminum M3 ReleaseThis and previous announcements are stored here.Code Samples can be found at http://aka.ms/CosmosCodeSamplesYou can find information about using Beta SDKs in this docu	0.28108611674388034
Global CAL Aluminum Plan	CAL MultiQuery {Matching\Ranking}		Page 3 of 4CAL MultiQuery {Matching\Ranking}DescriptionCAL is going to optimize against matching\ranking separately and will issue different queries to each tier. CAL will be leveraging several operator such as:m	0.2578498966301278
Global CAL Aluminum Plan	Combined ALterationsNeon\sodiumAgendaNeon AchievementsBreakdownsSodiumIdeas & PlanNeonOverall ProgressExceeded Neon Commitments on CQS!NeonCQS Deep-dive-34% Bad+14% Excellent-15% Bad+13% ExcellentDRDOCQS is impr	0.25644233182199067
Global CAL Aluminum Plan	Phrasal Alterations & CAL Infra 		Page 2 of 2Phrasal Alterations & CAL Infra DescriptionPhrasal Alterations is going to add CAL the functionality of doing N-to-M alterations. Given a query, CAL is going to generate multiple candidate queries without	0.24520451722294104
Global CAL Aluminum Plan	FastRank--- a Decision-Tree based Ranking ModelYu SHIOutlineBackgroundAlgorithm overviewTraining implementationExperimentationChallengesReferencesBackgroundInvestigated by MSR in OsloShipped with July Tree 2010 (Denver)GoalsSpe	0.23633519077583764

Generic Entity Extraction in Sodium	Generic Entity Extraction in Sodium Owner: Chuanxin HuContributors: Kang Li, Yi LiOverviewThe understanding of entities and their relationship is a one of the key pillars supporting the Bing’s strategic bet on the knowledge graph. Today, Satori ca	0.6190104389675101
Generic Entity Extraction in Sodium	Deep Dive: Query Generic Entity Extraction (GEE)Zhen Liao04/22/2016OutlineOverview of GEEFAQ for GEEArchitecture and ModelingRecent breakthrough via Deep LearningLessons we’ve learnedGeneric Entity Extraction for Queries: What is the g	0.4228186412832419
Generic Entity Extraction in Sodium	DU Pipeline Sodium Achievements And Magnesium Plans　　Jia Liu2013-08-05OutlineSodium AchievementsMagnesium PlanMagnesium Work ItemsSodium Work ItemsAppendixSodium AchievementsWrapstar rating signalsTaobao, tmall; qna; novel; videoL3	0.34918880171109207
Generic Entity Extraction in Sodium	Relevance Experimentation with DUOverviewThe ideal end state for any relevance improvement would consist of having one or more DU features shipped in the index that is then leveraged by the latest production ranker. This would achieve the highest leve	0.3416955964753364
Generic Entity Extraction in Sodium	Relevance Debug InfrastructureProblemFrequent  daily metric fluctuationRelevance gain negated by regressions from Sep to Oct 2013Painful to investigateChallengeLocal stack is complex with lots of componentsVarious relevance events mixed toge	0.3406377420407811
Generic Entity Extraction in Sodium	Entity Pane and Fact AnswerPresenter: Ze TianJun 25, 2013IntroductionIntroductionIntroductionProblems to SolveDoes the user search for entities or facts of entities?E.g. “who is msft ceo” (Entity: Microsoft, Fact: Chief Executive O	0.3236362164138341
Generic Entity Extraction in Sodium	Pattern Based Term Weight FrameworkIntroductionPattern based term weight recognizes the importance for part of terms or all the terms based on patterns/templates/knowledge. There are 2 differences between general and pattern based term weight.Compar	0.32317494529605423
Generic Entity Extraction in Sodium	Fast Brain – Memorization & InferenceQuery based memorization and inferenceLarge Memorization -  1B queries, clicks (Q-D) and moreDeep Brain100 - 200B Doc/Page IndexRecall, Tail and Scalability focusedLess dependency on popularity signalHeur	0.31226308890595106
Generic Entity Extraction in Sodium	Abacus Query Pattern SpecThis document describes how the query GEE pattern is passing from CAL into PDR, and generate a series of features depending on the <querypattern, URL-host> level matching. Query Property of GEEHere is the query property defi	0.30557254383291865
Generic Entity Extraction in Sodium	Local Search Entity Schema for RelationShips (Entity Containment, Affinities) Short blurb of what this spec is aboutMilestone:  MagnesiumSpec StatusDraftTFS Feature IDPM/Doc OwnerSandhya GuntreddyContributors Scott, Bruno,Andrew,Prajakta	0.30264423998882434

GQR-CAL-RoadmapFY13-GDI	CAL Problem, Vision and RoadmapContentsOverview	2Problem of today’s CAL	2Vision and Roadmap	3Start from simple but important one: infrastructure.	3Now comes core problem: Metrics	3Now comes to the interesting part: context	4Data	5Head qu	0.6119907902299976
GQR-CAL-RoadmapFY13-GDI	FY19 Search & AI Roadmap Review: AGI for Web RankingMay 2018Dev: Chen Zhou, Saurabh TiwaryPM: Kiki Liu, Mir RosenbergMotivation“…But often time we have more problems about the subjects we are not familiar with and therefore even the keywords	0.4432460122620792
GQR-CAL-RoadmapFY13-GDI	Text Latitude Longitude S0:Local_L3DCG3 G0:Local_L3DCG3 S1:Local_L3DCG3 S2:Local_L3DCG3 Assignment RootCause(BadMetastream,PartialMatch,Cal,BadKeyword,OtherQU,Ranker,BingNotStable,Scraping,Metrics,MicroSegment,JudgeNoise,Unknown,BadEntity) BTC CanBeResolv	0.40619635483993083
GQR-CAL-RoadmapFY13-GDI	CALQuery alterationAgendaRoadmap and VisionWhere are weWhere to goPlanHow to get thereProgress and looking aheadSodium so farMagnesium and beyondDeep DiveGolden QueryRoadmap & VisionWhere are weCurrent status/problem of CAL	0.39101964559039915
GQR-CAL-RoadmapFY13-GDI	AGI - Web Search / Tail FY18 Roadmap 	Rohit Kapoor, Saurabh Tiwary, Gargi Ghosh, Chen Zhou,  Kushal LakhotiaFY17 RecapFY18 GoalsFY18 Focus AreasFY18 TimelineFocus Area Deep DivesAgendaFY17 RecapIn-Progress:[Fusion] Out of market [F	0.3869168086323759
GQR-CAL-RoadmapFY13-GDI	FY19 Search & AI Roadmap Review: QRMay 2018Jie Cai, Garrett Kaminaga, Jingwen Lu, Momo JengMotivation – QR Query understanding and rewrite is the first opportunity for Bing to understand users’ intents;In current production, query rewrite is a	0.38198460589678374
GQR-CAL-RoadmapFY13-GDI	CRF Parser AnalysisBusiness category searchOverviewParser (phonebook)CRF ParserqueryLocation featuresCRF featuresQuery parsetoken[tag] token[tag] … token[tag]userBLUbusiness_namebusiness_categorylocationlocation_separatorbu	0.3699247466735164
GQR-CAL-RoadmapFY13-GDI	Local Category Search Plan3 month StrategyData: Entity categorizationScalable, high precision/recallSegments: Food & Drink, Retail, Service, Auto, HotelMetaStream enrichmentQuery UnderstandingDolphin by defaultConsume PhoneBookQU to im	0.3646523998467447
GQR-CAL-RoadmapFY13-GDI	IQ Team RecapH1 2016FY16H1 AccomplishmentsTeamSSRxen-* Desktop SBSen-* Mobile SBSen-* Semantic SBSCore Web Relevance0.55/0.62.46/3.02.65/3.01.88/2.0Adult LeakageSpamJunkCQDCGMPCMALTABing@WorkSubstrate0.02/0.01	0.35255055747045216
GQR-CAL-RoadmapFY13-GDI	Local DCG11/02/2012AgendaGoals of Local DCGHow Local DCG is calculatedComparison of Local DCG versus sNDCGOperationalization for scalePlan for international rolloutPlan for Local DCG enhancementsGoals of Local DCGGoalsActions take to	0.35226229729314806

GEE-relevance-dev-talk-20160422	Global relevance feature proposalFeature name: Title Match OptimizationPMJin GuoDevJia LiuTestReleaseALTeam site linkExecutive SummaryTitle is the summary/abstract of the document. Title Match is very important to SBS. Through many c	0.4362490327461953
GEE-relevance-dev-talk-20160422	WPO Local Relevance Tech TalkWPO Local Relevance TeamOverviewWPO’s role in local relevance pipelineLocal ExperienceArchitecture overviewMetricsWPO Local Relevance Model IntroductionWPO Query understanding and Location understandingWhy do	0.43139399310006427
GEE-relevance-dev-talk-20160422	Whole Page RelevanceShip Meeting 08/14/2012AgendaSummary of IssuesSpecial TopicsWhole Page Relevance - IssuesTeamIssue Description StatusOwnerDue Action UpdateINTL Mon-GsheldonNo major issuesCaptions MetricsSBS – Monthly 	0.4031934578241666
GEE-relevance-dev-talk-20160422	WPO Local RelevancePing Yin2017-03-21OverviewWPO’s role in local relevance pipelineLocal Entity StampingArchitecture overviewWPO Local Relevance Models.Query: exton mall, User location: Wallingford, PAWPO RolesExtract/detect all entity	0.40255215087976226
GEE-relevance-dev-talk-20160422	Deep Dive: Query Generic Entity Extraction (GEE)Zhen Liao04/22/2016OutlineOverview of GEEFAQ for GEEArchitecture and ModelingRecent breakthrough via Deep LearningLessons we’ve learnedGeneric Entity Extraction for Queries: What is the g	0.397182818057482
GEE-relevance-dev-talk-20160422	BLU V3 Minghua Zhang      01/26/2016Next version of BLU Relevance Infrastructure​OutlineWhy BLU v3BLU v3 DesignCurrent StatusFuture WorkWhy BLU v3 (1)Limitations of current BLU infrastructureFeaturesCouldn’t utilize QAS feature	0.39127815451497033
GEE-relevance-dev-talk-20160422	Successful Feeds Query DebuggingNikita Melnichenko, 2015-03-10Feeds query debugging overviewWhen to use:Checking a new rankerChecking new augmentation before running a scrapeComparing several rankersUnderstanding feature contributionDebugg	0.3909846798172557
GEE-relevance-dev-talk-20160422	Relevance Experimentation with DUOverviewThe ideal end state for any relevance improvement would consist of having one or more DU features shipped in the index that is then leveraged by the latest production ranker. This would achieve the highest leve	0.3902098857741578
GEE-relevance-dev-talk-20160422	Relevance Debug InfrastructureProblemFrequent  daily metric fluctuationRelevance gain negated by regressions from Sep to Oct 2013Painful to investigateChallengeLocal stack is complex with lots of componentsVarious relevance events mixed toge	0.38805991935632206
GEE-relevance-dev-talk-20160422	File Relevance Experimentation Design DocRecall AnalysisTest the search quality of external services like OLS, 3S, QF and SPO Search.Search scenarios: 0-term search, term search, 3S (Insert File and Attach File).Compare the recall: diff of returne	0.3743519695610096

Fusion_Roadmap-PM Meeting	CAL Problem, Vision and RoadmapContentsOverview	2Problem of today’s CAL	2Vision and Roadmap	3Start from simple but important one: infrastructure.	3Now comes core problem: Metrics	3Now comes to the interesting part: context	4Data	5Head qu	0.5200299884578738
Fusion_Roadmap-PM Meeting	FusionByTurker KeskinpalaTuesday, May 17, 2016OverviewMotivationsWhat is Fusion?GoalsFusion ComponentsRoadmapWeb AnswerQ:“gg”Qpath1:“gg”Qpath2:“google”TLACDG FetcherL2 FetcherTLACDG FetcherL2 FetcherLL4L3L3	0.46492039586055944
Fusion_Roadmap-PM Meeting	Relevance and AIBing and Information Platform GroupFY18 AGI Encoder RoadmapFeature OwnersProgram ManagersNitin SharmaDevelopersSaurabh Tiwary, Gargi GhoshResearchersMarketingPartnersYantao Li, Weihu, GuihongOverviewAGI Encoder go	0.4452553419534135
Fusion_Roadmap-PM Meeting	FY19 Search & AI Roadmap Review: AGI for Web RankingMay 2018Dev: Chen Zhou, Saurabh TiwaryPM: Kiki Liu, Mir RosenbergMotivation“…But often time we have more problems about the subjects we are not familiar with and therefore even the keywords	0.42413622515779015
Fusion_Roadmap-PM Meeting	AGI - Web Search / Tail FY18 Roadmap 	Rohit Kapoor, Saurabh Tiwary, Gargi Ghosh, Chen Zhou,  Kushal LakhotiaFY17 RecapFY18 GoalsFY18 Focus AreasFY18 TimelineFocus Area Deep DivesAgendaFY17 RecapIn-Progress:[Fusion] Out of market [F	0.42339091267720985
Fusion_Roadmap-PM Meeting	FY19 Search & AI Roadmap Review: QRMay 2018Jie Cai, Garrett Kaminaga, Jingwen Lu, Momo JengMotivation – QR Query understanding and rewrite is the first opportunity for Bing to understand users’ intents;In current production, query rewrite is a	0.39530820498595015
Fusion_Roadmap-PM Meeting	 Core Web RelevanceInformation Platform GroupBing Spam & JunkFeature OwnersProgram ManagersMichael AbboudDevelopersPavel Karpovich, Lidong Zhao, Gregory Minasyants, Ashok Ponnuswami,  Eugene Remizov, Mikhail BorbotDev ManagerLuke ChenM	0.3736599447099943
Fusion_Roadmap-PM Meeting	Bing Local Search				PBA Geo Location Feeds augmentation generation Dev ownerTetyana GolubBuddy dev(s)PM ownerDave BargeronContributorsFeature areaPBA Feeds query generationMilestoneAluminumTable of contents1	Overview	22	Goal	0.3730762854324867
Fusion_Roadmap-PM Meeting	Local DCG11/02/2012AgendaGoals of Local DCGHow Local DCG is calculatedComparison of Local DCG versus sNDCGOperationalization for scalePlan for international rolloutPlan for Local DCG enhancementsGoals of Local DCGGoalsActions take to	0.35877073452225405
Fusion_Roadmap-PM Meeting	PBAVnext and migrationFrank ZhangBenefit of vnextIt will reflect five years’ worth of local search relevance insights and lessons learned, including the relevance tuning principles we have discovered over the years.It will make it easier to suppor	0.3504695574982838

Fusion Update with David Ku	FusionByTurker KeskinpalaTuesday, May 17, 2016OverviewMotivationsWhat is Fusion?GoalsFusion ComponentsRoadmapWeb AnswerQ:“gg”Qpath1:“gg”Qpath2:“google”TLACDG FetcherL2 FetcherTLACDG FetcherL2 FetcherLL4L3L3	0.4733715586117712
Fusion Update with David Ku	The Data Skew ProblemFei Xu2/27/2018The Scheduled TalksMarch 18th Dave Maltz – OSD future network March 25th Pat – TBD April 1st Pat – TBDApril 8th Brad – Terasort in 12 minutesApril 15th Eric – The Global Scheduler April 22nd Brian – 	0.4281520168620125
Fusion Update with David Ku	Mobile LT Discussion6/20/2014AgendaTop IssuesAd Product and Ad Quality UpdateSummarized Finding NDT Supply AnalysisSummarized Finding Google CompeteStatusFeatureWindows phoneIphone/AndroidUp to 2 adsShipped 5/20/2014Shipped more 	0.40884341252764705
Fusion Update with David Ku	Satori Introduction2012-09-20  yukaihAgendaOverviewMajor ModulesIngestionConflationServingGet Started in Local BoxUseful linksAppendix: Satori Local PipelineOverview - SatoriMission: build the largest, freshest, and most accurate E	0.3912526265603063
Fusion Update with David Ku	1/29 AGI ReviewAttendees: Harry Shum, Yi-Min Wang, David Ku, Steven Yao, Jianfeng Gao, Saurabh Tiwary, JJ Liu, Mir RosenbergTask Oriented Dialog AgentsJianfengShare the “Hail Caesar” slide (rule-based vs. RL dialog)Write what we discussed on Cor	0.3822169543469687
Fusion Update with David Ku	GoldenQuery: Past Flights v1Session v1Nov, 2013Simple Explanation of GoldenQueryQuery level Explore & ExploitExplore against techniqueMemorization basedGQ service running before speller, intercept every queryContinues E&E{Microsoft off	0.374674768729494
Fusion Update with David Ku	Relevance and AIBing and Information Platform GroupFY18 AGI Encoder RoadmapFeature OwnersProgram ManagersNitin SharmaDevelopersSaurabh Tiwary, Gargi GhoshResearchersMarketingPartnersYantao Li, Weihu, GuihongOverviewAGI Encoder go	0.37352166325003533
Fusion Update with David Ku	LDCG V3Knowledge Transfer2017-04-14Brett Clippingdale, Sean King, Vikas Mittal, Li JiangLDCG V3 OutlineLDCG V2 vs V3: High-level comparisonLDCG V3: New distance ModelV2 vs V3 OverviewLDCG V3: GeoIntent HIT appLDCG V3: Calculate distance 	0.3730113951293562
Fusion Update with David Ku	Dynamic ConflationGanesh Poomal Girirajan  Kefeng                                                    Qiang WuAcknowledgementsChiping Tang: Helped us get the UPDR judgments for Training and Evaluation.Shital Shah, Aamer Mohammed: Helped us stam	0.3609721392228586
Fusion Update with David Ku	Daniel Bernhardt, STC Europe, danber@microsoft.comFeed ExplorerQuick Start GuideIntroductionFeedExplorer is a tool for exploring the Provider Feeds and Master Trees for MSN/Bing Local Search. The current capabilities of the tool include:Suppor	0.3591781836372316

Fusion Deep Dive with Steven 1-6-2017	Fusion: Next Gen Web IntelligenceDeep Dive with Steven 1/6/2017Goals:Power Bing & Bing Next with web open knowledgeNew post L2 ranking platformImproved agility and scalabilityInherent MQ + contextual capability Integrated ranking process: 	0.46197836364192313
Fusion Deep Dive with Steven 1-6-2017	A Step by step guide to Creating a new Block in the DU V2 PipelineThis document will demonstrate how to create a new block, including the testing and deployment for the new DU Pipeline.  To begin, if you do not yet have a block name, please send an em	0.43856621595825035
Fusion Deep Dive with Steven 1-6-2017	Query Simplification Deep DiveJON Fu12/11/2017AgendaQuery Simplification Motivation and TheoryQuery Simplification for WebQuery Simplification for Cortana 3ARecent Progress in Query Simplification WorkReferencesIntroductionMotiva	0.41480833780451887
Fusion Deep Dive with Steven 1-6-2017	TermX Deep Dive	Gord Lueck 2015.09.22ContributorsSaekoo LeeGarrett KaminagaJunfeng ZhouAsad MohuiddinKaan OzelGord LueckCiya LiaoCAL Alteration SystemsCoreCAL is the query rewriting engine for bingCustomers:  Bing Web, Ads, Local	0.40838403621611025
Fusion Deep Dive with Steven 1-6-2017	FusionByTurker KeskinpalaTuesday, May 17, 2016OverviewMotivationsWhat is Fusion?GoalsFusion ComponentsRoadmapWeb AnswerQ:“gg”Qpath1:“gg”Qpath2:“google”TLACDG FetcherL2 FetcherTLACDG FetcherL2 FetcherLL4L3L3	0.40468946915678855
Fusion Deep Dive with Steven 1-6-2017	Deep Dive: Query Generic Entity Extraction (GEE)Zhen Liao04/22/2016OutlineOverview of GEEFAQ for GEEArchitecture and ModelingRecent breakthrough via Deep LearningLessons we’ve learnedGeneric Entity Extraction for Queries: What is the g	0.3836567455573211
Fusion Deep Dive with Steven 1-6-2017	QU Deep Dive 2: Query Simplification and Recurrent Neural NetworkXiaolong Li (Lead of QU Fundamentals TEAM)2/12/2015AgendaQUFun Team ResponsibilitiesRecent Deliverables Query Simplification for WebQuery Simplification for Cortana 3ARec	0.38356221198068025
Fusion Deep Dive with Steven 1-6-2017	L4 Experiment PipelineDate: Aug 20th, 2013Author: Bangyong LiangMotivation:L4’s functionality is to merge results from multiple queries. L4 has two types of merging strategies. One is query level merger and the other one is document level merger. 	0.37889747961556847
Fusion Deep Dive with Steven 1-6-2017	NTCG DebuggingSteven Zittrower01/30/2015AgendaNTCGNTCG DashboardOverview of BLU Architecture (Address Specific)Address Debugging in QATNTCGNTCG (Normalized Total Cumulative Gain) is a composite metric that measures address query releva	0.37874085946019
Fusion Deep Dive with Steven 1-6-2017	cal deepdiverelaxationdec 2017AgendaProduct GoalsQuery SimplificationMechanism/RuntimeCRF Model TrainingQS Path SelectionOffline SimulatorSmart RelaxMechanism & TrainingRelaxation: ImpactRelaxation: Product goalsImprove Rec	0.37803931856376477

Find Deals with Opal	Find Deals with OpalKelly You, Jia Liu, Leon Zhang7/11/2016AGENDAScenariosTechniques & ChallengesNext StepsQ&AScenariosSearch Store DealsBrowse Nearby DealsFilter Restaurants with DealsDeal Action in Entity Detail CardTechniques 	0.3566475780041462
Find Deals with Opal	Deal Understanding and RankingBackgroundDeal is a very big segment in Bing Opal. We crawl store and single deals/coupons regularly from websites like groupon.com, coupons.com, restaurants.com, retailmenot.com, dealcatcher.com, dealplus.com and so on. 	0.336446073456213
Find Deals with Opal	Deal Ranking Improvement & MeasurementBackgroundAfter we shipped deal understanding, bad deals filtering, deal ranking for the entity search deals and popular deals nearby. We want to measure and improve our deal ranking based on user behaviors. We ca	0.27852019684468954
Find Deals with Opal	Deal Ranking ImprovementsDeal Understanding ImprovementsGoal: Increase general deal coverage (deal product type from specific to general).Solution: Identify the prefix and suffix of title by punctuations and prep. Remove the prefix and suffix from t	0.2437881797241977
Find Deals with Opal	Simplified Query Path SelectorSimplified query: current systemSimplified query path selectionCrf model produces a list of possible ways to place rankonly operatorQuery = “nibbana restaurant official site”nibbana restaurant rankonly:official site	0.22156080086104674
Find Deals with Opal	Deal UnderstandingDeals with Low Quality: (some features/rules are listed below)Features/RulesExamplesNo user used; no verified informationThe policies about return365 Day Return Policy;Free Returns on All Orders; 45 Day Return Money Back 	0.1958458341378788
Find Deals with Opal	Opal OSearch & XAP flight frameworkKevin Su & Duat Le06/22/2016OverviewOSearch basicsOpal OSearch high-level architectureProcess to onboard new feature for Opal OSearchXAP flight framework in OsearchOSearch basicsWhat's OSearch?A platf	0.15326602717184387
Find Deals with Opal	Country Level Market FY13 Goal Delivered - Neon Speller Delivered - Neon CAL Delivered - Neon Delivered - Sodium CAL Delivered - Sodium Speller Delivered - Sodium FY13 Remaining Metric Australia Very Deep en-AU NDCG - Overall Brazil Very Deep pt-BR 0 NDCG	0.1514763169375502
Find Deals with Opal	Golden QueryEvery query countsImprove relevance: Relevance TechniquesWin/Loss basedGood technique has better win/loss ratioGeneric Ranker always doesn’t have good win/loss ratioWe do technique triage, and better win/loss ratio technique got sh	0.1505294046096872
Find Deals with Opal	Query Simplification Deep DiveJON Fu12/11/2017AgendaQuery Simplification Motivation and TheoryQuery Simplification for WebQuery Simplification for Cortana 3ARecent Progress in Query Simplification WorkReferencesIntroductionMotiva	0.14658484228426294

File Relevance Experimentation Design	File Relevance Experimentation Design DocRecall AnalysisTest the search quality of external services like OLS, 3S, QF and SPO Search.Search scenarios: 0-term search, term search, 3S (Insert File and Attach File).Compare the recall: diff of returne	0.7257642888739858
File Relevance Experimentation Design	Relevance Experimentation with DUOverviewThe ideal end state for any relevance improvement would consist of having one or more DU features shipped in the index that is then leveraged by the latest production ranker. This would achieve the highest leve	0.5938228422924396
File Relevance Experimentation Design	Relevance Debug InfrastructureProblemFrequent  daily metric fluctuationRelevance gain negated by regressions from Sep to Oct 2013Painful to investigateChallengeLocal stack is complex with lots of componentsVarious relevance events mixed toge	0.5447346327099618
File Relevance Experimentation Design	Deal Ranking ImprovementsDeal Understanding ImprovementsGoal: Increase general deal coverage (deal product type from specific to general).Solution: Identify the prefix and suffix of title by punctuations and prep. Remove the prefix and suffix from t	0.43301807420896654
File Relevance Experimentation Design	L4 Experiment PipelineDate: Aug 20th, 2013Author: Bangyong LiangMotivation:L4’s functionality is to merge results from multiple queries. L4 has two types of merging strategies. One is query level merger and the other one is document level merger. 	0.41624631380910665
File Relevance Experimentation Design	Threshold Query Formulation Deep DiveGoal of the presentation is to communicate our approach for query formulation and get feedback on whether this aligns with overall Threshold goals.OverviewGoals & MetricsQF ModelRoadmapScenariosKey Ta	0.37548927890563377
File Relevance Experimentation Design	Site Quality ClassificationGuihong CaoDefinition of the ProblemWhat is site quality?Google’s definition includes the following dimensionsDuplicated content within the siteTrustworthyOn demand media? Quality controlSite authorityAuthor 	0.3740855872617527
File Relevance Experimentation Design	Relevance and AIBing and Information Platform GroupFY18 AGI Encoder RoadmapFeature OwnersProgram ManagersNitin SharmaDevelopersSaurabh Tiwary, Gargi GhoshResearchersMarketingPartnersYantao Li, Weihu, GuihongOverviewAGI Encoder go	0.37397137418937604
File Relevance Experimentation Design	Project-N DeepDiveAbstractSimilarity issue has been one of the biggest problems of zh-CN relevance for years but not well got solved. In this document, we will focus on one of the main problem of similarity - entity/phrase mismatch issue in query/doc 	0.3737854220860127
File Relevance Experimentation Design	Simplified Query Path SelectorSimplified query: current systemSimplified query path selectionCrf model produces a list of possible ways to place rankonly operatorQuery = “nibbana restaurant official site”nibbana restaurant rankonly:official site	0.3718181625657186

FeedExplorerGettingStarted	Restaurants Features and ToolsReview SnippetXAPOSearchQueryWPOLERWPO OSCacheItemCacheIdList of YpIdsFiltersSorterEntityUpdate PostFixEntity Update OSCache IdCache ItemYpId and PostFixUXReview Snippet Data GroupCac	0.2875144494207327
FeedExplorerGettingStarted	CALQuery alterationAgendaRoadmap and VisionWhere are weWhere to goPlanHow to get thereProgress and looking aheadSodium so farMagnesium and beyondDeep DiveGolden QueryRoadmap & VisionWhere are weCurrent status/problem of CAL	0.28276980122814493
FeedExplorerGettingStarted	Document classification based on urlBackgroundWe want to do document classification for better understanding the document type and document with query category match for ranking.  We will do zh-cn document classification based on url first, then docum	0.27522923528658993
FeedExplorerGettingStarted	GoldenQuery: Past Flights v1Session v1Nov, 2013Simple Explanation of GoldenQueryQuery level Explore & ExploitExplore against techniqueMemorization basedGQ service running before speller, intercept every queryContinues E&E{Microsoft off	0.2716262726173008
FeedExplorerGettingStarted	Anchor and Click Stream RankingSteven ZittrowerBing Local Search RelevanceHypothesisConverting local search’s unstructured and raw text streams into semi-structured forms will improve ranking and offer relevance benefits.TestUsing classifiers 	0.26273516527387814
FeedExplorerGettingStarted	Run web-search-like query against my dataSame Bing Web Search Indexing and Ranking engineIndex in a secondTransparent and real time index sync, no complex index-gen pipelinePrototype in an hourFast self-onboarding with freemium account, schema-d	0.24964581602096048
FeedExplorerGettingStarted	Global relevance feature proposalFeature name: Title Match OptimizationPMJin GuoDevJia LiuTestReleaseALTeam site linkExecutive SummaryTitle is the summary/abstract of the document. Title Match is very important to SBS. Through many c	0.2402691809463079
FeedExplorerGettingStarted	 Core Web RelevanceInformation Platform GroupBing Spam & JunkFeature OwnersProgram ManagersMichael AbboudDevelopersPavel Karpovich, Lidong Zhao, Gregory Minasyants, Ashok Ponnuswami,  Eugene Remizov, Mikhail BorbotDev ManagerLuke ChenM	0.24017806472363462
FeedExplorerGettingStarted	Combined ALterationsNeon\sodiumAgendaNeon AchievementsBreakdownsSodiumIdeas & PlanNeonOverall ProgressExceeded Neon Commitments on CQS!NeonCQS Deep-dive-34% Bad+14% Excellent-15% Bad+13% ExcellentDRDOCQS is impr	0.22640648264084118
FeedExplorerGettingStarted	alterationsalterations: product goalimprove recallby adding terms (not replacing or dropping user-entered terms)using word:which are synonyms to the original terms(we are re-examining each of these for vnext)alterations: general principl	0.22536276374887698

Feature management and L2-ranker	L2 Ranker Training and Feature Management						-- Shu HuangOutlineL2 ranker and truncation rankerFeature extractionFake L2 rankerFeature extraction pipelineMutiple ideal querysetsL2 ranker and truncation rankerFind the current prod ran	0.5888322635406119
Feature management and L2-ranker	DU feature usage summary about en-us and zh-cn prod ranker:<more detail please refer to the attached report>Basics:99 APF in en-us Ranker.47 APF in zh-cn Ranker.41 APF appear both in en-us Ranker and zh-cn Ranker. 58 APF only appear in  en-us 	0.4584292941391248
Feature management and L2-ranker	SKI online feature extraction design docTo build ML model to detect user intent and re-rank search result from different providers, we need training data. This document mainly covers the design how to collect the training data from the real Office usage	0.4411310531752621
Feature management and L2-ranker	Local Category Search StudyHuanan Zhang01/03/2018OutlineStructure of PBA (Prod) rankerIntent match ranker’s role in Prod rankerIssues of intent match rankerSolutions – metastream clean upMetastream measurementPreliminary resultsPBA	0.4338154473305291
Feature management and L2-ranker	Provider Feature Measured Coverage Corrected Coverage(Exclude No Rating) Improved Coverage Estimate(Include No Rating) Note Amazon Price Amazon Availability Amazon Rating&Count >95% >92% 1. A known client issue:The current logic is to show the rating&cou	0.4312107033257528
Feature management and L2-ranker	Publication date optimization for zh-cn marketBackgroundPublication date is a very fundamental and important feature. It can help fresh ranking, whole page user experience: caption date show and freshness internal metrics, also to solve mainline out	0.4137999689915688
Feature management and L2-ranker	How do we train SM-CRF for APN?AgendaOverviewGeneration of Lexicons (in aether)Generation of RegEx FeaturesCRF Training Pipeline (in aether)CRF Eval Pipeline (in aether)Debugging ToolsQuestions?OverviewCRF is responsible for entity e	0.4084486975075472
Feature management and L2-ranker	Ranker Training Pipeline IntroductionAgendaPipeline OverviewGCC platformExtractionData/Feature PreparationMain Ranker TrainingSegment RankersPipeline OverviewGR OctTree: gcclinkMain Steps:Metastream injection (just info here)Querys	0.4083237337318774
Feature management and L2-ranker	PAC: Features, Usage and ProcessThis is a document on how to get document features and build metaword/metastream via Page Analyzer and Classifier (PAC ) pipeline. ContentsKinds Of Features Supported By PAC	2Url/Title Features	2Body Features: Doc	0.38770192404995085
Feature management and L2-ranker	ML Model Scorecard Analysis8/8/2019Unexpected term search movementhttps://exp.microsoft.com/xcard/?view=4e77b420-7b77-4e41-92ac-8e84f506fb01Check correctness of scorecard metric implementationCalculate term AVG rank from raw data streamsSearch	0.3867505003704587

FastRank	FastRank--- a Decision-Tree based Ranking ModelYu SHIOutlineBackgroundAlgorithm overviewTraining implementationExperimentationChallengesReferencesBackgroundInvestigated by MSR in OsloShipped with July Tree 2010 (Denver)GoalsSpe	0.23495139698524548
FastRank		0.22130806130702535
FastRank	Microsoft ConfidentialSubstrate Day 2018 Naresh SundaramSubstrate Architecture Overview1High level framing Distributed Computing Fabric @Scale2Physical Fabric – Datacenters & Servers3Data Tier - Scalability & Availability4Logical	0.10932917244421679
FastRank	Span ClassifierSpan classifier is a general infrastructure that can be used to run a fastrank based classifier on a sequence of terms from a query.  It can be used to apply rankonly or norelax to parts of the query based on the result of the model.  Fea	0.09230204497163094
FastRank	Relaxcount=2 summaryRelaxcount=2 datagatheringDatagathering for relaxcount=2 branched path (3/14/15-3/20/15):Cal13a: control (OFE logging, relaxcount=2 off), 6% trafficCal13b: on (OFE logging, relaxcount=2 on for word count >=5), 12% traffic.Dat	0.08588178807583369
FastRank	Microsoft ConfidentialSubstrate Day 2018 Michelle QuintonBuilding onthe Substrate:From Scenario to SolutionSubstrate PatternsStoring DataProcessing DataAuth for Data AccessBuilding a Compliant ServiceThere are many talks today and I 	0.06888129769558328
FastRank	Google Mobile vs Desktop RankDiff StudyNov 2017GoalsUnderstand what Google does differently on Mobile, if anythingDrive product ideas & shape ranking improvements on MobileUnderstand any possible impact to Algo scrapes & metricsDrive scrapin	0.041743408855829486
FastRank	Fast Brain – Memorization & InferenceQuery based memorization and inferenceLarge Memorization -  1B queries, clicks (Q-D) and moreDeep Brain100 - 200B Doc/Page IndexRecall, Tail and Scalability focusedLess dependency on popularity signalHeur	0.035190123810848205
FastRank	TopChainNumber MasterId Label Type Name Phone AddressLine City Website Closed LastYearImpression LCMScore ChainId ChainName Score LPLink SparsedFeatureVector r 873x114637191399090866 0 http://maps.google.com/maps/place?cid=14233605658129796921 Ion Bank 36	0.033256663871259286
FastRank	Click to edit Master title styleEdit Master text stylesSecond levelThird levelFourth levelFifth levelThis deck is intended for use with INTERNAL AND EXTERNAL audiences.The slides and talking points are designed to help you tell our culture s	0.032686700169437845

FY19 Intelligent QnA Roadmap Review	FY19 Search & AI Roadmap Review: Intelligent QnAMay 2018PM: Ali Alvi, Kaan Ozel, Ganga Venkatasubramanian, Oana NicolovDev: Xia Song, Doran ChakrabortyAgendaOverall QnA Opportunity and GoalsSemi-Structured DataMALTATuring for QnAAGI En	0.5683812398480906
FY19 Intelligent QnA Roadmap Review	FY19 Search & AI Roadmap Review: AGI for Web RankingMay 2018Dev: Chen Zhou, Saurabh TiwaryPM: Kiki Liu, Mir RosenbergMotivation“…But often time we have more problems about the subjects we are not familiar with and therefore even the keywords	0.5664239154139379
FY19 Intelligent QnA Roadmap Review	FY19 Search & AI Roadmap Review: QRMay 2018Jie Cai, Garrett Kaminaga, Jingwen Lu, Momo JengMotivation – QR Query understanding and rewrite is the first opportunity for Bing to understand users’ intents;In current production, query rewrite is a	0.49377340100914
FY19 Intelligent QnA Roadmap Review	QR FY19 LRP Planning - 23/29/18Unified Concept Tagging – Key ChallengesStructural ComplexityFor ambiguous queries and multi-concept queries, how much organization is required?  How to represent this in a linear qlf?  What about inter-concept rel	0.4624507348444833
FY19 Intelligent QnA Roadmap Review	PDI Document AnnotationPDI Ranking PlatformAgendaPDI and forward indexDocument AnnotationSodium update and MG planQ&A DSAT: {books by children}Issue: Document matches the query terms, but its surrounding words may change the intent of 	0.4375988932940977
FY19 Intelligent QnA Roadmap Review	BLU V3 Minghua Zhang      01/26/2016Next version of BLU Relevance Infrastructure​OutlineWhy BLU v3BLU v3 DesignCurrent StatusFuture WorkWhy BLU v3 (1)Limitations of current BLU infrastructureFeaturesCouldn’t utilize QAS feature	0.4316679955099562
FY19 Intelligent QnA Roadmap Review	CAL Problem, Vision and RoadmapContentsOverview	2Problem of today’s CAL	2Vision and Roadmap	3Start from simple but important one: infrastructure.	3Now comes core problem: Metrics	3Now comes to the interesting part: context	4Data	5Head qu	0.4285478242966202
FY19 Intelligent QnA Roadmap Review	FY18 AGI Encoder Roadmap		Nitin Sharma, Gargi Ghosh, Saurabh TiwaryAgendaIntroductionFY18 Goals and Focus AreasFocus Area Deep DiveCustomer scenariosDetailed RoadmapAGI Encoder: MotivationGoal: One general intent encoder of source 	0.4073785896959104
FY19 Intelligent QnA Roadmap Review	AGI - Web Search / Tail FY18 Roadmap 	Rohit Kapoor, Saurabh Tiwary, Gargi Ghosh, Chen Zhou,  Kushal LakhotiaFY17 RecapFY18 GoalsFY18 Focus AreasFY18 TimelineFocus Area Deep DivesAgendaFY17 RecapIn-Progress:[Fusion] Out of market [F	0.4063042482735367
FY19 Intelligent QnA Roadmap Review	Fusion: Next Gen Web Intelligence Review with David KuJune 2016Goals:Power Bing and Bing Next with web open knowledgeNew post L2 ranking platform with MQ and contextual capability inherently Integrated ranking process provides jointly opti	0.401087612069858

FY18 Local Planning	Local Search Platform PM Onboarding GuideAuthors: Dany DaherDate: 10/18/2013Architecture OverviewHow Local Search Works Local Data Platform Architecture MetricsLocal Metrics:  http://jeffke/localMetrics/Definition of QLDCG: Local Discoun	0.2940154174846162
FY18 Local Planning	QR FY19 LRP Planning - 23/29/18Unified Concept Tagging – Key ChallengesStructural ComplexityFor ambiguous queries and multi-concept queries, how much organization is required?  How to represent this in a linear qlf?  What about inter-concept rel	0.2845415749337715
FY18 Local Planning	FY18 GreenlightLocal SearchJune 14, 2017FY18 Local Search: Top GoalsInitiativeMetricFY18 GoalsTop Segments (mobile and desktop): Competitive Segment SBS (mobile and desktop)TCxSBS weak score > 5 for EN-USSegments: Hotels, Retail, Hom	0.17815488994892825
FY18 Local Planning	Local Search Online Learning Lihong LiFengxia PanAgendaOnline LearningBiased user engagement dataLocal results positional bias estimation method & ExperimentOffline click evaluatorL2 ranker improvement using online click dataExperiment &	0.17440429867711307
FY18 Local Planning	WPO Local Relevance Tech TalkWPO Local Relevance TeamOverviewWPO’s role in local relevance pipelineLocal ExperienceArchitecture overviewMetricsWPO Local Relevance Model IntroductionWPO Query understanding and Location understandingWhy do	0.16778344790535976
FY18 Local Planning	PDI Document AnnotationPDI Ranking PlatformAgendaPDI and forward indexDocument AnnotationSodium update and MG planQ&A DSAT: {books by children}Issue: Document matches the query terms, but its surrounding words may change the intent of 	0.15678549684487814
FY18 Local Planning	L-1B SPECIALIZED KNOWLEDGE QUESTIONNAIREMICROSOFT POSITION IN THE U.S.Provide the following information for your current position at the Microsoft.MICROSOFT POSITION ABROADProvide the following information for your position at the Microsoft’s su	0.15340008625630525
FY18 Local Planning	L3 in LocalKefeng DengOutlineL3 IntroductionUse L3 in localL3 exampleL3 introductionFor Local: 28 IS machines per row, about 5 million entities per machine. MinBLA = 50L3 introductionL3 featuresSet featuresFeature Statistics for top 	0.1498316737798404
FY18 Local Planning	L3 Distance Model for LocalNikita Melnichenko, Bing Local2016-04-12AgendaIntroduction to the Distance problemPrevious workA new approach: experiments and designResultsFuture developmentIntroduction to the Distance problemWe say “it’s a	0.14210093462545353
FY18 Local Planning	ML Model Scorecard Analysis8/8/2019Unexpected term search movementhttps://exp.microsoft.com/xcard/?view=4e77b420-7b77-4e41-92ac-8e84f506fb01Check correctness of scorecard metric implementationCalculate term AVG rank from raw data streamsSearch	0.1380132393823764

FP-ChainHeadII	Brownbag:ElasticSearch ExtensibilityHeather Nakama (henakama)Azure Search09/04/14AgendaIntroductionModulesPluginsFinding extensibility pointsEnd-to-end exampleTips and tricksQ/AIntroductionHeather NakamaDeveloper with Azure S	0.24649082924911705
FP-ChainHeadII	Opal OSearch & XAP flight frameworkKevin Su & Duat Le06/22/2016OverviewOSearch basicsOpal OSearch high-level architectureProcess to onboard new feature for Opal OSearchXAP flight framework in OsearchOSearch basicsWhat's OSearch?A platf	0.23007608950195038
FP-ChainHeadII	Global CAL Aluminum PlanJunfeng ZhouAgendaMagnesium StatusAluminum FocusProjectsMagnesium Status - ReleasesJuly: aggressive relaxation on no result queriesSept: relax count classifier, morphological alterationsOct: JO v1Nov: morphologi	0.21255005506166205
FP-ChainHeadII	MQ for CALOverviewSpellerQASMQTriggerMQSingleQueryChainChainChainAugmentAugmentAugmentTailQuerySimplifiedSPCombSP1SP2Sp3AugmentAugmentPropertyBag - SQQueryAlterationListQueryAlterationSetQueryAlterationType	0.2124530622038549
FP-ChainHeadII	Normalization and Parsing OverviewTypes of NormalizationLimiting to just normalization, there are actually several different types of normalization which may be interesting:WhitespaceThis is:Converting all whitespace characters to spacestrippi	0.21100154946714156
FP-ChainHeadII	Training Data Repository v2Sourabh ChandakAgendaWhy TDR v2TDR explainedOnboarding processNext StepsSummaryDependenciesQuestionsProblemTraining data The most valuable resource for any ranker training experiment. Comprises of <quer	0.19082867036927473
FP-ChainHeadII	TopChainNumber MasterId Label Type Name Phone AddressLine City Website Closed LastYearImpression LCMScore ChainId ChainName Score LPLink SparsedFeatureVector r 873x114637191399090866 0 http://maps.google.com/maps/place?cid=14233605658129796921 Ion Bank 36	0.18557965585671415
FP-ChainHeadII	InstructionS FOR obtaining photographsfor your applicationPHOTO REQUIREMENTS:Your photographs must be:2x2 inches in size Identical Taken within 30 days of filing the application(s), showing current appearance In color Full face, front view	0.1847348184261767
FP-ChainHeadII	Global relevance feature proposalFeature name: Title Match OptimizationPMJin GuoDevJia LiuTestReleaseALTeam site linkExecutive SummaryTitle is the summary/abstract of the document. Title Match is very important to SBS. Through many c	0.18036864130011235
FP-ChainHeadII	FusionByTurker KeskinpalaTuesday, May 17, 2016OverviewMotivationsWhat is Fusion?GoalsFusion ComponentsRoadmapWeb AnswerQ:“gg”Qpath1:“gg”Qpath2:“google”TLACDG FetcherL2 FetcherTLACDG FetcherL2 FetcherLL4L3L3	0.17795824475263372

EntityTriggeringAndCollections	Reading List for Natural Language Query ParsingThis is for improving our NL query parsing for entity/local triggering.By NL query parsing, our goal is to automatically extract the structured information from the query, normally by segmenting queries a	0.43119757750161425
EntityTriggeringAndCollections	MQ for CALOverviewSpellerQASMQTriggerMQSingleQueryChainChainChainAugmentAugmentAugmentTailQuerySimplifiedSPCombSP1SP2Sp3AugmentAugmentPropertyBag - SQQueryAlterationListQueryAlterationSetQueryAlterationType	0.40345255830797877
EntityTriggeringAndCollections	Relevance Debug InfrastructureProblemFrequent  daily metric fluctuationRelevance gain negated by regressions from Sep to Oct 2013Painful to investigateChallengeLocal stack is complex with lots of componentsVarious relevance events mixed toge	0.3457205130343032
EntityTriggeringAndCollections	Entity Selection Pipeline Design DocScope:This document covers the design for entity selection pipeline in GDPV3. Near-Dupe clustering is not covered in this v1 version. The goal for this pipeline is to reduce junk rate and improve NII by stamping pub	0.3334739959425168
EntityTriggeringAndCollections	Document classification based on urlBackgroundWe want to do document classification for better understanding the document type and document with query category match for ranking.  We will do zh-cn document classification based on url first, then docum	0.3288367264298569
EntityTriggeringAndCollections	Name Entity Recognition based on Perceptron modelBackgroundWe have many name entity DSATs like user searched name “XYZ”, and the results may be “XY”,”YZ” or “XYW” related. We have done QU name entity recognition for zh-cn market already. So we want to	0.3247948152493635
EntityTriggeringAndCollections	Anchor and Click Stream RankingSteven ZittrowerBing Local Search RelevanceHypothesisConverting local search’s unstructured and raw text streams into semi-structured forms will improve ranking and offer relevance benefits.TestUsing classifiers 	0.32225159199662745
EntityTriggeringAndCollections	Production Models OverviewLU annotates incoming text input with semantic information in a contextual wayWorkflow built on top of Bing production infrastructure (QAS/XAP/Object Store)Feature representation: word embedding, n-grams and lexicons matche	0.3121899865945593
EntityTriggeringAndCollections	Integrating Knowledge Graph in Web SearchEntity Triggering and CollectionsPresenter: Ze TianKnowledge GraphEntities and RelationsEntities: celebrities, people, generic terms (e.g. light bulb)Relations: sibling, spouse, people and their works	0.30702301848365854
EntityTriggeringAndCollections	Normalization and Parsing OverviewTypes of NormalizationLimiting to just normalization, there are actually several different types of normalization which may be interesting:WhitespaceThis is:Converting all whitespace characters to spacestrippi	0.3055785231564857

EntitySelection	Entity Selection Pipeline Design DocScope:This document covers the design for entity selection pipeline in GDPV3. Near-Dupe clustering is not covered in this v1 version. The goal for this pipeline is to reduce junk rate and improve NII by stamping pub	0.39388308316150195
EntitySelection	Name Entity Recognition based on Perceptron modelBackgroundWe have many name entity DSATs like user searched name “XYZ”, and the results may be “XY”,”YZ” or “XYW” related. We have done QU name entity recognition for zh-cn market already. So we want to	0.35517673202678857
EntitySelection	Entity Selection ModelJia Liu2017-11-08GDP Pipeline View: local data pipelineEntity TypesEntity Types:Open/CloseHead/TailNonJunk/JunkJunk TypesGhost: Local business existed beforeJunk: General name like “Lock smith”, “ATM”Move/Br	0.3462141331114016
EntitySelection	Named Entity RecognizerTao Peng and Kang LiEntity names recognitionRecognize person, location and organization namesBOSTON, April  16 - Kevin Garnett helped the Boston Celtics beat the L. A. Lakers in last year's NBA final. ( Tony Gutierrez / Asso	0.31227131100569555
EntitySelection	Local Search Entity Schema for RelationShips (Entity Containment, Affinities) Short blurb of what this spec is aboutMilestone:  MagnesiumSpec StatusDraftTFS Feature IDPM/Doc OwnerSandhya GuntreddyContributors Scott, Bruno,Andrew,Prajakta	0.2846148974926738
EntitySelection	Production Models OverviewLU annotates incoming text input with semantic information in a contextual wayWorkflow built on top of Bing production infrastructure (QAS/XAP/Object Store)Feature representation: word embedding, n-grams and lexicons matche	0.26840837489573677
EntitySelection	Normalization and Parsing OverviewTypes of NormalizationLimiting to just normalization, there are actually several different types of normalization which may be interesting:WhitespaceThis is:Converting all whitespace characters to spacestrippi	0.260431045925818
EntitySelection	Index Quality UpdateAgendaMetrics UpdateSelection Model ImprovementRecall TierOffice ImprovementChallenges and Pain PointsHow to measure index quality?Ideally: sampling from all “good” images and see how much we covered.sampling from a	0.2580986595002661
EntitySelection	alterationsalterations: product goalimprove recallby adding terms (not replacing or dropping user-entered terms)using word:which are synonyms to the original terms(we are re-examining each of these for vnext)alterations: general principl	0.24571343073100757
EntitySelection	Bitext Alignment for Alteration Candidate GenerationJan 2018Alteration BasicsCAL alteration architecture is a big funnelCurrent mouth of the funnel is the altlist – a non-context-sensitive relation of <source, target, score>Built over time, qu	0.24269223321381883

EntityContainment ParentChild Matrix	Local Search Entity Schema for RelationShips (Entity Containment, Affinities) Short blurb of what this spec is aboutMilestone:  MagnesiumSpec StatusDraftTFS Feature IDPM/Doc OwnerSandhya GuntreddyContributors Scott, Bruno,Andrew,Prajakta	0.43555368824388113
EntityContainment ParentChild Matrix	This workbook contains Parent Child Relationship matrix of provider given relationships. Currently only navteq provides this information and that is the only one which is included here. Parent Category Parent Count Child Count 11579 Hospitals And Medical 	0.4261203099486072
EntityContainment ParentChild Matrix	Query AugmentationsTable of Contents1. Syntax Overview	22. Constraints	6General rules for operators	7Basic Operators	7Scoring and non-scoring constraint operators	9Stream Operators	9Literal Operators	10Meta Operators	11URL Operators	13	0.407352072369976
EntityContainment ParentChild Matrix	Competitive Query-Entity ClickMicrosoft ConfidentialMicrosoft ConfidentialGoalCreate a dataset that is readily available to utilize and analyze query-entity click patterns on competitive dataCompetitive Engine: GoogleMicrosoft ConfidentialCo	0.4025578092963367
EntityContainment ParentChild Matrix	Entity Selection ModelJia Liu2017-11-08GDP Pipeline View: local data pipelineEntity TypesEntity Types:Open/CloseHead/TailNonJunk/JunkJunk TypesGhost: Local business existed beforeJunk: General name like “Lock smith”, “ATM”Move/Br	0.3982904731625531
EntityContainment ParentChild Matrix	Partner Index as ServiceWhat is the Problem? RequirementCurrent status of Bing Image StackDiscoveryClient tend to provide feed for full corpusWeb crawlerImage Content RetrievalSpecial agreement, some even behind authentication for access	0.38335525503110157
EntityContainment ParentChild Matrix	Production Models OverviewLU annotates incoming text input with semantic information in a contextual wayWorkflow built on top of Bing production infrastructure (QAS/XAP/Object Store)Feature representation: word embedding, n-grams and lexicons matche	0.3668606091003652
EntityContainment ParentChild Matrix	Reading List for Natural Language Query ParsingThis is for improving our NL query parsing for entity/local triggering.By NL query parsing, our goal is to automatically extract the structured information from the query, normally by segmenting queries a	0.3650369388727435
EntityContainment ParentChild Matrix	Google-Bing Entity MatchingIn 75,563 Google scrape entities those with a non-empty name are 12,507: Mapped to Bing entities: 𝟖𝟒.𝟖𝟗% (=(10,162+455)/12,507). Missing data.Among entities in            and            1.07%(=83+51) have Lat/Lon	0.3500038949409623
EntityContainment ParentChild Matrix	Named Entity RecognizerTao Peng and Kang LiEntity names recognitionRecognize person, location and organization namesBOSTON, April  16 - Kevin Garnett helped the Boston Celtics beat the L. A. Lakers in last year's NBA final. ( Tony Gutierrez / Asso	0.34878801309729435

Entity Selection Model	Entity Selection ModelJia Liu2017-11-08GDP Pipeline View: local data pipelineEntity TypesEntity Types:Open/CloseHead/TailNonJunk/JunkJunk TypesGhost: Local business existed beforeJunk: General name like “Lock smith”, “ATM”Move/Br	0.489759711207888
Entity Selection Model	Entity Selection Pipeline Design DocScope:This document covers the design for entity selection pipeline in GDPV3. Near-Dupe clustering is not covered in this v1 version. The goal for this pipeline is to reduce junk rate and improve NII by stamping pub	0.39940637270102625
Entity Selection Model	Name Entity Recognition based on Perceptron modelBackgroundWe have many name entity DSATs like user searched name “XYZ”, and the results may be “XY”,”YZ” or “XYW” related. We have done QU name entity recognition for zh-cn market already. So we want to	0.39776214290050455
Entity Selection Model	Named Entity RecognizerTao Peng and Kang LiEntity names recognitionRecognize person, location and organization namesBOSTON, April  16 - Kevin Garnett helped the Boston Celtics beat the L. A. Lakers in last year's NBA final. ( Tony Gutierrez / Asso	0.36503032096597343
Entity Selection Model	Production Models OverviewLU annotates incoming text input with semantic information in a contextual wayWorkflow built on top of Bing production infrastructure (QAS/XAP/Object Store)Feature representation: word embedding, n-grams and lexicons matche	0.33285130875791497
Entity Selection Model	Simplified Query Path SelectorSimplified query: current systemSimplified query path selectionCrf model produces a list of possible ways to place rankonly operatorQuery = “nibbana restaurant official site”nibbana restaurant rankonly:official site	0.33150378590129204
Entity Selection Model	Local Search Entity Schema for RelationShips (Entity Containment, Affinities) Short blurb of what this spec is aboutMilestone:  MagnesiumSpec StatusDraftTFS Feature IDPM/Doc OwnerSandhya GuntreddyContributors Scott, Bruno,Andrew,Prajakta	0.30147949975852206
Entity Selection Model	Index Quality UpdateAgendaMetrics UpdateSelection Model ImprovementRecall TierOffice ImprovementChallenges and Pain PointsHow to measure index quality?Ideally: sampling from all “good” images and see how much we covered.sampling from a	0.2894052076822745
Entity Selection Model	Google-Bing Entity MatchingIn 75,563 Google scrape entities those with a non-empty name are 12,507: Mapped to Bing entities: 𝟖𝟒.𝟖𝟗% (=(10,162+455)/12,507). Missing data.Among entities in            and            1.07%(=83+51) have Lat/Lon	0.25851337792596096
Entity Selection Model	Local Category Search Plan3 month StrategyData: Entity categorizationScalable, high precision/recallSegments: Food & Drink, Retail, Service, Auto, HotelMetaStream enrichmentQuery UnderstandingDolphin by defaultConsume PhoneBookQU to im	0.24322110229805805

Entity Popularity Updated	Local Search Entity Schema for RelationShips (Entity Containment, Affinities) Short blurb of what this spec is aboutMilestone:  MagnesiumSpec StatusDraftTFS Feature IDPM/Doc OwnerSandhya GuntreddyContributors Scott, Bruno,Andrew,Prajakta	0.2988568593568884
Entity Popularity Updated	Publication date optimization for Japan marketBackgroundPublication date is very important to fresh queries, outdated issues and caption date showing. Now the coverage of publication date for Japan market is very low because publication date extract	0.2889890434466044
Entity Popularity Updated	Microsoft ConfidentialSeptember 14, 2016Relevance Next and our Path to AGIAll HandsFeb 10th 2016Relevance Next and our Path to AGIRelevance OpportunitiesAGI: Project Turing Relevance PowerSubstrate RelevanceDemos! Q&AAgendaFY16	0.2832546679850326
Entity Popularity Updated	Machine Learning Categorization & Popularity2012-08-30 | Nicolas NicolovGoalsShow how categorization and popularity systems work.Introduce important ML concepts.Illustrate ML techniques through examples.(aiming to be self-contained)Categoriz	0.27774792337927245
Entity Popularity Updated	Name Entity Recognition based on Perceptron modelBackgroundWe have many name entity DSATs like user searched name “XYZ”, and the results may be “XY”,”YZ” or “XYW” related. We have done QU name entity recognition for zh-cn market already. So we want to	0.27414108309851953
Entity Popularity Updated	Local Entity PopularityJia Liu4/23/2018Project statusStepsDetailsTime ScheduleInvestigateInvestigate old version local entity popularity:Problem define, measurement, feature extraction, training/publish pipeline, usage.12.4 – 12.18	0.263119874723451
Entity Popularity Updated	Competitive Query-Entity ClickMicrosoft ConfidentialMicrosoft ConfidentialGoalCreate a dataset that is readily available to utilize and analyze query-entity click patterns on competitive dataCompetitive Engine: GoogleMicrosoft ConfidentialCo	0.25997740951989523
Entity Popularity Updated	Microsoft ConfidentialSeptember 14, 2016Relevance Next and Artificial IntelligenceRelevance and Intent OffsiteFebruary 8thOur PrioritiesExpand our Capabilities towards a full fledged AGI Engine, with focus on Knowledge, NL/Semantic Understandi	0.2551373774360046
Entity Popularity Updated	Google-Bing Entity MatchingIn 75,563 Google scrape entities those with a non-empty name are 12,507: Mapped to Bing entities: 𝟖𝟒.𝟖𝟗% (=(10,162+455)/12,507). Missing data.Among entities in            and            1.07%(=83+51) have Lat/Lon	0.2523153010034883
Entity Popularity Updated	Index Quality UpdateAgendaMetrics UpdateSelection Model ImprovementRecall TierOffice ImprovementChallenges and Pain PointsHow to measure index quality?Ideally: sampling from all “good” images and see how much we covered.sampling from a	0.24563612574532617

Entity Popularity	Local Search Entity Schema for RelationShips (Entity Containment, Affinities) Short blurb of what this spec is aboutMilestone:  MagnesiumSpec StatusDraftTFS Feature IDPM/Doc OwnerSandhya GuntreddyContributors Scott, Bruno,Andrew,Prajakta	0.2974330854144477
Entity Popularity	Named Entity RecognizerTao Peng and Kang LiEntity names recognitionRecognize person, location and organization namesBOSTON, April  16 - Kevin Garnett helped the Boston Celtics beat the L. A. Lakers in last year's NBA final. ( Tony Gutierrez / Asso	0.2709616529272063
Entity Popularity	Name Entity Recognition based on Perceptron modelBackgroundWe have many name entity DSATs like user searched name “XYZ”, and the results may be “XY”,”YZ” or “XYW” related. We have done QU name entity recognition for zh-cn market already. So we want to	0.25581890003312713
Entity Popularity	Google-Bing Entity MatchingIn 75,563 Google scrape entities those with a non-empty name are 12,507: Mapped to Bing entities: 𝟖𝟒.𝟖𝟗% (=(10,162+455)/12,507). Missing data.Among entities in            and            1.07%(=83+51) have Lat/Lon	0.226016661353724
Entity Popularity	Machine Learning Categorization & Popularity2012-08-30 | Nicolas NicolovGoalsShow how categorization and popularity systems work.Introduce important ML concepts.Illustrate ML techniques through examples.(aiming to be self-contained)Categoriz	0.22215214239256711
Entity Popularity	Local Entity PopularityJia Liu4/23/2018Project statusStepsDetailsTime ScheduleInvestigateInvestigate old version local entity popularity:Problem define, measurement, feature extraction, training/publish pipeline, usage.12.4 – 12.18	0.21041707925853936
Entity Popularity	Competitive Query-Entity ClickMicrosoft ConfidentialMicrosoft ConfidentialGoalCreate a dataset that is readily available to utilize and analyze query-entity click patterns on competitive dataCompetitive Engine: GoogleMicrosoft ConfidentialCo	0.2023649309759562
Entity Popularity	Deal UnderstandingDeals with Low Quality: (some features/rules are listed below)Features/RulesExamplesNo user used; no verified informationThe policies about return365 Day Return Policy;Free Returns on All Orders; 45 Day Return Money Back 	0.19153311172347523
Entity Popularity	Publication date optimization for Japan marketBackgroundPublication date is very important to fresh queries, outdated issues and caption date showing. Now the coverage of publication date for Japan market is very low because publication date extract	0.1841797102000564
Entity Popularity	Normalization and Parsing OverviewTypes of NormalizationLimiting to just normalization, there are actually several different types of normalization which may be interesting:WhitespaceThis is:Converting all whitespace characters to spacestrippi	0.17495216534718228

Entity Pane and Fact Answer	Entity Pane and Fact AnswerPresenter: Ze TianJun 25, 2013IntroductionIntroductionIntroductionProblems to SolveDoes the user search for entities or facts of entities?E.g. “who is msft ceo” (Entity: Microsoft, Fact: Chief Executive O	0.4562549160770746
Entity Pane and Fact Answer	Pattern Based Term Weight FrameworkIntroductionPattern based term weight recognizes the importance for part of terms or all the terms based on patterns/templates/knowledge. There are 2 differences between general and pattern based term weight.Compar	0.2601315601704038
Entity Pane and Fact Answer	CRF Parser AnalysisBusiness category searchOverviewParser (phonebook)CRF ParserqueryLocation featuresCRF featuresQuery parsetoken[tag] token[tag] … token[tag]userBLUbusiness_namebusiness_categorylocationlocation_separatorbu	0.2508893281736548
Entity Pane and Fact Answer	Normalization and Parsing OverviewTypes of NormalizationLimiting to just normalization, there are actually several different types of normalization which may be interesting:WhitespaceThis is:Converting all whitespace characters to spacestrippi	0.23025925167517347
Entity Pane and Fact Answer	Local Search Entity Schema for RelationShips (Entity Containment, Affinities) Short blurb of what this spec is aboutMilestone:  MagnesiumSpec StatusDraftTFS Feature IDPM/Doc OwnerSandhya GuntreddyContributors Scott, Bruno,Andrew,Prajakta	0.2162488098307478
Entity Pane and Fact Answer	This workbook contains Parent Child Relationship matrix of provider given relationships. Currently only navteq provides this information and that is the only one which is included here. Parent Category Parent Count Child Count 11579 Hospitals And Medical 	0.21595689047443883
Entity Pane and Fact Answer	Project-N DeepDiveAbstractSimilarity issue has been one of the biggest problems of zh-CN relevance for years but not well got solved. In this document, we will focus on one of the main problem of similarity - entity/phrase mismatch issue in query/doc 	0.21505628435094282
Entity Pane and Fact Answer	I-130 Questionnaire for the Petitioner (Husband or Wife)PLEASE LEFT CLICK ON GRAY FIELDS TO ENTER DATA.  PLEASE DO NOT (A) MODIFY THE FORMAT OF THIS DOCUMENT, (B) USE ALL CAP'S; OR (C) RIGHT-CLICK ON GRAY FIELDS.  IF YOU SAVE THIS DOCUMENT, PLEASE SAVE 	0.1946900601955445
Entity Pane and Fact Answer	Reading List for Natural Language Query ParsingThis is for improving our NL query parsing for entity/local triggering.By NL query parsing, our goal is to automatically extract the structured information from the query, normally by segmenting queries a	0.1933966486951383
Entity Pane and Fact Answer	Zh-cn Transportation Segment Optimization by Pattern EngineIntroductionThe pattern queries can cover almost 10% in all queries. We can summarize lots of patterns on Query and Document sides for different segments. We can recognize key terms, relations	0.18406825200498378

ElasticSearch_oSearch	ElasticSearchInternalElasticSearch and oSearchElasticSearch  ArchitectureLucene FamilyoSearch  ArchitectureScenario and ScaleoSearchElasticSearchScope Strong structured dataImage with ANNUnstructured text Loose structured data	0.7335701121028725
ElasticSearch_oSearch	SmartRelax training and evaluation from 15%/15% flightForay scorecard: 15%+15% datagatheringUser-triggered scorecardSSRx gain of 0.12%, for 3+4 word on vs. 3+4 word off. (NOT vs. prod.)Gain is 36% from SSR, 11% from TTS, 52% from TSRSSRx gains s	0.3277756696929752
ElasticSearch_oSearch	Opal OSearch & XAP flight frameworkKevin Su & Duat Le06/22/2016OverviewOSearch basicsOpal OSearch high-level architectureProcess to onboard new feature for Opal OSearchXAP flight framework in OsearchOSearch basicsWhat's OSearch?A platf	0.326731315462292
ElasticSearch_oSearch	Restaurants Features and ToolsReview SnippetXAPOSearchQueryWPOLERWPO OSCacheItemCacheIdList of YpIdsFiltersSorterEntityUpdate PostFixEntity Update OSCache IdCache ItemYpId and PostFixUXReview Snippet Data GroupCac	0.2999512706890782
ElasticSearch_oSearch	SmartRelax OFE and TrainingOverviewAnalysis of smartrelax flightsOFE flight simulatorIs smartrelax ever bad?Smartrelax model training:Training method I: relax-specific targetsTraining method II: end-user targetsSmart Relax OFE and Training	0.29739243516347913
ElasticSearch_oSearch	Translation Model in Local Search- Shu HuangIntroductionTranslation model in web searchOdpTitle translation model in local searchData preparationModel trainingGenerate new metastreamIntroductionTranslation model used in web searchLea	0.2851840794291064
ElasticSearch_oSearch	Click to edit Master title styleEdit Master text stylesSecond levelThird levelFourth levelFifth levelThis deck is intended for use with INTERNAL AND EXTERNAL audiences.The slides and talking points are designed to help you tell our culture s	0.2821367560307078
ElasticSearch_oSearch	Entity Pane and Fact AnswerPresenter: Ze TianJun 25, 2013IntroductionIntroductionIntroductionProblems to SolveDoes the user search for entities or facts of entities?E.g. “who is msft ceo” (Entity: Microsoft, Fact: Chief Executive O	0.2718766483758314
ElasticSearch_oSearch	ODP Classification: Summarizing Pages as a Topic DistributionNov 17, 2010Paul Bennett (pauben), MSR CLUESJoint work with Max Chickering & Susan Dumais© 2006 Microsoft Corporation. All rights reserved. Microsoft, Windows, Windows Vista and ot	0.27170559095006913
ElasticSearch_oSearch	Brownbag:ElasticSearch ExtensibilityHeather Nakama (henakama)Azure Search09/04/14AgendaIntroductionModulesPluginsFinding extensibility pointsEnd-to-end exampleTips and tricksQ/AIntroductionHeather NakamaDeveloper with Azure S	0.26933923231304213

ElasticSearch Extensibility BrownBag	Brownbag:ElasticSearch ExtensibilityHeather Nakama (henakama)Azure Search09/04/14AgendaIntroductionModulesPluginsFinding extensibility pointsEnd-to-end exampleTips and tricksQ/AIntroductionHeather NakamaDeveloper with Azure S	0.5290761154020738
ElasticSearch Extensibility BrownBag	ElasticSearchInternalElasticSearch and oSearchElasticSearch  ArchitectureLucene FamilyoSearch  ArchitectureScenario and ScaleoSearchElasticSearchScope Strong structured dataImage with ANNUnstructured text Loose structured data	0.5179293568301262
ElasticSearch Extensibility BrownBag	Tiger Index BrownbagHui ShenSearch Platform Tiger TeamAgenda	OverviewKey ideasTiger architectureTiger ++ 2/24/2012Agenda	OverviewKey ideasTiger architectureTiger ++ 2/24/2012What is Tiger IndexAn new index serve technol	0.36974646406761924
ElasticSearch Extensibility BrownBag	Whole Page RelevanceShip Meeting 08/14/2012AgendaSummary of IssuesSpecial TopicsWhole Page Relevance - IssuesTeamIssue Description StatusOwnerDue Action UpdateINTL Mon-GsheldonNo major issuesCaptions MetricsSBS – Monthly 	0.3481755001344746
ElasticSearch Extensibility BrownBag	Ranker Training Pipeline IntroductionAgendaPipeline OverviewGCC platformExtractionData/Feature PreparationMain Ranker TrainingSegment RankersPipeline OverviewGR OctTree: gcclinkMain Steps:Metastream injection (just info here)Querys	0.34793983772632414
ElasticSearch Extensibility BrownBag	Microsoft ConfidentialSeptember 14, 2016Relevance Next and Artificial IntelligenceRelevance and Intent OffsiteFebruary 8thOur PrioritiesExpand our Capabilities towards a full fledged AGI Engine, with focus on Knowledge, NL/Semantic Understandi	0.31606018963347704
ElasticSearch Extensibility BrownBag	Restaurants Features and ToolsReview SnippetXAPOSearchQueryWPOLERWPO OSCacheItemCacheIdList of YpIdsFiltersSorterEntityUpdate PostFixEntity Update OSCache IdCache ItemYpId and PostFixUXReview Snippet Data GroupCac	0.31584336931676604
ElasticSearch Extensibility BrownBag	Index Quality UpdateAgendaMetrics UpdateSelection Model ImprovementRecall TierOffice ImprovementChallenges and Pain PointsHow to measure index quality?Ideally: sampling from all “good” images and see how much we covered.sampling from a	0.31385466346915336
ElasticSearch Extensibility BrownBag	Zhcn document classification based on topicJia Liu2012.11.14agendarTraining data selection&crawl&cleanFeature selection&cleanClassifierRating Bad case analysisTrainning data	0.3126901640745654
ElasticSearch Extensibility BrownBag	Relevance ServiceScenarioIconApplicationDoc typeCandidatesModelRun0-termWord;OutlookWin32 client.All file typesMRUReuse ContentModel 1Client0-termPower PointWin32 client.Only ppt typeLocal + MRUReuse Conte	0.31232216192177903

EVL - MSFT HR - Jia Liu	To whom it may concern,  We are Jia Liu and her husband, Edward Wild.  The bearers of this letter are Jia's mother, Chunxiang Lei, and father, Xinbao Liu.  Jia is a software engineer working at Microsoft on an L1 visa valid until 2020, and Edward is a	0.4898076893719281
EVL - MSFT HR - Jia Liu	6/8/2016To Whom It May Concern:Re:	Jia LiuThis letter is to confirm that Jia Liu was employed at Microsoft (China) Company Limited in Beijing, China from March 30, 2012 to June 21, 2015.  She worked full time, 40 hours per week.  Sincerely,Xue B	0.48914479291020585
EVL - MSFT HR - Jia Liu	To Whom It May ConcernPage 2DATETo Whom It May Concern:Re:	Jia LiuI write to certify that Jia Liu worked as a Software Development Engineer at Microsoft (China) Company Limited (Microsoft China) in Beijing, China from March 30, 2012 to September	0.4760023224879949
EVL - MSFT HR - Jia Liu	To whom it may concern,The bearer of this letter is my sister, Yan Liu. My name is Jia Liu, and I am a software engineer employed by Microsoft. I am working here on an L1 visa valid until 2019. I have invited my parents, my sister, and her son to come v	0.461978714790238
EVL - MSFT HR - Jia Liu	Page 23 of 26L2 General Title MatchDev: Jia Liu, Chuan Cao, Albert ZhouPM: Jin GuoDoc version: v1.0ContentsAbstract	2Project Status	2Goals	2Problem statement	3Architecture	3N-Gram Table	4Query Distribution in N-Gram Table	5Query 	0.4125485436506117
EVL - MSFT HR - Jia Liu	To whom it may concern,The bearers of this letter are my parents and nephew.  My name is Jia Liu, and I am a software engineer employed by Microsoft.  I am working here on an L1 visa valid until 2019.  I have invited my parents, my sister, and her son t	0.4022745826714093
EVL - MSFT HR - Jia Liu	DU work items on zh-cn market　　Jia Liu2013-05-14AgendaSerp classifierWrapstar rating signalsTaobao, tmall; qna; novel; videoGeneral classiferUrl-basedTopic-basedPage number extractionName entity recognitionPerson, location, organiz	0.40017062727603886
EVL - MSFT HR - Jia Liu	Progress in BLU Relevance  Marta Penas Centeno (mapena)Minghua Zhang (minghuaz)Jian Wu (jianwu)OutlineBLU as a service is the goal of our relevance improvementsBLU v3 is the relevance platform for BLU as a serviceRelevance improvements del	0.392198235359949
EVL - MSFT HR - Jia Liu	From: Kelsey Crouter (Search Wizards) Sent: Wednesday, March 04, 2015 2:16 AMTo: Jia Liu (STCA)Cc: Yi Li (AWE); Andrea LaCoy; Jennifer Sutherland; Hariharan Ragunathan; Kelsey Crouter (Search Wizards)Subject: * Updated * Confidential - Internal Of	0.3740594696434862
EVL - MSFT HR - Jia Liu	Keyword Predictor Summer 2018 SummaryIntern: Ruchir Rastogi (rrastogi@stanford.edu)Mentor: Jia LiuThe Aether ID’s listed in this document are more up to date than the one’s listed in the PowerPoint.PipelinesTraining data clean-up pipelineAethe	0.370487194444756

EVL - MSFT HR	L-1B SPECIALIZED KNOWLEDGE QUESTIONNAIREMICROSOFT POSITION IN THE U.S.Provide the following information for your current position at the Microsoft.MICROSOFT POSITION ABROADProvide the following information for your position at the Microsoft’s su	0.2779418863561822
EVL - MSFT HR	IQ Team RecapH1 2016FY16H1 AccomplishmentsTeamSSRxen-* Desktop SBSen-* Mobile SBSen-* Semantic SBSCore Web Relevance0.55/0.62.46/3.02.65/3.01.88/2.0Adult LeakageSpamJunkCQDCGMPCMALTABing@WorkSubstrate0.02/0.01	0.2446317350093552
EVL - MSFT HR	ML Model Scorecard Analysis8/8/2019Unexpected term search movementhttps://exp.microsoft.com/xcard/?view=4e77b420-7b77-4e41-92ac-8e84f506fb01Check correctness of scorecard metric implementationCalculate term AVG rank from raw data streamsSearch	0.22700711500046813
EVL - MSFT HR	Competitive Query-Entity ClickMicrosoft ConfidentialMicrosoft ConfidentialGoalCreate a dataset that is readily available to utilize and analyze query-entity click patterns on competitive dataCompetitive Engine: GoogleMicrosoft ConfidentialCo	0.22312199474332872
EVL - MSFT HR	Module 2:Deployment Considerations© 2014 Microsoft Corporation. All rights reserved. MICROSOFT MAKES NO WARRANTIES, EXPRESS, IMPLIED OR STATUTORY, AS TO THE INFORMATION IN THIS PRESENTATION.11/28/2016 8:58 PMMicrosoft ServicesConditions and Te	0.21829998209050752
EVL - MSFT HR	Microsoft ConfidentialCOMMON PATTERNSAuthentication in the Substrate© 2014 Microsoft Corporation. All rights reserved. MICROSOFT MAKES NO WARRANTIES, EXPRESS, IMPLIED OR STATUTORY, AS TO THE INFORMATION IN THIS PRESENTATION.7/22/2019 3:09 PMType	0.2158604876053496
EVL - MSFT HR	Investigating Job Performance Issues Using SCOPEStudio Author: Xiaoyong ZhuSupport: Client Tools Customer SupportContentsIntroduction	2Investigating Data Skew Problem	2Confirm data skew problem via SCOPEStudio	3Whether the data skew problem 	0.2102676742272083
EVL - MSFT HR	Office Shredding ServiceSKI Tech Talk – 3/29What do we shred?Office documents into reusable piecesService powering Add From Files in Word, Reuse slides in PPT, Files tab in Microsoft SearchAPIsGoLocalSearchShredding APIs (Document Manifest	0.20876609887219433
EVL - MSFT HR	Microsoft ConfidentialSeptember 14, 2016AGI EngineCore Relevance PM TeamJanuary 26thHuman and Artificial IntelligenceOur Approach to an AGI EngineSolving the AGI Engine GoalsUpgrading our Search StackAgendaLets start with a conceptual 	0.20830311147628056
EVL - MSFT HR	AGI UpdateDL Representation & Applications for NLU TasksSubhojit Som(Subhsom), Chen Zhou(chzho)Xia Song (xiaso), Saurabh Tiwary (satiwary)October. 2016Agenda / UpdatesMachine Reading ComprehensionLearning Generic Representation aka Semanti	0.19730976892250993

EVL - MSFT China2	Microsoft IT Technology AdoptionSee past and upcoming  talks at http://aka.ms/ITTechTalksSubscribe to IT Tech Talks DL @IT Tech Talk Invitethere’s a link on the Tech Talks siteQuestions about Tech Talks? Ask Justin Lane or Susan Sims.IT Tech T	0.32664630768915814
EVL - MSFT China2	Microsoft ConfidentialCOMMON PATTERNSAuthentication in the Substrate© 2014 Microsoft Corporation. All rights reserved. MICROSOFT MAKES NO WARRANTIES, EXPRESS, IMPLIED OR STATUTORY, AS TO THE INFORMATION IN THIS PRESENTATION.7/22/2019 3:09 PMType	0.32272823666493594
EVL - MSFT China2	AGI UpdateDL Representation & Applications for NLU TasksSubhojit Som(Subhsom), Chen Zhou(chzho)Xia Song (xiaso), Saurabh Tiwary (satiwary)October. 2016Agenda / UpdatesMachine Reading ComprehensionLearning Generic Representation aka Semanti	0.30254073119726327
EVL - MSFT China2	6/8/2016To Whom It May Concern:Re:	Jia LiuThis letter is to confirm that Jia Liu was employed at Microsoft (China) Company Limited in Beijing, China from March 30, 2012 to June 21, 2015.  She worked full time, 40 hours per week.  Sincerely,Xue B	0.2925315182207394
EVL - MSFT China2	FusionByTurker KeskinpalaTuesday, May 17, 2016OverviewMotivationsWhat is Fusion?GoalsFusion ComponentsRoadmapWeb AnswerQ:“gg”Qpath1:“gg”Qpath2:“google”TLACDG FetcherL2 FetcherTLACDG FetcherL2 FetcherLL4L3L3	0.28897799746135505
EVL - MSFT China2	Competitive Query-Entity ClickMicrosoft ConfidentialMicrosoft ConfidentialGoalCreate a dataset that is readily available to utilize and analyze query-entity click patterns on competitive dataCompetitive Engine: GoogleMicrosoft ConfidentialCo	0.28286687890710094
EVL - MSFT China2	Microsoft ConfidentialSubstrate Day 2018 Naresh SundaramSubstrate Architecture Overview1High level framing Distributed Computing Fabric @Scale2Physical Fabric – Datacenters & Servers3Data Tier - Scalability & Availability4Logical	0.26676067929230435
EVL - MSFT China2	学士学位证明BACHELOR DEGREE CERTIFICATEThis is to certify that Ms. Jia Liu, born in August 1986, with the specialty of Computer Science and Technology at Beijing University of Posts and Telecommunications from September 2005 to July 2009, has passed all req	0.2620211745446369
EVL - MSFT China2	QR MicrosegmentsSandeep AparajitAgendaWhat are microsegments?How does microsegment work in CAL?How can I add my own microsegment?DemoQuestions/SuggestionsWhat are Microsegments?Microsegment is a technique using which you can alter the be	0.2553479466945971
EVL - MSFT China2	To whom it may concern,We are Xinbao Liu and Chunxiang Lei, a married couple.  We are citizens of China visiting our daughter and son-in-law in Bothell, Washington on valid US B-2 visas.  Our daughter, Jia Liu is a citizen of China residing in the Unite	0.2499758772486577

EVL - MSFT China - Copy	6/8/2016To Whom It May Concern:Re:	Jia LiuThis letter is to confirm that Jia Liu was employed at Microsoft (China) Company Limited in Beijing, China from March 30, 2012 to June 21, 2015.  She worked full time, 40 hours per week.  Sincerely,Xue B	0.3425002941129785
EVL - MSFT China - Copy	Competitive Query-Entity ClickMicrosoft ConfidentialMicrosoft ConfidentialGoalCreate a dataset that is readily available to utilize and analyze query-entity click patterns on competitive dataCompetitive Engine: GoogleMicrosoft ConfidentialCo	0.3387018583121987
EVL - MSFT China - Copy	Microsoft IT Technology AdoptionSee past and upcoming  talks at http://aka.ms/ITTechTalksSubscribe to IT Tech Talks DL @IT Tech Talk Invitethere’s a link on the Tech Talks siteQuestions about Tech Talks? Ask Justin Lane or Susan Sims.IT Tech T	0.32308142660349903
EVL - MSFT China - Copy	Microsoft ConfidentialCOMMON PATTERNSAuthentication in the Substrate© 2014 Microsoft Corporation. All rights reserved. MICROSOFT MAKES NO WARRANTIES, EXPRESS, IMPLIED OR STATUTORY, AS TO THE INFORMATION IN THIS PRESENTATION.7/22/2019 3:09 PMType	0.3058641235441515
EVL - MSFT China - Copy	To whom it may concern,We are Xinbao Liu and Chunxiang Lei, a married couple.  We are citizens of China visiting our daughter and son-in-law in Bothell, Washington on valid US B-2 visas.  Our daughter, Jia Liu is a citizen of China residing in the Unite	0.27645738795150815
EVL - MSFT China - Copy	Page 23 of 26L2 General Title MatchDev: Jia Liu, Chuan Cao, Albert ZhouPM: Jin GuoDoc version: v1.0ContentsAbstract	2Project Status	2Goals	2Problem statement	3Architecture	3N-Gram Table	4Query Distribution in N-Gram Table	5Query 	0.27576566255408136
EVL - MSFT China - Copy	Dynamic ConflationGanesh Poomal Girirajan  Kefeng                                                    Qiang WuAcknowledgementsChiping Tang: Helped us get the UPDR judgments for Training and Evaluation.Shital Shah, Aamer Mohammed: Helped us stam	0.2567324209806836
EVL - MSFT China - Copy	Mobile LT Discussion6/20/2014AgendaTop IssuesAd Product and Ad Quality UpdateSummarized Finding NDT Supply AnalysisSummarized Finding Google CompeteStatusFeatureWindows phoneIphone/AndroidUp to 2 adsShipped 5/20/2014Shipped more 	0.2562916895670549
EVL - MSFT China - Copy	DU work items on zh-cn market　　Jia Liu2013-05-14AgendaSerp classifierWrapstar rating signalsTaobao, tmall; qna; novel; videoGeneral classiferUrl-basedTopic-basedPage number extractionName entity recognitionPerson, location, organiz	0.24935335337292325
EVL - MSFT China - Copy	SPAM & JunkSi Planning Cheng Niu, Alex Rahin6/18/2014Agenda	Focus AreasMetricsSPAM/Junk Metrics BreakdownData Analysis and Project DefinitionFocus AreasImprove SPAM Detection (~35% of team bandwidth)Stolen ContentContent Keyword St	0.2493210370173225

EVL - MSFT China	6/8/2016To Whom It May Concern:Re:	Jia LiuThis letter is to confirm that Jia Liu was employed at Microsoft (China) Company Limited in Beijing, China from March 30, 2012 to June 21, 2015.  She worked full time, 40 hours per week.  Sincerely,Xue B	0.31823427870441556
EVL - MSFT China	Microsoft IT Technology AdoptionSee past and upcoming  talks at http://aka.ms/ITTechTalksSubscribe to IT Tech Talks DL @IT Tech Talk Invitethere’s a link on the Tech Talks siteQuestions about Tech Talks? Ask Justin Lane or Susan Sims.IT Tech T	0.30189827464448843
EVL - MSFT China	Microsoft ConfidentialCOMMON PATTERNSAuthentication in the Substrate© 2014 Microsoft Corporation. All rights reserved. MICROSOFT MAKES NO WARRANTIES, EXPRESS, IMPLIED OR STATUTORY, AS TO THE INFORMATION IN THIS PRESENTATION.7/22/2019 3:09 PMType	0.2842218429134195
EVL - MSFT China	To whom it may concern,We are Xinbao Liu and Chunxiang Lei, a married couple.  We are citizens of China visiting our daughter and son-in-law in Bothell, Washington on valid US B-2 visas.  Our daughter, Jia Liu is a citizen of China residing in the Unite	0.24536548780606376
EVL - MSFT China	Competitive Query-Entity ClickMicrosoft ConfidentialMicrosoft ConfidentialGoalCreate a dataset that is readily available to utilize and analyze query-entity click patterns on competitive dataCompetitive Engine: GoogleMicrosoft ConfidentialCo	0.24154778925516054
EVL - MSFT China	AGI UpdateDL Representation & Applications for NLU TasksSubhojit Som(Subhsom), Chen Zhou(chzho)Xia Song (xiaso), Saurabh Tiwary (satiwary)October. 2016Agenda / UpdatesMachine Reading ComprehensionLearning Generic Representation aka Semanti	0.23226434956537378
EVL - MSFT China	Page 23 of 26L2 General Title MatchDev: Jia Liu, Chuan Cao, Albert ZhouPM: Jin GuoDoc version: v1.0ContentsAbstract	2Project Status	2Goals	2Problem statement	3Architecture	3N-Gram Table	4Query Distribution in N-Gram Table	5Query 	0.22719542040584223
EVL - MSFT China	Dynamic ConflationGanesh Poomal Girirajan  Kefeng                                                    Qiang WuAcknowledgementsChiping Tang: Helped us get the UPDR judgments for Training and Evaluation.Shital Shah, Aamer Mohammed: Helped us stam	0.22177586921765488
EVL - MSFT China	学士学位证明BACHELOR DEGREE CERTIFICATEThis is to certify that Ms. Jia Liu, born in August 1986, with the specialty of Computer Science and Technology at Beijing University of Posts and Telecommunications from September 2005 to July 2009, has passed all req	0.21977690508247075
EVL - MSFT China	QR MicrosegmentsSandeep AparajitAgendaWhat are microsegments?How does microsegment work in CAL?How can I add my own microsegment?DemoQuestions/SuggestionsWhat are Microsegments?Microsegment is a technique using which you can alter the be	0.21941405091304603

DynamicRankFeatures	Module 2:Deployment Considerations© 2014 Microsoft Corporation. All rights reserved. MICROSOFT MAKES NO WARRANTIES, EXPRESS, IMPLIED OR STATUTORY, AS TO THE INFORMATION IN THIS PRESENTATION.11/28/2016 8:58 PMMicrosoft ServicesConditions and Te	0.3350686017001385
DynamicRankFeatures	Translation Model in Local Search- Shu HuangIntroductionTranslation model in web searchOdpTitle translation model in local searchData preparationModel trainingGenerate new metastreamIntroductionTranslation model used in web searchLea	0.31705493969598375
DynamicRankFeatures	Index Quality UpdateAgendaMetrics UpdateSelection Model ImprovementRecall TierOffice ImprovementChallenges and Pain PointsHow to measure index quality?Ideally: sampling from all “good” images and see how much we covered.sampling from a	0.29162282971123854
DynamicRankFeatures	cal deepdiverelaxationdec 2017AgendaProduct GoalsQuery SimplificationMechanism/RuntimeCRF Model TrainingQS Path SelectionOffline SimulatorSmart RelaxMechanism & TrainingRelaxation: ImpactRelaxation: Product goalsImprove Rec	0.28382714989941593
DynamicRankFeatures	Tiger MigrationKefeng Deng6/15/2015Microsoft ConfidentialTiger MigrationMotivationTiger IntroductionHow do we get thereCurrent statusRemaining works6/15/2015Microsoft ConfidentialMotivationSame index serve architecture as Satori 	0.27547308661268194
DynamicRankFeatures	Introduction to dynamic ranking Xiao WuOutlinesIntroductionRelevance MeasurementDynamic rankingRanking FeaturesRanking DataRanking modelsRelevance ExperiementIntroductionWhat is dynamic rankingRanking based on query dependent featu	0.2729099988864433
DynamicRankFeatures	Ranker Training Pipeline IntroductionAgendaPipeline OverviewGCC platformExtractionData/Feature PreparationMain Ranker TrainingSegment RankersPipeline OverviewGR OctTree: gcclinkMain Steps:Metastream injection (just info here)Querys	0.24106310762835925
DynamicRankFeatures	Bitext Alignment for Alteration Candidate GenerationJan 2018Alteration BasicsCAL alteration architecture is a big funnelCurrent mouth of the funnel is the altlist – a non-context-sensitive relation of <source, target, score>Built over time, qu	0.23519287190939425
DynamicRankFeatures	ElasticSearchInternalElasticSearch and oSearchElasticSearch  ArchitectureLucene FamilyoSearch  ArchitectureScenario and ScaleoSearchElasticSearchScope Strong structured dataImage with ANNUnstructured text Loose structured data	0.2327436097158372
DynamicRankFeatures	Anchor and Click Stream RankingSteven ZittrowerBing Local Search RelevanceHypothesisConverting local search’s unstructured and raw text streams into semi-structured forms will improve ranking and offer relevance benefits.TestUsing classifiers 	0.23214729878459361

Dynamic Ranking Overview2	Deal Ranking Improvement & MeasurementBackgroundAfter we shipped deal understanding, bad deals filtering, deal ranking for the entity search deals and popular deals nearby. We want to measure and improve our deal ranking based on user behaviors. We ca	0.3917439535359758
Dynamic Ranking Overview2	L2 Ranker Training and Feature Management						-- Shu HuangOutlineL2 ranker and truncation rankerFeature extractionFake L2 rankerFeature extraction pipelineMutiple ideal querysetsL2 ranker and truncation rankerFind the current prod ran	0.37926367755526
Dynamic Ranking Overview2	L3 Reranking FrameworkL3 Infrastructure TeamAgendaOverviewL3 featuresL3 ranker and L3 workflowAggregatedFreeFormList-wise ranking previewL3 and L4Future WorkOverviewRank Stack in IS PlatformL4 - MergerL3 – List reorderingL2 - S	0.3736951477323023
Dynamic Ranking Overview2	Multi-Query Issue and QR/Ranking Joint Optimization Bhuvan MiddhaJonas BarklundYinzhe YuYuan Wang6/26/2012AgendaPresentation TopicTime/PresenterIntroduction/QR/Ranking for Joint Optimization3:05 pm – 3:30 pm [Bhuvan/Jonas]Joint Opt	0.3725683263083483
Dynamic Ranking Overview2	Deal Ranking ImprovementsDeal Understanding ImprovementsGoal: Increase general deal coverage (deal product type from specific to general).Solution: Identify the prefix and suffix of title by punctuations and prep. Remove the prefix and suffix from t	0.37159842944273547
Dynamic Ranking Overview2	Introduction to dynamic ranking Xiao WuOutlinesIntroductionRelevance MeasurementDynamic rankingRanking FeaturesRanking DataRanking modelsRelevance ExperiementIntroductionWhat is dynamic rankingRanking based on query dependent featu	0.3653796706310012
Dynamic Ranking Overview2	Google Mobile vs Desktop RankDiff StudyNov 2017GoalsUnderstand what Google does differently on Mobile, if anythingDrive product ideas & shape ranking improvements on MobileUnderstand any possible impact to Algo scrapes & metricsDrive scrapin	0.3610210965990838
Dynamic Ranking Overview2	FastRank--- a Decision-Tree based Ranking ModelYu SHIOutlineBackgroundAlgorithm overviewTraining implementationExperimentationChallengesReferencesBackgroundInvestigated by MSR in OsloShipped with July Tree 2010 (Denver)GoalsSpe	0.33773799548699734
Dynamic Ranking Overview2	Production Models OverviewLU annotates incoming text input with semantic information in a contextual wayWorkflow built on top of Bing production infrastructure (QAS/XAP/Object Store)Feature representation: word embedding, n-grams and lexicons matche	0.3372872555879755
Dynamic Ranking Overview2	Anchor and Click Stream RankingSteven ZittrowerBing Local Search RelevanceHypothesisConverting local search’s unstructured and raw text streams into semi-structured forms will improve ranking and offer relevance benefits.TestUsing classifiers 	0.32965042139357903

Dynamic Conflation	Dynamic ConflationGanesh Poomal Girirajan  Kefeng                                                    Qiang WuAcknowledgementsChiping Tang: Helped us get the UPDR judgments for Training and Evaluation.Shital Shah, Aamer Mohammed: Helped us stam	0.47185921930050007
Dynamic Conflation	Containment and Conflation – Sprint  2Story DescriptionDone?In Demo?Implement and ship Segment Studio integration changes for Preconflation and MatchYYIdentify top K entity setYYRoot cause why entities have too many identifiersYY	0.36516283231722513
Dynamic Conflation	Competitive Query-Entity ClickMicrosoft ConfidentialMicrosoft ConfidentialGoalCreate a dataset that is readily available to utilize and analyze query-entity click patterns on competitive dataCompetitive Engine: GoogleMicrosoft ConfidentialCo	0.35851158672862593
Dynamic Conflation	Global relevance feature proposalFeature name: Title Match OptimizationPMJin GuoDevJia LiuTestReleaseALTeam site linkExecutive SummaryTitle is the summary/abstract of the document. Title Match is very important to SBS. Through many c	0.33624623880809223
Dynamic Conflation	Index Quality UpdateAgendaMetrics UpdateSelection Model ImprovementRecall TierOffice ImprovementChallenges and Pain PointsHow to measure index quality?Ideally: sampling from all “good” images and see how much we covered.sampling from a	0.32096802045453765
Dynamic Conflation	Tiger MigrationKefeng Deng6/15/2015Microsoft ConfidentialTiger MigrationMotivationTiger IntroductionHow do we get thereCurrent statusRemaining works6/15/2015Microsoft ConfidentialMotivationSame index serve architecture as Satori 	0.3121802669501649
Dynamic Conflation	Microsoft ConfidentialSeptember 14, 2016Relevance Next and Artificial IntelligenceRelevance and Intent OffsiteFebruary 8thOur PrioritiesExpand our Capabilities towards a full fledged AGI Engine, with focus on Knowledge, NL/Semantic Understandi	0.3100958141456045
Dynamic Conflation	Deal Ranking ImprovementsDeal Understanding ImprovementsGoal: Increase general deal coverage (deal product type from specific to general).Solution: Identify the prefix and suffix of title by punctuations and prep. Remove the prefix and suffix from t	0.30040826350208905
Dynamic Conflation	Introduction to dynamic ranking Xiao WuOutlinesIntroductionRelevance MeasurementDynamic rankingRanking FeaturesRanking DataRanking modelsRelevance ExperiementIntroductionWhat is dynamic rankingRanking based on query dependent featu	0.29713522701377076
Dynamic Conflation	Microsoft ConfidentialSeptember 14, 2016Relevance Next and our Path to AGIAll HandsFeb 10th 2016Relevance Next and our Path to AGIRelevance OpportunitiesAGI: Project Turing Relevance PowerSubstrate RelevanceDemos! Q&AAgendaFY16	0.2958161031256204

Dsats_20120521	DSAT Mining & LSRBhagirath AddepalliCUV Log Based DSAT IdentificationIdentifying Google Local Answer Clicks from CUV LogsFor local queries, Google pushes users to search on MapClicking on Map results in url of type: https://www.google.com/webhp?	0.5777297214963923
Dsats_20120521	IQ Team RecapH1 2016FY16H1 AccomplishmentsTeamSSRxen-* Desktop SBSen-* Mobile SBSen-* Semantic SBSCore Web Relevance0.55/0.62.46/3.02.65/3.01.88/2.0Adult LeakageSpamJunkCQDCGMPCMALTABing@WorkSubstrate0.02/0.01	0.3997143185421635
Dsats_20120521	The Data Skew ProblemFei Xu2/27/2018The Scheduled TalksMarch 18th Dave Maltz – OSD future network March 25th Pat – TBD April 1st Pat – TBDApril 8th Brad – Terasort in 12 minutesApril 15th Eric – The Global Scheduler April 22nd Brian – 	0.36924730108799836
Dsats_20120521	NTCG DebuggingSteven Zittrower01/30/2015AgendaNTCGNTCG DashboardOverview of BLU Architecture (Address Specific)Address Debugging in QATNTCGNTCG (Normalized Total Cumulative Gain) is a composite metric that measures address query releva	0.36500006171803395
Dsats_20120521	ML Model Scorecard Analysis8/8/2019Unexpected term search movementhttps://exp.microsoft.com/xcard/?view=4e77b420-7b77-4e41-92ac-8e84f506fb01Check correctness of scorecard metric implementationCalculate term AVG rank from raw data streamsSearch	0.35253292461629926
Dsats_20120521	Windows Search RS5July 9, 2018ContextCortana branded searchbox in taskbar has two key experiences:A speech first Cortana NL experienceA search first typing experience – we refer to this as Windows SearchWindows Search Key StatsUSERS: 160m mo	0.3401305759005474
Dsats_20120521	LDCG V3Knowledge Transfer2017-04-14Brett Clippingdale, Sean King, Vikas Mittal, Li JiangLDCG V3 OutlineLDCG V2 vs V3: High-level comparisonLDCG V3: New distance ModelV2 vs V3 OverviewLDCG V3: GeoIntent HIT appLDCG V3: Calculate distance 	0.3300712711921636
Dsats_20120521	Author: Tony AngellDate: 08/01/13LocalProbe Improvements for Corrections Analysis and DebuggingTable of ContentsP0 Issues	2Issue: LocalProbe is unpredictable in the amount of time it takes to return a query and how long it takes to investigate a	0.31409818337874384
Dsats_20120521	Local Junk Detection and DemotionJia Liu2017-06-14GDP Pipeline View: local data pipelineTriple StoreGOALStore every entity as a set of triples.Track all changes to an entity.TripleColumnDetailsSubjectThe guid of a triple’s pa	0.31231987848058496
Dsats_20120521	ODP Classification: Summarizing Pages as a Topic DistributionNov 17, 2010Paul Bennett (pauben), MSR CLUESJoint work with Max Chickering & Susan Dumais© 2006 Microsoft Corporation. All rights reserved. Microsoft, Windows, Windows Vista and ot	0.31115601081101424

DomainAuthority	Domain Authority CAL One PageIntroductionCurrent shipped ngram domain authority in L3 is using complete query match against an offline generated meta-stream (q, url, score), which derives (q,url) pairs from click stream and is the result of aggregatio	0.45621678053626435
DomainAuthority	MQ for CALOverviewSpellerQASMQTriggerMQSingleQueryChainChainChainAugmentAugmentAugmentTailQuerySimplifiedSPCombSP1SP2Sp3AugmentAugmentPropertyBag - SQQueryAlterationListQueryAlterationSetQueryAlterationType	0.31437070628406616
DomainAuthority	Normalization and Parsing OverviewTypes of NormalizationLimiting to just normalization, there are actually several different types of normalization which may be interesting:WhitespaceThis is:Converting all whitespace characters to spacestrippi	0.2881865994228614
DomainAuthority	Document classification based on urlBackgroundWe want to do document classification for better understanding the document type and document with query category match for ranking.  We will do zh-cn document classification based on url first, then docum	0.22021907092421494
DomainAuthority	Author: Tony AngellDate: 08/01/13LocalProbe Improvements for Corrections Analysis and DebuggingTable of ContentsP0 Issues	2Issue: LocalProbe is unpredictable in the amount of time it takes to return a query and how long it takes to investigate a	0.21601927713386035
DomainAuthority	Translation Model in Local Search- Shu HuangIntroductionTranslation model in web searchOdpTitle translation model in local searchData preparationModel trainingGenerate new metastreamIntroductionTranslation model used in web searchLea	0.20970569114367313
DomainAuthority	BusinessV3TaxonomyClassifierAugust, 2018Daniel WeinshenkerMicrosoft ConfidentialAgendaMicrosoft ConfidentialPurpose / OverviewDemoData Pipeline / Lexicon GenerationMeasurementQASChallenges / Future WorkPurpose We want to improve 	0.20946510431797047
DomainAuthority	Discover More – RestaurantsJune, 2018Daniel WeinshenkerMicrosoft ConfidentialOverview Suggests cuisines, dishes, amenities, and nearby POIs to users searching for restaurants Top 50 cities in the USA suggest the followingWell-known dishes 	0.209243152933877
DomainAuthority	OSG Threshold[Cortana/Improving Cortana Personalization Through Finances]functional specification[Shell/CAST]CONTACTSROLEName; AliasProgram ManagerColleen Hamilton; chamiltDeveloperQualityDesignPartner(s)ONE PAGE SPEC - Guideline	0.2076910021552142
DomainAuthority		0.20604142855680926

Distance-Aware Local Search_animation	Distance-Aware Local SearchZhao Zhout-zhazho@microsoft.comOutlineProject Goal and MotivationMethodologyExperimental ResultsConclusionBackgroundEntities having LatLonNew York City (40.7127,-74.0059) Facing East Restaurant (47.619905, 	0.4897510070905402
Distance-Aware Local Search_animation	L3 Distance Model for LocalNikita Melnichenko, Bing Local2016-04-12AgendaIntroduction to the Distance problemPrevious workA new approach: experiments and designResultsFuture developmentIntroduction to the Distance problemWe say “it’s a	0.35034139424760674
Distance-Aware Local Search_animation	Local Search Platform PM Onboarding GuideAuthors: Dany DaherDate: 10/18/2013Architecture OverviewHow Local Search Works Local Data Platform Architecture MetricsLocal Metrics:  http://jeffke/localMetrics/Definition of QLDCG: Local Discoun	0.2977084184804759
Distance-Aware Local Search_animation	Restaurants Features and ToolsReview SnippetXAPOSearchQueryWPOLERWPO OSCacheItemCacheIdList of YpIdsFiltersSorterEntityUpdate PostFixEntity Update OSCache IdCache ItemYpId and PostFixUXReview Snippet Data GroupCac	0.29085011440005637
Distance-Aware Local Search_animation	Integrating Knowledge Graph in Web SearchEntity Triggering and CollectionsPresenter: Ze TianKnowledge GraphEntities and RelationsEntities: celebrities, people, generic terms (e.g. light bulb)Relations: sibling, spouse, people and their works	0.24184616828424094
Distance-Aware Local Search_animation	Distance Model, LDS, L3Knowledge SharingNikita Melnichenko, Bing Local2017-04-21Overview of PBA relevance flow in FeedsL1Keyword matchWPOL2 levelRankerTruncationCategory matchName matchLogical DistanceUI sortingGIMXIMGDM	0.23439882118726127
Distance-Aware Local Search_animation	Decision Tree Ensemble decodeAdaboost Decision tree:A forest.  One feature can be multiple nodes.Support Market checkingWord/entity classificationOne or more feature set inputMeaning[DecisionTree]Roots=90  (tree number)Nodes=630 (all n	0.23045769883435982
Distance-Aware Local Search_animation	Local Search Online Learning Lihong LiFengxia PanAgendaOnline LearningBiased user engagement dataLocal results positional bias estimation method & ExperimentOffline click evaluatorL2 ranker improvement using online click dataExperiment &	0.22325794848690042
Distance-Aware Local Search_animation	 Core Web RelevanceInformation Platform GroupBing Spam & JunkFeature OwnersProgram ManagersMichael AbboudDevelopersPavel Karpovich, Lidong Zhao, Gregory Minasyants, Ashok Ponnuswami,  Eugene Remizov, Mikhail BorbotDev ManagerLuke ChenM	0.22196933732070345
Distance-Aware Local Search_animation	TopChainNumber MasterId Label Type Name Phone AddressLine City Website Closed LastYearImpression LCMScore ChainId ChainName Score LPLink SparsedFeatureVector r 873x114637191399090866 0 http://maps.google.com/maps/place?cid=14233605658129796921 Ion Bank 36	0.22063354952332462

Disitributed Deep Learning-Tie-Yan Liu	Distributed Deep Learning: New Driving Force of Artificial IntelligenceTie-Yan LiuPrincipal Researcher Microsoft Research AsiaAI Is Making Break-through!2016/12/21Tie-Yan Liu -  Distributed Deep Learningvs.Sedol LeeAtari Games“Deep	0.503454928852053
Disitributed Deep Learning-Tie-Yan Liu	Augmented Query Parser Using Deep LearningDemi Guo (Bing Local Intern t-deguo)Manager: Leon ZhangMentor: Simona CabuzHello everyone, Today, I’m going to present my intern project: Augmented query parser using deep learning.About Me My name i	0.4926028600433175
Disitributed Deep Learning-Tie-Yan Liu	To whom it may concern,The bearer of this letter is my sister, Yan Liu. My name is Jia Liu, and I am a software engineer employed by Microsoft. I am working here on an L1 visa valid until 2019. I have invited my parents, my sister, and her son to come v	0.4737583331157494
Disitributed Deep Learning-Tie-Yan Liu	To whom it may concern,The bearers of this letter are my parents and nephew.  My name is Jia Liu, and I am a software engineer employed by Microsoft.  I am working here on an L1 visa valid until 2019.  I have invited my parents, my sister, and her son t	0.44514348094596345
Disitributed Deep Learning-Tie-Yan Liu	To whom it may concern,  We are Jia Liu and her husband, Edward Wild.  The bearers of this letter are Jia's mother, Chunxiang Lei, and father, Xinbao Liu.  Jia is a software engineer working at Microsoft on an L1 visa valid until 2020, and Edward is a	0.4414603112972377
Disitributed Deep Learning-Tie-Yan Liu	Bing Location Understanding (BLU) As a ServiceDeep-Dive PresentationRajasi Saha (tech lead for BLU infrastructure)Jian Wu (tech lead for BLU relevance)Microsoft ConfidentialOutlineIntroduction to BLUBLU as a serviceMotivationScenarios an	0.4361526875025669
Disitributed Deep Learning-Tie-Yan Liu	6/8/2016To Whom It May Concern:Re:	Jia LiuThis letter is to confirm that Jia Liu was employed at Microsoft (China) Company Limited in Beijing, China from March 30, 2012 to June 21, 2015.  She worked full time, 40 hours per week.  Sincerely,Xue B	0.43295368725467265
Disitributed Deep Learning-Tie-Yan Liu	To whom it may concern,We are Xinbao Liu and Chunxiang Lei, a married couple.  We are citizens of China visiting our daughter and son-in-law in Bothell, Washington on valid US B-2 visas.  Our daughter, Jia Liu is a citizen of China residing in the Unite	0.42071897773755856
Disitributed Deep Learning-Tie-Yan Liu	Deep Learning: The Path ForwardTuring/AGI/WITSaurabh TiwaryGoalsStrategyDL first everywhereScaleAGI-fying building blocksNew ScenarioLight up T@W & Unified QUDL-firstWe have been hedging our effortsLet’s do (a little bit of) everyt	0.4089850790817023
Disitributed Deep Learning-Tie-Yan Liu	Country Level Market FY13 Goal Delivered - Neon Speller Delivered - Neon CAL Delivered - Neon Delivered - Sodium CAL Delivered - Sodium Speller Delivered - Sodium FY13 Remaining Metric Australia Very Deep en-AU NDCG - Overall Brazil Very Deep pt-BR 0 NDCG	0.40117541751475405

Discover More – Restaurants	Discover More – RestaurantsJune, 2018Daniel WeinshenkerMicrosoft ConfidentialOverview Suggests cuisines, dishes, amenities, and nearby POIs to users searching for restaurants Top 50 cities in the USA suggest the followingWell-known dishes 	0.4089656220378945
Discover More – Restaurants	L3 Distance Model for LocalNikita Melnichenko, Bing Local2016-04-12AgendaIntroduction to the Distance problemPrevious workA new approach: experiments and designResultsFuture developmentIntroduction to the Distance problemWe say “it’s a	0.21310992712536594
Discover More – Restaurants	Restaurant segment metrics collectionObjectiveTo understand user behavior/engagement on Restaurant answers.Why this is important? The metrics will help us understand:The comparisons between different answersWhat is important to our users and w	0.21301363482966995
Discover More – Restaurants	Adaboost算法总结Adaboost原理AdaBoost是英文"Adaptive Boosting"（自适应增强）的缩写，由Yoav Freund和Robert Schapire在1995年提出。AdaBoost 是一种迭代算法，其核心思想是针对同一个训练集训练不同的分类器，即弱分类器，然后把这些弱分类器集合起来，构造一个更强的最终分类器。算法本身是改变数据分布实现的，它根据每次训练集之中的每个样本的分类是否正确，以及上次的总体分类的准确率，来确定每个样本的权值。将修改权值的新数据送给下层分类	0.2048792116741354
Discover More – Restaurants	Mobile 100k Compete Data analysis with G - Simulation Report6/6/2014Mobile Simulation AnalysisThis analysis compares Google and Bing on iOS for 3 querysets.REPORTS GENERATED FOR **: Overall Metrics Coverage (WP, ML and Bot)IY (WP, ML and Bot	0.19319102294649168
Discover More – Restaurants	Core Web RelevanceFY16 H2 PlanCore Web RelevanceFY16 H2 PlanCore Web RelevanceFY16 H2 PlanCore Web RelevanceFY16 H2 Plan	0.191630810046689
Discover More – Restaurants	Distance-Aware Local SearchZhao Zhout-zhazho@microsoft.comOutlineProject Goal and MotivationMethodologyExperimental ResultsConclusionBackgroundEntities having LatLonNew York City (40.7127,-74.0059) Facing East Restaurant (47.619905, 	0.18597600733367808
Discover More – Restaurants	SmartRelax training and evaluation from 15%/15% flightForay scorecard: 15%+15% datagatheringUser-triggered scorecardSSRx gain of 0.12%, for 3+4 word on vs. 3+4 word off. (NOT vs. prod.)Gain is 36% from SSR, 11% from TTS, 52% from TSRSSRx gains s	0.18037405661147088
Discover More – Restaurants	Decision Tree Ensemble decodeAdaboost Decision tree:A forest.  One feature can be multiple nodes.Support Market checkingWord/entity classificationOne or more feature set inputMeaning[DecisionTree]Roots=90  (tree number)Nodes=630 (all n	0.170562685817233
Discover More – Restaurants	TopChainNumber MasterId Label Type Name Phone AddressLine City Website Closed LastYearImpression LCMScore ChainId ChainName Score LPLink SparsedFeatureVector r 873x114637191399090866 0 http://maps.google.com/maps/place?cid=14233605658129796921 Ion Bank 36	0.16678701476078703

DemoFest Leveraging Satori Knowledge in Web Ranking Stack	Leveraging Satori Knowledge Graph in Web Ranking StackMicroSegment and Index ServeThe demo is about how to leverage Satori Knowledge Graph in Web ranking. It is joint work among relevance microsegment, Satori and index serve teams.MotivationSome	0.7641855091389623
DemoFest Leveraging Satori Knowledge in Web Ranking Stack	Leveraging Satori Knowledge in Web Ranking StackMicroSegment and Index ServeMotivationTarget at semantic queries (*defined by MALTA)Often contain more than one entity and relationSometimes involve entity inferenceTerm matching may not handle s	0.6429518500324234
DemoFest Leveraging Satori Knowledge in Web Ranking Stack	L2 Ranker Training and Feature Management						-- Shu HuangOutlineL2 ranker and truncation rankerFeature extractionFake L2 rankerFeature extraction pipelineMutiple ideal querysetsL2 ranker and truncation rankerFind the current prod ran	0.4119361152157767
DemoFest Leveraging Satori Knowledge in Web Ranking Stack	Deal Ranking Improvement & MeasurementBackgroundAfter we shipped deal understanding, bad deals filtering, deal ranking for the entity search deals and popular deals nearby. We want to measure and improve our deal ranking based on user behaviors. We ca	0.3965393973960334
DemoFest Leveraging Satori Knowledge in Web Ranking Stack	Content Quality Classification & RankingGuihong Cao, Cheng NiuContent Quality for RankingContent quality = originality + trustworthy + information satisfaction + freshnessSpam sites, junk site, link farm, content farm, ….Search users are interes	0.3932120146774327
DemoFest Leveraging Satori Knowledge in Web Ranking Stack	Tmall&Taobao Rating MetawordsBackgroundWe’ve seen in regular DSAT review meetings the DSATs that we rank too high Tmall or Taobao page with low quality(Tmall page:low sales volume; Taobao page: low sales volume or shop with poor reputation).  Zh-CN ha	0.3900667673250896
DemoFest Leveraging Satori Knowledge in Web Ranking Stack	Local Search Online Learning Lihong LiFengxia PanAgendaOnline LearningBiased user engagement dataLocal results positional bias estimation method & ExperimentOffline click evaluatorL2 ranker improvement using online click dataExperiment &	0.38452944305956926
DemoFest Leveraging Satori Knowledge in Web Ranking Stack	Wrapstar rating signalsfor zh-cn documentsJia LiuWrapstar rating signals for rankingWrapstar Taobao ratingWrapstar Tmall ratingWrapstar Qna ratingWrapstar Book ratingWrapstar Video ratingDsats examplesTaobao examplesQuery=“蓝色休闲裤	淘宝”	0.3450187883542258
DemoFest Leveraging Satori Knowledge in Web Ranking Stack	Partner Index as ServiceWhat is the Problem? RequirementCurrent status of Bing Image StackDiscoveryClient tend to provide feed for full corpusWeb crawlerImage Content RetrievalSpecial agreement, some even behind authentication for access	0.34366815394377226
DemoFest Leveraging Satori Knowledge in Web Ranking Stack	Local Category Search StudyHuanan Zhang01/03/2018OutlineStructure of PBA (Prod) rankerIntent match ranker’s role in Prod rankerIssues of intent match rankerSolutions – metastream clean upMetastream measurementPreliminary resultsPBA	0.34234778624750256

Deep Relax	Deep RelaxQuery Relaxation and L1 FidelityQuery Relaxation{printable iphone 7 user guide}rankonly:printable iphone 7 rankonly:user guiderankonly:printable iphone 7 user guideDeep Relax and vector similarity Encode query without each toke	0.5047645315891115
Deep Relax	SmartRelax OFE and TrainingOverviewAnalysis of smartrelax flightsOFE flight simulatorIs smartrelax ever bad?Smartrelax model training:Training method I: relax-specific targetsTraining method II: end-user targetsSmart Relax OFE and Training	0.18831386229809405
Deep Relax	Relaxcount=2 summaryRelaxcount=2 datagatheringDatagathering for relaxcount=2 branched path (3/14/15-3/20/15):Cal13a: control (OFE logging, relaxcount=2 off), 6% trafficCal13b: on (OFE logging, relaxcount=2 on for word count >=5), 12% traffic.Dat	0.17481098363687375
Deep Relax	Deal Understanding and RankingBackgroundDeal is a very big segment in Bing Opal. We crawl store and single deals/coupons regularly from websites like groupon.com, coupons.com, restaurants.com, retailmenot.com, dealcatcher.com, dealplus.com and so on. 	0.17113089663966066
Deep Relax	Deal Ranking Improvement & MeasurementBackgroundAfter we shipped deal understanding, bad deals filtering, deal ranking for the entity search deals and popular deals nearby. We want to measure and improve our deal ranking based on user behaviors. We ca	0.14541138020901018
Deep Relax	Bing IQ Deep Learning ProgressAlejandro Gutierrez, Anton Savin, Frank Guo, Luis Velazco, Gilbert Wong7/22/2016Overall Plan and PrioritiesLearn Deep Learning and Neural NetworkLearn CNTK (Computational Network Toolkit) by walking through the exam	0.14360342353403613
Deep Relax	cal deepdiverelaxationdec 2017AgendaProduct GoalsQuery SimplificationMechanism/RuntimeCRF Model TrainingQS Path SelectionOffline SimulatorSmart RelaxMechanism & TrainingRelaxation: ImpactRelaxation: Product goalsImprove Rec	0.13987500870775385
Deep Relax	SmartRelax training and evaluation from 15%/15% flightForay scorecard: 15%+15% datagatheringUser-triggered scorecardSSRx gain of 0.12%, for 3+4 word on vs. 3+4 word off. (NOT vs. prod.)Gain is 36% from SSR, 11% from TTS, 52% from TSRSSRx gains s	0.12801985306753366
Deep Relax	浅谈Redis的原理与应用tianzhedong（董天喆）大纲What is RedisWhy RedisHow To Use RedisWhat Is RedisWhat is RedisWhat is Rediskey value store可以持久化的cacheHashTableMemory DB它的高性能都是基于内存操作的基础data structure serverRedis支持复杂的数据特性，比如List, Set等Redis	0.12386539408372421
Deep Relax	Bing Location Understanding (BLU) As a ServiceDeep-Dive PresentationRajasi Saha (tech lead for BLU infrastructure)Jian Wu (tech lead for BLU relevance)Microsoft ConfidentialOutlineIntroduction to BLUBLU as a serviceMotivationScenarios an	0.12145546651220049

Decision Tree Ensemble decode	Decision Tree Ensemble decodeAdaboost Decision tree:A forest.  One feature can be multiple nodes.Support Market checkingWord/entity classificationOne or more feature set inputMeaning[DecisionTree]Roots=90  (tree number)Nodes=630 (all n	0.7643790490680249
Decision Tree Ensemble decode	FastRank--- a Decision-Tree based Ranking ModelYu SHIOutlineBackgroundAlgorithm overviewTraining implementationExperimentationChallengesReferencesBackgroundInvestigated by MSR in OsloShipped with July Tree 2010 (Denver)GoalsSpe	0.37090605894146833
Decision Tree Ensemble decode	Deal Understanding and RankingBackgroundDeal is a very big segment in Bing Opal. We crawl store and single deals/coupons regularly from websites like groupon.com, coupons.com, restaurants.com, retailmenot.com, dealcatcher.com, dealplus.com and so on. 	0.3292590120692915
Decision Tree Ensemble decode	[PLEASE REMOVE THIS TEXT AND BRACKETSANDPRINT ON COMPANY LETTERHEAD]INSERT DATETo Whom It May Concern:Re:	Jia LiuThis letter is to confirm that Jia Liu was employed at Microsoft (China) Company Limited in Beijing, China from March 30, 2012 to 	0.3196569255493127
Decision Tree Ensemble decode	Relevance and AIBing and Information Platform GroupFY18 AGI Encoder RoadmapFeature OwnersProgram ManagersNitin SharmaDevelopersSaurabh Tiwary, Gargi GhoshResearchersMarketingPartnersYantao Li, Weihu, GuihongOverviewAGI Encoder go	0.31588655137864213
Decision Tree Ensemble decode	Name Entity Recognition based on Perceptron modelBackgroundWe have many name entity DSATs like user searched name “XYZ”, and the results may be “XY”,”YZ” or “XYW” related. We have done QU name entity recognition for zh-cn market already. So we want to	0.30802007944435644
Decision Tree Ensemble decode	cal deepdiverelaxationdec 2017AgendaProduct GoalsQuery SimplificationMechanism/RuntimeCRF Model TrainingQS Path SelectionOffline SimulatorSmart RelaxMechanism & TrainingRelaxation: ImpactRelaxation: Product goalsImprove Rec	0.30242146982387924
Decision Tree Ensemble decode	Entity Selection Pipeline Design DocScope:This document covers the design for entity selection pipeline in GDPV3. Near-Dupe clustering is not covered in this v1 version. The goal for this pipeline is to reduce junk rate and improve NII by stamping pub	0.29041620864580975
Decision Tree Ensemble decode	WrapStar On-Demand DesignDrafted by ZiliuContentsContext2Design Goals2Automation2Deployment Agility2High Availability2Non-Goals2Metrics2Required Changes3Orchestration3AP Migrations3Pipeline Evolution3Tools/services refactoring3	0.28964099238521235
Decision Tree Ensemble decode	Local Category Search Plan3 month StrategyData: Entity categorizationScalable, high precision/recallSegments: Food & Drink, Retail, Service, Auto, HotelMetaStream enrichmentQuery UnderstandingDolphin by defaultConsume PhoneBookQU to im	0.28522639066521016

Debug Address Queries	Successful Feeds Query DebuggingNikita Melnichenko, 2015-03-10Feeds query debugging overviewWhen to use:Checking a new rankerChecking new augmentation before running a scrapeComparing several rankersUnderstanding feature contributionDebugg	0.5118244169036827
Debug Address Queries	Analyzed Query represents all information derived from all classification tasks executed on the Query. QAS supports 3 basic classifications tasks: binary classification (Domain Classification), entity extraction (Query Parse), category classification (Dom	0.4927519978913105
Debug Address Queries	Debug Address Queries8/23/2013Bing Local Search RelevanceNTCG MetricsDocumentationhttps://microsoft-my.sharepoint.com/personal/aoakley_microsoft_com/Documents/2013/2013-05-22%20Maps%20metrics%20Qi.pptx?web=1Use it to identify the group of quer	0.45787784048380287
Debug Address Queries	Run web-search-like query against my dataSame Bing Web Search Indexing and Ranking engineIndex in a secondTransparent and real time index sync, no complex index-gen pipelinePrototype in an hourFast self-onboarding with freemium account, schema-d	0.41239012711905704
Debug Address Queries	PBA Dependency and DebugMing Wu2014-01-28PBA DependenciesLocation Understanding (LES/BLU)Location info (explicit/implicit) – fulfill detailed location infoProvide location related features to phonebook CRFXapQuServiceAnswer (QAS)For most c	0.40941600639247305
Debug Address Queries	Publication date optimization for Japan marketBackgroundPublication date is very important to fresh queries, outdated issues and caption date showing. Now the coverage of publication date for Japan market is very low because publication date extract	0.39360857257909854
Debug Address Queries	Simplified Query Path SelectorSimplified query: current systemSimplified query path selectionCrf model produces a list of possible ways to place rankonly operatorQuery = “nibbana restaurant official site”nibbana restaurant rankonly:official site	0.3642954052473528
Debug Address Queries	QueryString Category owner Searchvote url 寇仲最后和谁在一起 ranking  xiaopeng http://searchvote.com/default.aspx?reviewid=209877 布里斯班 ranking  xiaopeng http://searchvote.com/default.aspx?reviewid=211685 必应词典 ranking  xiaopeng http://searchvote.com/default.aspx?re	0.3628562573335218
Debug Address Queries	query分类—分享                     刘佳2011.6.8web query classification(query分类):	将web search query根据它的主题，分派到1个或者多个预先定义的分类中。web search query的特征：有噪声：拼写错误等长度很短：信息量少，特征少表意含糊：query可能包含多个含义,属于多个分类含义会随时间演变目标分类的特征：目标分类定义缺少语义注解一级或者多级分类分类数目：几	0.35425480253525404
Debug Address Queries	LEDB Transition8/6/2014ScopeLEDB serialization jobsLEDB Object Store publish jobsLEDB Odyssey Publish job for the VanueMap featureEntity Schema update and maintenanceObject Store payload size and perf SLAPartner engagement and change manag	0.35132125831968747

DealTypes	Deal Ranking Improvement & MeasurementBackgroundAfter we shipped deal understanding, bad deals filtering, deal ranking for the entity search deals and popular deals nearby. We want to measure and improve our deal ranking based on user behaviors. We ca	0.35411028723671983
DealTypes	Deal Ranking ImprovementsDeal Understanding ImprovementsGoal: Increase general deal coverage (deal product type from specific to general).Solution: Identify the prefix and suffix of title by punctuations and prep. Remove the prefix and suffix from t	0.33231507994023596
DealTypes	Deal UnderstandingDeals with Low Quality: (some features/rules are listed below)Features/RulesExamplesNo user used; no verified informationThe policies about return365 Day Return Policy;Free Returns on All Orders; 45 Day Return Money Back 	0.25982924514970107
DealTypes	Deal Understanding and RankingBackgroundDeal is a very big segment in Bing Opal. We crawl store and single deals/coupons regularly from websites like groupon.com, coupons.com, restaurants.com, retailmenot.com, dealcatcher.com, dealplus.com and so on. 	0.2345969005458567
DealTypes	alterationsalterations: product goalimprove recallby adding terms (not replacing or dropping user-entered terms)using word:which are synonyms to the original terms(we are re-examining each of these for vnext)alterations: general principl	0.22069711723505622
DealTypes	Named Entity RecognizerTao Peng and Kang LiEntity names recognitionRecognize person, location and organization namesBOSTON, April  16 - Kevin Garnett helped the Boston Celtics beat the L. A. Lakers in last year's NBA final. ( Tony Gutierrez / Asso	0.21626255227339872
DealTypes	L-1B SPECIALIZED KNOWLEDGE QUESTIONNAIREMICROSOFT POSITION IN THE U.S.Provide the following information for your current position at the Microsoft.MICROSOFT POSITION ABROADProvide the following information for your position at the Microsoft’s su	0.19704212081912678
DealTypes	Decision Tree Ensemble decodeAdaboost Decision tree:A forest.  One feature can be multiple nodes.Support Market checkingWord/entity classificationOne or more feature set inputMeaning[DecisionTree]Roots=90  (tree number)Nodes=630 (all n	0.1916991887280528
DealTypes		0.19140621911549158
DealTypes	cal deepdiverelaxationdec 2017AgendaProduct GoalsQuery SimplificationMechanism/RuntimeCRF Model TrainingQS Path SelectionOffline SimulatorSmart RelaxMechanism & TrainingRelaxation: ImpactRelaxation: Product goalsImprove Rec	0.13389487815115808

Deal Understanding And Ranking	Deal Ranking Improvement & MeasurementBackgroundAfter we shipped deal understanding, bad deals filtering, deal ranking for the entity search deals and popular deals nearby. We want to measure and improve our deal ranking based on user behaviors. We ca	0.6269776633990709
Deal Understanding And Ranking	Deal Understanding and RankingBackgroundDeal is a very big segment in Bing Opal. We crawl store and single deals/coupons regularly from websites like groupon.com, coupons.com, restaurants.com, retailmenot.com, dealcatcher.com, dealplus.com and so on. 	0.6102530697339417
Deal Understanding And Ranking	Deal Ranking ImprovementsDeal Understanding ImprovementsGoal: Increase general deal coverage (deal product type from specific to general).Solution: Identify the prefix and suffix of title by punctuations and prep. Remove the prefix and suffix from t	0.5007076977806204
Deal Understanding And Ranking	Deal UnderstandingDeals with Low Quality: (some features/rules are listed below)Features/RulesExamplesNo user used; no verified informationThe policies about return365 Day Return Policy;Free Returns on All Orders; 45 Day Return Money Back 	0.3488896952882139
Deal Understanding And Ranking	Google Mobile vs Desktop RankDiff StudyNov 2017GoalsUnderstand what Google does differently on Mobile, if anythingDrive product ideas & shape ranking improvements on MobileUnderstand any possible impact to Algo scrapes & metricsDrive scrapin	0.3240009850791462
Deal Understanding And Ranking	CAL MultiQuery {Matching\Ranking}		Page 3 of 4CAL MultiQuery {Matching\Ranking}DescriptionCAL is going to optimize against matching\ranking separately and will issue different queries to each tier. CAL will be leveraging several operator such as:m	0.29300349705763357
Deal Understanding And Ranking	FastRank--- a Decision-Tree based Ranking ModelYu SHIOutlineBackgroundAlgorithm overviewTraining implementationExperimentationChallengesReferencesBackgroundInvestigated by MSR in OsloShipped with July Tree 2010 (Denver)GoalsSpe	0.27093728880920015
Deal Understanding And Ranking	Content Quality Classification & RankingGuihong Cao, Cheng NiuContent Quality for RankingContent quality = originality + trustworthy + information satisfaction + freshnessSpam sites, junk site, link farm, content farm, ….Search users are interes	0.26465568490509306
Deal Understanding And Ranking	Tmall&Taobao Rating MetawordsBackgroundWe’ve seen in regular DSAT review meetings the DSATs that we rank too high Tmall or Taobao page with low quality(Tmall page:low sales volume; Taobao page: low sales volume or shop with poor reputation).  Zh-CN ha	0.2473973917844422
Deal Understanding And Ranking	Wrapstar rating signalsfor zh-cn documentsJia LiuWrapstar rating signals for rankingWrapstar Taobao ratingWrapstar Tmall ratingWrapstar Qna ratingWrapstar Book ratingWrapstar Video ratingDsats examplesTaobao examplesQuery=“蓝色休闲裤	淘宝”	0.22201620626758584

Deal Ranking Improvements	Deal Ranking Improvement & MeasurementBackgroundAfter we shipped deal understanding, bad deals filtering, deal ranking for the entity search deals and popular deals nearby. We want to measure and improve our deal ranking based on user behaviors. We ca	0.7470670464088557
Deal Ranking Improvements	Deal Ranking ImprovementsDeal Understanding ImprovementsGoal: Increase general deal coverage (deal product type from specific to general).Solution: Identify the prefix and suffix of title by punctuations and prep. Remove the prefix and suffix from t	0.7051898008669858
Deal Ranking Improvements	Deal Understanding and RankingBackgroundDeal is a very big segment in Bing Opal. We crawl store and single deals/coupons regularly from websites like groupon.com, coupons.com, restaurants.com, retailmenot.com, dealcatcher.com, dealplus.com and so on. 	0.4628713201819035
Deal Ranking Improvements	Relevance Experimentation with DUOverviewThe ideal end state for any relevance improvement would consist of having one or more DU features shipped in the index that is then leveraged by the latest production ranker. This would achieve the highest leve	0.4315583702752247
Deal Ranking Improvements	FastRank--- a Decision-Tree based Ranking ModelYu SHIOutlineBackgroundAlgorithm overviewTraining implementationExperimentationChallengesReferencesBackgroundInvestigated by MSR in OsloShipped with July Tree 2010 (Denver)GoalsSpe	0.3954053649421876
Deal Ranking Improvements	Google Mobile vs Desktop RankDiff StudyNov 2017GoalsUnderstand what Google does differently on Mobile, if anythingDrive product ideas & shape ranking improvements on MobileUnderstand any possible impact to Algo scrapes & metricsDrive scrapin	0.33962748793711794
Deal Ranking Improvements	Wrapstar rating signalsfor zh-cn documentsJia LiuWrapstar rating signals for rankingWrapstar Taobao ratingWrapstar Tmall ratingWrapstar Qna ratingWrapstar Book ratingWrapstar Video ratingDsats examplesTaobao examplesQuery=“蓝色休闲裤	淘宝”	0.3350536135036843
Deal Ranking Improvements	L2 Ranker Training and Feature Management						-- Shu HuangOutlineL2 ranker and truncation rankerFeature extractionFake L2 rankerFeature extraction pipelineMutiple ideal querysetsL2 ranker and truncation rankerFind the current prod ran	0.33191758178281544
Deal Ranking Improvements	Content Quality Classification & RankingGuihong Cao, Cheng NiuContent Quality for RankingContent quality = originality + trustworthy + information satisfaction + freshnessSpam sites, junk site, link farm, content farm, ….Search users are interes	0.32152477171068977
Deal Ranking Improvements	Deal UnderstandingDeals with Low Quality: (some features/rules are listed below)Features/RulesExamplesNo user used; no verified informationThe policies about return365 Day Return Policy;Free Returns on All Orders; 45 Day Return Money Back 	0.30175825620431423

DU work items on zh-cn market	DU work items on zh-cn market　　Jia Liu2013-05-14AgendaSerp classifierWrapstar rating signalsTaobao, tmall; qna; novel; videoGeneral classiferUrl-basedTopic-basedPage number extractionName entity recognitionPerson, location, organiz	0.6821426344849333
DU work items on zh-cn market	How DUv2 worksZehua Liu, DU GDI Team12/6/2013 Q1: How to develop a DUv2 feature?Processor + Description fileQ2: How to guarantee monthly release?Q3: Difference between the development of DUv1 and DUv2 feature?DUv1: a) ProcessorCode  	0.45916766047447455
DU work items on zh-cn market	DU feature usage summary about en-us and zh-cn prod ranker:<more detail please refer to the attached report>Basics:99 APF in en-us Ranker.47 APF in zh-cn Ranker.41 APF appear both in en-us Ranker and zh-cn Ranker. 58 APF only appear in  en-us 	0.39568520383604966
DU work items on zh-cn market	DU items studyJia Liu2013-05-14AgendaPublication dateMain body blockDocument qualityurl static featuresPublication dateFreshness rankingYear in title, year in url, publication dateEn-us publication date coverage is ~20%Zh-cn public	0.37238130256214486
DU work items on zh-cn market	Zh-cn Document classification based on topicBackgroundWe want to do zh-cn document classification for better understanding the document type and topic. It can help ranking with document and  query category matching. We defined our category system: 69 	0.2995976938658906
DU work items on zh-cn market	11/17 AGI review with HarryCES: cover AI for OfficeCo-market with NvidiaMPQnA Keep in Jordi’s demo in the Dec AI eventAbortion query is very controversial	Not our responsibility to make the decision for the user but it’s the search engine’s re	0.2904099411580731
DU work items on zh-cn market	Publication date optimization for zh-cn marketBackgroundPublication date is a very fundamental and important feature. It can help fresh ranking, whole page user experience: caption date show and freshness internal metrics, also to solve mainline out	0.2900777750842731
DU work items on zh-cn market	Zh-cn Transportation Segment Optimization by Pattern EngineIntroductionThe pattern queries can cover almost 10% in all queries. We can summarize lots of patterns on Query and Document sides for different segments. We can recognize key terms, relations	0.28829076987518326
DU work items on zh-cn market	To Whom It May ConcernPage 2DATETo Whom It May Concern:Re:	Jia LiuI write to certify that Jia Liu worked as a Software Development Engineer at Microsoft (China) Company Limited (Microsoft China) in Beijing, China from March 30, 2012 to September	0.287712464675724
DU work items on zh-cn market	Page 23 of 26L2 General Title MatchDev: Jia Liu, Chuan Cao, Albert ZhouPM: Jin GuoDoc version: v1.0ContentsAbstract	2Project Status	2Goals	2Problem statement	3Architecture	3N-Gram Table	4Query Distribution in N-Gram Table	5Query 	0.2800526117240724

DU metawords study	DU items studyJia Liu2013-05-14AgendaPublication dateMain body blockDocument qualityurl static featuresPublication dateFreshness rankingYear in title, year in url, publication dateEn-us publication date coverage is ~20%Zh-cn public	0.40297739985524705
DU metawords study	Metrics Pipeline & ToolsJia Liu / Xiaohui Sun / Alex SergeevASG Data Mining TeamDemo link: http://dmsql05/MetricsDefinitionTool/MetricsDefinition.aspx?DataSet=BFT&MetricName=HasCortanaChitChatsTopicsBing Live Metrics PipelineUsage and Perf	0.38566311101166406
DU metawords study	DU Pipeline V2Bram Gruneir, Ted Wild and Connie YangDocument Understanding Dev Talk6/27/2013DU Pipeline V2: frequency demoIntroduce the demo featureDevelopmentDeploymentDU Pipeline V2: frequency demoIntroduce the demo featureDevelopmen	0.3782988201991282
DU metawords study	How DUv2 worksZehua Liu, DU GDI Team12/6/2013 Q1: How to develop a DUv2 feature?Processor + Description fileQ2: How to guarantee monthly release?Q3: Difference between the development of DUv1 and DUv2 feature?DUv1: a) ProcessorCode  	0.35583938772984114
DU metawords study	Translation ModelMei YangDU talk5/11/2011OutlineIntroduction to Machine Translation (MT)Introduction to phrase-based statistical machine translation (PBSMT)Translation Model @ DUFuture WorkIntroduction to MTTranslate one natural langua	0.35418320911380197
DU metawords study	Crawler Tech TalkOctober 14, 2008AgendaOverview of Msnbot Internal Data FlowFlow of Chunks and Chunk MetadataReal-Time MonitoringDaily Data Reporting SubsystemPrevious Instances Requiring InterventionPotential Future ProblemsQ&AMsnbot 	0.351266741982475
DU metawords study	L3 in LocalKefeng DengOutlineL3 IntroductionUse L3 in localL3 exampleL3 introductionFor Local: 28 IS machines per row, about 5 million entities per machine. MinBLA = 50L3 introductionL3 featuresSet featuresFeature Statistics for top 	0.34559349510723547
DU metawords study	Restaurant segment metrics collectionObjectiveTo understand user behavior/engagement on Restaurant answers.Why this is important? The metrics will help us understand:The comparisons between different answersWhat is important to our users and w	0.3232042980131604
DU metawords study	Generic Entity Extraction in Sodium Owner: Chuanxin HuContributors: Kang Li, Yi LiOverviewThe understanding of entities and their relationship is a one of the key pillars supporting the Bing’s strategic bet on the knowledge graph. Today, Satori ca	0.3035100466106341
DU metawords study	Tmall&Taobao Rating MetawordsBackgroundWe’ve seen in regular DSAT review meetings the DSATs that we rank too high Tmall or Taobao page with low quality(Tmall page:low sales volume; Taobao page: low sales volume or shop with poor reputation).  Zh-CN ha	0.29383746716397724

DU items study	DU items studyJia Liu2013-05-14AgendaPublication dateMain body blockDocument qualityurl static featuresPublication dateFreshness rankingYear in title, year in url, publication dateEn-us publication date coverage is ~20%Zh-cn public	0.4002308226198333
DU items study	How DUv2 worksZehua Liu, DU GDI Team12/6/2013 Q1: How to develop a DUv2 feature?Processor + Description fileQ2: How to guarantee monthly release?Q3: Difference between the development of DUv1 and DUv2 feature?DUv1: a) ProcessorCode  	0.3089267632489196
DU items study	DU Pipeline Sodium Achievements And Magnesium Plans　　Jia Liu2013-08-05OutlineSodium AchievementsMagnesium PlanMagnesium Work ItemsSodium Work ItemsAppendixSodium AchievementsWrapstar rating signalsTaobao, tmall; qna; novel; videoL3	0.2771424865969022
DU items study	A Step by step guide to Creating a new Block in the DU V2 PipelineThis document will demonstrate how to create a new block, including the testing and deployment for the new DU Pipeline.  To begin, if you do not yet have a block name, please send an em	0.25836420006548744
DU items study	DU work items on zh-cn market　　Jia Liu2013-05-14AgendaSerp classifierWrapstar rating signalsTaobao, tmall; qna; novel; videoGeneral classiferUrl-basedTopic-basedPage number extractionName entity recognitionPerson, location, organiz	0.24864582727868278
DU items study	Site Quality ClassificationGuihong CaoDefinition of the ProblemWhat is site quality?Google’s definition includes the following dimensionsDuplicated content within the siteTrustworthyOn demand media? Quality controlSite authorityAuthor 	0.23477154459002927
DU items study	Deep Dive: Query Generic Entity Extraction (GEE)Zhen Liao04/22/2016OutlineOverview of GEEFAQ for GEEArchitecture and ModelingRecent breakthrough via Deep LearningLessons we’ve learnedGeneric Entity Extraction for Queries: What is the g	0.2297669837265933
DU items study	Analyzed Query represents all information derived from all classification tasks executed on the Query. QAS supports 3 basic classifications tasks: binary classification (Domain Classification), entity extraction (Query Parse), category classification (Dom	0.22868021852598294
DU items study	DU Pipeline V2Bram Gruneir, Ted Wild and Connie YangDocument Understanding Dev Talk6/27/2013DU Pipeline V2: frequency demoIntroduce the demo featureDevelopmentDeploymentDU Pipeline V2: frequency demoIntroduce the demo featureDevelopmen	0.22169753119308333
DU items study	QU Deep Dive 2: Query Simplification and Recurrent Neural NetworkXiaolong Li (Lead of QU Fundamentals TEAM)2/12/2015AgendaQUFun Team ResponsibilitiesRecent Deliverables Query Simplification for WebQuery Simplification for Cortana 3ARec	0.21153334216801495

DU V2 Pipeline - Step by Step	DU Pipeline Sodium Achievements And Magnesium Plans　　Jia Liu2013-08-05OutlineSodium AchievementsMagnesium PlanMagnesium Work ItemsSodium Work ItemsAppendixSodium AchievementsWrapstar rating signalsTaobao, tmall; qna; novel; videoL3	0.6454899659264752
DU V2 Pipeline - Step by Step	DU Pipeline V2Bram Gruneir, Ted Wild and Connie YangDocument Understanding Dev Talk6/27/2013DU Pipeline V2: frequency demoIntroduce the demo featureDevelopmentDeploymentDU Pipeline V2: frequency demoIntroduce the demo featureDevelopmen	0.6450557277459557
DU V2 Pipeline - Step by Step	Jia Liu2013-08-05DU Pipeline Sodium Achievements And Magnesium Plans For CJK　　OutlineSodium AchievementsMagnesium PlanMagnesium Work ItemsSodium Work ItemsAppendixSodium AchievementsWrapstar rating signalsTaobao, tmall; qna; novel; v	0.5797023957400655
DU V2 Pipeline - Step by Step	A Step by step guide to Creating a new Block in the DU V2 PipelineThis document will demonstrate how to create a new block, including the testing and deployment for the new DU Pipeline.  To begin, if you do not yet have a block name, please send an em	0.557720531222859
DU V2 Pipeline - Step by Step	How DUv2 worksZehua Liu, DU GDI Team12/6/2013 Q1: How to develop a DUv2 feature?Processor + Description fileQ2: How to guarantee monthly release?Q3: Difference between the development of DUv1 and DUv2 feature?DUv1: a) ProcessorCode  	0.507142286876075
DU V2 Pipeline - Step by Step	Local Junk Detection and DemotionJia Liu2017-06-14GDP Pipeline View: local data pipelineTriple StoreGOALStore every entity as a set of triples.Track all changes to an entity.TripleColumnDetailsSubjectThe guid of a triple’s pa	0.4868388048851162
DU V2 Pipeline - Step by Step	LDCG V3Knowledge Transfer2017-04-14Brett Clippingdale, Sean King, Vikas Mittal, Li JiangLDCG V3 OutlineLDCG V2 vs V3: High-level comparisonLDCG V3: New distance ModelV2 vs V3 OverviewLDCG V3: GeoIntent HIT appLDCG V3: Calculate distance 	0.46874029554568997
DU V2 Pipeline - Step by Step	Entity Selection ModelJia Liu2017-11-08GDP Pipeline View: local data pipelineEntity TypesEntity Types:Open/CloseHead/TailNonJunk/JunkJunk TypesGhost: Local business existed beforeJunk: General name like “Lock smith”, “ATM”Move/Br	0.46501329682655673
DU V2 Pipeline - Step by Step	L4 Experiment PipelineDate: Aug 20th, 2013Author: Bangyong LiangMotivation:L4’s functionality is to merge results from multiple queries. L4 has two types of merging strategies. One is query level merger and the other one is document level merger. 	0.4516860318179949
DU V2 Pipeline - Step by Step	DU items studyJia Liu2013-05-14AgendaPublication dateMain body blockDocument qualityurl static featuresPublication dateFreshness rankingYear in title, year in url, publication dateEn-us publication date coverage is ~20%Zh-cn public	0.45092530991060553

DU Sodium Achievements and Magnesium Plans for CJK	DU Pipeline Sodium Achievements And Magnesium Plans　　Jia Liu2013-08-05OutlineSodium AchievementsMagnesium PlanMagnesium Work ItemsSodium Work ItemsAppendixSodium AchievementsWrapstar rating signalsTaobao, tmall; qna; novel; videoL3	0.8192278674799853
DU Sodium Achievements and Magnesium Plans for CJK	Jia Liu2013-08-05DU Pipeline Sodium Achievements And Magnesium Plans For CJK　　OutlineSodium AchievementsMagnesium PlanMagnesium Work ItemsSodium Work ItemsAppendixSodium AchievementsWrapstar rating signalsTaobao, tmall; qna; novel; v	0.6941888756606298
DU Sodium Achievements and Magnesium Plans for CJK	Generic Entity Extraction in Sodium Owner: Chuanxin HuContributors: Kang Li, Yi LiOverviewThe understanding of entities and their relationship is a one of the key pillars supporting the Bing’s strategic bet on the knowledge graph. Today, Satori ca	0.5319816721079906
DU Sodium Achievements and Magnesium Plans for CJK	Combined ALterationsNeon\sodiumAgendaNeon AchievementsBreakdownsSodiumIdeas & PlanNeonOverall ProgressExceeded Neon Commitments on CQS!NeonCQS Deep-dive-34% Bad+14% Excellent-15% Bad+13% ExcellentDRDOCQS is impr	0.43105190489224504
DU Sodium Achievements and Magnesium Plans for CJK	AGI UpdateDL Representation & Applications for NLU TasksSubhojit Som(Subhsom), Chen Zhou(chzho)Xia Song (xiaso), Saurabh Tiwary (satiwary)October. 2016Agenda / UpdatesMachine Reading ComprehensionLearning Generic Representation aka Semanti	0.43013423805688306
DU Sodium Achievements and Magnesium Plans for CJK	FY18 AGI Encoder Roadmap		Nitin Sharma, Gargi Ghosh, Saurabh TiwaryAgendaIntroductionFY18 Goals and Focus AreasFocus Area Deep DiveCustomer scenariosDetailed RoadmapAGI Encoder: MotivationGoal: One general intent encoder of source 	0.4229225879540598
DU Sodium Achievements and Magnesium Plans for CJK	Global CAL Aluminum PlanJunfeng ZhouAgendaMagnesium StatusAluminum FocusProjectsMagnesium Status - ReleasesJuly: aggressive relaxation on no result queriesSept: relax count classifier, morphological alterationsOct: JO v1Nov: morphologi	0.4130344645435643
DU Sodium Achievements and Magnesium Plans for CJK	The Data Skew ProblemFei Xu2/27/2018The Scheduled TalksMarch 18th Dave Maltz – OSD future network March 25th Pat – TBD April 1st Pat – TBDApril 8th Brad – Terasort in 12 minutesApril 15th Eric – The Global Scheduler April 22nd Brian – 	0.41301819739690626
DU Sodium Achievements and Magnesium Plans for CJK	1/29 AGI ReviewAttendees: Harry Shum, Yi-Min Wang, David Ku, Steven Yao, Jianfeng Gao, Saurabh Tiwary, JJ Liu, Mir RosenbergTask Oriented Dialog AgentsJianfengShare the “Hail Caesar” slide (rule-based vs. RL dialog)Write what we discussed on Cor	0.41297887691078444
DU Sodium Achievements and Magnesium Plans for CJK	Deep Dive: Query Generic Entity Extraction (GEE)Zhen Liao04/22/2016OutlineOverview of GEEFAQ for GEEArchitecture and ModelingRecent breakthrough via Deep LearningLessons we’ve learnedGeneric Entity Extraction for Queries: What is the g	0.412794452339356

DU Sodium Achievements and Magnesium Plans	DU Pipeline Sodium Achievements And Magnesium Plans　　Jia Liu2013-08-05OutlineSodium AchievementsMagnesium PlanMagnesium Work ItemsSodium Work ItemsAppendixSodium AchievementsWrapstar rating signalsTaobao, tmall; qna; novel; videoL3	0.7950853585266617
DU Sodium Achievements and Magnesium Plans	Jia Liu2013-08-05DU Pipeline Sodium Achievements And Magnesium Plans For CJK　　OutlineSodium AchievementsMagnesium PlanMagnesium Work ItemsSodium Work ItemsAppendixSodium AchievementsWrapstar rating signalsTaobao, tmall; qna; novel; v	0.6324212551285265
DU Sodium Achievements and Magnesium Plans	Generic Entity Extraction in Sodium Owner: Chuanxin HuContributors: Kang Li, Yi LiOverviewThe understanding of entities and their relationship is a one of the key pillars supporting the Bing’s strategic bet on the knowledge graph. Today, Satori ca	0.46919327719781934
DU Sodium Achievements and Magnesium Plans	Combined ALterationsNeon\sodiumAgendaNeon AchievementsBreakdownsSodiumIdeas & PlanNeonOverall ProgressExceeded Neon Commitments on CQS!NeonCQS Deep-dive-34% Bad+14% Excellent-15% Bad+13% ExcellentDRDOCQS is impr	0.38923472999400965
DU Sodium Achievements and Magnesium Plans	Global CAL Aluminum PlanJunfeng ZhouAgendaMagnesium StatusAluminum FocusProjectsMagnesium Status - ReleasesJuly: aggressive relaxation on no result queriesSept: relax count classifier, morphological alterationsOct: JO v1Nov: morphologi	0.3769571148015486
DU Sodium Achievements and Magnesium Plans	Deep Dive: Query Generic Entity Extraction (GEE)Zhen Liao04/22/2016OutlineOverview of GEEFAQ for GEEArchitecture and ModelingRecent breakthrough via Deep LearningLessons we’ve learnedGeneric Entity Extraction for Queries: What is the g	0.340807840378051
DU Sodium Achievements and Magnesium Plans	Paul LuberPrincipal Group PMSamim ErdoganPrincipal Pm ManagerIntroducing Substrate 	MICROSOFT CONFIDENTIALSubstrate Day 2018A cloud platform for compliant, scalable apps that offer intelligent experiences built on rich user data.What is Su	0.33374550499716443
DU Sodium Achievements and Magnesium Plans	FY18 AGI Encoder Roadmap		Nitin Sharma, Gargi Ghosh, Saurabh TiwaryAgendaIntroductionFY18 Goals and Focus AreasFocus Area Deep DiveCustomer scenariosDetailed RoadmapAGI Encoder: MotivationGoal: One general intent encoder of source 	0.332918732435025
DU Sodium Achievements and Magnesium Plans	DU Pipeline V2Bram Gruneir, Ted Wild and Connie YangDocument Understanding Dev Talk6/27/2013DU Pipeline V2: frequency demoIntroduce the demo featureDevelopmentDeploymentDU Pipeline V2: frequency demoIntroduce the demo featureDevelopmen	0.3292582780479985
DU Sodium Achievements and Magnesium Plans	The Data Skew ProblemFei Xu2/27/2018The Scheduled TalksMarch 18th Dave Maltz – OSD future network March 25th Pat – TBD April 1st Pat – TBDApril 8th Brad – Terasort in 12 minutesApril 15th Eric – The Global Scheduler April 22nd Brian – 	0.32056511994668496

DU Pipeline V2	DU Pipeline V2Bram Gruneir, Ted Wild and Connie YangDocument Understanding Dev Talk6/27/2013DU Pipeline V2: frequency demoIntroduce the demo featureDevelopmentDeploymentDU Pipeline V2: frequency demoIntroduce the demo featureDevelopmen	0.6241019020291281
DU Pipeline V2	DU Pipeline Sodium Achievements And Magnesium Plans　　Jia Liu2013-08-05OutlineSodium AchievementsMagnesium PlanMagnesium Work ItemsSodium Work ItemsAppendixSodium AchievementsWrapstar rating signalsTaobao, tmall; qna; novel; videoL3	0.5990624395024405
DU Pipeline V2	Jia Liu2013-08-05DU Pipeline Sodium Achievements And Magnesium Plans For CJK　　OutlineSodium AchievementsMagnesium PlanMagnesium Work ItemsSodium Work ItemsAppendixSodium AchievementsWrapstar rating signalsTaobao, tmall; qna; novel; v	0.47419701066612
DU Pipeline V2	Ranker Training Pipeline IntroductionAgendaPipeline OverviewGCC platformExtractionData/Feature PreparationMain Ranker TrainingSegment RankersPipeline OverviewGR OctTree: gcclinkMain Steps:Metastream injection (just info here)Querys	0.3918697190719749
DU Pipeline V2	Local Junk Detection and DemotionJia Liu2017-06-14GDP Pipeline View: local data pipelineTriple StoreGOALStore every entity as a set of triples.Track all changes to an entity.TripleColumnDetailsSubjectThe guid of a triple’s pa	0.37585034587734484
DU Pipeline V2	L4 Experiment PipelineDate: Aug 20th, 2013Author: Bangyong LiangMotivation:L4’s functionality is to merge results from multiple queries. L4 has two types of merging strategies. One is query level merger and the other one is document level merger. 	0.3715388868923323
DU Pipeline V2	Metrics Pipeline & ToolsJia Liu / Xiaohui Sun / Alex SergeevASG Data Mining TeamDemo link: http://dmsql05/MetricsDefinitionTool/MetricsDefinition.aspx?DataSet=BFT&MetricName=HasCortanaChitChatsTopicsBing Live Metrics PipelineUsage and Perf	0.3687916891347223
DU Pipeline V2	Entity Selection Pipeline Design DocScope:This document covers the design for entity selection pipeline in GDPV3. Near-Dupe clustering is not covered in this v1 version. The goal for this pipeline is to reduce junk rate and improve NII by stamping pub	0.3493092787998066
DU Pipeline V2	How DUv2 worksZehua Liu, DU GDI Team12/6/2013 Q1: How to develop a DUv2 feature?Processor + Description fileQ2: How to guarantee monthly release?Q3: Difference between the development of DUv1 and DUv2 feature?DUv1: a) ProcessorCode  	0.3477830654922691
DU Pipeline V2	A Step by step guide to Creating a new Block in the DU V2 PipelineThis document will demonstrate how to create a new block, including the testing and deployment for the new DU Pipeline.  To begin, if you do not yet have a block name, please send an em	0.3133178221885556

DSATMining_LSR	DSAT Mining & LSRBhagirath AddepalliCUV Log Based DSAT IdentificationIdentifying Google Local Answer Clicks from CUV LogsFor local queries, Google pushes users to search on MapClicking on Map results in url of type: https://www.google.com/webhp?	0.6592275963192079
DSATMining_LSR	 阿里浏览器DNS解析加速布可2010.12.31AgendaDNS解析过程DNS协议阿里浏览器DNS解析加速浏览器查找域名的IPtaobao.com浏览器缓存(2-30min)系统缓存(DNS client resolver cache)Local DNS递归查询->dns1.禁用IE的dns缓存：Start Registry Editor. Locate and click the following key in the reg	0.37943872378887616
DSATMining_LSR	空检索优化：背景：空检索请求耗时分析：统计7.21的所有空检索耗时：(71551个)      1 10144.000000      2 bs:4767252.000000       ----->66.63ms      3 390.000000      4 统计：2818865.000000   ----->39.4ms      5 1187696.000000      6 1588991.000000          7 7554473.000000	0.3508557615267066
DSATMining_LSR	Tmall&Taobao Rating MetawordsBackgroundWe’ve seen in regular DSAT review meetings the DSATs that we rank too high Tmall or Taobao page with low quality(Tmall page:low sales volume; Taobao page: low sales volume or shop with poor reputation).  Zh-CN ha	0.3344428816768115
DSATMining_LSR	Pattern Based Term WeightVersion 1Jia Liu2014-06-16FrameworkTerm AttributesSemantics definitionHuman understanding and knowledgeChange in different contextsLevels:KeywordAttributeRequirementStrong constraintWeak constraintVer	0.3333882098944693
DSATMining_LSR	成交日期 买卖标志 成交价格 成交数量 成交金额 2016年亏319 2015及2016年已完结 20160105 买入 100 897 20160108 卖出 8 200 1600 20150615 买入 100 1889 20150615 买入 100 1840 20150624 卖出 100 1585 20150720 买入 100 1073 20150721 买入 100 1098 20150721 买入 100 1086 20150723 买入 100 1110 20150818 卖出 500 	0.33326630520996187
DSATMining_LSR	BLU V3 Minghua Zhang      01/26/2016Next version of BLU Relevance Infrastructure​OutlineWhy BLU v3BLU v3 DesignCurrent StatusFuture WorkWhy BLU v3 (1)Limitations of current BLU infrastructureFeaturesCouldn’t utilize QAS feature	0.3324594409147519
DSATMining_LSR	成交日期 买卖标志 成交价格 成交数量 成交金额 20160105 买入 100 897 20160108 卖出 8 200 1600 成交日期 买卖标志 成交价格 成交数量 成交金额 20160106 买入 100 1702 20160113 买入 100 1532 20160325 卖出 100 1695 20160708 卖出 100 1570 20160725 卖出 500 10700 20160802 卖出 300 6660 20160802 卖出 200 4430 20160803 卖出 20	0.33101041277805127
DSATMining_LSR	贴吧大数据存储luhongbo@baidu.com2011-8-7/31目录概述和现状设计原则pbFrs负载均衡发展方向2011-8-7/31贴吧数据概述2011-8-7/31贴吧存储现状按照功能做模块水平拆分各模块均为数据单机模式镜像抗压力2011-8-7/31设计要求和原则性能（更新、浏览）访问模式决定设计最优化内存使用有效利用磁盘特性硬盘？Flash？顺序io还是随机读写？区别对待高峰期和	0.33021636661460896
DSATMining_LSR	IQ Team RecapH1 2016FY16H1 AccomplishmentsTeamSSRxen-* Desktop SBSen-* Mobile SBSen-* Semantic SBSCore Web Relevance0.55/0.62.46/3.02.65/3.01.88/2.0Adult LeakageSpamJunkCQDCGMPCMALTABing@WorkSubstrate0.02/0.01	0.3289741090379117

C专家编程读书笔记	贝叶斯分类模型：基础知识：假设	X：是数据元组，由n个属性描述；	H：是某种假设，如数据元组属于某特定类C	P(H|X)：表示给定X的属性描述，找出元组X属于类C的概率举例：X：一位35岁的顾客，收入为4w美元；H：顾客将购买计算机P(H|X)：在X的条件下，H的后验概率。当我们知道顾客的年龄和收入时，顾客X将购买计算机的概率。P(H)：H的先验概率。任意给定顾客将购买计算机的概率，独立与X。P(X|H)：在条件H下，X的后验概率。已知顾客购买了计算机，顾客是一位3	0.9147268687314584
C专家编程读书笔记	排序及扩展：插入排序，选择排序（冒泡排序），使用二分思想求第k大数，快速排序，非递归的快速排序，使用快排思想求第k大数，归并排序，求逆序数，自然排序算法，堆排序，最小优先级队列，计数排序，桶排序，鸽巢排序（分块排序），基数排序，外部排序：二路归并，K路归并，胜者树，败者树。  算法一：使用插入或者选择排序，得到最大的K个数，时间复杂度为：O(N*k)。 冒泡排序： void swap(int * a,int * b){            //注意	0.9105450918363406
C专家编程读书笔记	克拉玛依公证处:本人因生活在国外，不能亲自到贵单位办理出生证明公证事项，兹授权委托雷春香女士全权代表我办理相关事项。对委托人在办理上述事项过程中所签署的有关文件，我均予以认可，并承担相应的法律责任。委托人：刘佳			委托人身份证号码：654301198608243929被委托人：雷春香		被委托人身份证号码：6526196207113926委托人：刘佳2018年5月24日	0.9105450918363406
C专家编程读书笔记	性能升级性能升级的几个层面：系统结构：模块分解，模块交互，系统构建中的粗略估算。算法和数据结构：获得快速模块的关键：表示数据的结构，操作数据的算法：索引结构及拉链归并。代码调优：分支预测等。循环：将循环体中不改变的变量移动到循环体外；多重循环嵌套顺序。函数调用：inline函数节省函数调用开销：若makefile中不指定至少-O优化，即使声明为inline函数，编译器也不会进行函数内联。内存寻址：避免重复内存寻址。Cpu流水线的分支预测：将满足概率最高的条件放在靠前的位置。	0.9105450918363406
C专家编程读书笔记	业务生成平台用户指南总体说明开发背景下一代网络是业务驱动的网络，在融合的下一代网络上高效、灵活地开发和部署各种丰富多彩的业务，从而提高网络使用率、增加收益的目标，是下一代网络的关键环节。下一代网络的发展要求呼叫与承载相分离、呼叫控制与业务相分离，使业务真正独立于网络，业务开发者不必关心与业务承载相关的底层网络知识以及具体的通信协议，只需利用业务生成平台提供的业务开发工具，就可以开发出灵活丰富且极具个性化的业务。 为了适合多种技术水平的业务开发人员的需要，现在主要有四种业务开发方式：	0.9105450918363406
C专家编程读书笔记	K最近邻分类模型：原理：训练元组用n个属性描述，每个元组代表n维空间中的一个点，所有的训练元组存放在n维的模式空间。当给定一个未知元组时，KNN搜索该模式空间，找出最接近未知元组的k个训练元组。未知元组指派到它的k个最近邻中的多数类。“邻近性”用距离度量，如欧几里德距离。欧几里德距离：	设元组X1=(X11,X12,…X1n)，X2=(X21,X22,…X2n)，	Dist(X1,X2)=√ ∑ k= 1 n (X1i-X2i) 2 	使用上式之前，对每个属性的值规范化，以防止具有	0.9105324249901643
C专家编程读书笔记	工作6周年5个月小记今天是中国时间8/24/2018，也就是我32岁的生日，这是一个不老也不再年轻的年纪。最近总是因为工作而郁郁寡欢，心中不快，所以决定记录总结一下，希望自己能有所释怀、转变、确立新的目标。从2012年3月31到现在，我已在微软Bing工作6年5个月。在此之前，我在百度实习9个月，在阿里巴巴实习2个月，在搜狗实习1个月。在微软北京CJK relevance组勤恳的工作2年6个月，从级别59升到61，做了1年半的DU, 1年的relevance。总体来说，老板们的风格是相关性主导基础	0.9096211845632957
C专家编程读书笔记	海量数据库的设计和实现淘宝海量数据库之一：来自业务的挑战(2010-11-24 11:34:38) 作为一个电子商务企业，从一开始，数据库及其事务能力在淘宝一直扮演着十分关键的角色，淘宝积累了丰富的数据库的架构和规划等方面的经验，产生了众多优秀的DBA。 淘宝是一家迅速发展的公司。全球网站排名公司Alexa提供的数据显示，2010年4月27日，Amazon、Ebay的用户占全球互联网用户的百分比分别为3.47%和2.68%，而淘宝的用户占全球互联网用户的百分比则达到了4.1%，淘宝网日	0.9091479607007864
C专家编程读书笔记	C专家编程读书笔记难点关键字的用法：关键字用法extern在函数名前，表示该函数全局可见，一般缺省。即一个文件的全局变量和函数对其他文件，具有可见性。在变量或者函数前，表示对象的定义在别处进行。由于重载，在c++中调用以C方式编译的函数时，需要加extern “c”。static隐藏：修饰的对象对其他文件不可见，防止多个文件命名冲突。持久性：修饰的对象，存储在数据段或者bss段，和程序有相同的生命周期。只有一次初始化。3、修饰的变量未初始化时，默认为“0	0.9078401235624469
C专家编程读书笔记	BS代码阅读：BS基本功能：索引相关性切词成分分析offset调权query解析 （where+what）多路归并 综合调权类聚（偏离点）query分类空间调权数据来源点击调权BS代码阅读：bs_cache:map库的term cachemap库term cache操作锁where库term cachewhere库term cache操作锁init_map_term_cache: 初始化map库term cachein	0.907141040353761

Culture Story Deck	Decision Tree Ensemble decodeAdaboost Decision tree:A forest.  One feature can be multiple nodes.Support Market checkingWord/entity classificationOne or more feature set inputMeaning[DecisionTree]Roots=90  (tree number)Nodes=630 (all n	0.2911428918230333
Culture Story Deck	Deep Dive: Query Generic Entity Extraction (GEE)Zhen Liao04/22/2016OutlineOverview of GEEFAQ for GEEArchitecture and ModelingRecent breakthrough via Deep LearningLessons we’ve learnedGeneric Entity Extraction for Queries: What is the g	0.2867856058119004
Culture Story Deck	Deep Dive on Statistical Simplification Model for Hard QueriesBin Zhang (intern, University of Washington)Xiaolong Li, Ye-Yi Wang (Bing)Xiaodong He (MSR)9/11/2012OutlineHard query backgroundDeletion modelsTraining dataOnline experiment	0.27018449150175494
Culture Story Deck	Deal UnderstandingDeals with Low Quality: (some features/rules are listed below)Features/RulesExamplesNo user used; no verified informationThe policies about return365 Day Return Policy;Free Returns on All Orders; 45 Day Return Money Back 	0.26966855024528047
Culture Story Deck	Deal Ranking ImprovementsDeal Understanding ImprovementsGoal: Increase general deal coverage (deal product type from specific to general).Solution: Identify the prefix and suffix of title by punctuations and prep. Remove the prefix and suffix from t	0.260684834815941
Culture Story Deck	A Step by step guide to Creating a new Block in the DU V2 PipelineThis document will demonstrate how to create a new block, including the testing and deployment for the new DU Pipeline.  To begin, if you do not yet have a block name, please send an em	0.25555728500396063
Culture Story Deck	Containment and Conflation – Sprint  2Story DescriptionDone?In Demo?Implement and ship Segment Studio integration changes for Preconflation and MatchYYIdentify top K entity setYYRoot cause why entities have too many identifiersYY	0.24582484468791563
Culture Story Deck	Deal Ranking Improvement & MeasurementBackgroundAfter we shipped deal understanding, bad deals filtering, deal ranking for the entity search deals and popular deals nearby. We want to measure and improve our deal ranking based on user behaviors. We ca	0.24208480827083118
Culture Story Deck	Translation Model in Local Search- Shu HuangIntroductionTranslation model in web searchOdpTitle translation model in local searchData preparationModel trainingGenerate new metastreamIntroductionTranslation model used in web searchLea	0.23972776092438827
Culture Story Deck	Relevance Experimentation with DUOverviewThe ideal end state for any relevance improvement would consist of having one or more DU features shipped in the index that is then leveraged by the latest production ranker. This would achieve the highest leve	0.23517502313075614

Crawler Tech Talk	Crawler Tech TalkOctober 14, 2008AgendaOverview of Msnbot Internal Data FlowFlow of Chunks and Chunk MetadataReal-Time MonitoringDaily Data Reporting SubsystemPrevious Instances Requiring InterventionPotential Future ProblemsQ&AMsnbot 	0.5893745413335603
Crawler Tech Talk	Microsoft IT Technology AdoptionSee past and upcoming  talks at http://aka.ms/ITTechTalksSubscribe to IT Tech Talks DL @IT Tech Talk Invitethere’s a link on the Tech Talks siteQuestions about Tech Talks? Ask Justin Lane or Susan Sims.IT Tech T	0.2994121121722768
Crawler Tech Talk	WPO Local Relevance Tech TalkWPO Local Relevance TeamOverviewWPO’s role in local relevance pipelineLocal ExperienceArchitecture overviewMetricsWPO Local Relevance Model IntroductionWPO Query understanding and Location understandingWhy do	0.2576109009356818
Crawler Tech Talk	DU Pipeline V2Bram Gruneir, Ted Wild and Connie YangDocument Understanding Dev Talk6/27/2013DU Pipeline V2: frequency demoIntroduce the demo featureDevelopmentDeploymentDU Pipeline V2: frequency demoIntroduce the demo featureDevelopmen	0.2232379633888367
Crawler Tech Talk	Office Shredding ServiceSKI Tech Talk – 3/29What do we shred?Office documents into reusable piecesService powering Add From Files in Word, Reuse slides in PPT, Files tab in Microsoft SearchAPIsGoLocalSearchShredding APIs (Document Manifest	0.2060135233624573
Crawler Tech Talk	How do we train SM-CRF for APN?AgendaOverviewGeneration of Lexicons (in aether)Generation of RegEx FeaturesCRF Training Pipeline (in aether)CRF Eval Pipeline (in aether)Debugging ToolsQuestions?OverviewCRF is responsible for entity e	0.20300077968683994
Crawler Tech Talk	A Step by step guide to Creating a new Block in the DU V2 PipelineThis document will demonstrate how to create a new block, including the testing and deployment for the new DU Pipeline.  To begin, if you do not yet have a block name, please send an em	0.20068197234020532
Crawler Tech Talk	QR Team ReviewJan 2017Team IntroductionConceptXDeep QRAgendaQR Team MembersDev Manager: Ciya LiaoLeads: Garrett Kaminaga, Jingwen Lu, Saekoo Lee, Gord LueckPMs: Shyam Jayasankar, Jie CaiSTC-A Speller team: Yongen Gong and his teamWha	0.193459672383013
Crawler Tech Talk	Bing Local Search				Phonebook vNext Design DocumentDev ownerMickadBuddy dev(s)MichstePM ownerDabargerContributorsFeature areaMilestoneTable of contents1	Overview	32	Goals/Non Goals	53	Dependencies	64	Risks/Open Issues	75	0.1930373117548763
Crawler Tech Talk	Pattern Based Term Weight FrameworkIntroductionPattern based term weight recognizes the importance for part of terms or all the terms based on patterns/templates/knowledge. There are 2 differences between general and pattern based term weight.Compar	0.19246113773581153

Cosmos-Scope-Aluminum-M3-(2014-H1)	Cosmos Scope Aluminum M3 Release Announcement Cosmos Scope Aluminum M3 ReleaseThis and previous announcements are stored here.Code Samples can be found at http://aka.ms/CosmosCodeSamplesYou can find information about using Beta SDKs in this docu	0.7677479968745603
Cosmos-Scope-Aluminum-M3-(2014-H1)	CosmosScope> Complex Data TypesMichael Rys & Saveen Reddy2015/02/25http://aka.ms/CosmosPresentations© 2012 Microsoft Corporation. All rights reserved. Microsoft, Windows, and other product names are or may be registered trademarks and/or tradema	0.5933797901692547
Cosmos-Scope-Aluminum-M3-(2014-H1)	CosmosStreamSetsSaveen Reddy2014/04/15http://aka.ms/CosmosPresentationshttp://aka.ms/CosmosCodeSamples© 2012 Microsoft Corporation. All rights reserved. Microsoft, Windows, and other product names are or may be registered trademarks and/or tra	0.54192421767731
Cosmos-Scope-Aluminum-M3-(2014-H1)	https://cosmos11.osdinfra.net/cosmos/skypedata.adhoc/local/SkypeFeedback/Mined/v2/full/ FULLActionEntity.sshttps://cosmos11.osdinfra.net/cosmos/skypedata.adhoc/local/SkypeFeedback/Mined/v2/1d/ SkypeFeedback.ssSkypeSHRComments.ssSkypeSupportSea	0.4402241529198779
Cosmos-Scope-Aluminum-M3-(2014-H1)	CosmosScope > StreamSetsHiren Patel & Saveen Reddy2014/02/06© 2012 Microsoft Corporation. All rights reserved. Microsoft, Windows, and other product names are or may be registered trademarks and/or trademarks in the U.S. and/or other countries.The	0.43594171115953756
Cosmos-Scope-Aluminum-M3-(2014-H1)	Scope > Modules Author: Lianjie Zhu	Date: 3/15/2015SummaryModules are a key component for Cosmos customers to build their data platforms. In summary they allow developers to simplify how their data is consumed by others by bundling/packaging Scope	0.4071566148231389
Cosmos-Scope-Aluminum-M3-(2014-H1)	Metrics Pipeline & ToolsJia Liu / Xiaohui Sun / Alex SergeevASG Data Mining TeamDemo link: http://dmsql05/MetricsDefinitionTool/MetricsDefinition.aspx?DataSet=BFT&MetricName=HasCortanaChitChatsTopicsBing Live Metrics PipelineUsage and Perf	0.3991859492978975
Cosmos-Scope-Aluminum-M3-(2014-H1)	Online Click Labels for CAL Ranker:End – To End:aether://experiments/31148112-679c-476c-91d0-bb3ebbef81c2Continuous trained module continuously trains trees using HRS and then the ranker.OFE Ranker Training Pipeline:aether://experiments/01dbe0	0.38037299267339597
Cosmos-Scope-Aluminum-M3-(2014-H1)	Page | 2                                 <Si-09.1> Cross Page Junk Detection – V2Feature One-PagerDocument Version:0.9Authors:arahin, lidonzDocument Status:1.0Date:7/20/2014Feature OverviewDescription:Use new Main Body signal	0.3526896785742622
Cosmos-Scope-Aluminum-M3-(2014-H1)	The Data Skew ProblemFei Xu2/27/2018The Scheduled TalksMarch 18th Dave Maltz – OSD future network March 25th Pat – TBD April 1st Pat – TBDApril 8th Brad – Terasort in 12 minutesApril 15th Eric – The Global Scheduler April 22nd Brian – 	0.3442384409641979

Cosmos Tables	Cosmos Scope Aluminum M3 Release Announcement Cosmos Scope Aluminum M3 ReleaseThis and previous announcements are stored here.Code Samples can be found at http://aka.ms/CosmosCodeSamplesYou can find information about using Beta SDKs in this docu	0.47005111964179647
Cosmos Tables	CosmosSearch RESTful APIsWe now provide the cosmos search REST APIs to enable users to get more insights of their historical SCOPE jobs. This document walks through the basic steps to try out this API.If you have any questions for this document or wan	0.44537952966583616
Cosmos Tables	CosmosStreamSetsSaveen Reddy2014/04/15http://aka.ms/CosmosPresentationshttp://aka.ms/CosmosCodeSamples© 2012 Microsoft Corporation. All rights reserved. Microsoft, Windows, and other product names are or may be registered trademarks and/or tra	0.4307008286506116
Cosmos Tables	CosmosScope> Complex Data TypesMichael Rys & Saveen Reddy2015/02/25http://aka.ms/CosmosPresentations© 2012 Microsoft Corporation. All rights reserved. Microsoft, Windows, and other product names are or may be registered trademarks and/or tradema	0.3855511642747175
Cosmos Tables	CosmosScope > StreamSetsHiren Patel & Saveen Reddy2014/02/06© 2012 Microsoft Corporation. All rights reserved. Microsoft, Windows, and other product names are or may be registered trademarks and/or trademarks in the U.S. and/or other countries.The	0.29841110739241306
Cosmos Tables	Row Labels Sum of Cost (Months) Amit 2 Hugang Jia 3 Luke Mahaveer Max 3 Team 0 Vinay Xianming 2 (blank) 8 Grand Total Area Item Area Order Priority Owner Cost (Months) Status Column1 PPT Win32 Insert All 3 0 Amit Engineers 7 PPT Win32 Multi-Select 5 0 Ami	0.23229883251166347
Cosmos Tables	https://cosmos11.osdinfra.net/cosmos/skypedata.adhoc/local/SkypeFeedback/Mined/v2/full/ FULLActionEntity.sshttps://cosmos11.osdinfra.net/cosmos/skypedata.adhoc/local/SkypeFeedback/Mined/v2/1d/ SkypeFeedback.ssSkypeSHRComments.ssSkypeSupportSea	0.22423475150308958
Cosmos Tables	DU Pipeline Sodium Achievements And Magnesium Plans　　Jia Liu2013-08-05OutlineSodium AchievementsMagnesium PlanMagnesium Work ItemsSodium Work ItemsAppendixSodium AchievementsWrapstar rating signalsTaobao, tmall; qna; novel; videoL3	0.19268332221754403
Cosmos Tables	Combined ALterationsNeon\sodiumAgendaNeon AchievementsBreakdownsSodiumIdeas & PlanNeonOverall ProgressExceeded Neon Commitments on CQS!NeonCQS Deep-dive-34% Bad+14% Excellent-15% Bad+13% ExcellentDRDOCQS is impr	0.18688431586144835
Cosmos Tables	Smart relax, 3-way choiceMomo JengOffline simulationGeneral process for offline simulation:We have n choices to decide between, where n is small.Given choices A, B, and C, randomly show users A, B, or C.Randomization can be per-user (i.e. se	0.1844661188926757

ContentQualityRanking	Content Quality Classification & RankingGuihong Cao, Cheng NiuContent Quality for RankingContent quality = originality + trustworthy + information satisfaction + freshnessSpam sites, junk site, link farm, content farm, ….Search users are interes	0.5288004236057723
ContentQualityRanking	Site Quality ClassificationGuihong CaoDefinition of the ProblemWhat is site quality?Google’s definition includes the following dimensionsDuplicated content within the siteTrustworthyOn demand media? Quality controlSite authorityAuthor 	0.27538358582571165
ContentQualityRanking	MQ for CALOverviewSpellerQASMQTriggerMQSingleQueryChainChainChainAugmentAugmentAugmentTailQuerySimplifiedSPCombSP1SP2Sp3AugmentAugmentPropertyBag - SQQueryAlterationListQueryAlterationSetQueryAlterationType	0.25276516908655167
ContentQualityRanking	PDI Document AnnotationPDI Ranking PlatformAgendaPDI and forward indexDocument AnnotationSodium update and MG planQ&A DSAT: {books by children}Issue: Document matches the query terms, but its surrounding words may change the intent of 	0.23674058753039273
ContentQualityRanking	Content Quality Progress & StatusFeb 23, 2012Yi Li, Guihong Cao, Santhosh Kodipaka, Cheng NiuDocument UnderstandingAgendaContent Quality Problem AreasNDCG vs. SBSSummarizationProblemWhat We DidBing StatusScraperXXXSegment Aut	0.23148829892900571
ContentQualityRanking	Partner Index as ServiceWhat is the Problem? RequirementCurrent status of Bing Image StackDiscoveryClient tend to provide feed for full corpusWeb crawlerImage Content RetrievalSpecial agreement, some even behind authentication for access	0.21006378244011434
ContentQualityRanking	VORTEXTowards An E2E Vector-based Search StackProjects OverviewVector-based Retrieval(ANN recall path)L2 vector injectionVector-based RankingDeep Dejavu SpaceVWideDeep in FusionProjects OverviewVector-based RetrievalL2 vector i	0.18159449461734672
ContentQualityRanking	Leveraging Satori Knowledge in Web Ranking StackMicroSegment and Index ServeMotivationTarget at semantic queries (*defined by MALTA)Often contain more than one entity and relationSometimes involve entity inferenceTerm matching may not handle s	0.17765236865668457
ContentQualityRanking	Index Quality UpdateAgendaMetrics UpdateSelection Model ImprovementRecall TierOffice ImprovementChallenges and Pain PointsHow to measure index quality?Ideally: sampling from all “good” images and see how much we covered.sampling from a	0.16983863992630935
ContentQualityRanking	Production Models OverviewLU annotates incoming text input with semantic information in a contextual wayWorkflow built on top of Bing production infrastructure (QAS/XAP/Object Store)Feature representation: word embedding, n-grams and lexicons matche	0.16901605712678877

Content Reuse in WPO	AGI UpdateDL Representation & Applications for NLU TasksSubhojit Som(Subhsom), Chen Zhou(chzho)Xia Song (xiaso), Saurabh Tiwary (satiwary)October. 2016Agenda / UpdatesMachine Reading ComprehensionLearning Generic Representation aka Semanti	0.3488526401717711
Content Reuse in WPO	WPO Local RelevancePing Yin2017-03-21OverviewWPO’s role in local relevance pipelineLocal Entity StampingArchitecture overviewWPO Local Relevance Models.Query: exton mall, User location: Wallingford, PAWPO RolesExtract/detect all entity	0.30030954091317846
Content Reuse in WPO	WPO Local Relevance Tech TalkWPO Local Relevance TeamOverviewWPO’s role in local relevance pipelineLocal ExperienceArchitecture overviewMetricsWPO Local Relevance Model IntroductionWPO Query understanding and Location understandingWhy do	0.26933369810447744
Content Reuse in WPO	浅谈Redis的原理与应用tianzhedong（董天喆）大纲What is RedisWhy RedisHow To Use RedisWhat Is RedisWhat is RedisWhat is Rediskey value store可以持久化的cacheHashTableMemory DB它的高性能都是基于内存操作的基础data structure serverRedis支持复杂的数据特性，比如List, Set等Redis	0.2643049639352566
Content Reuse in WPO	VORTEXTowards An E2E Vector-based Search StackProjects OverviewVector-based Retrieval(ANN recall path)L2 vector injectionVector-based RankingDeep Dejavu SpaceVWideDeep in FusionProjects OverviewVector-based RetrievalL2 vector i	0.2496189837486529
Content Reuse in WPO	Distance Model Updates in LDCG V2Local Relevance and Measurement TeamAgendaDistance feature in LDCG V1Why was the switch to computing distance made?First implementation of Distance feature in LDCG V2, & improvement areasProcess followed for 	0.24111098780305915
Content Reuse in WPO	QAS Setup & Config-Supriya HarpaleQAS ConfigurationDefines workflow of classifier executionFeature Set is the main data used as input and output of modelsModels can depend on other models output, creating dependency graphMultiple dimensions 	0.23534002443087576
Content Reuse in WPO	AGI Intent EncoderGavin YingWeb Intelligence Team(Tail Ranking team)7/29/2016What is Intent EncoderGiven a text like query, question, short sentence, get a vector represent in a high dimension space. The vector should capture semantic meanin	0.23461475100635226
Content Reuse in WPO	Word representationsMotivationWhy word representations?StructureWhy vectors?Distance and similarityBuild models that will automatically understand language for us.Vector space modelsVector space modelsCount based methodsDSM (distribu	0.22882737490431893
Content Reuse in WPO	CAL OverviewPhysical InfrastructurePHR machine functionCO3 (WA) 44 machines, 6-10 kQPSCH1D (Chicago) 83 machines, 4-8 kQPSBN1 (VA) 62 machines, 6-16 kQPSDB3 (Dublin) 16 machines, 1-5 kQPSSG1 (Singapore) 9 machines, 1-4 kQPSBJ1 (Beijing) 3 	0.22533245903467553

Content Quality Progress and Status	Content Quality Classification & RankingGuihong Cao, Cheng NiuContent Quality for RankingContent quality = originality + trustworthy + information satisfaction + freshnessSpam sites, junk site, link farm, content farm, ….Search users are interes	0.5651884938237345
Content Quality Progress and Status	Content Quality Progress & StatusFeb 23, 2012Yi Li, Guihong Cao, Santhosh Kodipaka, Cheng NiuDocument UnderstandingAgendaContent Quality Problem AreasNDCG vs. SBSSummarizationProblemWhat We DidBing StatusScraperXXXSegment Aut	0.5384089889214457
Content Quality Progress and Status	Site Quality ClassificationGuihong CaoDefinition of the ProblemWhat is site quality?Google’s definition includes the following dimensionsDuplicated content within the siteTrustworthyOn demand media? Quality controlSite authorityAuthor 	0.46667609764692375
Content Quality Progress and Status	Partner Index as ServiceWhat is the Problem? RequirementCurrent status of Bing Image StackDiscoveryClient tend to provide feed for full corpusWeb crawlerImage Content RetrievalSpecial agreement, some even behind authentication for access	0.3978862536781345
Content Quality Progress and Status	Named Entity RecognizerTao Peng and Kang LiEntity names recognitionRecognize person, location and organization namesBOSTON, April  16 - Kevin Garnett helped the Boston Celtics beat the L. A. Lakers in last year's NBA final. ( Tony Gutierrez / Asso	0.37125205477224543
Content Quality Progress and Status	Index Quality UpdateAgendaMetrics UpdateSelection Model ImprovementRecall TierOffice ImprovementChallenges and Pain PointsHow to measure index quality?Ideally: sampling from all “good” images and see how much we covered.sampling from a	0.3475612366653
Content Quality Progress and Status	Index Quality Team’s Deep Learning ExperienceLuke ChenOutlineMotivationsCNTK/Phily ExperienceIQ team DL projects highlightsResourcesMotivationsRecent progress in deep neural net provides inspirations to upgrade Bing’s machine learning stac	0.3111030147563523
Content Quality Progress and Status	Threshold Query Formulation Deep DiveGoal of the presentation is to communicate our approach for query formulation and get feedback on whether this aligns with overall Threshold goals.OverviewGoals & MetricsQF ModelRoadmapScenariosKey Ta	0.29755823287994515
Content Quality Progress and Status	This workbook contains Parent Child Relationship matrix of provider given relationships. Currently only navteq provides this information and that is the only one which is included here. Parent Category Parent Count Child Count 11579 Hospitals And Medical 	0.29494113252207776
Content Quality Progress and Status	File Relevance Experimentation Design DocRecall AnalysisTest the search quality of external services like OLS, 3S, QF and SPO Search.Search scenarios: 0-term search, term search, 3S (Insert File and Attach File).Compare the recall: diff of returne	0.2947003683193832

Conflation – S2 Demo	Containment and Conflation – Sprint  2Story DescriptionDone?In Demo?Implement and ship Segment Studio integration changes for Preconflation and MatchYYIdentify top K entity setYYRoot cause why entities have too many identifiersYY	0.4592510881481616
Conflation – S2 Demo	PBA Dependency and DebugMing Wu2014-01-28PBA DependenciesLocation Understanding (LES/BLU)Location info (explicit/implicit) – fulfill detailed location infoProvide location related features to phonebook CRFXapQuServiceAnswer (QAS)For most c	0.38521767776982646
Conflation – S2 Demo	WrapStar On-Demand DesignDrafted by ZiliuContentsContext2Design Goals2Automation2Deployment Agility2High Availability2Non-Goals2Metrics2Required Changes3Orchestration3AP Migrations3Pipeline Evolution3Tools/services refactoring3	0.3377424332372786
Conflation – S2 Demo	L3 Reranking FrameworkL3 Infrastructure TeamAgendaOverviewL3 featuresL3 ranker and L3 workflowAggregatedFreeFormList-wise ranking previewL3 and L4Future WorkOverviewRank Stack in IS PlatformL4 - MergerL3 – List reorderingL2 - S	0.32637986245631845
Conflation – S2 Demo	QR Team ReviewJan 2017Team IntroductionConceptXDeep QRAgendaQR Team MembersDev Manager: Ciya LiaoLeads: Garrett Kaminaga, Jingwen Lu, Saekoo Lee, Gord LueckPMs: Shyam Jayasankar, Jie CaiSTC-A Speller team: Yongen Gong and his teamWha	0.3246322493589693
Conflation – S2 Demo	Local Junk Detection and DemotionJia Liu2017-06-14GDP Pipeline View: local data pipelineTriple StoreGOALStore every entity as a set of triples.Track all changes to an entity.TripleColumnDetailsSubjectThe guid of a triple’s pa	0.32265911864436614
Conflation – S2 Demo	QAS Setup & Config-Supriya HarpaleQAS ConfigurationDefines workflow of classifier executionFeature Set is the main data used as input and output of modelsModels can depend on other models output, creating dependency graphMultiple dimensions 	0.31959177610764555
Conflation – S2 Demo	Microsoft ConfidentialSeptember 14, 2016AGI EngineCore Relevance PM TeamJanuary 26thHuman and Artificial IntelligenceOur Approach to an AGI EngineSolving the AGI Engine GoalsUpgrading our Search StackAgendaLets start with a conceptual 	0.3135395343217998
Conflation – S2 Demo	Entity Categorization Using Convolutional Neural NetworkWeiwu Zhu8/23/2018AgendaMotivationCNN introductionCNN in NLPCNN based entity categorizationMeasurementMotivationTaxonomy mapping is not scalable (Feature Normalization)Nee	0.31241059310759767
Conflation – S2 Demo	Module 2:Deployment Considerations© 2014 Microsoft Corporation. All rights reserved. MICROSOFT MAKES NO WARRANTIES, EXPRESS, IMPLIED OR STATUTORY, AS TO THE INFORMATION IN THIS PRESENTATION.11/28/2016 8:58 PMMicrosoft ServicesConditions and Te	0.3077271592034465

Competitive Query-Entity Click	Competitive Query-Entity ClickMicrosoft ConfidentialMicrosoft ConfidentialGoalCreate a dataset that is readily available to utilize and analyze query-entity click patterns on competitive dataCompetitive Engine: GoogleMicrosoft ConfidentialCo	0.6513486205888754
Competitive Query-Entity Click	Named Entity RecognizerTao Peng and Kang LiEntity names recognitionRecognize person, location and organization namesBOSTON, April  16 - Kevin Garnett helped the Boston Celtics beat the L. A. Lakers in last year's NBA final. ( Tony Gutierrez / Asso	0.40125562608353543
Competitive Query-Entity Click	Analyzed Query represents all information derived from all classification tasks executed on the Query. QAS supports 3 basic classifications tasks: binary classification (Domain Classification), entity extraction (Query Parse), category classification (Dom	0.380715421264704
Competitive Query-Entity Click	query分类—分享                     刘佳2011.6.8web query classification(query分类):	将web search query根据它的主题，分派到1个或者多个预先定义的分类中。web search query的特征：有噪声：拼写错误等长度很短：信息量少，特征少表意含糊：query可能包含多个含义,属于多个分类含义会随时间演变目标分类的特征：目标分类定义缺少语义注解一级或者多级分类分类数目：几	0.3545954032761601
Competitive Query-Entity Click	Successful Feeds Query DebuggingNikita Melnichenko, 2015-03-10Feeds query debugging overviewWhen to use:Checking a new rankerChecking new augmentation before running a scrapeComparing several rankersUnderstanding feature contributionDebugg	0.34698112764907935
Competitive Query-Entity Click	Reading List for Natural Language Query ParsingThis is for improving our NL query parsing for entity/local triggering.By NL query parsing, our goal is to automatically extract the structured information from the query, normally by segmenting queries a	0.3370569725093129
Competitive Query-Entity Click	I-130 Questionnaire for the Petitioner (Husband or Wife)PLEASE LEFT CLICK ON GRAY FIELDS TO ENTER DATA.  PLEASE DO NOT (A) MODIFY THE FORMAT OF THIS DOCUMENT, (B) USE ALL CAP'S; OR (C) RIGHT-CLICK ON GRAY FIELDS.  IF YOU SAVE THIS DOCUMENT, PLEASE SAVE 	0.33419548541785554
Competitive Query-Entity Click	PERM Labor Certification Questionnaire:  Technical (continued)PERM Labor Certification Questionnaire (Technical)Please complete the information requested in this questionnaire carefully.  This information is necessary for the legal analysis and prepar	0.33072634217736063
Competitive Query-Entity Click	Name Entity Recognition based on Perceptron modelBackgroundWe have many name entity DSATs like user searched name “XYZ”, and the results may be “XY”,”YZ” or “XYW” related. We have done QU name entity recognition for zh-cn market already. So we want to	0.32819929725872854
Competitive Query-Entity Click	Golden QueryEvery query countsImprove relevance: Relevance TechniquesWin/Loss basedGood technique has better win/loss ratioGeneric Ranker always doesn’t have good win/loss ratioWe do technique triage, and better win/loss ratio technique got sh	0.3262089403239214

Combined ALterations	Bitext Alignment for Alteration Candidate GenerationJan 2018Alteration BasicsCAL alteration architecture is a big funnelCurrent mouth of the funnel is the altlist – a non-context-sensitive relation of <source, target, score>Built over time, qu	0.5009701463325388
Combined ALterations	alterationsalterations: product goalimprove recallby adding terms (not replacing or dropping user-entered terms)using word:which are synonyms to the original terms(we are re-examining each of these for vnext)alterations: general principl	0.4369370925081483
Combined ALterations	Phrasal Alterations & CAL Infra 		Page 2 of 2Phrasal Alterations & CAL Infra DescriptionPhrasal Alterations is going to add CAL the functionality of doing N-to-M alterations. Given a query, CAL is going to generate multiple candidate queries without	0.3544645715621114
Combined ALterations	Combined ALterationsNeon\sodiumAgendaNeon AchievementsBreakdownsSodiumIdeas & PlanNeonOverall ProgressExceeded Neon Commitments on CQS!NeonCQS Deep-dive-34% Bad+14% Excellent-15% Bad+13% ExcellentDRDOCQS is impr	0.2994419058253702
Combined ALterations	CALQuery alterationAgendaRoadmap and VisionWhere are weWhere to goPlanHow to get thereProgress and looking aheadSodium so farMagnesium and beyondDeep DiveGolden QueryRoadmap & VisionWhere are weCurrent status/problem of CAL	0.29697677478426865
Combined ALterations		0.20016608048367987
Combined ALterations	Provider Feature Measured Coverage Corrected Coverage(Exclude No Rating) Improved Coverage Estimate(Include No Rating) Note Amazon Price Amazon Availability Amazon Rating&Count >95% >92% 1. A known client issue:The current logic is to show the rating&cou	0.17425027122478404
Combined ALterations	CAL MultiQuery {Matching\Ranking}		Page 3 of 4CAL MultiQuery {Matching\Ranking}DescriptionCAL is going to optimize against matching\ranking separately and will issue different queries to each tier. CAL will be leveraging several operator such as:m	0.13984249431832968
Combined ALterations	Entity Selection Pipeline Design DocScope:This document covers the design for entity selection pipeline in GDPV3. Near-Dupe clustering is not covered in this v1 version. The goal for this pipeline is to reduce junk rate and improve NII by stamping pub	0.1333885192530207
Combined ALterations	Normalization and Parsing OverviewTypes of NormalizationLimiting to just normalization, there are actually several different types of normalization which may be interesting:WhitespaceThis is:Converting all whitespace characters to spacestrippi	0.1298322321251475

Carrier Phrase Resource	Phrasal Alterations & CAL Infra 		Page 2 of 2Phrasal Alterations & CAL Infra DescriptionPhrasal Alterations is going to add CAL the functionality of doing N-to-M alterations. Given a query, CAL is going to generate multiple candidate queries without	0.26163372246067856
Carrier Phrase Resource	LES with Speller in BFPRAnton AmirovBenefitsSupport for misspelled location, metrics improvementAlignment with web resultsCurrent statusHybridLESRaw QuerySpell Corrected QuerySpellerFLEFLEWithSpellerSome answers (AmberAlerts, Electio	0.210337133385912
Carrier Phrase Resource	L-1B SPECIALIZED KNOWLEDGE QUESTIONNAIREMICROSOFT POSITION IN THE U.S.Provide the following information for your current position at the Microsoft.MICROSOFT POSITION ABROADProvide the following information for your position at the Microsoft’s su	0.19733819254394575
Carrier Phrase Resource	Relevance Experimentation with DUOverviewThe ideal end state for any relevance improvement would consist of having one or more DU features shipped in the index that is then leveraged by the latest production ranker. This would achieve the highest leve	0.19198829587237326
Carrier Phrase Resource	Word representationsMotivationWhy word representations?StructureWhy vectors?Distance and similarityBuild models that will automatically understand language for us.Vector space modelsVector space modelsCount based methodsDSM (distribu	0.1605215157868581
Carrier Phrase Resource	CAL OFE logsOFE raw logs are cooked with the CALOFELogExtraction script, located in answers_alterations\private\OfflineDataGen\QueryAlteration\CALOFE\CALOFE.slnCooking the raw logsTo cook your logs, you need to runanswers_alterations\private\Offli	0.159055317992982
Carrier Phrase Resource	Fast Brain – Memorization & InferenceQuery based memorization and inferenceLarge Memorization -  1B queries, clicks (Q-D) and moreDeep Brain100 - 200B Doc/Page IndexRecall, Tail and Scalability focusedLess dependency on popularity signalHeur	0.15676498987725548
Carrier Phrase Resource	Integrating Knowledge Graph in Web SearchEntity Triggering and CollectionsPresenter: Ze TianKnowledge GraphEntities and RelationsEntities: celebrities, people, generic terms (e.g. light bulb)Relations: sibling, spouse, people and their works	0.1563896887382879
Carrier Phrase Resource	Index Quality UpdateAgendaMetrics UpdateSelection Model ImprovementRecall TierOffice ImprovementChallenges and Pain PointsHow to measure index quality?Ideally: sampling from all “good” images and see how much we covered.sampling from a	0.1514529450740097
Carrier Phrase Resource	File Relevance Experimentation Design DocRecall AnalysisTest the search quality of external services like OLS, 3S, QF and SPO Search.Search scenarios: 0-term search, term search, 3S (Insert File and Attach File).Compare the recall: diff of returne	0.14662399328668238

CalUpdatesForInternational	CRF Parser AnalysisBusiness category searchOverviewParser (phonebook)CRF ParserqueryLocation featuresCRF featuresQuery parsetoken[tag] token[tag] … token[tag]userBLUbusiness_namebusiness_categorylocationlocation_separatorbu	0.3230279228316562
CalUpdatesForInternational	Auto Category Classification PipelineHanqing Cui2012/10/25OutlinePain PointsThinkingAuto Category Classification PipelineAuto Page LabelingData SamplingTrainingFeature SelectionThresholdIterative TrainingInitial Seed Model Creati	0.31399342115039613
CalUpdatesForInternational	MQ for CALOverviewSpellerQASMQTriggerMQSingleQueryChainChainChainAugmentAugmentAugmentTailQuerySimplifiedSPCombSP1SP2Sp3AugmentAugmentPropertyBag - SQQueryAlterationListQueryAlterationSetQueryAlterationType	0.30261781601047866
CalUpdatesForInternational	Pattern Based Term WeightVersion 1Jia Liu2014-06-16FrameworkTerm AttributesSemantics definitionHuman understanding and knowledgeChange in different contextsLevels:KeywordAttributeRequirementStrong constraintWeak constraintVer	0.2704462642453549
CalUpdatesForInternational	Entity Categorization Using Convolutional Neural NetworkWeiwu Zhu8/23/2018AgendaMotivationCNN introductionCNN in NLPCNN based entity categorizationMeasurementMotivationTaxonomy mapping is not scalable (Feature Normalization)Nee	0.2562701878094376
CalUpdatesForInternational	Domain Authority CAL One PageIntroductionCurrent shipped ngram domain authority in L3 is using complete query match against an offline generated meta-stream (q, url, score), which derives (q,url) pairs from click stream and is the result of aggregatio	0.25606003253535703
CalUpdatesForInternational	Training data distributionContain categories as many as possible : 36 categies. The data of category in the same amountContain hudong data and  host dataPositive : negative = 1:7  ~ 1:10 categoryhudonghostpositivenegativeNegative_total	0.2541439879406752
CalUpdatesForInternational	CAL OverviewPhysical InfrastructurePHR machine functionCO3 (WA) 44 machines, 6-10 kQPSCH1D (Chicago) 83 machines, 4-8 kQPSBN1 (VA) 62 machines, 6-16 kQPSDB3 (Dublin) 16 machines, 1-5 kQPSSG1 (Singapore) 9 machines, 1-4 kQPSBJ1 (Beijing) 3 	0.25204067117486423
CalUpdatesForInternational	Global CAL Aluminum PlanJunfeng ZhouAgendaMagnesium StatusAluminum FocusProjectsMagnesium Status - ReleasesJuly: aggressive relaxation on no result queriesSept: relax count classifier, morphological alterationsOct: JO v1Nov: morphologi	0.24927502698964255
CalUpdatesForInternational	Summary of 50 queries:QueryIssue categoryResolved促销策略案例分析Page NumberYes美丽说面膜Page NumberYes朝鲜金正恩腐化生活 图片Page NumberNo(L3 rule not cover this case: the second page is higher than the first page)智慧树2012全集Page NumberYes潘阳老公石磊P	0.2458575574526285

CRF deep learning model final presentation	SKI online feature extraction design docTo build ML model to detect user intent and re-rank search result from different providers, we need training data. This document mainly covers the design how to collect the training data from the real Office usage	0.39355729385350396
CRF deep learning model final presentation	Deal Understanding and RankingBackgroundDeal is a very big segment in Bing Opal. We crawl store and single deals/coupons regularly from websites like groupon.com, coupons.com, restaurants.com, retailmenot.com, dealcatcher.com, dealplus.com and so on. 	0.3756673596890208
CRF deep learning model final presentation	Deal Ranking Improvement & MeasurementBackgroundAfter we shipped deal understanding, bad deals filtering, deal ranking for the entity search deals and popular deals nearby. We want to measure and improve our deal ranking based on user behaviors. We ca	0.37204710828836995
CRF deep learning model final presentation	Threshold Query Formulation Deep DiveGoal of the presentation is to communicate our approach for query formulation and get feedback on whether this aligns with overall Threshold goals.OverviewGoals & MetricsQF ModelRoadmapScenariosKey Ta	0.36965953892249187
CRF deep learning model final presentation	cal deepdiverelaxationdec 2017AgendaProduct GoalsQuery SimplificationMechanism/RuntimeCRF Model TrainingQS Path SelectionOffline SimulatorSmart RelaxMechanism & TrainingRelaxation: ImpactRelaxation: Product goalsImprove Rec	0.365720767117138
CRF deep learning model final presentation	Containment and Conflation – Sprint  2Story DescriptionDone?In Demo?Implement and ship Segment Studio integration changes for Preconflation and MatchYYIdentify top K entity setYYRoot cause why entities have too many identifiersYY	0.3583567868128047
CRF deep learning model final presentation	Deal Ranking ImprovementsDeal Understanding ImprovementsGoal: Increase general deal coverage (deal product type from specific to general).Solution: Identify the prefix and suffix of title by punctuations and prep. Remove the prefix and suffix from t	0.3569183502919338
CRF deep learning model final presentation	CRF Parser AnalysisBusiness category searchOverviewParser (phonebook)CRF ParserqueryLocation featuresCRF featuresQuery parsetoken[tag] token[tag] … token[tag]userBLUbusiness_namebusiness_categorylocationlocation_separatorbu	0.3521385210085615
CRF deep learning model final presentation	Term expansion summaryGoalsVisible changes in ARDSImprove “no match” issuesImprove rank qualityLimit FPs. Pre-work neededPort names tagger to C#/C++Query timeWSD and entity taggerEntity tagging in query logs (Britney Spears bio -> <p	0.3456129346742932
CRF deep learning model final presentation	Deep Dive on Statistical Simplification Model for Hard QueriesBin Zhang (intern, University of Washington)Xiaolong Li, Ye-Yi Wang (Bing)Xiaodong He (MSR)9/11/2012OutlineHard query backgroundDeletion modelsTraining dataOnline experiment	0.33925238020114457

CRF Parser Analysis	CRF Parser AnalysisBusiness category searchOverviewParser (phonebook)CRF ParserqueryLocation featuresCRF featuresQuery parsetoken[tag] token[tag] … token[tag]userBLUbusiness_namebusiness_categorylocationlocation_separatorbu	0.7295699766814624
CRF Parser Analysis	Pattern Based Term Weight FrameworkIntroductionPattern based term weight recognizes the importance for part of terms or all the terms based on patterns/templates/knowledge. There are 2 differences between general and pattern based term weight.Compar	0.35215269547481537
CRF Parser Analysis	Span ClassifierSpan classifier is a general infrastructure that can be used to run a fastrank based classifier on a sequence of terms from a query.  It can be used to apply rankonly or norelax to parts of the query based on the result of the model.  Fea	0.34010975187617637
CRF Parser Analysis	ODP Classification: Summarizing Pages as a Topic DistributionNov 17, 2010Paul Bennett (pauben), MSR CLUESJoint work with Max Chickering & Susan Dumais© 2006 Microsoft Corporation. All rights reserved. Microsoft, Windows, Windows Vista and ot	0.32585904408625305
CRF Parser Analysis	SKI online feature extraction design docTo build ML model to detect user intent and re-rank search result from different providers, we need training data. This document mainly covers the design how to collect the training data from the real Office usage	0.3229150174256943
CRF Parser Analysis	Entity Pane and Fact AnswerPresenter: Ze TianJun 25, 2013IntroductionIntroductionIntroductionProblems to SolveDoes the user search for entities or facts of entities?E.g. “who is msft ceo” (Entity: Microsoft, Fact: Chief Executive O	0.3191796385164496
CRF Parser Analysis	How do we train SM-CRF for APN?AgendaOverviewGeneration of Lexicons (in aether)Generation of RegEx FeaturesCRF Training Pipeline (in aether)CRF Eval Pipeline (in aether)Debugging ToolsQuestions?OverviewCRF is responsible for entity e	0.298068187755964
CRF Parser Analysis	Abacus Query Pattern SpecThis document describes how the query GEE pattern is passing from CAL into PDR, and generate a series of features depending on the <querypattern, URL-host> level matching. Query Property of GEEHere is the query property defi	0.28268607257616457
CRF Parser Analysis	Crawler Tech TalkOctober 14, 2008AgendaOverview of Msnbot Internal Data FlowFlow of Chunks and Chunk MetadataReal-Time MonitoringDaily Data Reporting SubsystemPrevious Instances Requiring InterventionPotential Future ProblemsQ&AMsnbot 	0.2824869257587195
CRF Parser Analysis	CoreCAL Improvements		Page 2 of 5CoreCAL ImprovementsDescriptionDuring Sodium, CAL Team would invest on optimizing separately for L0\L1\L2 on top of current CoreCAL improvements. Multiple Query Project will target Fidelity\SBS\SSRx while CoreCAL imp	0.27937511571719864

CQS_DRQ4_Issues_Eris	LDCG V3Knowledge Transfer2017-04-14Brett Clippingdale, Sean King, Vikas Mittal, Li JiangLDCG V3 OutlineLDCG V2 vs V3: High-level comparisonLDCG V3: New distance ModelV2 vs V3 OverviewLDCG V3: GeoIntent HIT appLDCG V3: Calculate distance 	0.4469332468471483
CQS_DRQ4_Issues_Eris	Mobile LT Discussion6/20/2014AgendaTop IssuesAd Product and Ad Quality UpdateSummarized Finding NDT Supply AnalysisSummarized Finding Google CompeteStatusFeatureWindows phoneIphone/AndroidUp to 2 adsShipped 5/20/2014Shipped more 	0.415239827616824
CQS_DRQ4_Issues_Eris	Local Probe WinPhone AppPrint Date: 0000-00-00Spec StatusDraftTFS Feature IDRelease[Release]PMJacob Haynes Florian VossDesign[Design]Milestone[Milestone]Dev[Dev]User Research[User Research]Feature Team[Feature Team]Test	0.41380378182327265
CQS_DRQ4_Issues_Eris	BLU V3 Minghua Zhang      01/26/2016Next version of BLU Relevance Infrastructure​OutlineWhy BLU v3BLU v3 DesignCurrent StatusFuture WorkWhy BLU v3 (1)Limitations of current BLU infrastructureFeaturesCouldn’t utilize QAS feature	0.4064336157341986
CQS_DRQ4_Issues_Eris	CJK RELEVANCE ALL HANDS03/06/201401Qi ASG Memo02MS Poll	03USBS MeasurementAGENDA04Win in USBSVideoEbookMemo DocWatch the VideoVideoIntroductionWho We AreOur VisionClosingDiscussion and QnA01Qi ASG Memo02	0.39808983875186305
CQS_DRQ4_Issues_Eris	唐蕾电话: (+86) 180-0132-3861Email: tanglei91@126.com工作经历                                                                    04/2014至今 :    	中国电信集团系统集成有限责任公司 软件测试工程师1.招标测试时间:05/2016至今项目描述：通过招标测试帮助甲方找到合适的厂家做他们项目中的某些模块。项目职责：负责招标测试跟产品经理讨论并细化需	0.3744553101595629
CQS_DRQ4_Issues_Eris	Brownbag:ElasticSearch ExtensibilityHeather Nakama (henakama)Azure Search09/04/14AgendaIntroductionModulesPluginsFinding extensibility pointsEnd-to-end exampleTips and tricksQ/AIntroductionHeather NakamaDeveloper with Azure S	0.37404619962985425
CQS_DRQ4_Issues_Eris	空检索优化：背景：空检索请求耗时分析：统计7.21的所有空检索耗时：(71551个)      1 10144.000000      2 bs:4767252.000000       ----->66.63ms      3 390.000000      4 统计：2818865.000000   ----->39.4ms      5 1187696.000000      6 1588991.000000          7 7554473.000000	0.3713933436419497
CQS_DRQ4_Issues_Eris	NTCG DebuggingSteven Zittrower01/30/2015AgendaNTCGNTCG DashboardOverview of BLU Architecture (Address Specific)Address Debugging in QATNTCGNTCG (Normalized Total Cumulative Gain) is a composite metric that measures address query releva	0.3696013914149492
CQS_DRQ4_Issues_Eris	QR FY19 LRP Planning - 23/29/18Unified Concept Tagging – Key ChallengesStructural ComplexityFor ambiguous queries and multi-concept queries, how much organization is required?  How to represent this in a linear qlf?  What about inter-concept rel	0.36833472849091553

CNTK Junk Classifier Prototype 2016-07-22	CNTK Junk Classifier PrototypeAnton Savin and Gilbert Wong6/3/2016Overall Plan and PrioritiesLearn Deep Learning and Neural NetworkLearn CNTK (Computational Network Toolkit) by walking through the examplesBuild a junk classifier using CNTKEv	0.6222668187601057
CNTK Junk Classifier Prototype 2016-07-22	Online Click Labels for CAL Ranker:End – To End:aether://experiments/31148112-679c-476c-91d0-bb3ebbef81c2Continuous trained module continuously trains trees using HRS and then the ranker.OFE Ranker Training Pipeline:aether://experiments/01dbe0	0.3988476605888066
CNTK Junk Classifier Prototype 2016-07-22	SVMT UpdateNovember 2016AgendaMorning (10:00-12:00)Overview – 15 minQnA:MALTA – 55 minInfoBot – 30 minLunch break (12:00-1:00)Afternoon (1:00-3:00)Query:Deep QR – 30 minRanking:ConceptX – 30 minFusion – 30 minNapa – 30 minO	0.35731391170248855
CNTK Junk Classifier Prototype 2016-07-22	FY18 GreenlightLocal SearchJune 14, 2017FY18 Local Search: Top GoalsInitiativeMetricFY18 GoalsTop Segments (mobile and desktop): Competitive Segment SBS (mobile and desktop)TCxSBS weak score > 5 for EN-USSegments: Hotels, Retail, Hom	0.3428958429999248
CNTK Junk Classifier Prototype 2016-07-22	SPAM & JunkSi Planning Cheng Niu, Alex Rahin6/18/2014Agenda	Focus AreasMetricsSPAM/Junk Metrics BreakdownData Analysis and Project DefinitionFocus AreasImprove SPAM Detection (~35% of team bandwidth)Stolen ContentContent Keyword St	0.3421424338233171
CNTK Junk Classifier Prototype 2016-07-22	DU work items on zh-cn market　　Jia Liu2013-05-14AgendaSerp classifierWrapstar rating signalsTaobao, tmall; qna; novel; videoGeneral classiferUrl-basedTopic-basedPage number extractionName entity recognitionPerson, location, organiz	0.3310721108688087
CNTK Junk Classifier Prototype 2016-07-22	RelaxCount Classifier in JO V3By: Gord Lueck, 2013.09.04BackgroundCAL now has the ability to ship with a relaxcount classifier.  That is, a trained decision tree that is designed to predict the relaxcount decision on a query.  The classifier can be 	0.3291991336090324
CNTK Junk Classifier Prototype 2016-07-22	成交日期 买卖标志 成交价格 成交数量 成交金额 20160106 买入 100 1702 20160113 买入 100 1532 20160325 卖出 100 1695 20160708 卖出 100 1570 20160725 卖出 500 10700 20160802 卖出 300 6660 20160802 卖出 200 4430 20160803 卖出 200 4672 20160908 卖出 100 2695 成交日期 买卖标志 成交价格 成交数量 成交金额 20160112 买入 100	0.3191455491959059
CNTK Junk Classifier Prototype 2016-07-22	Spam/Junk Technology Review8/8/2017 Pavel KarpovichAgendaSpam/Junk OverviewReview of current system and metricsSJRE Fishtank pipelines UrlExclusion and Defect Subranker	Blue Whale Spam Types of Fresh SpamActions to Detect Fresh	0.31115503851153276
CNTK Junk Classifier Prototype 2016-07-22	PO Box 91059Seattle, WA 98111-9159	VISION 	Member Claim Form 	for Microsoft  This form is to be used for Vision claims (routine exam and hardware) where you incurred expenses from a provider who did not bill the plan directly.For Medical or De	0.3103559276618246

CNTK Junk Classifier Prototype 2016-06-03	CNTK Junk Classifier PrototypeAnton Savin and Gilbert Wong6/3/2016Overall Plan and PrioritiesLearn Deep Learning and Neural NetworkLearn CNTK (Computational Network Toolkit) by walking through the examplesBuild a junk classifier using CNTKEv	0.5994735629222904
CNTK Junk Classifier Prototype 2016-06-03	SVMT UpdateNovember 2016AgendaMorning (10:00-12:00)Overview – 15 minQnA:MALTA – 55 minInfoBot – 30 minLunch break (12:00-1:00)Afternoon (1:00-3:00)Query:Deep QR – 30 minRanking:ConceptX – 30 minFusion – 30 minNapa – 30 minO	0.40855942144247964
CNTK Junk Classifier Prototype 2016-06-03	Online Click Labels for CAL Ranker:End – To End:aether://experiments/31148112-679c-476c-91d0-bb3ebbef81c2Continuous trained module continuously trains trees using HRS and then the ranker.OFE Ranker Training Pipeline:aether://experiments/01dbe0	0.40158496110231956
CNTK Junk Classifier Prototype 2016-06-03	SPAM & JunkSi Planning Cheng Niu, Alex Rahin6/18/2014Agenda	Focus AreasMetricsSPAM/Junk Metrics BreakdownData Analysis and Project DefinitionFocus AreasImprove SPAM Detection (~35% of team bandwidth)Stolen ContentContent Keyword St	0.3767317761305661
CNTK Junk Classifier Prototype 2016-06-03	DU work items on zh-cn market　　Jia Liu2013-05-14AgendaSerp classifierWrapstar rating signalsTaobao, tmall; qna; novel; videoGeneral classiferUrl-basedTopic-basedPage number extractionName entity recognitionPerson, location, organiz	0.3643699015255212
CNTK Junk Classifier Prototype 2016-06-03	PO Box 91059Seattle, WA 98111-9159	VISION 	Member Claim Form 	for Microsoft  This form is to be used for Vision claims (routine exam and hardware) where you incurred expenses from a provider who did not bill the plan directly.For Medical or De	0.3517204467114703
CNTK Junk Classifier Prototype 2016-06-03	RelaxCount Classifier in JO V3By: Gord Lueck, 2013.09.04BackgroundCAL now has the ability to ship with a relaxcount classifier.  That is, a trained decision tree that is designed to predict the relaxcount decision on a query.  The classifier can be 	0.3224814102552251
CNTK Junk Classifier Prototype 2016-06-03	Spam/Junk Technology Review8/8/2017 Pavel KarpovichAgendaSpam/Junk OverviewReview of current system and metricsSJRE Fishtank pipelines UrlExclusion and Defect Subranker	Blue Whale Spam Types of Fresh SpamActions to Detect Fresh	0.32004794295304306
CNTK Junk Classifier Prototype 2016-06-03	成交日期 买卖标志 成交价格 成交数量 成交金额 20160106 买入 100 1702 20160113 买入 100 1532 20160325 卖出 100 1695 20160708 卖出 100 1570 20160725 卖出 500 10700 20160802 卖出 300 6660 20160802 卖出 200 4430 20160803 卖出 200 4672 20160908 卖出 100 2695 成交日期 买卖标志 成交价格 成交数量 成交金额 20160112 买入 100	0.31204187377391496
CNTK Junk Classifier Prototype 2016-06-03	FY18 GreenlightLocal SearchJune 14, 2017FY18 Local Search: Top GoalsInitiativeMetricFY18 GoalsTop Segments (mobile and desktop): Competitive Segment SBS (mobile and desktop)TCxSBS weak score > 5 for EN-USSegments: Hotels, Retail, Hom	0.30150486075292776

CNNBasedCategorization	Zh-cn Transportation Segment Optimization by Pattern EngineJia Liu/Allen WangDSATsQuery: 吉林市到查干湖Relevant result title: 吉林市到查干湖怎么走近？_百度知道Irrelevant result title 1: 查干湖,中国查干湖,吉林查干湖,查干湖旅游,查干湖冬捕,国家AAAA ...Irrelevant result title 2: 查干湖_百度百科Irrel	0.4011451532599617
CNNBasedCategorization	Zh-cn Document classification based on topicBackgroundWe want to do zh-cn document classification for better understanding the document type and topic. It can help ranking with document and  query category matching. We defined our category system: 69 	0.3987148333226689
CNNBasedCategorization	Publication date optimization for zh-cn marketBackgroundPublication date is a very fundamental and important feature. It can help fresh ranking, whole page user experience: caption date show and freshness internal metrics, also to solve mainline out	0.369970718076947
CNNBasedCategorization	DU work items on zh-cn market　　Jia Liu2013-05-14AgendaSerp classifierWrapstar rating signalsTaobao, tmall; qna; novel; videoGeneral classiferUrl-basedTopic-basedPage number extractionName entity recognitionPerson, location, organiz	0.3675835454731243
CNNBasedCategorization	Machine Learning Categorization & Popularity2012-08-30 | Nicolas NicolovGoalsShow how categorization and popularity systems work.Introduce important ML concepts.Illustrate ML techniques through examples.(aiming to be self-contained)Categoriz	0.3553273870548617
CNNBasedCategorization	Zh-cn Transportation Segment Optimization by Pattern EngineIntroductionThe pattern queries can cover almost 10% in all queries. We can summarize lots of patterns on Query and Document sides for different segments. We can recognize key terms, relations	0.3437804723023231
CNNBasedCategorization	Local Category Search Plan3 month StrategyData: Entity categorizationScalable, high precision/recallSegments: Food & Drink, Retail, Service, Auto, HotelMetaStream enrichmentQuery UnderstandingDolphin by defaultConsume PhoneBookQU to im	0.342041117609723
CNNBasedCategorization	Entity Categorization Using Convolutional Neural NetworkWeiwu Zhu8/23/2018AgendaMotivationCNN introductionCNN in NLPCNN based entity categorizationMeasurementMotivationTaxonomy mapping is not scalable (Feature Normalization)Nee	0.33194445239279075
CNNBasedCategorization	Fast Brain – Memorization & InferenceQuery based memorization and inferenceLarge Memorization -  1B queries, clicks (Q-D) and moreDeep Brain100 - 200B Doc/Page IndexRecall, Tail and Scalability focusedLess dependency on popularity signalHeur	0.30481428334201766
CNNBasedCategorization	Publication Date Optimization Design and Implement For zh-cn MarketReview and CommentMei Yang; Ted WildAuthorJia LiuDesignBackgroundPublication date is a very fundamental and important feature. It can help fresh ranking, solve mainline out	0.30312633442375103

CDN全局流量调度算法	CDN全局流量调度算法介绍摘要本文主要介绍了CDN全局流量调度系统。首先给出了全局流量调度系统的基本流程和设计目标，然后简述了现有的流量调度系统的工作原理和方式，重点阐述了三种新开发的全局流量调度算法：基于负载能力的调度算法、基于链路的调度算法和基于成本的调度算法。一、流量调度的基本流程目前CDN系统流量调度是通过DNS解析来实现的，其基本原理如下图1所示。用户想要访问某个图片的url，分为四步：1、用户来自某个区域（如Beijing TelCom）的用户，想访问特定Url（如	0.8831307212613915
CDN全局流量调度算法	贝叶斯分类模型：基础知识：假设	X：是数据元组，由n个属性描述；	H：是某种假设，如数据元组属于某特定类C	P(H|X)：表示给定X的属性描述，找出元组X属于类C的概率举例：X：一位35岁的顾客，收入为4w美元；H：顾客将购买计算机P(H|X)：在X的条件下，H的后验概率。当我们知道顾客的年龄和收入时，顾客X将购买计算机的概率。P(H)：H的先验概率。任意给定顾客将购买计算机的概率，独立与X。P(X|H)：在条件H下，X的后验概率。已知顾客购买了计算机，顾客是一位3	0.8673275608062307
CDN全局流量调度算法	海量数据库的设计和实现淘宝海量数据库之一：来自业务的挑战(2010-11-24 11:34:38) 作为一个电子商务企业，从一开始，数据库及其事务能力在淘宝一直扮演着十分关键的角色，淘宝积累了丰富的数据库的架构和规划等方面的经验，产生了众多优秀的DBA。 淘宝是一家迅速发展的公司。全球网站排名公司Alexa提供的数据显示，2010年4月27日，Amazon、Ebay的用户占全球互联网用户的百分比分别为3.47%和2.68%，而淘宝的用户占全球互联网用户的百分比则达到了4.1%，淘宝网日	0.8628841936396159
CDN全局流量调度算法	K最近邻分类模型：原理：训练元组用n个属性描述，每个元组代表n维空间中的一个点，所有的训练元组存放在n维的模式空间。当给定一个未知元组时，KNN搜索该模式空间，找出最接近未知元组的k个训练元组。未知元组指派到它的k个最近邻中的多数类。“邻近性”用距离度量，如欧几里德距离。欧几里德距离：	设元组X1=(X11,X12,…X1n)，X2=(X21,X22,…X2n)，	Dist(X1,X2)=√ ∑ k= 1 n (X1i-X2i) 2 	使用上式之前，对每个属性的值规范化，以防止具有	0.8588657824155309
CDN全局流量调度算法	排序及扩展：插入排序，选择排序（冒泡排序），使用二分思想求第k大数，快速排序，非递归的快速排序，使用快排思想求第k大数，归并排序，求逆序数，自然排序算法，堆排序，最小优先级队列，计数排序，桶排序，鸽巢排序（分块排序），基数排序，外部排序：二路归并，K路归并，胜者树，败者树。  算法一：使用插入或者选择排序，得到最大的K个数，时间复杂度为：O(N*k)。 冒泡排序： void swap(int * a,int * b){            //注意	0.8581585209238538
CDN全局流量调度算法	克拉玛依公证处:本人因生活在国外，不能亲自到贵单位办理出生证明公证事项，兹授权委托雷春香女士全权代表我办理相关事项。对委托人在办理上述事项过程中所签署的有关文件，我均予以认可，并承担相应的法律责任。委托人：刘佳			委托人身份证号码：654301198608243929被委托人：雷春香		被委托人身份证号码：6526196207113926委托人：刘佳2018年5月24日	0.8581585209238538
CDN全局流量调度算法	性能升级性能升级的几个层面：系统结构：模块分解，模块交互，系统构建中的粗略估算。算法和数据结构：获得快速模块的关键：表示数据的结构，操作数据的算法：索引结构及拉链归并。代码调优：分支预测等。循环：将循环体中不改变的变量移动到循环体外；多重循环嵌套顺序。函数调用：inline函数节省函数调用开销：若makefile中不指定至少-O优化，即使声明为inline函数，编译器也不会进行函数内联。内存寻址：避免重复内存寻址。Cpu流水线的分支预测：将满足概率最高的条件放在靠前的位置。	0.8581585209238538
CDN全局流量调度算法	业务生成平台用户指南总体说明开发背景下一代网络是业务驱动的网络，在融合的下一代网络上高效、灵活地开发和部署各种丰富多彩的业务，从而提高网络使用率、增加收益的目标，是下一代网络的关键环节。下一代网络的发展要求呼叫与承载相分离、呼叫控制与业务相分离，使业务真正独立于网络，业务开发者不必关心与业务承载相关的底层网络知识以及具体的通信协议，只需利用业务生成平台提供的业务开发工具，就可以开发出灵活丰富且极具个性化的业务。 为了适合多种技术水平的业务开发人员的需要，现在主要有四种业务开发方式：	0.8581585209238538
CDN全局流量调度算法	Svm分类模型：基本原理：将所有待分类的点映射到“高维空间”，然后在高维空间中找到一个能将这些点分开的“超平面”，这在理论上是被完全证明了是成立的，而且在实际计算中也是可行的。满足条件的“超平面”的个数不是唯一的。SVM需要的是利用这些超平面，找到这两类点之间的“最大间隔”。并非所有的数据都线性可分，将非线性映射到更高维的特征空间变成线性可分。（低维空间向量集通常难于划分，解决的方法是将它们映射到高维空间。）但这个办法带来的困难就是计算复杂度的增加，而核函数正好巧妙地解决了这个问题。也就是说，只要选用	0.8579186944453708
CDN全局流量调度算法	工作6周年5个月小记今天是中国时间8/24/2018，也就是我32岁的生日，这是一个不老也不再年轻的年纪。最近总是因为工作而郁郁寡欢，心中不快，所以决定记录总结一下，希望自己能有所释怀、转变、确立新的目标。从2012年3月31到现在，我已在微软Bing工作6年5个月。在此之前，我在百度实习9个月，在阿里巴巴实习2个月，在搜狗实习1个月。在微软北京CJK relevance组勤恳的工作2年6个月，从级别59升到61，做了1年半的DU, 1年的relevance。总体来说，老板们的风格是相关性主导基础	0.8578238278932069

CAL_OFE_Cooking	CAL OFE logsOFE raw logs are cooked with the CALOFELogExtraction script, located in answers_alterations\private\OfflineDataGen\QueryAlteration\CALOFE\CALOFE.slnCooking the raw logsTo cook your logs, you need to runanswers_alterations\private\Offli	0.27973160122456864
CAL_OFE_Cooking		0.2550713778349824
CAL_OFE_Cooking	Smart relax, 3-way choiceMomo JengOffline simulationGeneral process for offline simulation:We have n choices to decide between, where n is small.Given choices A, B, and C, randomly show users A, B, or C.Randomization can be per-user (i.e. se	0.21581707251070456
CAL_OFE_Cooking	Offline Flight Simulation and JO triggering in CALMomo JengOffline Flight SimulatorOffline simulator:System for evaluation of models: What would we have seen in Foray, had we flighted this model?Used to optimize JO triggering for click metrics.	0.18413997959949058
CAL_OFE_Cooking	Offline Simulator in ChlorineOffline simulator in ChlorineOffline simulator in Chlorine (Jan-Jun 2016):New Query Simplification Path (QS3) in en-*European Query SimplificationRelaxcount in en-*New infrastructure in en-non-USNew triggering th	0.156389711810008
CAL_OFE_Cooking	CoreCAL Improvements		Page 2 of 5CoreCAL ImprovementsDescriptionDuring Sodium, CAL Team would invest on optimizing separately for L0\L1\L2 on top of current CoreCAL improvements. Multiple Query Project will target Fidelity\SBS\SSRx while CoreCAL imp	0.1322813330777982
CAL_OFE_Cooking	6/8/2016To Whom It May Concern:Re:	Jia LiuThis letter is to confirm that Jia Liu was employed at Microsoft (China) Company Limited in Beijing, China from March 30, 2012 to June 21, 2015.  She worked full time, 40 hours per week.  Sincerely,Xue B	0.12713635428367548
CAL_OFE_Cooking	To whom it may concern,The bearer of this letter is my sister, Yan Liu. My name is Jia Liu, and I am a software engineer employed by Microsoft. I am working here on an L1 visa valid until 2019. I have invited my parents, my sister, and her son to come v	0.1152536231516161
CAL_OFE_Cooking	To whom it may concern,The bearers of this letter are my parents and nephew.  My name is Jia Liu, and I am a software engineer employed by Microsoft.  I am working here on an L1 visa valid until 2019.  I have invited my parents, my sister, and her son t	0.11512404795888377
CAL_OFE_Cooking	To whom it may concern,  We are Jia Liu and her husband, Edward Wild.  The bearers of this letter are Jia's mother, Chunxiang Lei, and father, Xinbao Liu.  Jia is a software engineer working at Microsoft on an L1 visa valid until 2020, and Edward is a	0.09735024893079218

CALRanker	CAL MultiQuery {Matching\Ranking}		Page 3 of 4CAL MultiQuery {Matching\Ranking}DescriptionCAL is going to optimize against matching\ranking separately and will issue different queries to each tier. CAL will be leveraging several operator such as:m	0.22040958376727637
CALRanker		0.2162763973338887
CALRanker	MQ for CALOverviewSpellerQASMQTriggerMQSingleQueryChainChainChainAugmentAugmentAugmentTailQuerySimplifiedSPCombSP1SP2Sp3AugmentAugmentPropertyBag - SQQueryAlterationListQueryAlterationSetQueryAlterationType	0.12803862160799634
CALRanker	CALQuery alterationAgendaRoadmap and VisionWhere are weWhere to goPlanHow to get thereProgress and looking aheadSodium so farMagnesium and beyondDeep DiveGolden QueryRoadmap & VisionWhere are weCurrent status/problem of CAL	0.12621747212222767
CALRanker	Meta-stream work summaryHeyong WangClickstream exampleOverview: Click-Stream generationWeb logsLocal logsLocal clicked dataJoin with Local IndexWeb Clicked data (query, url etc.)IE ClickBing ClickIE SessionIE Tool Bar…Web Click	0.09009868378543834
CALRanker	CAL OFE logsOFE raw logs are cooked with the CALOFELogExtraction script, located in answers_alterations\private\OfflineDataGen\QueryAlteration\CALOFE\CALOFE.slnCooking the raw logsTo cook your logs, you need to runanswers_alterations\private\Offli	0.08698690252459154
CALRanker	Content Quality Classification & RankingGuihong Cao, Cheng NiuContent Quality for RankingContent quality = originality + trustworthy + information satisfaction + freshnessSpam sites, junk site, link farm, content farm, ….Search users are interes	0.08000410825268002
CALRanker	L2 Ranker Training and Feature Management						-- Shu HuangOutlineL2 ranker and truncation rankerFeature extractionFake L2 rankerFeature extraction pipelineMutiple ideal querysetsL2 ranker and truncation rankerFind the current prod ran	0.07594153487141678
CALRanker	YPCutoff Selection                                                                                    -Ganesh Poomal GirirajanQuery Flow in IndexFilterSet GenerationL1 RankingL2 RankingExampleQuery: Southeast{Miami,Florida}-broward county sc	0.07501333680047856
CALRanker	Relaxcount=2 summaryRelaxcount=2 datagatheringDatagathering for relaxcount=2 branched path (3/14/15-3/20/15):Cal13a: control (OFE logging, relaxcount=2 off), 6% trafficCal13b: on (OFE logging, relaxcount=2 on for word count >=5), 12% traffic.Dat	0.06607432068029605

CALMultiQuery	CAL MultiQuery {Matching\Ranking}		Page 3 of 4CAL MultiQuery {Matching\Ranking}DescriptionCAL is going to optimize against matching\ranking separately and will issue different queries to each tier. CAL will be leveraging several operator such as:m	0.33275052370550884
CALMultiQuery	MQ for CALOverviewSpellerQASMQTriggerMQSingleQueryChainChainChainAugmentAugmentAugmentTailQuerySimplifiedSPCombSP1SP2Sp3AugmentAugmentPropertyBag - SQQueryAlterationListQueryAlterationSetQueryAlterationType	0.2821858819633912
CALMultiQuery	Relaxcount=2 summaryRelaxcount=2 datagatheringDatagathering for relaxcount=2 branched path (3/14/15-3/20/15):Cal13a: control (OFE logging, relaxcount=2 off), 6% trafficCal13b: on (OFE logging, relaxcount=2 on for word count >=5), 12% traffic.Dat	0.22923988493194264
CALMultiQuery	CALQuery alterationAgendaRoadmap and VisionWhere are weWhere to goPlanHow to get thereProgress and looking aheadSodium so farMagnesium and beyondDeep DiveGolden QueryRoadmap & VisionWhere are weCurrent status/problem of CAL	0.22303372760753276
CALMultiQuery		0.21389568158820732
CALMultiQuery	Local Category Search Plan3 month StrategyData: Entity categorizationScalable, high precision/recallSegments: Food & Drink, Retail, Service, Auto, HotelMetaStream enrichmentQuery UnderstandingDolphin by defaultConsume PhoneBookQU to im	0.19602247788799562
CALMultiQuery	Summary of 50 queries:QueryIssue categoryResolved促销策略案例分析Page NumberYes美丽说面膜Page NumberYes朝鲜金正恩腐化生活 图片Page NumberNo(L3 rule not cover this case: the second page is higher than the first page)智慧树2012全集Page NumberYes潘阳老公石磊P	0.19271399700079764
CALMultiQuery	Training data distributionContain categories as many as possible : 36 categies. The data of category in the same amountContain hudong data and  host dataPositive : negative = 1:7  ~ 1:10 categoryhudonghostpositivenegativeNegative_total	0.1467874605450966
CALMultiQuery	CRF Parser AnalysisBusiness category searchOverviewParser (phonebook)CRF ParserqueryLocation featuresCRF featuresQuery parsetoken[tag] token[tag] … token[tag]userBLUbusiness_namebusiness_categorylocationlocation_separatorbu	0.14591142718184943
CALMultiQuery	Text Latitude Longitude S0:Local_L3DCG3 G0:Local_L3DCG3 S1:Local_L3DCG3 S2:Local_L3DCG3 Assignment RootCause(BadMetastream,PartialMatch,Cal,BadKeyword,OtherQU,Ranker,BingNotStable,Scraping,Metrics,MicroSegment,JudgeNoise,Unknown,BadEntity) BTC CanBeResolv	0.1299706493271608

CAL requirements MM	CAL MultiQuery {Matching\Ranking}		Page 3 of 4CAL MultiQuery {Matching\Ranking}DescriptionCAL is going to optimize against matching\ranking separately and will issue different queries to each tier. CAL will be leveraging several operator such as:m	0.268589949045113
CAL requirements MM		0.2488674736159034
CAL requirements MM	Local Category Search Plan3 month StrategyData: Entity categorizationScalable, high precision/recallSegments: Food & Drink, Retail, Service, Auto, HotelMetaStream enrichmentQuery UnderstandingDolphin by defaultConsume PhoneBookQU to im	0.15601103812929468
CAL requirements MM	Local and mm magnesium asksCALApril 2013Microsoft ConfidentialContextWe are expanding to many international markets for Win-blueCAL/Speller impact can range from -1 to +2 points in DCG. Recent MM US DSAT analysis (Dec 2012) showed close to 1	0.14519867632419975
CAL requirements MM	Training data distributionContain categories as many as possible : 36 categies. The data of category in the same amountContain hudong data and  host dataPositive : negative = 1:7  ~ 1:10 categoryhudonghostpositivenegativeNegative_total	0.14456212105319316
CAL requirements MM	InstructionS FOR obtaining photographsfor your applicationPHOTO REQUIREMENTS:Your photographs must be:2x2 inches in size Identical Taken within 30 days of filing the application(s), showing current appearance In color Full face, front view	0.14000641646180095
CAL requirements MM	Publication date optimization for zh-cn marketBackgroundPublication date is a very fundamental and important feature. It can help fresh ranking, whole page user experience: caption date show and freshness internal metrics, also to solve mainline out	0.12753314974431745
CAL requirements MM	Relaxcount=2 summaryRelaxcount=2 datagatheringDatagathering for relaxcount=2 branched path (3/14/15-3/20/15):Cal13a: control (OFE logging, relaxcount=2 off), 6% trafficCal13b: on (OFE logging, relaxcount=2 on for word count >=5), 12% traffic.Dat	0.12356099122745044
CAL requirements MM	Deep Learning: The Path ForwardTuring/AGI/WITSaurabh TiwaryGoalsStrategyDL first everywhereScaleAGI-fying building blocksNew ScenarioLight up T@W & Unified QUDL-firstWe have been hedging our effortsLet’s do (a little bit of) everyt	0.10870783255375828
CAL requirements MM	CAL OverviewPhysical InfrastructurePHR machine functionCO3 (WA) 44 machines, 6-10 kQPSCH1D (Chicago) 83 machines, 4-8 kQPSBN1 (VA) 62 machines, 6-16 kQPSDB3 (Dublin) 16 machines, 1-5 kQPSSG1 (Singapore) 9 machines, 1-4 kQPSBJ1 (Beijing) 3 	0.10643942912497178

CAL Users Guide	CAL MultiQuery {Matching\Ranking}		Page 3 of 4CAL MultiQuery {Matching\Ranking}DescriptionCAL is going to optimize against matching\ranking separately and will issue different queries to each tier. CAL will be leveraging several operator such as:m	0.2748294746319376
CAL Users Guide	CAL User’s GuideLast Update April 5, 2013 by Garrett KaminagaChange Log4/5/13garretkSkeleton outline, operational detailsOverviewCAL (Combined ALterations) analyzes the spell-corrected user query, and attempts to augment it to improve releva	0.22162521626469656
CAL Users Guide	alterationsalterations: product goalimprove recallby adding terms (not replacing or dropping user-entered terms)using word:which are synonyms to the original terms(we are re-examining each of these for vnext)alterations: general principl	0.19244099054667424
CAL Users Guide	CALQuery alterationAgendaRoadmap and VisionWhere are weWhere to goPlanHow to get thereProgress and looking aheadSodium so farMagnesium and beyondDeep DiveGolden QueryRoadmap & VisionWhere are weCurrent status/problem of CAL	0.18557146381572104
CAL Users Guide	Phrasal Alterations & CAL Infra 		Page 2 of 2Phrasal Alterations & CAL Infra DescriptionPhrasal Alterations is going to add CAL the functionality of doing N-to-M alterations. Given a query, CAL is going to generate multiple candidate queries without	0.1826307794241767
CAL Users Guide	Site Quality ClassificationGuihong CaoDefinition of the ProblemWhat is site quality?Google’s definition includes the following dimensionsDuplicated content within the siteTrustworthyOn demand media? Quality controlSite authorityAuthor 	0.18169584229590743
CAL Users Guide	Local Category Search Plan3 month StrategyData: Entity categorizationScalable, high precision/recallSegments: Food & Drink, Retail, Service, Auto, HotelMetaStream enrichmentQuery UnderstandingDolphin by defaultConsume PhoneBookQU to im	0.1778878075716999
CAL Users Guide	Training data distributionContain categories as many as possible : 36 categies. The data of category in the same amountContain hudong data and  host dataPositive : negative = 1:7  ~ 1:10 categoryhudonghostpositivenegativeNegative_total	0.1720222689667876
CAL Users Guide	Bitext Alignment for Alteration Candidate GenerationJan 2018Alteration BasicsCAL alteration architecture is a big funnelCurrent mouth of the funnel is the altlist – a non-context-sensitive relation of <source, target, score>Built over time, qu	0.17159054735377133
CAL Users Guide	Auto Category Classification PipelineHanqing Cui2012/10/25OutlinePain PointsThinkingAuto Category Classification PipelineAuto Page LabelingData SamplingTrainingFeature SelectionThresholdIterative TrainingInitial Seed Model Creati	0.15634145974449246

CAL TermX, Triggering overview	MQ for CALOverviewSpellerQASMQTriggerMQSingleQueryChainChainChainAugmentAugmentAugmentTailQuerySimplifiedSPCombSP1SP2Sp3AugmentAugmentPropertyBag - SQQueryAlterationListQueryAlterationSetQueryAlterationType	0.3145148467430791
CAL TermX, Triggering overview	TermX TrainingLast saved by Gord Lueck, 8/17/2015 2:15 PMContentsTermX Training	1Overview	1Prerequisites	1Inputs	1Translation Model Generation	2TermX_GenerateTrainingData	2TermX_GenerateTM	2TermX Trim Model	3TermX_PostProcess TM	3C	0.2985066425135051
CAL TermX, Triggering overview	Training data distributionContain categories as many as possible : 36 categies. The data of category in the same amountContain hudong data and  host dataPositive : negative = 1:7  ~ 1:10 categoryhudonghostpositivenegativeNegative_total	0.2924011616470791
CAL TermX, Triggering overview	Reading List for Natural Language Query ParsingThis is for improving our NL query parsing for entity/local triggering.By NL query parsing, our goal is to automatically extract the structured information from the query, normally by segmenting queries a	0.287958011607668
CAL TermX, Triggering overview	Integrating Knowledge Graph in Web SearchEntity Triggering and CollectionsPresenter: Ze TianKnowledge GraphEntities and RelationsEntities: celebrities, people, generic terms (e.g. light bulb)Relations: sibling, spouse, people and their works	0.2872797948905315
CAL TermX, Triggering overview	CAL OFE logsOFE raw logs are cooked with the CALOFELogExtraction script, located in answers_alterations\private\OfflineDataGen\QueryAlteration\CALOFE\CALOFE.slnCooking the raw logsTo cook your logs, you need to runanswers_alterations\private\Offli	0.2829506276261202
CAL TermX, Triggering overview	Production Models OverviewLU annotates incoming text input with semantic information in a contextual wayWorkflow built on top of Bing production infrastructure (QAS/XAP/Object Store)Feature representation: word embedding, n-grams and lexicons matche	0.28089026538641904
CAL TermX, Triggering overview	CALQuery alterationAgendaRoadmap and VisionWhere are weWhere to goPlanHow to get thereProgress and looking aheadSodium so farMagnesium and beyondDeep DiveGolden QueryRoadmap & VisionWhere are weCurrent status/problem of CAL	0.2563637646023921
CAL TermX, Triggering overview	Interactive BingGoalSolving hard queryOverview Search engine is helping people solving problem. A lot of cases, search engine couldn’t solve problem at first shot. At this point, search engine need take more information to narrow down the user int	0.2507449151239834
CAL TermX, Triggering overview	FastRank--- a Decision-Tree based Ranking ModelYu SHIOutlineBackgroundAlgorithm overviewTraining implementationExperimentationChallengesReferencesBackgroundInvestigated by MSR in OsloShipped with July Tree 2010 (Denver)GoalsSpe	0.25014063820546795

CAL Problem Vision and Roadmap V2	CAL Problem, Vision and RoadmapContentsOverview	2Problem of today’s CAL	2Vision and Roadmap	3Start from simple but important one: infrastructure.	3Now comes core problem: Metrics	3Now comes to the interesting part: context	4Data	5Head qu	0.8032173006440829
CAL Problem Vision and Roadmap V2	CALQuery alterationAgendaRoadmap and VisionWhere are weWhere to goPlanHow to get thereProgress and looking aheadSodium so farMagnesium and beyondDeep DiveGolden QueryRoadmap & VisionWhere are weCurrent status/problem of CAL	0.35792816269157346
CAL Problem Vision and Roadmap V2	Relevance and AIBing and Information Platform GroupFY18 AGI Encoder RoadmapFeature OwnersProgram ManagersNitin SharmaDevelopersSaurabh Tiwary, Gargi GhoshResearchersMarketingPartnersYantao Li, Weihu, GuihongOverviewAGI Encoder go	0.31481529381964696
CAL Problem Vision and Roadmap V2	Local Category Search Plan3 month StrategyData: Entity categorizationScalable, high precision/recallSegments: Food & Drink, Retail, Service, Auto, HotelMetaStream enrichmentQuery UnderstandingDolphin by defaultConsume PhoneBookQU to im	0.29902045831045254
CAL Problem Vision and Roadmap V2	 Core Web RelevanceInformation Platform GroupBing Spam & JunkFeature OwnersProgram ManagersMichael AbboudDevelopersPavel Karpovich, Lidong Zhao, Gregory Minasyants, Ashok Ponnuswami,  Eugene Remizov, Mikhail BorbotDev ManagerLuke ChenM	0.2825913875665803
CAL Problem Vision and Roadmap V2	Training data distributionContain categories as many as possible : 36 categies. The data of category in the same amountContain hudong data and  host dataPositive : negative = 1:7  ~ 1:10 categoryhudonghostpositivenegativeNegative_total	0.2724100438021083
CAL Problem Vision and Roadmap V2	FY19 Search & AI Roadmap Review: AGI for Web RankingMay 2018Dev: Chen Zhou, Saurabh TiwaryPM: Kiki Liu, Mir RosenbergMotivation“…But often time we have more problems about the subjects we are not familiar with and therefore even the keywords	0.2689638923720684
CAL Problem Vision and Roadmap V2	Bing Location Understanding (BLU)Marta Penas CentenoBoot camp (03/30/2016)BLU overviewLocation candidate extractionFeature extractionRankingTruncationLocation candidate extractionLocation candidate extractionFeature extractionRan	0.268043211988225
CAL Problem Vision and Roadmap V2	Who Am I?Name: Jefferson WangClass: Rising CS SeniorUniversity: Georgia TechTeam: Bing Local RelevanceMentor: Supriya HarpaleManager: Jian WuProject SummaryTitle: QAS MLG Featurizer DebuggerDescription: Minimize the time it takes for a	0.2615624467490876
CAL Problem Vision and Roadmap V2	InstructionS FOR obtaining photographsfor your applicationPHOTO REQUIREMENTS:Your photographs must be:2x2 inches in size Identical Taken within 30 days of filing the application(s), showing current appearance In color Full face, front view	0.259167486334573

CAL Overview	Production Models OverviewLU annotates incoming text input with semantic information in a contextual wayWorkflow built on top of Bing production infrastructure (QAS/XAP/Object Store)Feature representation: word embedding, n-grams and lexicons matche	0.24776813385840815
CAL Overview	CAL OFE logsOFE raw logs are cooked with the CALOFELogExtraction script, located in answers_alterations\private\OfflineDataGen\QueryAlteration\CALOFE\CALOFE.slnCooking the raw logsTo cook your logs, you need to runanswers_alterations\private\Offli	0.22077485554692916
CAL Overview	Local Category Search Plan3 month StrategyData: Entity categorizationScalable, high precision/recallSegments: Food & Drink, Retail, Service, Auto, HotelMetaStream enrichmentQuery UnderstandingDolphin by defaultConsume PhoneBookQU to im	0.21831425783510644
CAL Overview	CAL MultiQuery {Matching\Ranking}		Page 3 of 4CAL MultiQuery {Matching\Ranking}DescriptionCAL is going to optimize against matching\ranking separately and will issue different queries to each tier. CAL will be leveraging several operator such as:m	0.2169060872191254
CAL Overview	CAL OverviewPhysical InfrastructurePHR machine functionCO3 (WA) 44 machines, 6-10 kQPSCH1D (Chicago) 83 machines, 4-8 kQPSBN1 (VA) 62 machines, 6-16 kQPSDB3 (Dublin) 16 machines, 1-5 kQPSSG1 (Singapore) 9 machines, 1-4 kQPSBJ1 (Beijing) 3 	0.19852430081740924
CAL Overview	CALQuery alterationAgendaRoadmap and VisionWhere are weWhere to goPlanHow to get thereProgress and looking aheadSodium so farMagnesium and beyondDeep DiveGolden QueryRoadmap & VisionWhere are weCurrent status/problem of CAL	0.18024397534334147
CAL Overview	Training data distributionContain categories as many as possible : 36 categies. The data of category in the same amountContain hudong data and  host dataPositive : negative = 1:7  ~ 1:10 categoryhudonghostpositivenegativeNegative_total	0.17490168252913296
CAL Overview	Phrasal Alterations & CAL Infra 		Page 2 of 2Phrasal Alterations & CAL Infra DescriptionPhrasal Alterations is going to add CAL the functionality of doing N-to-M alterations. Given a query, CAL is going to generate multiple candidate queries without	0.16024684717910634
CAL Overview	CoreCAL Improvements		Page 2 of 5CoreCAL ImprovementsDescriptionDuring Sodium, CAL Team would invest on optimizing separately for L0\L1\L2 on top of current CoreCAL improvements. Multiple Query Project will target Fidelity\SBS\SSRx while CoreCAL imp	0.14744249199048357
CAL Overview	Spam/Junk Technology ReviewAgendaSpam/Junk OverviewReview of current metrics and pipelinesExample of recently shipped technologiesJunk page elimination by cross page signalsAnti-{malicious page redirection spam attack}Looking aheadSpam in 	0.14569654026105214

CAL LRP	www.mhb.comPage 2www.mhb.comwww.mhb.comwww.mhb.comwww.mhb.comwww.mhb.comInstructionS FOR scheduling your medical exam Medical Examination and Insurance InformationEach applicant for adjustment of status to permanent resident must have 	0.2441402845994254
CAL LRP		0.2314196045307957
CAL LRP	CAL MultiQuery {Matching\Ranking}		Page 3 of 4CAL MultiQuery {Matching\Ranking}DescriptionCAL is going to optimize against matching\ranking separately and will issue different queries to each tier. CAL will be leveraging several operator such as:m	0.19691741084642314
CAL LRP	CAL OFE logsOFE raw logs are cooked with the CALOFELogExtraction script, located in answers_alterations\private\OfflineDataGen\QueryAlteration\CALOFE\CALOFE.slnCooking the raw logsTo cook your logs, you need to runanswers_alterations\private\Offli	0.18877398002538812
CAL LRP	Auto Category Classification PipelineHanqing Cui2012/10/25OutlinePain PointsThinkingAuto Category Classification PipelineAuto Page LabelingData SamplingTrainingFeature SelectionThresholdIterative TrainingInitial Seed Model Creati	0.17963128503993675
CAL LRP	QR FY19 LRP Planning - 23/29/18Unified Concept Tagging – Key ChallengesStructural ComplexityFor ambiguous queries and multi-concept queries, how much organization is required?  How to represent this in a linear qlf?  What about inter-concept rel	0.1781132882034047
CAL LRP	CAL OverviewPhysical InfrastructurePHR machine functionCO3 (WA) 44 machines, 6-10 kQPSCH1D (Chicago) 83 machines, 4-8 kQPSBN1 (VA) 62 machines, 6-16 kQPSDB3 (Dublin) 16 machines, 1-5 kQPSSG1 (Singapore) 9 machines, 1-4 kQPSBJ1 (Beijing) 3 	0.16583371113769374
CAL LRP	Entity Categorization Using Convolutional Neural NetworkWeiwu Zhu8/23/2018AgendaMotivationCNN introductionCNN in NLPCNN based entity categorizationMeasurementMotivationTaxonomy mapping is not scalable (Feature Normalization)Nee	0.16520349881931004
CAL LRP	Core Web RelevanceFY16 H2 PlanCore Web RelevanceFY16 H2 PlanCore Web RelevanceFY16 H2 PlanCore Web RelevanceFY16 H2 Plan	0.14714060165407966
CAL LRP	www.mhb.comwww.mhb.comwww.mhb.comwww.mhb.comwww.mhb.comwww.mhb.comPage 2REQUIREMENTS FORBIRTH AND MARRIAGE RECORDSBirth Certificates:  Each birth certificate should state the name, place, date of birth, and names of parents.  (These 	0.14619496768676163

BusinessV3TaxonomyClassifier_Design	BusinessV3TaxonomyClassifierAugust, 2018Daniel WeinshenkerMicrosoft ConfidentialAgendaMicrosoft ConfidentialPurpose / OverviewDemoData Pipeline / Lexicon GenerationMeasurementQASChallenges / Future WorkPurpose We want to improve 	0.5878777676871436
BusinessV3TaxonomyClassifier_Design	Global CAL Aluminum PlanJunfeng ZhouAgendaMagnesium StatusAluminum FocusProjectsMagnesium Status - ReleasesJuly: aggressive relaxation on no result queriesSept: relax count classifier, morphological alterationsOct: JO v1Nov: morphologi	0.3866776576738291
BusinessV3TaxonomyClassifier_Design	Thoughts on Interest Graph – Experience, Business and TechnologyPersonalized recommendation that you don’t want to miss Author: Ting Cai Contributors: AC Surendran, Xiaodong Fan, Chuanxin Hu, Yan Ke, Tony Chor, Richard Qian1.	What is Interest Graph?	0.37250472458343126
BusinessV3TaxonomyClassifier_Design	OPG- Business Continuity PlanTellMeService, Shredder, AugmentationService, Enrichment, UCIService (Insights), Entity ServiceDocument Revision HistoryDateAuthorChange NotesLeader Sign off4/30/2018alyanInitial document5/10/2019alyanU	0.3706136015773941
BusinessV3TaxonomyClassifier_Design	Entity Pane and Fact AnswerPresenter: Ze TianJun 25, 2013IntroductionIntroductionIntroductionProblems to SolveDoes the user search for entities or facts of entities?E.g. “who is msft ceo” (Entity: Microsoft, Fact: Chief Executive O	0.3569766134722463
BusinessV3TaxonomyClassifier_Design	Span ClassifierSpan classifier is a general infrastructure that can be used to run a fastrank based classifier on a sequence of terms from a query.  It can be used to apply rankonly or norelax to parts of the query based on the result of the model.  Fea	0.35438988706930963
BusinessV3TaxonomyClassifier_Design	Keyword Predictor Design DocumentName: Ruchir RastogiMentor: Jia LiuManager: Leon ZhangProject overviewThe goal of this project is to design a machine-learning model that can predict keywords in a local query for improving local search relevance	0.3405039572057286
BusinessV3TaxonomyClassifier_Design	FusionByTurker KeskinpalaTuesday, May 17, 2016OverviewMotivationsWhat is Fusion?GoalsFusion ComponentsRoadmapWeb AnswerQ:“gg”Qpath1:“gg”Qpath2:“google”TLACDG FetcherL2 FetcherTLACDG FetcherL2 FetcherLL4L3L3	0.33694834813314756
BusinessV3TaxonomyClassifier_Design	WrapStar On-Demand DesignDrafted by ZiliuContentsContext2Design Goals2Automation2Deployment Agility2High Availability2Non-Goals2Metrics2Required Changes3Orchestration3AP Migrations3Pipeline Evolution3Tools/services refactoring3	0.33085411109830404
BusinessV3TaxonomyClassifier_Design	Combined ALterationsNeon\sodiumAgendaNeon AchievementsBreakdownsSodiumIdeas & PlanNeonOverall ProgressExceeded Neon Commitments on CQS!NeonCQS Deep-dive-34% Bad+14% Excellent-15% Bad+13% ExcellentDRDOCQS is impr	0.330011587471514

Bitext alignment	Bitext Alignment for Alteration Candidate GenerationJan 2018Alteration BasicsCAL alteration architecture is a big funnelCurrent mouth of the funnel is the altlist – a non-context-sensitive relation of <source, target, score>Built over time, qu	0.5816680325540942
Bitext alignment	Phrasal Alterations & CAL Infra 		Page 2 of 2Phrasal Alterations & CAL Infra DescriptionPhrasal Alterations is going to add CAL the functionality of doing N-to-M alterations. Given a query, CAL is going to generate multiple candidate queries without	0.3192999067674636
Bitext alignment	Span ClassifierSpan classifier is a general infrastructure that can be used to run a fastrank based classifier on a sequence of terms from a query.  It can be used to apply rankonly or norelax to parts of the query based on the result of the model.  Fea	0.2544698798219222
Bitext alignment	Stateful Query Intent RefinementFeature OverviewStateful Query Intent Refinement is a Bing QR service that can be leveraged to guide users to their specific intent. Queries that have ambiguous intent or multiple intents/sub-intents can be refined usin	0.23684250612830646
Bitext alignment	alterationsalterations: product goalimprove recallby adding terms (not replacing or dropping user-entered terms)using word:which are synonyms to the original terms(we are re-examining each of these for vnext)alterations: general principl	0.22411030065201593
Bitext alignment	VORTEXTowards An E2E Vector-based Search StackProjects OverviewVector-based Retrieval(ANN recall path)L2 vector injectionVector-based RankingDeep Dejavu SpaceVWideDeep in FusionProjects OverviewVector-based RetrievalL2 vector i	0.2187311866446299
Bitext alignment	Document classification based on urlBackgroundWe want to do document classification for better understanding the document type and document with query category match for ranking.  We will do zh-cn document classification based on url first, then docum	0.2164706862732852
Bitext alignment	Normalization and Parsing OverviewTypes of NormalizationLimiting to just normalization, there are actually several different types of normalization which may be interesting:WhitespaceThis is:Converting all whitespace characters to spacestrippi	0.21253893448590266
Bitext alignment	Spam/Junk Technology ReviewAgendaSpam/Junk OverviewReview of current metrics and pipelinesExample of recently shipped technologiesJunk page elimination by cross page signalsAnti-{malicious page redirection spam attack}Looking aheadSpam in 	0.2048170246465187
Bitext alignment	Query AugmentationsTable of Contents1. Syntax Overview	22. Constraints	6General rules for operators	7Basic Operators	7Scoring and non-scoring constraint operators	9Stream Operators	9Literal Operators	10Meta Operators	11URL Operators	13	0.1868735569281755

Birth Marriage Cert Requirements	PERM Labor Certification Questionnaire:  Technical (continued)PERM Labor Certification Questionnaire (Technical)Please complete the information requested in this questionnaire carefully.  This information is necessary for the legal analysis and prepar	0.27294207396050957
Birth Marriage Cert Requirements	Bing Ads Insight Track Weekly Review9/07/2015Primary KPIs  -- Product UsageCallout –NAPrimary KPIs – Platform ServiceHighlights/Lowlights: (http://adspulse/Report/61998 ) Callout – N/AUser feedbacks (Premium Tool Phase 1 release) 	0.2437595667757699
Birth Marriage Cert Requirements	学士学位证明BACHELOR DEGREE CERTIFICATEThis is to certify that Ms. Jia Liu, born in August 1986, with the specialty of Computer Science and Technology at Beijing University of Posts and Telecommunications from September 2005 to July 2009, has passed all req	0.23536409606052286
Birth Marriage Cert Requirements	Bing Ads Insight Track Weekly Review11/09/2015Primary KPIs  -- Product UsageCallout –NA- A memory cache mechanism was deployed last week for data platform, which benefits around half traffic and latency decreased significantly.Primary KPIs –	0.21076578437648025
Birth Marriage Cert Requirements	Primary Category: What Is It, Why Is It Important, & How Do We Measure ItBing Local & Geospatial – ShruthiM, DillTellClassificationProcess in which local business entities are categorized based on the type of products and/or services that the busine	0.1813333898891759
Birth Marriage Cert Requirements	11/17 AGI review with HarryCES: cover AI for OfficeCo-market with NvidiaMPQnA Keep in Jordi’s demo in the Dec AI eventAbortion query is very controversial	Not our responsibility to make the decision for the user but it’s the search engine’s re	0.17275861637644874
Birth Marriage Cert Requirements	Deep Dive: Query Generic Entity Extraction (GEE)Zhen Liao04/22/2016OutlineOverview of GEEFAQ for GEEArchitecture and ModelingRecent breakthrough via Deep LearningLessons we’ve learnedGeneric Entity Extraction for Queries: What is the g	0.1726226225381949
Birth Marriage Cert Requirements	Partner Index as ServiceWhat is the Problem? RequirementCurrent status of Bing Image StackDiscoveryClient tend to provide feed for full corpusWeb crawlerImage Content RetrievalSpecial agreement, some even behind authentication for access	0.16933845296827155
Birth Marriage Cert Requirements	Bing Adult FilteringNeil ZhaoSmart adult filtering GloabelSmartAdultFiltering=offSmartAdultFiltering=onStrict-category:ff000001tla:adultfilter:onModerateprefer:-category:ff000001tla:adultfilter:smartOff tla:adultfilter:off ZH	0.1628083618822125
Birth Marriage Cert Requirements	Relevance Experimentation with DUOverviewThe ideal end state for any relevance improvement would consist of having one or more DU features shipped in the index that is then leveraged by the latest production ranker. This would achieve the highest leve	0.1601593812904851

BingGC Multi-Pointer Query	BingGC Multi-Pointer Stack11/4/2014BingGCI@microsoft.comMulti-Pointer ResolutionUsing a tiling system, we first find the correct Tile, then search inside to find matching entities:	 Chipotle Mission St 2nd StQuery: Chipotle Mission St 2nd St	0.7636281912055299
BingGC Multi-Pointer Query	Bing GC Deep DiveBingGCI 9/26/2014Introduction – Pavel, 2minsProject overview – Wei, 6minsBing GC XAP workflow – John, 10minsBing GC data pipeline and data ingestion – Florin, 7minsBing GC Offline relevance platform – Jian, 8minsSingle-poi	0.4073927675685427
BingGC Multi-Pointer Query	https://cosmos11.osdinfra.net/cosmos/skypedata.adhoc/local/SkypeFeedback/Mined/v2/full/ FULLActionEntity.sshttps://cosmos11.osdinfra.net/cosmos/skypedata.adhoc/local/SkypeFeedback/Mined/v2/1d/ SkypeFeedback.ssSkypeSHRComments.ssSkypeSupportSea	0.38282569202074
BingGC Multi-Pointer Query	Pthreads mutex vs Pthreads spinlock 锁机制(lock) 是多线程编程中最常用的同步机制,用来对多线程间共享的临界区(Critical Section) 进行保护。Pthreads提供了多种锁机制,常见的有：1) Mutex（互斥量）：pthread_mutex_***2) Spin lock（自旋锁）：pthread_spin_***3) Condition Variable（条件变量）：pthread_con_***4) Read/Write 	0.3644944769066914
BingGC Multi-Pointer Query	TermX: the Query Rewriting Engine for BingCore Relevance PM Meeting | Shu Zheng | Jan 5th, 2016AgendaWhat is TermX? Technique DeepdiveCurrent StateFuture WorksWhat is TermX? TermX = TermExp = Term ExpansionThe query rewriting engine for 	0.36094494212138384
BingGC Multi-Pointer Query	Query Rewriting Micro SegmentWhy QR Micro SegmentMicro Segment is way to fix corner case that main Bing ranking pipeline couldn’t fix easily by machine learningThere are many ways to do micro segment. Micro segment can be done in many layers. QR, 	0.3599251950375093
BingGC Multi-Pointer Query	Interactive BingGoalSolving hard queryOverview Search engine is helping people solving problem. A lot of cases, search engine couldn’t solve problem at first shot. At this point, search engine need take more information to narrow down the user int	0.3450377605668031
BingGC Multi-Pointer Query	query分类—分享                     刘佳2011.6.8web query classification(query分类):	将web search query根据它的主题，分派到1个或者多个预先定义的分类中。web search query的特征：有噪声：拼写错误等长度很短：信息量少，特征少表意含糊：query可能包含多个含义,属于多个分类含义会随时间演变目标分类的特征：目标分类定义缺少语义注解一级或者多级分类分类数目：几	0.33658145714237875
BingGC Multi-Pointer Query	QueryString Category owner Searchvote url 寇仲最后和谁在一起 ranking  xiaopeng http://searchvote.com/default.aspx?reviewid=209877 布里斯班 ranking  xiaopeng http://searchvote.com/default.aspx?reviewid=211685 必应词典 ranking  xiaopeng http://searchvote.com/default.aspx?re	0.33363273799637944
BingGC Multi-Pointer Query	CAL MultiQuery {Matching\Ranking}		Page 3 of 4CAL MultiQuery {Matching\Ranking}DescriptionCAL is going to optimize against matching\ranking separately and will issue different queries to each tier. CAL will be leveraging several operator such as:m	0.32472268300208823

BingGC DeepDive	Bing GC Deep DiveBingGCI 9/26/2014Introduction – Pavel, 2minsProject overview – Wei, 6minsBing GC XAP workflow – John, 10minsBing GC data pipeline and data ingestion – Florin, 7minsBing GC Offline relevance platform – Jian, 8minsSingle-poi	0.5869811595169518
BingGC DeepDive	ID Phrase Should be removed? 1 all of y 2 bing 3 bing can you 4 bing could you 5 bing could you please 6 bing i d like to 7 bing i d like you to 8 bing i need to 9 bing i need you to 10 bing i wanna 11 bing i want to 12 bing i want you to 13 bing i would 	0.4027986733841836
BingGC DeepDive	Bing IQ Deep Learning ProgressAlejandro Gutierrez, Anton Savin, Frank Guo, Luis Velazco, Gilbert Wong7/22/2016Overall Plan and PrioritiesLearn Deep Learning and Neural NetworkLearn CNTK (Computational Network Toolkit) by walking through the exam	0.37116871183239647
BingGC DeepDive	Google-Bing Entity MatchingIn 75,563 Google scrape entities those with a non-empty name are 12,507: Mapped to Bing entities: 𝟖𝟒.𝟖𝟗% (=(10,162+455)/12,507). Missing data.Among entities in            and            1.07%(=83+51) have Lat/Lon	0.33730503195202416
BingGC DeepDive	BingGC Multi-Pointer Stack11/4/2014BingGCI@microsoft.comMulti-Pointer ResolutionUsing a tiling system, we first find the correct Tile, then search inside to find matching entities:	 Chipotle Mission St 2nd StQuery: Chipotle Mission St 2nd St	0.3354634542160287
BingGC DeepDive	Augmented Query Parser Using Deep LearningDemi Guo (Bing Local Intern t-deguo)Manager: Leon ZhangMentor: Simona CabuzHello everyone, Today, I’m going to present my intern project: Augmented query parser using deep learning.About Me My name i	0.3276276133627656
BingGC DeepDive	Bing Local Search				PBA Geo Location Feeds augmentation generation Dev ownerTetyana GolubBuddy dev(s)PM ownerDave BargeronContributorsFeature areaPBA Feeds query generationMilestoneAluminumTable of contents1	Overview	22	Goal	0.29790924314383327
BingGC DeepDive	Bing Local Search				CAL updates for international Dev ownerkfritzBuddy dev(s)Kefeng;heyongPM ownerDivye Khilnani ContributorsFeature areaMilestoneTable of contents1	Overview	31.1	Basic algorithm	32	Goals/Non Goals	43	Ris	0.2676274771332238
BingGC DeepDive	Fusion: Next Gen Web IntelligenceDeep Dive with Steven 1/6/2017Goals:Power Bing & Bing Next with web open knowledgeNew post L2 ranking platformImproved agility and scalabilityInherent MQ + contextual capability Integrated ranking process: 	0.26177806302706585
BingGC DeepDive	Deal Understanding and RankingBackgroundDeal is a very big segment in Bing Opal. We crawl store and single deals/coupons regularly from websites like groupon.com, coupons.com, restaurants.com, retailmenot.com, dealcatcher.com, dealplus.com and so on. 	0.25918230114129465

Bing Spam & Junk Product Roadmap	SPAM & JunkSi Planning Cheng Niu, Alex Rahin6/18/2014Agenda	Focus AreasMetricsSPAM/Junk Metrics BreakdownData Analysis and Project DefinitionFocus AreasImprove SPAM Detection (~35% of team bandwidth)Stolen ContentContent Keyword St	0.4784175143523701
Bing Spam & Junk Product Roadmap	BingGC Multi-Pointer Stack11/4/2014BingGCI@microsoft.comMulti-Pointer ResolutionUsing a tiling system, we first find the correct Tile, then search inside to find matching entities:	 Chipotle Mission St 2nd StQuery: Chipotle Mission St 2nd St	0.4257663758656299
Bing Spam & Junk Product Roadmap	Spam/Junk Technology Review8/8/2017 Pavel KarpovichAgendaSpam/Junk OverviewReview of current system and metricsSJRE Fishtank pipelines UrlExclusion and Defect Subranker	Blue Whale Spam Types of Fresh SpamActions to Detect Fresh	0.4107815430421549
Bing Spam & Junk Product Roadmap	FY19 Search & AI Roadmap Review: AGI for Web RankingMay 2018Dev: Chen Zhou, Saurabh TiwaryPM: Kiki Liu, Mir RosenbergMotivation“…But often time we have more problems about the subjects we are not familiar with and therefore even the keywords	0.3933809813635622
Bing Spam & Junk Product Roadmap	Spam/Junk Technology ReviewAgendaSpam/Junk OverviewReview of current metrics and pipelinesExample of recently shipped technologiesJunk page elimination by cross page signalsAnti-{malicious page redirection spam attack}Looking aheadSpam in 	0.38880214684369724
Bing Spam & Junk Product Roadmap	Bing GC Deep DiveBingGCI 9/26/2014Introduction – Pavel, 2minsProject overview – Wei, 6minsBing GC XAP workflow – John, 10minsBing GC data pipeline and data ingestion – Florin, 7minsBing GC Offline relevance platform – Jian, 8minsSingle-poi	0.38179826277301776
Bing Spam & Junk Product Roadmap	Google-Bing Entity MatchingIn 75,563 Google scrape entities those with a non-empty name are 12,507: Mapped to Bing entities: 𝟖𝟒.𝟖𝟗% (=(10,162+455)/12,507). Missing data.Among entities in            and            1.07%(=83+51) have Lat/Lon	0.3723492613117399
Bing Spam & Junk Product Roadmap	FY19 Search & AI Roadmap Review: QRMay 2018Jie Cai, Garrett Kaminaga, Jingwen Lu, Momo JengMotivation – QR Query understanding and rewrite is the first opportunity for Bing to understand users’ intents;In current production, query rewrite is a	0.3423410417380964
Bing Spam & Junk Product Roadmap	CAL Problem, Vision and RoadmapContentsOverview	2Problem of today’s CAL	2Vision and Roadmap	3Start from simple but important one: infrastructure.	3Now comes core problem: Metrics	3Now comes to the interesting part: context	4Data	5Head qu	0.34233124078220506
Bing Spam & Junk Product Roadmap	Bing Location Understanding (BLU) As a ServiceDeep-Dive PresentationRajasi Saha (tech lead for BLU infrastructure)Jian Wu (tech lead for BLU relevance)Microsoft ConfidentialOutlineIntroduction to BLUBLU as a serviceMotivationScenarios an	0.33407896849299784

Bing Adult Filtering	Bing Adult FilteringNeil ZhaoSmart adult filtering GloabelSmartAdultFiltering=offSmartAdultFiltering=onStrict-category:ff000001tla:adultfilter:onModerateprefer:-category:ff000001tla:adultfilter:smartOff tla:adultfilter:off ZH	0.5346209439058557
Bing Adult Filtering	Bing GC Deep DiveBingGCI 9/26/2014Introduction – Pavel, 2minsProject overview – Wei, 6minsBing GC XAP workflow – John, 10minsBing GC data pipeline and data ingestion – Florin, 7minsBing GC Offline relevance platform – Jian, 8minsSingle-poi	0.29019089840451323
Bing Adult Filtering	ID Phrase Should be removed? 1 all of y 2 bing 3 bing can you 4 bing could you 5 bing could you please 6 bing i d like to 7 bing i d like you to 8 bing i need to 9 bing i need you to 10 bing i wanna 11 bing i want to 12 bing i want you to 13 bing i would 	0.27993134554003296
Bing Adult Filtering	BingGC Multi-Pointer Stack11/4/2014BingGCI@microsoft.comMulti-Pointer ResolutionUsing a tiling system, we first find the correct Tile, then search inside to find matching entities:	 Chipotle Mission St 2nd StQuery: Chipotle Mission St 2nd St	0.25884031058820944
Bing Adult Filtering	Google-Bing Entity MatchingIn 75,563 Google scrape entities those with a non-empty name are 12,507: Mapped to Bing entities: 𝟖𝟒.𝟖𝟗% (=(10,162+455)/12,507). Missing data.Among entities in            and            1.07%(=83+51) have Lat/Lon	0.25770390530044884
Bing Adult Filtering	Bing Ads Insight Track Weekly Review11/09/2015Primary KPIs  -- Product UsageCallout –NA- A memory cache mechanism was deployed last week for data platform, which benefits around half traffic and latency decreased significantly.Primary KPIs –	0.24546681200563678
Bing Adult Filtering	Stateful Query Intent RefinementFeature OverviewStateful Query Intent Refinement is a Bing QR service that can be leveraged to guide users to their specific intent. Queries that have ambiguous intent or multiple intents/sub-intents can be refined usin	0.24455637706462433
Bing Adult Filtering	Document classification based on urlBackgroundWe want to do document classification for better understanding the document type and document with query category match for ranking.  We will do zh-cn document classification based on url first, then docum	0.22427241330014305
Bing Adult Filtering	CAL MultiQuery {Matching\Ranking}		Page 3 of 4CAL MultiQuery {Matching\Ranking}DescriptionCAL is going to optimize against matching\ranking separately and will issue different queries to each tier. CAL will be leveraging several operator such as:m	0.20794150389222685
Bing Adult Filtering	Zh-cn Publication date design docBackgroundDesignPublication date from wrapstarPublication date from URLPublication date from titlescore(c1) = w11*f1+w12*f2+w13*f3+w14*f4+w15*f5+bias1score(c2) = w21*f1+w22*f2+w23*f3+w24*f4+w25*f5+bias2Pack	0.20524998056059113

BW_MM_Rank	Blue-Whale Multimedia Rank Data-FlowEugene Jian Huangjianhua@microsoft.com2012-03-13MM Page Static RankMedia LinkExpress RankMM Page Express RankMM PageSuper-Fresh RankMM PageSubmission RankMM PageEffective Rank Media Entit	0.30074432187768474
BW_MM_Rank	Wrapstar rating signalsfor zh-cn documentsJia LiuWrapstar rating signals for rankingWrapstar Taobao ratingWrapstar Tmall ratingWrapstar Qna ratingWrapstar Book ratingWrapstar Video ratingDsats examplesTaobao examplesQuery=“蓝色休闲裤	淘宝”	0.27072060250964225
BW_MM_Rank	L2 Ranker Training and Feature Management						-- Shu HuangOutlineL2 ranker and truncation rankerFeature extractionFake L2 rankerFeature extraction pipelineMutiple ideal querysetsL2 ranker and truncation rankerFind the current prod ran	0.23488537445121996
BW_MM_Rank	Introduction to dynamic ranking Xiao WuOutlinesIntroductionRelevance MeasurementDynamic rankingRanking FeaturesRanking DataRanking modelsRelevance ExperiementIntroductionWhat is dynamic rankingRanking based on query dependent featu	0.21953928480851845
BW_MM_Rank	PDI Document AnnotationPDI Ranking PlatformAgendaPDI and forward indexDocument AnnotationSodium update and MG planQ&A DSAT: {books by children}Issue: Document matches the query terms, but its surrounding words may change the intent of 	0.20529566474141742
BW_MM_Rank	Move SBS (Learning from L3)Xiaopeng WuJunzhou WangWhat’s L3Bing ranking stackIndex selectionWorking on offline system, target recallL1Working on IFM, target recallL2Working on IFM, target precisionL3Working on TLA, target whole pag	0.20016321707293247
BW_MM_Rank	Multi-Query Issue and QR/Ranking Joint Optimization Bhuvan MiddhaJonas BarklundYinzhe YuYuan Wang6/26/2012AgendaPresentation TopicTime/PresenterIntroduction/QR/Ranking for Joint Optimization3:05 pm – 3:30 pm [Bhuvan/Jonas]Joint Opt	0.19312341769126024
BW_MM_Rank	Google Mobile vs Desktop RankDiff StudyNov 2017GoalsUnderstand what Google does differently on Mobile, if anythingDrive product ideas & shape ranking improvements on MobileUnderstand any possible impact to Algo scrapes & metricsDrive scrapin	0.18682372947594045
BW_MM_Rank	PBAVnext and migrationFrank ZhangBenefit of vnextIt will reflect five years’ worth of local search relevance insights and lessons learned, including the relevance tuning principles we have discovered over the years.It will make it easier to suppor	0.17230992851100066
BW_MM_Rank	Tmall&Taobao Rating MetawordsBackgroundWe’ve seen in regular DSAT review meetings the DSATs that we rank too high Tmall or Taobao page with low quality(Tmall page:low sales volume; Taobao page: low sales volume or shop with poor reputation).  Zh-CN ha	0.1701098269872318

BS代码阅读	BS代码阅读：BS基本功能：索引相关性切词成分分析offset调权query解析 （where+what）多路归并 综合调权类聚（偏离点）query分类空间调权数据来源点击调权BS代码阅读：bs_cache:map库的term cachemap库term cache操作锁where库term cachewhere库term cache操作锁init_map_term_cache: 初始化map库term cachein	0.7699602051514453
BS代码阅读	贝叶斯分类模型：基础知识：假设	X：是数据元组，由n个属性描述；	H：是某种假设，如数据元组属于某特定类C	P(H|X)：表示给定X的属性描述，找出元组X属于类C的概率举例：X：一位35岁的顾客，收入为4w美元；H：顾客将购买计算机P(H|X)：在X的条件下，H的后验概率。当我们知道顾客的年龄和收入时，顾客X将购买计算机的概率。P(H)：H的先验概率。任意给定顾客将购买计算机的概率，独立与X。P(X|H)：在条件H下，X的后验概率。已知顾客购买了计算机，顾客是一位3	0.7537656773977773
BS代码阅读	K最近邻分类模型：原理：训练元组用n个属性描述，每个元组代表n维空间中的一个点，所有的训练元组存放在n维的模式空间。当给定一个未知元组时，KNN搜索该模式空间，找出最接近未知元组的k个训练元组。未知元组指派到它的k个最近邻中的多数类。“邻近性”用距离度量，如欧几里德距离。欧几里德距离：	设元组X1=(X11,X12,…X1n)，X2=(X21,X22,…X2n)，	Dist(X1,X2)=√ ∑ k= 1 n (X1i-X2i) 2 	使用上式之前，对每个属性的值规范化，以防止具有	0.7464128151440134
BS代码阅读	Svm分类模型：基本原理：将所有待分类的点映射到“高维空间”，然后在高维空间中找到一个能将这些点分开的“超平面”，这在理论上是被完全证明了是成立的，而且在实际计算中也是可行的。满足条件的“超平面”的个数不是唯一的。SVM需要的是利用这些超平面，找到这两类点之间的“最大间隔”。并非所有的数据都线性可分，将非线性映射到更高维的特征空间变成线性可分。（低维空间向量集通常难于划分，解决的方法是将它们映射到高维空间。）但这个办法带来的困难就是计算复杂度的增加，而核函数正好巧妙地解决了这个问题。也就是说，只要选用	0.7463467101861299
BS代码阅读	排序及扩展：插入排序，选择排序（冒泡排序），使用二分思想求第k大数，快速排序，非递归的快速排序，使用快排思想求第k大数，归并排序，求逆序数，自然排序算法，堆排序，最小优先级队列，计数排序，桶排序，鸽巢排序（分块排序），基数排序，外部排序：二路归并，K路归并，胜者树，败者树。  算法一：使用插入或者选择排序，得到最大的K个数，时间复杂度为：O(N*k)。 冒泡排序： void swap(int * a,int * b){            //注意	0.7458288018511633
BS代码阅读	克拉玛依公证处:本人因生活在国外，不能亲自到贵单位办理出生证明公证事项，兹授权委托雷春香女士全权代表我办理相关事项。对委托人在办理上述事项过程中所签署的有关文件，我均予以认可，并承担相应的法律责任。委托人：刘佳			委托人身份证号码：654301198608243929被委托人：雷春香		被委托人身份证号码：6526196207113926委托人：刘佳2018年5月24日	0.7458288018511633
BS代码阅读	性能升级性能升级的几个层面：系统结构：模块分解，模块交互，系统构建中的粗略估算。算法和数据结构：获得快速模块的关键：表示数据的结构，操作数据的算法：索引结构及拉链归并。代码调优：分支预测等。循环：将循环体中不改变的变量移动到循环体外；多重循环嵌套顺序。函数调用：inline函数节省函数调用开销：若makefile中不指定至少-O优化，即使声明为inline函数，编译器也不会进行函数内联。内存寻址：避免重复内存寻址。Cpu流水线的分支预测：将满足概率最高的条件放在靠前的位置。	0.7458288018511633
BS代码阅读	业务生成平台用户指南总体说明开发背景下一代网络是业务驱动的网络，在融合的下一代网络上高效、灵活地开发和部署各种丰富多彩的业务，从而提高网络使用率、增加收益的目标，是下一代网络的关键环节。下一代网络的发展要求呼叫与承载相分离、呼叫控制与业务相分离，使业务真正独立于网络，业务开发者不必关心与业务承载相关的底层网络知识以及具体的通信协议，只需利用业务生成平台提供的业务开发工具，就可以开发出灵活丰富且极具个性化的业务。 为了适合多种技术水平的业务开发人员的需要，现在主要有四种业务开发方式：	0.7458288018511633
BS代码阅读	神经网络原理及应用介绍Anti RD：王伟琼、张爱华主要内容特点及应用场景神经网络原理我们的经验和教训多线程训练下一步的工作应用场景分类预测时间允许的场合使用并行化等方法加速测试过程很快，且可以方便的使用hadoop平台环境比较固定的场合数据的统计特性变化不大需要定量预测的场合给出未知数据的定量预测神经网络特点优点对噪音数据有较好的适应能力对未知数据具有较好的预测分类能力拟合各种函数得出定量值缺点学习时间较长	0.7449852166876456
BS代码阅读	C专家编程读书笔记难点关键字的用法：关键字用法extern在函数名前，表示该函数全局可见，一般缺省。即一个文件的全局变量和函数对其他文件，具有可见性。在变量或者函数前，表示对象的定义在别处进行。由于重载，在c++中调用以C方式编译的函数时，需要加extern “c”。static隐藏：修饰的对象对其他文件不可见，防止多个文件命名冲突。持久性：修饰的对象，存储在数据段或者bss段，和程序有相同的生命周期。只有一次初始化。3、修饰的变量未初始化时，默认为“0	0.7440836016951544

BLU_bootcamp	BLU V3 Minghua Zhang      01/26/2016Next version of BLU Relevance Infrastructure​OutlineWhy BLU v3BLU v3 DesignCurrent StatusFuture WorkWhy BLU v3 (1)Limitations of current BLU infrastructureFeaturesCouldn’t utilize QAS feature	0.3677310494980878
BLU_bootcamp	Bing Location Understanding (BLU)Marta Penas CentenoBoot camp (03/30/2016)BLU overviewLocation candidate extractionFeature extractionRankingTruncationLocation candidate extractionLocation candidate extractionFeature extractionRan	0.3026112828235723
BLU_bootcamp	Blue-Whale Multimedia Rank Data-FlowEugene Jian Huangjianhua@microsoft.com2012-03-13MM Page Static RankMedia LinkExpress RankMM Page Express RankMM PageSuper-Fresh RankMM PageSubmission RankMM PageEffective Rank Media Entit	0.28855033544363706
BLU_bootcamp	www.mhb.comwww.mhb.comwww.mhb.comwww.mhb.comwww.mhb.comwww.mhb.comPage 2REQUIREMENTS FORBIRTH AND MARRIAGE RECORDSBirth Certificates:  Each birth certificate should state the name, place, date of birth, and names of parents.  (These 	0.23768986809023915
BLU_bootcamp	Deep RelaxQuery Relaxation and L1 FidelityQuery Relaxation{printable iphone 7 user guide}rankonly:printable iphone 7 rankonly:user guiderankonly:printable iphone 7 user guideDeep Relax and vector similarity Encode query without each toke	0.2116718923434255
BLU_bootcamp	Bing Location Understanding (BLU) As a ServiceDeep-Dive PresentationRajasi Saha (tech lead for BLU infrastructure)Jian Wu (tech lead for BLU relevance)Microsoft ConfidentialOutlineIntroduction to BLUBLU as a serviceMotivationScenarios an	0.2066872329190822
BLU_bootcamp	Adaboost算法总结Adaboost原理AdaBoost是英文"Adaptive Boosting"（自适应增强）的缩写，由Yoav Freund和Robert Schapire在1995年提出。AdaBoost 是一种迭代算法，其核心思想是针对同一个训练集训练不同的分类器，即弱分类器，然后把这些弱分类器集合起来，构造一个更强的最终分类器。算法本身是改变数据分布实现的，它根据每次训练集之中的每个样本的分类是否正确，以及上次的总体分类的准确率，来确定每个样本的权值。将修改权值的新数据送给下层分类	0.1883668011180369
BLU_bootcamp	Progress in BLU Relevance  Marta Penas Centeno (mapena)Minghua Zhang (minghuaz)Jian Wu (jianwu)OutlineBLU as a service is the goal of our relevance improvementsBLU v3 is the relevance platform for BLU as a serviceRelevance improvements del	0.1699524342400556
BLU_bootcamp	www.mhb.comPage 2www.mhb.comwww.mhb.comwww.mhb.comwww.mhb.comwww.mhb.comInstructionS FOR scheduling your medical exam Medical Examination and Insurance InformationEach applicant for adjustment of status to permanent resident must have 	0.1698499109407336
BLU_bootcamp	libsvm的相关工具和使用方法libsvm工具：编译并能够使用 : libsvm-3.0.tarsvm的基本原理 ： libsvm-guide.pdflibsvm相关的grid工具 : [sep@ai-iknow-septest1.ai01.baidu.com auto_classifier]$ pwd grid_tools.py /home/sep/yangfan/Basic_Tools/for_lyq/auto_classifier特征筛选的相关资料和方法了解特征筛选方法	0.13930694369175425

BLU_as_a_service	BLU V3 Minghua Zhang      01/26/2016Next version of BLU Relevance Infrastructure​OutlineWhy BLU v3BLU v3 DesignCurrent StatusFuture WorkWhy BLU v3 (1)Limitations of current BLU infrastructureFeaturesCouldn’t utilize QAS feature	0.45781457714599016
BLU_as_a_service	Blue-Whale Multimedia Rank Data-FlowEugene Jian Huangjianhua@microsoft.com2012-03-13MM Page Static RankMedia LinkExpress RankMM Page Express RankMM PageSuper-Fresh RankMM PageSubmission RankMM PageEffective Rank Media Entit	0.36581369630391797
BLU_as_a_service	Progress in BLU Relevance  Marta Penas Centeno (mapena)Minghua Zhang (minghuaz)Jian Wu (jianwu)OutlineBLU as a service is the goal of our relevance improvementsBLU v3 is the relevance platform for BLU as a serviceRelevance improvements del	0.3464720731723331
BLU_as_a_service	Bing Location Understanding (BLU) As a ServiceDeep-Dive PresentationRajasi Saha (tech lead for BLU infrastructure)Jian Wu (tech lead for BLU relevance)Microsoft ConfidentialOutlineIntroduction to BLUBLU as a serviceMotivationScenarios an	0.3392182063525285
BLU_as_a_service	Bing Location Understanding (BLU)Marta Penas CentenoBoot camp (03/30/2016)BLU overviewLocation candidate extractionFeature extractionRankingTruncationLocation candidate extractionLocation candidate extractionFeature extractionRan	0.2674641814430104
BLU_as_a_service	L-1B SPECIALIZED KNOWLEDGE QUESTIONNAIREMICROSOFT POSITION IN THE U.S.Provide the following information for your current position at the Microsoft.MICROSOFT POSITION ABROADProvide the following information for your position at the Microsoft’s su	0.23549965029113482
BLU_as_a_service	OPG- Business Continuity PlanTellMeService, Shredder, AugmentationService, Enrichment, UCIService (Insights), Entity ServiceDocument Revision HistoryDateAuthorChange NotesLeader Sign off4/30/2018alyanInitial document5/10/2019alyanU	0.22864529069227546
BLU_as_a_service	PBA Dependency and DebugMing Wu2014-01-28PBA DependenciesLocation Understanding (LES/BLU)Location info (explicit/implicit) – fulfill detailed location infoProvide location related features to phonebook CRFXapQuServiceAnswer (QAS)For most c	0.17348579245196907
BLU_as_a_service	SKI Contextual Reranking V1 design doc User ScenarioWhole page relevance of “All Tab” in the SerpletContextual relevance of “File Tab” in the Serplet DeliverablesMicrosoft search serves as an intelligence service to take user query and return be	0.1645526780105158
BLU_as_a_service	Local Search Entity Schema for RelationShips (Entity Containment, Affinities) Short blurb of what this spec is aboutMilestone:  MagnesiumSpec StatusDraftTFS Feature IDPM/Doc OwnerSandhya GuntreddyContributors Scott, Bruno,Andrew,Prajakta	0.1524403264833226

BLU as a Service	BLU V3 Minghua Zhang      01/26/2016Next version of BLU Relevance Infrastructure​OutlineWhy BLU v3BLU v3 DesignCurrent StatusFuture WorkWhy BLU v3 (1)Limitations of current BLU infrastructureFeaturesCouldn’t utilize QAS feature	0.45781457714599016
BLU as a Service	Blue-Whale Multimedia Rank Data-FlowEugene Jian Huangjianhua@microsoft.com2012-03-13MM Page Static RankMedia LinkExpress RankMM Page Express RankMM PageSuper-Fresh RankMM PageSubmission RankMM PageEffective Rank Media Entit	0.36581369630391797
BLU as a Service	Progress in BLU Relevance  Marta Penas Centeno (mapena)Minghua Zhang (minghuaz)Jian Wu (jianwu)OutlineBLU as a service is the goal of our relevance improvementsBLU v3 is the relevance platform for BLU as a serviceRelevance improvements del	0.3464720731723331
BLU as a Service	Bing Location Understanding (BLU) As a ServiceDeep-Dive PresentationRajasi Saha (tech lead for BLU infrastructure)Jian Wu (tech lead for BLU relevance)Microsoft ConfidentialOutlineIntroduction to BLUBLU as a serviceMotivationScenarios an	0.3392182063525285
BLU as a Service	Bing Location Understanding (BLU)Marta Penas CentenoBoot camp (03/30/2016)BLU overviewLocation candidate extractionFeature extractionRankingTruncationLocation candidate extractionLocation candidate extractionFeature extractionRan	0.2674641814430104
BLU as a Service	L-1B SPECIALIZED KNOWLEDGE QUESTIONNAIREMICROSOFT POSITION IN THE U.S.Provide the following information for your current position at the Microsoft.MICROSOFT POSITION ABROADProvide the following information for your position at the Microsoft’s su	0.23549965029113482
BLU as a Service	OPG- Business Continuity PlanTellMeService, Shredder, AugmentationService, Enrichment, UCIService (Insights), Entity ServiceDocument Revision HistoryDateAuthorChange NotesLeader Sign off4/30/2018alyanInitial document5/10/2019alyanU	0.22864529069227546
BLU as a Service	PBA Dependency and DebugMing Wu2014-01-28PBA DependenciesLocation Understanding (LES/BLU)Location info (explicit/implicit) – fulfill detailed location infoProvide location related features to phonebook CRFXapQuServiceAnswer (QAS)For most c	0.17348579245196907
BLU as a Service	SKI Contextual Reranking V1 design doc User ScenarioWhole page relevance of “All Tab” in the SerpletContextual relevance of “File Tab” in the Serplet DeliverablesMicrosoft search serves as an intelligence service to take user query and return be	0.1645526780105158
BLU as a Service	Local Search Entity Schema for RelationShips (Entity Containment, Affinities) Short blurb of what this spec is aboutMilestone:  MagnesiumSpec StatusDraftTFS Feature IDPM/Doc OwnerSandhya GuntreddyContributors Scott, Bruno,Andrew,Prajakta	0.1524403264833226

BLU V3_20160126	BLU V3 Minghua Zhang      01/26/2016Next version of BLU Relevance Infrastructure​OutlineWhy BLU v3BLU v3 DesignCurrent StatusFuture WorkWhy BLU v3 (1)Limitations of current BLU infrastructureFeaturesCouldn’t utilize QAS feature	0.66766110275035
BLU V3_20160126	NTCG DebuggingSteven Zittrower01/30/2015AgendaNTCGNTCG DashboardOverview of BLU Architecture (Address Specific)Address Debugging in QATNTCGNTCG (Normalized Total Cumulative Gain) is a composite metric that measures address query releva	0.43568801787977324
BLU V3_20160126	Bing Location Understanding (BLU)Marta Penas CentenoBoot camp (03/30/2016)BLU overviewLocation candidate extractionFeature extractionRankingTruncationLocation candidate extractionLocation candidate extractionFeature extractionRan	0.3920349709325589
BLU V3_20160126	Blue-Whale Multimedia Rank Data-FlowEugene Jian Huangjianhua@microsoft.com2012-03-13MM Page Static RankMedia LinkExpress RankMM Page Express RankMM PageSuper-Fresh RankMM PageSubmission RankMM PageEffective Rank Media Entit	0.385687509704878
BLU V3_20160126	Author: Tony AngellDate: 08/01/13LocalProbe Improvements for Corrections Analysis and DebuggingTable of ContentsP0 Issues	2Issue: LocalProbe is unpredictable in the amount of time it takes to return a query and how long it takes to investigate a	0.3716901872068699
BLU V3_20160126	Bing Location Understanding (BLU) As a ServiceDeep-Dive PresentationRajasi Saha (tech lead for BLU infrastructure)Jian Wu (tech lead for BLU relevance)Microsoft ConfidentialOutlineIntroduction to BLUBLU as a serviceMotivationScenarios an	0.3531494344309085
BLU V3_20160126	PDI Document AnnotationPDI Ranking PlatformAgendaPDI and forward indexDocument AnnotationSodium update and MG planQ&A DSAT: {books by children}Issue: Document matches the query terms, but its surrounding words may change the intent of 	0.34975364379951523
BLU V3_20160126	Mobile LT Discussion6/20/2014AgendaTop IssuesAd Product and Ad Quality UpdateSummarized Finding NDT Supply AnalysisSummarized Finding Google CompeteStatusFeatureWindows phoneIphone/AndroidUp to 2 adsShipped 5/20/2014Shipped more 	0.3451510764180968
BLU V3_20160126	LDCG V3Knowledge Transfer2017-04-14Brett Clippingdale, Sean King, Vikas Mittal, Li JiangLDCG V3 OutlineLDCG V2 vs V3: High-level comparisonLDCG V3: New distance ModelV2 vs V3 OverviewLDCG V3: GeoIntent HIT appLDCG V3: Calculate distance 	0.33904972662163624
BLU V3_20160126	PBA Dependency and DebugMing Wu2014-01-28PBA DependenciesLocation Understanding (LES/BLU)Location info (explicit/implicit) – fulfill detailed location infoProvide location related features to phonebook CRFXapQuServiceAnswer (QAS)For most c	0.33276441114568855

BLR Substrate Day - Infuse AI across M365 experiences	TermX: the Query Rewriting Engine for BingCore Relevance PM Meeting | Shu Zheng | Jan 5th, 2016AgendaWhat is TermX? Technique DeepdiveCurrent StateFuture WorksWhat is TermX? TermX = TermExp = Term ExpansionThe query rewriting engine for 	0.47483685079927196
BLR Substrate Day - Infuse AI across M365 experiences	Microsoft ConfidentialSubstrate Day 2018 Naresh SundaramSubstrate Architecture Overview1High level framing Distributed Computing Fabric @Scale2Physical Fabric – Datacenters & Servers3Data Tier - Scalability & Availability4Logical	0.4672526015298447
BLR Substrate Day - Infuse AI across M365 experiences	Microsoft ConfidentialSeptember 14, 2016DRAFTSearch and AI PM Team MeetingApril 14th 2017Our MissionWho are we?Thoughts on PMQ&AAgendaThe 5 Priorities for Artificial Intelligence and Research Bing becomes 10 billion dollar business	0.44016545092226705
BLR Substrate Day - Infuse AI across M365 experiences	FY19 Search & AI Roadmap Review: AGI for Web RankingMay 2018Dev: Chen Zhou, Saurabh TiwaryPM: Kiki Liu, Mir RosenbergMotivation“…But often time we have more problems about the subjects we are not familiar with and therefore even the keywords	0.4289136701050087
BLR Substrate Day - Infuse AI across M365 experiences	SPAM & JunkSi Planning Cheng Niu, Alex Rahin6/18/2014Agenda	Focus AreasMetricsSPAM/Junk Metrics BreakdownData Analysis and Project DefinitionFocus AreasImprove SPAM Detection (~35% of team bandwidth)Stolen ContentContent Keyword St	0.4253204199422571
BLR Substrate Day - Infuse AI across M365 experiences	Microsoft ConfidentialSubstrate Day 2018 Michelle QuintonBuilding onthe Substrate:From Scenario to SolutionSubstrate PatternsStoring DataProcessing DataAuth for Data AccessBuilding a Compliant ServiceThere are many talks today and I 	0.4189280392232891
BLR Substrate Day - Infuse AI across M365 experiences	Debug Address Queries8/23/2013Bing Local Search RelevanceNTCG MetricsDocumentationhttps://microsoft-my.sharepoint.com/personal/aoakley_microsoft_com/Documents/2013/2013-05-22%20Maps%20metrics%20Qi.pptx?web=1Use it to identify the group of quer	0.4064299690544279
BLR Substrate Day - Infuse AI across M365 experiences	Online Click Labels for CAL Ranker:End – To End:aether://experiments/31148112-679c-476c-91d0-bb3ebbef81c2Continuous trained module continuously trains trees using HRS and then the ranker.OFE Ranker Training Pipeline:aether://experiments/01dbe0	0.4059565480782159
BLR Substrate Day - Infuse AI across M365 experiences	Auto Category Classification PipelineHanqing Cui2012/10/25OutlinePain PointsThinkingAuto Category Classification PipelineAuto Page LabelingData SamplingTrainingFeature SelectionThresholdIterative TrainingInitial Seed Model Creati	0.4016790062320497
BLR Substrate Day - Infuse AI across M365 experiences	Metrics Pipeline & ToolsJia Liu / Xiaohui Sun / Alex SergeevASG Data Mining TeamDemo link: http://dmsql05/MetricsDefinitionTool/MetricsDefinition.aspx?DataSet=BFT&MetricName=HasCortanaChitChatsTopicsBing Live Metrics PipelineUsage and Perf	0.3981551447907341

Ares brownbag OPT	Brownbag:ElasticSearch ExtensibilityHeather Nakama (henakama)Azure Search09/04/14AgendaIntroductionModulesPluginsFinding extensibility pointsEnd-to-end exampleTips and tricksQ/AIntroductionHeather NakamaDeveloper with Azure S	0.31123168207895224
Ares brownbag OPT	Find Deals with OpalKelly You, Jia Liu, Leon Zhang7/11/2016AGENDAScenariosTechniques & ChallengesNext StepsQ&AScenariosSearch Store DealsBrowse Nearby DealsFilter Restaurants with DealsDeal Action in Entity Detail CardTechniques 	0.3073880755229233
Ares brownbag OPT	[PLEASE REMOVE THIS TEXT AND BRACKETSANDPRINT ON COMPANY LETTERHEAD]INSERT DATETo Whom It May Concern:Re:	Jia LiuThis letter is to confirm that Jia Liu was employed at Microsoft (China) Company Limited in Beijing, China from March 30, 2012 to 	0.2808785914624366
Ares brownbag OPT	To Whom It May ConcernPage 2DATETo Whom It May Concern:Re:	Jia LiuI write to certify that Jia Liu worked as a Software Development Engineer at Microsoft (China) Company Limited (Microsoft China) in Beijing, China from March 30, 2012 to September	0.24063081067533812
Ares brownbag OPT	Tiger Index BrownbagHui ShenSearch Platform Tiger TeamAgenda	OverviewKey ideasTiger architectureTiger ++ 2/24/2012Agenda	OverviewKey ideasTiger architectureTiger ++ 2/24/2012What is Tiger IndexAn new index serve technol	0.23181761713472226
Ares brownbag OPT	GoldenQuery: Past Flights v1Session v1Nov, 2013Simple Explanation of GoldenQueryQuery level Explore & ExploitExplore against techniqueMemorization basedGQ service running before speller, intercept every queryContinues E&E{Microsoft off	0.22913021520231586
Ares brownbag OPT	Google Mobile vs Desktop RankDiff StudyNov 2017GoalsUnderstand what Google does differently on Mobile, if anythingDrive product ideas & shape ranking improvements on MobileUnderstand any possible impact to Algo scrapes & metricsDrive scrapin	0.21159959403759895
Ares brownbag OPT	WrapStar On-Demand DesignDrafted by ZiliuContentsContext2Design Goals2Automation2Deployment Agility2High Availability2Non-Goals2Metrics2Required Changes3Orchestration3AP Migrations3Pipeline Evolution3Tools/services refactoring3	0.21064824352506764
Ares brownbag OPT	SVMT UpdateNovember 2016AgendaMorning (10:00-12:00)Overview – 15 minQnA:MALTA – 55 minInfoBot – 30 minLunch break (12:00-1:00)Afternoon (1:00-3:00)Query:Deep QR – 30 minRanking:ConceptX – 30 minFusion – 30 minNapa – 30 minO	0.20903067082597743
Ares brownbag OPT	Home TeamLocal Brown Baghttp://aka.ms/gethometeam ADContactsBusiness cardsAppsEmailsWeb searchThe opportunity For consumers: Most people prefer to use referrals, or “word of mouth” Competition doesn’t embrace thisAmazon – anony	0.19785403679887353

Appointment_Confirmation	Competitive Query-Entity ClickMicrosoft ConfidentialMicrosoft ConfidentialGoalCreate a dataset that is readily available to utilize and analyze query-entity click patterns on competitive dataCompetitive Engine: GoogleMicrosoft ConfidentialCo	0.2397256484802169
Appointment_Confirmation	Partner Index as ServiceWhat is the Problem? RequirementCurrent status of Bing Image StackDiscoveryClient tend to provide feed for full corpusWeb crawlerImage Content RetrievalSpecial agreement, some even behind authentication for access	0.23721072857484943
Appointment_Confirmation	Publication Date Optimization Design and Implement For zh-cn MarketReview and CommentMei Yang; Ted WildAuthorJia LiuDesignBackgroundPublication date is a very fundamental and important feature. It can help fresh ranking, solve mainline out	0.22150339496721433
Appointment_Confirmation	Thoughts on Interest Graph – Experience, Business and TechnologyPersonalized recommendation that you don’t want to miss Author: Ting Cai Contributors: AC Surendran, Xiaodong Fan, Chuanxin Hu, Yan Ke, Tony Chor, Richard Qian1.	What is Interest Graph?	0.22145819973576958
Appointment_Confirmation	BusinessV3TaxonomyClassifierAugust, 2018Daniel WeinshenkerMicrosoft ConfidentialAgendaMicrosoft ConfidentialPurpose / OverviewDemoData Pipeline / Lexicon GenerationMeasurementQASChallenges / Future WorkPurpose We want to improve 	0.21513864783739983
Appointment_Confirmation	Microsoft ConfidentialSeptember 14, 2016Relevance Next and Artificial IntelligenceRelevance and Intent OffsiteFebruary 8thOur PrioritiesExpand our Capabilities towards a full fledged AGI Engine, with focus on Knowledge, NL/Semantic Understandi	0.20010002909891003
Appointment_Confirmation	Microsoft ConfidentialSeptember 14, 2016Microsoft’s Artificial General Intelligence Effort at ASG and DLTCLi Deng, Rangan Majumder, Saurabh Tiwary, Sean Yang, Mir Rosenberg, Jianfeng GaoDefinitionsDeep learning is a class of machine learni	0.19944651769296318
Appointment_Confirmation	Translation Model APIStatus: Sodium-2, API Version 6.7OverviewThe TM API – including support for high compression - was developed as one of several architectural considerations to ship machine translation model features to production, initially for 	0.19508807449570856
Appointment_Confirmation	Integrating Knowledge Graph in Web SearchEntity Triggering and CollectionsPresenter: Ze TianKnowledge GraphEntities and RelationsEntities: celebrities, people, generic terms (e.g. light bulb)Relations: sibling, spouse, people and their works	0.19481537219886808
Appointment_Confirmation	Microsoft ConfidentialSeptember 14, 2016AGI EngineCore Relevance PM TeamJanuary 26thHuman and Artificial IntelligenceOur Approach to an AGI EngineSolving the AGI Engine GoalsUpgrading our Search StackAgendaLets start with a conceptual 	0.18735289427963972

Anchor and Click Stream Ranking	Anchor and Click Stream RankingSteven ZittrowerBing Local Search RelevanceHypothesisConverting local search’s unstructured and raw text streams into semi-structured forms will improve ranking and offer relevance benefits.TestUsing classifiers 	0.5310948881010157
Anchor and Click Stream Ranking	Wrapstar rating signalsfor zh-cn documentsJia LiuWrapstar rating signals for rankingWrapstar Taobao ratingWrapstar Tmall ratingWrapstar Qna ratingWrapstar Book ratingWrapstar Video ratingDsats examplesTaobao examplesQuery=“蓝色休闲裤	淘宝”	0.22675688887019682
Anchor and Click Stream Ranking	Meta-stream work summaryHeyong WangClickstream exampleOverview: Click-Stream generationWeb logsLocal logsLocal clicked dataJoin with Local IndexWeb Clicked data (query, url etc.)IE ClickBing ClickIE SessionIE Tool Bar…Web Click	0.20241190776481074
Anchor and Click Stream Ranking	Click through handling & Organic search on One Map and Mobile L2. Challenge & problemsCurrently we have a lot of issues with click through experience.  For example, click see more results link on local listing experience get single entity pane experie	0.1832865559599849
Anchor and Click Stream Ranking	Blue-Whale Multimedia Rank Data-FlowEugene Jian Huangjianhua@microsoft.com2012-03-13MM Page Static RankMedia LinkExpress RankMM Page Express RankMM PageSuper-Fresh RankMM PageSubmission RankMM PageEffective Rank Media Entit	0.1815818963369389
Anchor and Click Stream Ranking	Core Web RelevanceFY16 H2 PlanCore Web RelevanceFY16 H2 PlanCore Web RelevanceFY16 H2 PlanCore Web RelevanceFY16 H2 Plan	0.17773564045448903
Anchor and Click Stream Ranking	CALQuery alterationAgendaRoadmap and VisionWhere are weWhere to goPlanHow to get thereProgress and looking aheadSodium so farMagnesium and beyondDeep DiveGolden QueryRoadmap & VisionWhere are weCurrent status/problem of CAL	0.17765154201156072
Anchor and Click Stream Ranking	Relaxcount=2Momo JengRelaxcount=2 datagatheringDatagathering flight for relaxcount=2:3/14/2015-3/20/2015Cal13a: control (OFE logging, relaxcount=2 off), 6% trafficCal13b: always on (OFE logging, relaxcount=2 on), 12% trafficThe flight was do	0.16373418326866657
Anchor and Click Stream Ranking	Lexical analyzer (fa_lex)Input: a buffer of textOutput: a sequence of tokens, each token is <from, to, tag>For C++:Input: “if(++i==0) {j = 0;}”Output: if/OP (/LRB ++/OP i/VAR ==/OP 0/NUM )/RBR {/LCBR j/VAR =/OP 0/NUM ;/OP }/RCBREach rule:Des	0.15357950208087018
Anchor and Click Stream Ranking	Brownbag:ElasticSearch ExtensibilityHeather Nakama (henakama)Azure Search09/04/14AgendaIntroductionModulesPluginsFinding extensibility pointsEnd-to-end exampleTips and tricksQ/AIntroductionHeather NakamaDeveloper with Azure S	0.14870326661164585

Analyzed Query	Analyzed Query represents all information derived from all classification tasks executed on the Query. QAS supports 3 basic classifications tasks: binary classification (Domain Classification), entity extraction (Query Parse), category classification (Dom	0.47296435995594666
Analyzed Query	Query AugmentationsTable of Contents1. Syntax Overview	22. Constraints	6General rules for operators	7Basic Operators	7Scoring and non-scoring constraint operators	9Stream Operators	9Literal Operators	10Meta Operators	11URL Operators	13	0.3303712239031369
Analyzed Query	Simplified Query Path SelectorSimplified query: current systemSimplified query path selectionCrf model produces a list of possible ways to place rankonly operatorQuery = “nibbana restaurant official site”nibbana restaurant rankonly:official site	0.3127172756365735
Analyzed Query	Summary of 50 queries:QueryIssue categoryResolved促销策略案例分析Page NumberYes美丽说面膜Page NumberYes朝鲜金正恩腐化生活 图片Page NumberNo(L3 rule not cover this case: the second page is higher than the first page)智慧树2012全集Page NumberYes潘阳老公石磊P	0.29467225595616614
Analyzed Query	Golden QueryEvery query countsImprove relevance: Relevance TechniquesWin/Loss basedGood technique has better win/loss ratioGeneric Ranker always doesn’t have good win/loss ratioWe do technique triage, and better win/loss ratio technique got sh	0.2927573356334582
Analyzed Query	Named Entity RecognizerTao Peng and Kang LiEntity names recognitionRecognize person, location and organization namesBOSTON, April  16 - Kevin Garnett helped the Boston Celtics beat the L. A. Lakers in last year's NBA final. ( Tony Gutierrez / Asso	0.285863434209462
Analyzed Query	Production Models OverviewLU annotates incoming text input with semantic information in a contextual wayWorkflow built on top of Bing production infrastructure (QAS/XAP/Object Store)Feature representation: word embedding, n-grams and lexicons matche	0.28255351672081375
Analyzed Query	Abacus Query Pattern SpecThis document describes how the query GEE pattern is passing from CAL into PDR, and generate a series of features depending on the <querypattern, URL-host> level matching. Query Property of GEEHere is the query property defi	0.2799891855848524
Analyzed Query	Index Quality UpdateAgendaMetrics UpdateSelection Model ImprovementRecall TierOffice ImprovementChallenges and Pain PointsHow to measure index quality?Ideally: sampling from all “good” images and see how much we covered.sampling from a	0.2647331756319699
Analyzed Query	QueryString Category owner Searchvote url 寇仲最后和谁在一起 ranking  xiaopeng http://searchvote.com/default.aspx?reviewid=209877 布里斯班 ranking  xiaopeng http://searchvote.com/default.aspx?reviewid=211685 必应词典 ranking  xiaopeng http://searchvote.com/default.aspx?re	0.25885669456516824

All hands 10-01-14	Distance Model Updates in LDCG V2Local Relevance and Measurement TeamAgendaDistance feature in LDCG V1Why was the switch to computing distance made?First implementation of Distance feature in LDCG V2, & improvement areasProcess followed for 	0.22251505736173108
All hands 10-01-14	CJK RELEVANCE ALL HANDS03/06/201401Qi ASG Memo02MS Poll	03USBS MeasurementAGENDA04Win in USBSVideoEbookMemo DocWatch the VideoVideoIntroductionWho We AreOur VisionClosingDiscussion and QnA01Qi ASG Memo02	0.2140099627298018
All hands 10-01-14	BLU V3 Minghua Zhang      01/26/2016Next version of BLU Relevance Infrastructure​OutlineWhy BLU v3BLU v3 DesignCurrent StatusFuture WorkWhy BLU v3 (1)Limitations of current BLU infrastructureFeaturesCouldn’t utilize QAS feature	0.18987279455248712
All hands 10-01-14	LDCG V3Knowledge Transfer2017-04-14Brett Clippingdale, Sean King, Vikas Mittal, Li JiangLDCG V3 OutlineLDCG V2 vs V3: High-level comparisonLDCG V3: New distance ModelV2 vs V3 OverviewLDCG V3: GeoIntent HIT appLDCG V3: Calculate distance 	0.18582021433509183
All hands 10-01-14	Issue Solution Scrape Instability  - Unable to get stable scrapes Short term- @Nikita - Try two changes together to see if that helps. Long Term - @Ping to investigate- Request index team to investigate- Support for URP scrapes (Lockdown and send URP q	0.1821000621633263
All hands 10-01-14	Bitext Alignment for Alteration Candidate GenerationJan 2018Alteration BasicsCAL alteration architecture is a big funnelCurrent mouth of the funnel is the altlist – a non-context-sensitive relation of <source, target, score>Built over time, qu	0.17409837107595216
All hands 10-01-14		0.16962845863164847
All hands 10-01-14	Location and Data Services Team all hands10/08/2014AgendaCelebrate – Wei, 5minsLocal partners – Andy, 10minsLocal Data Services – Alex, 15minsGeocoder and GeoSpatial Services – Jai, 20minsLocation and Autosuggest Services – Sid, 15minsBing	0.16896038943104108
All hands 10-01-14	Page | 2                                 <Si-09.1> Cross Page Junk Detection – V2Feature One-PagerDocument Version:0.9Authors:arahin, lidonzDocument Status:1.0Date:7/20/2014Feature OverviewDescription:Use new Main Body signal	0.1576758982829521
All hands 10-01-14	DU work items on zh-cn market　　Jia Liu2013-05-14AgendaSerp classifierWrapstar rating signalsTaobao, tmall; qna; novel; videoGeneral classiferUrl-basedTopic-basedPage number extractionName entity recognitionPerson, location, organiz	0.1565083768404307

Adaboost算法总结	Adaboost算法总结Adaboost原理AdaBoost是英文"Adaptive Boosting"（自适应增强）的缩写，由Yoav Freund和Robert Schapire在1995年提出。AdaBoost 是一种迭代算法，其核心思想是针对同一个训练集训练不同的分类器，即弱分类器，然后把这些弱分类器集合起来，构造一个更强的最终分类器。算法本身是改变数据分布实现的，它根据每次训练集之中的每个样本的分类是否正确，以及上次的总体分类的准确率，来确定每个样本的权值。将修改权值的新数据送给下层分类	0.7600204180617999
Adaboost算法总结	As字符串重查优化及评估结果：背景	当bs返回的结果为空，或者返回的结果数小于30，as会进行字符串重查。即将所有的商铺名称及id建立后缀数组(suffix_name,shop_id)。字符串重查时，将检索请求的what query切词，依次取出其中的term，根据term在后缀数组中找到一系列的shop_id，进行去重及过滤，最后将所有term对应的shop_id的列表进行求交，得到结果。结果数的最大值为10000。优化方法：原实现方法：建立后缀数组：求出商铺名称的所有后缀，结构体快	0.5146069045292144
Adaboost算法总结	BS代码阅读：BS基本功能：索引相关性切词成分分析offset调权query解析 （where+what）多路归并 综合调权类聚（偏离点）query分类空间调权数据来源点击调权BS代码阅读：bs_cache:map库的term cachemap库term cache操作锁where库term cachewhere库term cache操作锁init_map_term_cache: 初始化map库term cachein	0.5135523651393857
Adaboost算法总结	C专家编程读书笔记难点关键字的用法：关键字用法extern在函数名前，表示该函数全局可见，一般缺省。即一个文件的全局变量和函数对其他文件，具有可见性。在变量或者函数前，表示对象的定义在别处进行。由于重载，在c++中调用以C方式编译的函数时，需要加extern “c”。static隐藏：修饰的对象对其他文件不可见，防止多个文件命名冲突。持久性：修饰的对象，存储在数据段或者bss段，和程序有相同的生命周期。只有一次初始化。3、修饰的变量未初始化时，默认为“0	0.5101214494684663
Adaboost算法总结	K最近邻分类模型：原理：训练元组用n个属性描述，每个元组代表n维空间中的一个点，所有的训练元组存放在n维的模式空间。当给定一个未知元组时，KNN搜索该模式空间，找出最接近未知元组的k个训练元组。未知元组指派到它的k个最近邻中的多数类。“邻近性”用距离度量，如欧几里德距离。欧几里德距离：	设元组X1=(X11,X12,…X1n)，X2=(X21,X22,…X2n)，	Dist(X1,X2)=√ ∑ k= 1 n (X1i-X2i) 2 	使用上式之前，对每个属性的值规范化，以防止具有	0.5098439992232495
Adaboost算法总结	排序及扩展：插入排序，选择排序（冒泡排序），使用二分思想求第k大数，快速排序，非递归的快速排序，使用快排思想求第k大数，归并排序，求逆序数，自然排序算法，堆排序，最小优先级队列，计数排序，桶排序，鸽巢排序（分块排序），基数排序，外部排序：二路归并，K路归并，胜者树，败者树。  算法一：使用插入或者选择排序，得到最大的K个数，时间复杂度为：O(N*k)。 冒泡排序： void swap(int * a,int * b){            //注意	0.5097496110109341
Adaboost算法总结	克拉玛依公证处:本人因生活在国外，不能亲自到贵单位办理出生证明公证事项，兹授权委托雷春香女士全权代表我办理相关事项。对委托人在办理上述事项过程中所签署的有关文件，我均予以认可，并承担相应的法律责任。委托人：刘佳			委托人身份证号码：654301198608243929被委托人：雷春香		被委托人身份证号码：6526196207113926委托人：刘佳2018年5月24日	0.5097496110109341
Adaboost算法总结	性能升级性能升级的几个层面：系统结构：模块分解，模块交互，系统构建中的粗略估算。算法和数据结构：获得快速模块的关键：表示数据的结构，操作数据的算法：索引结构及拉链归并。代码调优：分支预测等。循环：将循环体中不改变的变量移动到循环体外；多重循环嵌套顺序。函数调用：inline函数节省函数调用开销：若makefile中不指定至少-O优化，即使声明为inline函数，编译器也不会进行函数内联。内存寻址：避免重复内存寻址。Cpu流水线的分支预测：将满足概率最高的条件放在靠前的位置。	0.5097496110109341
Adaboost算法总结	业务生成平台用户指南总体说明开发背景下一代网络是业务驱动的网络，在融合的下一代网络上高效、灵活地开发和部署各种丰富多彩的业务，从而提高网络使用率、增加收益的目标，是下一代网络的关键环节。下一代网络的发展要求呼叫与承载相分离、呼叫控制与业务相分离，使业务真正独立于网络，业务开发者不必关心与业务承载相关的底层网络知识以及具体的通信协议，只需利用业务生成平台提供的业务开发工具，就可以开发出灵活丰富且极具个性化的业务。 为了适合多种技术水平的业务开发人员的需要，现在主要有四种业务开发方式：	0.5097496110109341
Adaboost算法总结	工作6周年5个月小记今天是中国时间8/24/2018，也就是我32岁的生日，这是一个不老也不再年轻的年纪。最近总是因为工作而郁郁寡欢，心中不快，所以决定记录总结一下，希望自己能有所释怀、转变、确立新的目标。从2012年3月31到现在，我已在微软Bing工作6年5个月。在此之前，我在百度实习9个月，在阿里巴巴实习2个月，在搜狗实习1个月。在微软北京CJK relevance组勤恳的工作2年6个月，从级别59升到61，做了1年半的DU, 1年的relevance。总体来说，老板们的风格是相关性主导基础	0.5076155952622937

AbacusQueryPattern-Spec-v1	Abacus Query Pattern SpecThis document describes how the query GEE pattern is passing from CAL into PDR, and generate a series of features depending on the <querypattern, URL-host> level matching. Query Property of GEEHere is the query property defi	0.5846300969245385
AbacusQueryPattern-Spec-v1	DSAT Mining & LSRBhagirath AddepalliCUV Log Based DSAT IdentificationIdentifying Google Local Answer Clicks from CUV LogsFor local queries, Google pushes users to search on MapClicking on Map results in url of type: https://www.google.com/webhp?	0.46378682677823607
AbacusQueryPattern-Spec-v1	Pattern Based Term WeightVersion 1Jia Liu2014-06-16FrameworkTerm AttributesSemantics definitionHuman understanding and knowledgeChange in different contextsLevels:KeywordAttributeRequirementStrong constraintWeak constraintVer	0.44341124857445346
AbacusQueryPattern-Spec-v1	NTCG DebuggingSteven Zittrower01/30/2015AgendaNTCGNTCG DashboardOverview of BLU Architecture (Address Specific)Address Debugging in QATNTCGNTCG (Normalized Total Cumulative Gain) is a composite metric that measures address query releva	0.4158096547360698
AbacusQueryPattern-Spec-v1	Pattern Based Term WeightJia Liu2014-05-06FrameworkTerm AttributesSemantics definitionHuman understanding and knowledgeChange in different contextsLevels:KeywordAttributeRequirementStrong constraintWeak constraintVerbUseless	0.4039486936931916
AbacusQueryPattern-Spec-v1	Leveraging Satori Knowledge in Web Ranking StackMicroSegment and Index ServeMotivationTarget at semantic queries (*defined by MALTA)Often contain more than one entity and relationSometimes involve entity inferenceTerm matching may not handle s	0.4033867049791789
AbacusQueryPattern-Spec-v1	WrapStar On-Demand DesignDrafted by ZiliuContentsContext2Design Goals2Automation2Deployment Agility2High Availability2Non-Goals2Metrics2Required Changes3Orchestration3AP Migrations3Pipeline Evolution3Tools/services refactoring3	0.37975572739959623
AbacusQueryPattern-Spec-v1	GoldenQuery: Past Flights v1Session v1Nov, 2013Simple Explanation of GoldenQueryQuery level Explore & ExploitExplore against techniqueMemorization basedGQ service running before speller, intercept every queryContinues E&E{Microsoft off	0.37385618442966306
AbacusQueryPattern-Spec-v1	Analyzed Query represents all information derived from all classification tasks executed on the Query. QAS supports 3 basic classifications tasks: binary classification (Domain Classification), entity extraction (Query Parse), category classification (Dom	0.3654427136641194
AbacusQueryPattern-Spec-v1	Debug Address Queries8/23/2013Bing Local Search RelevanceNTCG MetricsDocumentationhttps://microsoft-my.sharepoint.com/personal/aoakley_microsoft_com/Documents/2013/2013-05-22%20Maps%20metrics%20Qi.pptx?web=1Use it to identify the group of quer	0.3567243793444926

AOS Medical Exam Instructions	WPO Local RelevancePing Yin2017-03-21OverviewWPO’s role in local relevance pipelineLocal Entity StampingArchitecture overviewWPO Local Relevance Models.Query: exton mall, User location: Wallingford, PAWPO RolesExtract/detect all entity	0.3408102429158693
AOS Medical Exam Instructions	Fast Brain – Memorization & InferenceQuery based memorization and inferenceLarge Memorization -  1B queries, clicks (Q-D) and moreDeep Brain100 - 200B Doc/Page IndexRecall, Tail and Scalability focusedLess dependency on popularity signalHeur	0.3074316811749961
AOS Medical Exam Instructions	WPO Local Relevance Tech TalkWPO Local Relevance TeamOverviewWPO’s role in local relevance pipelineLocal ExperienceArchitecture overviewMetricsWPO Local Relevance Model IntroductionWPO Query understanding and Location understandingWhy do	0.3072906189994233
AOS Medical Exam Instructions	L3 Distance Model for LocalNikita Melnichenko, Bing Local2016-04-12AgendaIntroduction to the Distance problemPrevious workA new approach: experiments and designResultsFuture developmentIntroduction to the Distance problemWe say “it’s a	0.2861743696108462
AOS Medical Exam Instructions	File Relevance Experimentation Design DocRecall AnalysisTest the search quality of external services like OLS, 3S, QF and SPO Search.Search scenarios: 0-term search, term search, 3S (Insert File and Attach File).Compare the recall: diff of returne	0.27948394672057475
AOS Medical Exam Instructions	Core Web RelevanceFY16 H2 PlanCore Web RelevanceFY16 H2 PlanCore Web RelevanceFY16 H2 PlanCore Web RelevanceFY16 H2 Plan	0.25843582537262205
AOS Medical Exam Instructions	Path Classifier FeaturesLast saved 16 March 2015 (build 3790878) by Garrett Kaminaga.NotesFeature names are composed of a group name and a feature name, separated by underscoreFeature values are always UInt32.  There are various encoding mechanism	0.25407114267797537
AOS Medical Exam Instructions	学士学位证明BACHELOR DEGREE CERTIFICATEThis is to certify that Ms. Jia Liu, born in August 1986, with the specialty of Computer Science and Technology at Beijing University of Posts and Telecommunications from September 2005 to July 2009, has passed all req	0.24505044996540107
AOS Medical Exam Instructions	Relevance Debug InfrastructureProblemFrequent  daily metric fluctuationRelevance gain negated by regressions from Sep to Oct 2013Painful to investigateChallengeLocal stack is complex with lots of componentsVarious relevance events mixed toge	0.2429859492794196
AOS Medical Exam Instructions	L3 in LocalKefeng DengOutlineL3 IntroductionUse L3 in localL3 exampleL3 introductionFor Local: 28 IS machines per row, about 5 million entities per machine. MinBLA = 50L3 introductionL3 featuresSet featuresFeature Statistics for top 	0.2423800494137422

AGI-Intent-Encoder	AGI Intent EncoderGavin YingWeb Intelligence Team(Tail Ranking team)7/29/2016What is Intent EncoderGiven a text like query, question, short sentence, get a vector represent in a high dimension space. The vector should capture semantic meanin	0.5780073320161632
AGI-Intent-Encoder	FY18 AGI Encoder Roadmap		Nitin Sharma, Gargi Ghosh, Saurabh TiwaryAgendaIntroductionFY18 Goals and Focus AreasFocus Area Deep DiveCustomer scenariosDetailed RoadmapAGI Encoder: MotivationGoal: One general intent encoder of source 	0.39220356147035373
AGI-Intent-Encoder	AGI EngineAuthors & Contributors: Li Deng, Jianfeng Gao, Rangan Majumder, Mir Rosenberg, Sean YangIntroductionThis document is a set of collective thoughts around building an Artificial General Intelligence (AGI) Engine for Microsoft. Artificial gen	0.368150473537655
AGI-Intent-Encoder	AGI UpdateDL Representation & Applications for NLU TasksSubhojit Som(Subhsom), Chen Zhou(chzho)Xia Song (xiaso), Saurabh Tiwary (satiwary)October. 2016Agenda / UpdatesMachine Reading ComprehensionLearning Generic Representation aka Semanti	0.35453335980947404
AGI-Intent-Encoder	Relevance and AIBing and Information Platform GroupFY18 AGI Encoder RoadmapFeature OwnersProgram ManagersNitin SharmaDevelopersSaurabh Tiwary, Gargi GhoshResearchersMarketingPartnersYantao Li, Weihu, GuihongOverviewAGI Encoder go	0.2997772353109498
AGI-Intent-Encoder	WPO Local RelevancePing Yin2017-03-21OverviewWPO’s role in local relevance pipelineLocal Entity StampingArchitecture overviewWPO Local Relevance Models.Query: exton mall, User location: Wallingford, PAWPO RolesExtract/detect all entity	0.29787127998555035
AGI-Intent-Encoder	Microsoft ConfidentialSeptember 14, 2016AGI EngineCore Relevance PM TeamJanuary 26thHuman and Artificial IntelligenceOur Approach to an AGI EngineSolving the AGI Engine GoalsUpgrading our Search StackAgendaLets start with a conceptual 	0.28234815965704313
AGI-Intent-Encoder	Decision Tree Ensemble decodeAdaboost Decision tree:A forest.  One feature can be multiple nodes.Support Market checkingWord/entity classificationOne or more feature set inputMeaning[DecisionTree]Roots=90  (tree number)Nodes=630 (all n	0.2573684522973669
AGI-Intent-Encoder	1/29 AGI ReviewAttendees: Harry Shum, Yi-Min Wang, David Ku, Steven Yao, Jianfeng Gao, Saurabh Tiwary, JJ Liu, Mir RosenbergTask Oriented Dialog AgentsJianfengShare the “Hail Caesar” slide (rule-based vs. RL dialog)Write what we discussed on Cor	0.24562649646539608
AGI-Intent-Encoder	Satori Introduction2012-09-20  yukaihAgendaOverviewMajor ModulesIngestionConflationServingGet Started in Local BoxUseful linksAppendix: Satori Local PipelineOverview - SatoriMission: build the largest, freshest, and most accurate E	0.23734715324584524

AGI for Web Search - FY18 Roadmap	AGI - Web Search / Tail FY18 Roadmap 	Rohit Kapoor, Saurabh Tiwary, Gargi Ghosh, Chen Zhou,  Kushal LakhotiaFY17 RecapFY18 GoalsFY18 Focus AreasFY18 TimelineFocus Area Deep DivesAgendaFY17 RecapIn-Progress:[Fusion] Out of market [F	0.548545337698563
AGI for Web Search - FY18 Roadmap	FY19 Search & AI Roadmap Review: AGI for Web RankingMay 2018Dev: Chen Zhou, Saurabh TiwaryPM: Kiki Liu, Mir RosenbergMotivation“…But often time we have more problems about the subjects we are not familiar with and therefore even the keywords	0.49373207604169805
AGI for Web Search - FY18 Roadmap	FY18 AGI Encoder Roadmap		Nitin Sharma, Gargi Ghosh, Saurabh TiwaryAgendaIntroductionFY18 Goals and Focus AreasFocus Area Deep DiveCustomer scenariosDetailed RoadmapAGI Encoder: MotivationGoal: One general intent encoder of source 	0.4558392060700374
AGI for Web Search - FY18 Roadmap	Relevance and AIBing and Information Platform GroupFY18 AGI Encoder RoadmapFeature OwnersProgram ManagersNitin SharmaDevelopersSaurabh Tiwary, Gargi GhoshResearchersMarketingPartnersYantao Li, Weihu, GuihongOverviewAGI Encoder go	0.4123974907739567
AGI for Web Search - FY18 Roadmap	AGI EngineAuthors & Contributors: Li Deng, Jianfeng Gao, Rangan Majumder, Mir Rosenberg, Sean YangIntroductionThis document is a set of collective thoughts around building an Artificial General Intelligence (AGI) Engine for Microsoft. Artificial gen	0.41050929529888613
AGI for Web Search - FY18 Roadmap	CAL Problem, Vision and RoadmapContentsOverview	2Problem of today’s CAL	2Vision and Roadmap	3Start from simple but important one: infrastructure.	3Now comes core problem: Metrics	3Now comes to the interesting part: context	4Data	5Head qu	0.39729016768175884
AGI for Web Search - FY18 Roadmap	FY19 Search & AI Roadmap Review: QRMay 2018Jie Cai, Garrett Kaminaga, Jingwen Lu, Momo JengMotivation – QR Query understanding and rewrite is the first opportunity for Bing to understand users’ intents;In current production, query rewrite is a	0.39570109586479385
AGI for Web Search - FY18 Roadmap	CALQuery alterationAgendaRoadmap and VisionWhere are weWhere to goPlanHow to get thereProgress and looking aheadSodium so farMagnesium and beyondDeep DiveGolden QueryRoadmap & VisionWhere are weCurrent status/problem of CAL	0.33011956343208254
AGI for Web Search - FY18 Roadmap	IQ Team RecapH1 2016FY16H1 AccomplishmentsTeamSSRxen-* Desktop SBSen-* Mobile SBSen-* Semantic SBSCore Web Relevance0.55/0.62.46/3.02.65/3.01.88/2.0Adult LeakageSpamJunkCQDCGMPCMALTABing@WorkSubstrate0.02/0.01	0.32993862684705105
AGI for Web Search - FY18 Roadmap	FusionByTurker KeskinpalaTuesday, May 17, 2016OverviewMotivationsWhat is Fusion?GoalsFusion ComponentsRoadmapWeb AnswerQ:“gg”Qpath1:“gg”Qpath2:“google”TLACDG FetcherL2 FetcherTLACDG FetcherL2 FetcherLL4L3L3	0.32410790296457

AGI for Web Ranking - FY19 Search & AI Roadmap Review	FY19 Search & AI Roadmap Review: AGI for Web RankingMay 2018Dev: Chen Zhou, Saurabh TiwaryPM: Kiki Liu, Mir RosenbergMotivation“…But often time we have more problems about the subjects we are not familiar with and therefore even the keywords	0.7782857335911644
AGI for Web Ranking - FY19 Search & AI Roadmap Review	FY19 Search & AI Roadmap Review: QRMay 2018Jie Cai, Garrett Kaminaga, Jingwen Lu, Momo JengMotivation – QR Query understanding and rewrite is the first opportunity for Bing to understand users’ intents;In current production, query rewrite is a	0.5968878446835105
AGI for Web Ranking - FY19 Search & AI Roadmap Review	FY19 Search & AI Roadmap Review: Intelligent QnAMay 2018PM: Ali Alvi, Kaan Ozel, Ganga Venkatasubramanian, Oana NicolovDev: Xia Song, Doran ChakrabortyAgendaOverall QnA Opportunity and GoalsSemi-Structured DataMALTATuring for QnAAGI En	0.5758181906504924
AGI for Web Ranking - FY19 Search & AI Roadmap Review	AGI - Web Search / Tail FY18 Roadmap 	Rohit Kapoor, Saurabh Tiwary, Gargi Ghosh, Chen Zhou,  Kushal LakhotiaFY17 RecapFY18 GoalsFY18 Focus AreasFY18 TimelineFocus Area Deep DivesAgendaFY17 RecapIn-Progress:[Fusion] Out of market [F	0.5649856871908202
AGI for Web Ranking - FY19 Search & AI Roadmap Review	FY18 AGI Encoder Roadmap		Nitin Sharma, Gargi Ghosh, Saurabh TiwaryAgendaIntroductionFY18 Goals and Focus AreasFocus Area Deep DiveCustomer scenariosDetailed RoadmapAGI Encoder: MotivationGoal: One general intent encoder of source 	0.4730864920705453
AGI for Web Ranking - FY19 Search & AI Roadmap Review	PDI Document AnnotationPDI Ranking PlatformAgendaPDI and forward indexDocument AnnotationSodium update and MG planQ&A DSAT: {books by children}Issue: Document matches the query terms, but its surrounding words may change the intent of 	0.45322174215364
AGI for Web Ranking - FY19 Search & AI Roadmap Review	OPG- Business Continuity PlanTellMeService, Shredder, AugmentationService, Enrichment, UCIService (Insights), Entity ServiceDocument Revision HistoryDateAuthorChange NotesLeader Sign off4/30/2018alyanInitial document5/10/2019alyanU	0.450911242139151
AGI for Web Ranking - FY19 Search & AI Roadmap Review	AgendaAres Data Access FrameworkEntitySet Creation WorkflowMetric CalculatorQuestion & AnswerARES logical conceptsARES AssetsLogical ModelEntity/RelationRelated RVT data model ARES Data ModelUnit of ExecutionEntityJobTask	0.44400921679245264
AGI for Web Ranking - FY19 Search & AI Roadmap Review	Relevance and AIBing and Information Platform GroupFY18 AGI Encoder RoadmapFeature OwnersProgram ManagersNitin SharmaDevelopersSaurabh Tiwary, Gargi GhoshResearchersMarketingPartnersYantao Li, Weihu, GuihongOverviewAGI Encoder go	0.42510805655356365
AGI for Web Ranking - FY19 Search & AI Roadmap Review	After Action Report TellMeService, Shredder, AugmentationService, Enrichment, UCIService (Insights), Entity Service<<insert Service Name>>	 [Technology /Service Name]Disaster Recovery Plan (DRP)	 						Office Group Name : After Action Report 	0.42436197489645894

AGI Update	AGI UpdateDL Representation & Applications for NLU TasksSubhojit Som(Subhsom), Chen Zhou(chzho)Xia Song (xiaso), Saurabh Tiwary (satiwary)October. 2016Agenda / UpdatesMachine Reading ComprehensionLearning Generic Representation aka Semanti	0.3648358544825037
AGI Update	AGI EngineAuthors & Contributors: Li Deng, Jianfeng Gao, Rangan Majumder, Mir Rosenberg, Sean YangIntroductionThis document is a set of collective thoughts around building an Artificial General Intelligence (AGI) Engine for Microsoft. Artificial gen	0.2706011104397859
AGI Update	Index Quality UpdateAgendaMetrics UpdateSelection Model ImprovementRecall TierOffice ImprovementChallenges and Pain PointsHow to measure index quality?Ideally: sampling from all “good” images and see how much we covered.sampling from a	0.2489150054901753
AGI Update	Relevance and AIBing and Information Platform GroupFY18 AGI Encoder RoadmapFeature OwnersProgram ManagersNitin SharmaDevelopersSaurabh Tiwary, Gargi GhoshResearchersMarketingPartnersYantao Li, Weihu, GuihongOverviewAGI Encoder go	0.2409243986770572
AGI Update	FY18 AGI Encoder Roadmap		Nitin Sharma, Gargi Ghosh, Saurabh TiwaryAgendaIntroductionFY18 Goals and Focus AreasFocus Area Deep DiveCustomer scenariosDetailed RoadmapAGI Encoder: MotivationGoal: One general intent encoder of source 	0.2162503022730143
AGI Update	AGI - Web Search / Tail FY18 Roadmap 	Rohit Kapoor, Saurabh Tiwary, Gargi Ghosh, Chen Zhou,  Kushal LakhotiaFY17 RecapFY18 GoalsFY18 Focus AreasFY18 TimelineFocus Area Deep DivesAgendaFY17 RecapIn-Progress:[Fusion] Out of market [F	0.1945309010024502
AGI Update	FusionByTurker KeskinpalaTuesday, May 17, 2016OverviewMotivationsWhat is Fusion?GoalsFusion ComponentsRoadmapWeb AnswerQ:“gg”Qpath1:“gg”Qpath2:“google”TLACDG FetcherL2 FetcherTLACDG FetcherL2 FetcherLL4L3L3	0.18838564709130065
AGI Update	1/29 AGI ReviewAttendees: Harry Shum, Yi-Min Wang, David Ku, Steven Yao, Jianfeng Gao, Saurabh Tiwary, JJ Liu, Mir RosenbergTask Oriented Dialog AgentsJianfengShare the “Hail Caesar” slide (rule-based vs. RL dialog)Write what we discussed on Cor	0.17902866244748325
AGI Update	SVMT UpdateNovember 2016AgendaMorning (10:00-12:00)Overview – 15 minQnA:MALTA – 55 minInfoBot – 30 minLunch break (12:00-1:00)Afternoon (1:00-3:00)Query:Deep QR – 30 minRanking:ConceptX – 30 minFusion – 30 minNapa – 30 minO	0.17805255737715672
AGI Update	AGI Intent EncoderGavin YingWeb Intelligence Team(Tail Ranking team)7/29/2016What is Intent EncoderGiven a text like query, question, short sentence, get a vector represent in a high dimension space. The vector should capture semantic meanin	0.16864841581485004

AGI Encoder FY18 Roadmap	FY18 AGI Encoder Roadmap		Nitin Sharma, Gargi Ghosh, Saurabh TiwaryAgendaIntroductionFY18 Goals and Focus AreasFocus Area Deep DiveCustomer scenariosDetailed RoadmapAGI Encoder: MotivationGoal: One general intent encoder of source 	0.6155808679776972
AGI Encoder FY18 Roadmap	AGI - Web Search / Tail FY18 Roadmap 	Rohit Kapoor, Saurabh Tiwary, Gargi Ghosh, Chen Zhou,  Kushal LakhotiaFY17 RecapFY18 GoalsFY18 Focus AreasFY18 TimelineFocus Area Deep DivesAgendaFY17 RecapIn-Progress:[Fusion] Out of market [F	0.5120148285178776
AGI Encoder FY18 Roadmap	AGI EngineAuthors & Contributors: Li Deng, Jianfeng Gao, Rangan Majumder, Mir Rosenberg, Sean YangIntroductionThis document is a set of collective thoughts around building an Artificial General Intelligence (AGI) Engine for Microsoft. Artificial gen	0.4853692612140832
AGI Encoder FY18 Roadmap	Relevance and AIBing and Information Platform GroupFY18 AGI Encoder RoadmapFeature OwnersProgram ManagersNitin SharmaDevelopersSaurabh Tiwary, Gargi GhoshResearchersMarketingPartnersYantao Li, Weihu, GuihongOverviewAGI Encoder go	0.4634540790535626
AGI Encoder FY18 Roadmap	AGI Intent EncoderGavin YingWeb Intelligence Team(Tail Ranking team)7/29/2016What is Intent EncoderGiven a text like query, question, short sentence, get a vector represent in a high dimension space. The vector should capture semantic meanin	0.4335353292655378
AGI Encoder FY18 Roadmap	FY19 Search & AI Roadmap Review: AGI for Web RankingMay 2018Dev: Chen Zhou, Saurabh TiwaryPM: Kiki Liu, Mir RosenbergMotivation“…But often time we have more problems about the subjects we are not familiar with and therefore even the keywords	0.40649192881865137
AGI Encoder FY18 Roadmap	AGI UpdateDL Representation & Applications for NLU TasksSubhojit Som(Subhsom), Chen Zhou(chzho)Xia Song (xiaso), Saurabh Tiwary (satiwary)October. 2016Agenda / UpdatesMachine Reading ComprehensionLearning Generic Representation aka Semanti	0.390905751352568
AGI Encoder FY18 Roadmap	WPO Local RelevancePing Yin2017-03-21OverviewWPO’s role in local relevance pipelineLocal Entity StampingArchitecture overviewWPO Local Relevance Models.Query: exton mall, User location: Wallingford, PAWPO RolesExtract/detect all entity	0.37517501807824816
AGI Encoder FY18 Roadmap	CAL Problem, Vision and RoadmapContentsOverview	2Problem of today’s CAL	2Vision and Roadmap	3Start from simple but important one: infrastructure.	3Now comes core problem: Metrics	3Now comes to the interesting part: context	4Data	5Head qu	0.3625153471955057
AGI Encoder FY18 Roadmap	FY19 Search & AI Roadmap Review: QRMay 2018Jie Cai, Garrett Kaminaga, Jingwen Lu, Momo JengMotivation – QR Query understanding and rewrite is the first opportunity for Bing to understand users’ intents;In current production, query rewrite is a	0.3475209719289342

AGI Encoder - FY18 Roadmap	FY18 AGI Encoder Roadmap		Nitin Sharma, Gargi Ghosh, Saurabh TiwaryAgendaIntroductionFY18 Goals and Focus AreasFocus Area Deep DiveCustomer scenariosDetailed RoadmapAGI Encoder: MotivationGoal: One general intent encoder of source 	0.6155808679776972
AGI Encoder - FY18 Roadmap	AGI - Web Search / Tail FY18 Roadmap 	Rohit Kapoor, Saurabh Tiwary, Gargi Ghosh, Chen Zhou,  Kushal LakhotiaFY17 RecapFY18 GoalsFY18 Focus AreasFY18 TimelineFocus Area Deep DivesAgendaFY17 RecapIn-Progress:[Fusion] Out of market [F	0.5120148285178776
AGI Encoder - FY18 Roadmap	AGI EngineAuthors & Contributors: Li Deng, Jianfeng Gao, Rangan Majumder, Mir Rosenberg, Sean YangIntroductionThis document is a set of collective thoughts around building an Artificial General Intelligence (AGI) Engine for Microsoft. Artificial gen	0.4853692612140832
AGI Encoder - FY18 Roadmap	Relevance and AIBing and Information Platform GroupFY18 AGI Encoder RoadmapFeature OwnersProgram ManagersNitin SharmaDevelopersSaurabh Tiwary, Gargi GhoshResearchersMarketingPartnersYantao Li, Weihu, GuihongOverviewAGI Encoder go	0.4634540790535626
AGI Encoder - FY18 Roadmap	AGI Intent EncoderGavin YingWeb Intelligence Team(Tail Ranking team)7/29/2016What is Intent EncoderGiven a text like query, question, short sentence, get a vector represent in a high dimension space. The vector should capture semantic meanin	0.4335353292655378
AGI Encoder - FY18 Roadmap	FY19 Search & AI Roadmap Review: AGI for Web RankingMay 2018Dev: Chen Zhou, Saurabh TiwaryPM: Kiki Liu, Mir RosenbergMotivation“…But often time we have more problems about the subjects we are not familiar with and therefore even the keywords	0.40649192881865137
AGI Encoder - FY18 Roadmap	AGI UpdateDL Representation & Applications for NLU TasksSubhojit Som(Subhsom), Chen Zhou(chzho)Xia Song (xiaso), Saurabh Tiwary (satiwary)October. 2016Agenda / UpdatesMachine Reading ComprehensionLearning Generic Representation aka Semanti	0.390905751352568
AGI Encoder - FY18 Roadmap	WPO Local RelevancePing Yin2017-03-21OverviewWPO’s role in local relevance pipelineLocal Entity StampingArchitecture overviewWPO Local Relevance Models.Query: exton mall, User location: Wallingford, PAWPO RolesExtract/detect all entity	0.37517501807824816
AGI Encoder - FY18 Roadmap	CAL Problem, Vision and RoadmapContentsOverview	2Problem of today’s CAL	2Vision and Roadmap	3Start from simple but important one: infrastructure.	3Now comes core problem: Metrics	3Now comes to the interesting part: context	4Data	5Head qu	0.3625153471955057
AGI Encoder - FY18 Roadmap	FY19 Search & AI Roadmap Review: QRMay 2018Jie Cai, Garrett Kaminaga, Jingwen Lu, Momo JengMotivation – QR Query understanding and rewrite is the first opportunity for Bing to understand users’ intents;In current production, query rewrite is a	0.3475209719289342

AGI Conceptual Architecture	AGI Intent EncoderGavin YingWeb Intelligence Team(Tail Ranking team)7/29/2016What is Intent EncoderGiven a text like query, question, short sentence, get a vector represent in a high dimension space. The vector should capture semantic meanin	0.4460085177663462
AGI Conceptual Architecture	AGI EngineAuthors & Contributors: Li Deng, Jianfeng Gao, Rangan Majumder, Mir Rosenberg, Sean YangIntroductionThis document is a set of collective thoughts around building an Artificial General Intelligence (AGI) Engine for Microsoft. Artificial gen	0.39805513390808894
AGI Conceptual Architecture	WrapStar On-Demand DesignDrafted by ZiliuContentsContext2Design Goals2Automation2Deployment Agility2High Availability2Non-Goals2Metrics2Required Changes3Orchestration3AP Migrations3Pipeline Evolution3Tools/services refactoring3	0.3505125312976444
AGI Conceptual Architecture	FY18 AGI Encoder Roadmap		Nitin Sharma, Gargi Ghosh, Saurabh TiwaryAgendaIntroductionFY18 Goals and Focus AreasFocus Area Deep DiveCustomer scenariosDetailed RoadmapAGI Encoder: MotivationGoal: One general intent encoder of source 	0.34904428699290824
AGI Conceptual Architecture	Global CAL Aluminum PlanJunfeng ZhouAgendaMagnesium StatusAluminum FocusProjectsMagnesium Status - ReleasesJuly: aggressive relaxation on no result queriesSept: relax count classifier, morphological alterationsOct: JO v1Nov: morphologi	0.3451211535993678
AGI Conceptual Architecture	AGI UpdateDL Representation & Applications for NLU TasksSubhojit Som(Subhsom), Chen Zhou(chzho)Xia Song (xiaso), Saurabh Tiwary (satiwary)October. 2016Agenda / UpdatesMachine Reading ComprehensionLearning Generic Representation aka Semanti	0.3444419369905683
AGI Conceptual Architecture	Entity Categorization Using Convolutional Neural NetworkWeiwu Zhu8/23/2018AgendaMotivationCNN introductionCNN in NLPCNN based entity categorizationMeasurementMotivationTaxonomy mapping is not scalable (Feature Normalization)Nee	0.33108194206724373
AGI Conceptual Architecture	WPO Local RelevancePing Yin2017-03-21OverviewWPO’s role in local relevance pipelineLocal Entity StampingArchitecture overviewWPO Local Relevance Models.Query: exton mall, User location: Wallingford, PAWPO RolesExtract/detect all entity	0.3309372283773355
AGI Conceptual Architecture	Containment and Conflation – Sprint  2Story DescriptionDone?In Demo?Implement and ship Segment Studio integration changes for Preconflation and MatchYYIdentify top K entity setYYRoot cause why entities have too many identifiersYY	0.3298374911795253
AGI Conceptual Architecture	Publication date optimization for zh-cn marketBackgroundPublication date is a very fundamental and important feature. It can help fresh ranking, whole page user experience: caption date show and freshness internal metrics, also to solve mainline out	0.3234315273312664

600517置信电气	空检索优化：背景：空检索请求耗时分析：统计7.21的所有空检索耗时：(71551个)      1 10144.000000      2 bs:4767252.000000       ----->66.63ms      3 390.000000      4 统计：2818865.000000   ----->39.4ms      5 1187696.000000      6 1588991.000000          7 7554473.000000	0.7640787319311255
600517置信电气	海量数据库的设计和实现淘宝海量数据库之一：来自业务的挑战(2010-11-24 11:34:38) 作为一个电子商务企业，从一开始，数据库及其事务能力在淘宝一直扮演着十分关键的角色，淘宝积累了丰富的数据库的架构和规划等方面的经验，产生了众多优秀的DBA。 淘宝是一家迅速发展的公司。全球网站排名公司Alexa提供的数据显示，2010年4月27日，Amazon、Ebay的用户占全球互联网用户的百分比分别为3.47%和2.68%，而淘宝的用户占全球互联网用户的百分比则达到了4.1%，淘宝网日	0.7406919558531164
600517置信电气	成交日期 买卖标志 成交价格 成交数量 成交金额 20160105 买入 100 897 20160108 卖出 8 200 1600 成交日期 买卖标志 成交价格 成交数量 成交金额 20160106 买入 100 1702 成交日期 买卖标志 成交价格 成交数量 成交金额 20160105 买入 100 897 20160108 卖出 8 200 1600 	0.7363755026229685
600517置信电气	贝叶斯分类模型：基础知识：假设	X：是数据元组，由n个属性描述；	H：是某种假设，如数据元组属于某特定类C	P(H|X)：表示给定X的属性描述，找出元组X属于类C的概率举例：X：一位35岁的顾客，收入为4w美元；H：顾客将购买计算机P(H|X)：在X的条件下，H的后验概率。当我们知道顾客的年龄和收入时，顾客X将购买计算机的概率。P(H)：H的先验概率。任意给定顾客将购买计算机的概率，独立与X。P(X|H)：在条件H下，X的后验概率。已知顾客购买了计算机，顾客是一位3	0.7303927698711961
600517置信电气	工作6周年5个月小记今天是中国时间8/24/2018，也就是我32岁的生日，这是一个不老也不再年轻的年纪。最近总是因为工作而郁郁寡欢，心中不快，所以决定记录总结一下，希望自己能有所释怀、转变、确立新的目标。从2012年3月31到现在，我已在微软Bing工作6年5个月。在此之前，我在百度实习9个月，在阿里巴巴实习2个月，在搜狗实习1个月。在微软北京CJK relevance组勤恳的工作2年6个月，从级别59升到61，做了1年半的DU, 1年的relevance。总体来说，老板们的风格是相关性主导基础	0.7285022027869539
600517置信电气	神经网络原理及应用介绍Anti RD：王伟琼、张爱华主要内容特点及应用场景神经网络原理我们的经验和教训多线程训练下一步的工作应用场景分类预测时间允许的场合使用并行化等方法加速测试过程很快，且可以方便的使用hadoop平台环境比较固定的场合数据的统计特性变化不大需要定量预测的场合给出未知数据的定量预测神经网络特点优点对噪音数据有较好的适应能力对未知数据具有较好的预测分类能力拟合各种函数得出定量值缺点学习时间较长	0.7261367385043349
600517置信电气	hbase介绍阳云2011.10.27存储问题怎么持久化存储10亿行以上不断更新的数据并且保证其实时响应？HBase是什么分布式数据库，基于Google Bigtable2模型分布式、面向列、多维度、稀疏、高扩展、高性能、持久化的数据存储系统运行在Hadoop-HDFS上多副本，保证可靠性2007年开始，2008.2 成为Apache Hadoop开源项目的子项目；目前版本: 0.9HBase不是什么不是一个关系型SQL数据库！没有join操	0.7253147657988607
600517置信电气	K最近邻分类模型：原理：训练元组用n个属性描述，每个元组代表n维空间中的一个点，所有的训练元组存放在n维的模式空间。当给定一个未知元组时，KNN搜索该模式空间，找出最接近未知元组的k个训练元组。未知元组指派到它的k个最近邻中的多数类。“邻近性”用距离度量，如欧几里德距离。欧几里德距离：	设元组X1=(X11,X12,…X1n)，X2=(X21,X22,…X2n)，	Dist(X1,X2)=√ ∑ k= 1 n (X1i-X2i) 2 	使用上式之前，对每个属性的值规范化，以防止具有	0.7244372094508196
600517置信电气	拉链归并算法探讨忻舟2008-8-18背景与基础知识在新产品的各个产品线中，检索作为一个必不可少的核心服务，其性能、结果相关性一直受到我们的普遍关注。检索的实现采用倒排拉链，而倒排拉链归并的效率直接影响了检索的性能。本文就拉链的归并算法展开探讨，分析各种拉链归并算法的利弊，并结合iknow的tbs升级项目讲述算法实现上的各种优化。首先简单的回顾一下拉链归并的基础知识。倒排拉链也称作拉链，是index模块对文档集合处理后的产物，每一个term都有一个拉链，记录这个term所出现的	0.7243987414806285
600517置信电气	排序及扩展：插入排序，选择排序（冒泡排序），使用二分思想求第k大数，快速排序，非递归的快速排序，使用快排思想求第k大数，归并排序，求逆序数，自然排序算法，堆排序，最小优先级队列，计数排序，桶排序，鸽巢排序（分块排序），基数排序，外部排序：二路归并，K路归并，胜者树，败者树。  算法一：使用插入或者选择排序，得到最大的K个数，时间复杂度为：O(N*k)。 冒泡排序： void swap(int * a,int * b){            //注意	0.7239537784793816

600159大龙地产	空检索优化：背景：空检索请求耗时分析：统计7.21的所有空检索耗时：(71551个)      1 10144.000000      2 bs:4767252.000000       ----->66.63ms      3 390.000000      4 统计：2818865.000000   ----->39.4ms      5 1187696.000000      6 1588991.000000          7 7554473.000000	0.7698297223942931
600159大龙地产	成交日期 买卖标志 成交价格 成交数量 成交金额 20160105 买入 100 897 20160108 卖出 8 200 1600 成交日期 买卖标志 成交价格 成交数量 成交金额 20160106 买入 100 1702 成交日期 买卖标志 成交价格 成交数量 成交金额 20160105 买入 100 897 20160108 卖出 8 200 1600 	0.7444159858002538
600159大龙地产	成交日期 买卖标志 成交价格 成交数量 成交金额 20160106 买入 100 1702 20160113 买入 100 1532 20160325 卖出 100 1695 20160708 卖出 100 1570 20160725 卖出 500 10700 20160802 卖出 300 6660 20160802 卖出 200 4430 20160803 卖出 200 4672 20160908 卖出 100 2695 成交日期 买卖标志 成交价格 成交数量 成交金额 20160112 买入 100	0.7407750103484865
600159大龙地产	成交日期 买卖标志 成交价格 成交数量 成交金额 20160105 买入 100 897 20160108 卖出 8 200 1600 成交日期 买卖标志 成交价格 成交数量 成交金额 20160106 买入 100 1702 20160113 买入 100 1532 20160325 卖出 100 1695 20160708 卖出 100 1570 20160725 卖出 500 10700 20160802 卖出 300 6660 20160802 卖出 200 4430 20160803 卖出 20	0.7391912355144854
600159大龙地产	海量数据库的设计和实现淘宝海量数据库之一：来自业务的挑战(2010-11-24 11:34:38) 作为一个电子商务企业，从一开始，数据库及其事务能力在淘宝一直扮演着十分关键的角色，淘宝积累了丰富的数据库的架构和规划等方面的经验，产生了众多优秀的DBA。 淘宝是一家迅速发展的公司。全球网站排名公司Alexa提供的数据显示，2010年4月27日，Amazon、Ebay的用户占全球互联网用户的百分比分别为3.47%和2.68%，而淘宝的用户占全球互联网用户的百分比则达到了4.1%，淘宝网日	0.7371560944352196
600159大龙地产	成交日期 买卖标志 成交价格 成交数量 成交金额 2016年亏319 2015及2016年已完结 20160105 买入 100 897 20160108 卖出 8 200 1600 20150615 买入 100 1889 20150615 买入 100 1840 20150624 卖出 100 1585 20150720 买入 100 1073 20150721 买入 100 1098 20150721 买入 100 1086 20150723 买入 100 1110 20150818 卖出 500 	0.7321704697254345
600159大龙地产	工作6周年5个月小记今天是中国时间8/24/2018，也就是我32岁的生日，这是一个不老也不再年轻的年纪。最近总是因为工作而郁郁寡欢，心中不快，所以决定记录总结一下，希望自己能有所释怀、转变、确立新的目标。从2012年3月31到现在，我已在微软Bing工作6年5个月。在此之前，我在百度实习9个月，在阿里巴巴实习2个月，在搜狗实习1个月。在微软北京CJK relevance组勤恳的工作2年6个月，从级别59升到61，做了1年半的DU, 1年的relevance。总体来说，老板们的风格是相关性主导基础	0.731281884935422
600159大龙地产	拉链归并算法探讨忻舟2008-8-18背景与基础知识在新产品的各个产品线中，检索作为一个必不可少的核心服务，其性能、结果相关性一直受到我们的普遍关注。检索的实现采用倒排拉链，而倒排拉链归并的效率直接影响了检索的性能。本文就拉链的归并算法展开探讨，分析各种拉链归并算法的利弊，并结合iknow的tbs升级项目讲述算法实现上的各种优化。首先简单的回顾一下拉链归并的基础知识。倒排拉链也称作拉链，是index模块对文档集合处理后的产物，每一个term都有一个拉链，记录这个term所出现的	0.7296618896669325
600159大龙地产	贝叶斯分类模型：基础知识：假设	X：是数据元组，由n个属性描述；	H：是某种假设，如数据元组属于某特定类C	P(H|X)：表示给定X的属性描述，找出元组X属于类C的概率举例：X：一位35岁的顾客，收入为4w美元；H：顾客将购买计算机P(H|X)：在X的条件下，H的后验概率。当我们知道顾客的年龄和收入时，顾客X将购买计算机的概率。P(H)：H的先验概率。任意给定顾客将购买计算机的概率，独立与X。P(X|H)：在条件H下，X的后验概率。已知顾客购买了计算机，顾客是一位3	0.7294360098051248
600159大龙地产	hbase介绍阳云2011.10.27存储问题怎么持久化存储10亿行以上不断更新的数据并且保证其实时响应？HBase是什么分布式数据库，基于Google Bigtable2模型分布式、面向列、多维度、稀疏、高扩展、高性能、持久化的数据存储系统运行在Hadoop-HDFS上多副本，保证可靠性2007年开始，2008.2 成为Apache Hadoop开源项目的子项目；目前版本: 0.9HBase不是什么不是一个关系型SQL数据库！没有join操	0.729370484082707

600119长江投资	空检索优化：背景：空检索请求耗时分析：统计7.21的所有空检索耗时：(71551个)      1 10144.000000      2 bs:4767252.000000       ----->66.63ms      3 390.000000      4 统计：2818865.000000   ----->39.4ms      5 1187696.000000      6 1588991.000000          7 7554473.000000	0.7275625529889943
600119长江投资	成交日期 买卖标志 成交价格 成交数量 成交金额 20160105 买入 100 897 20160108 卖出 8 200 1600 成交日期 买卖标志 成交价格 成交数量 成交金额 20160106 买入 100 1702 成交日期 买卖标志 成交价格 成交数量 成交金额 20160105 买入 100 897 20160108 卖出 8 200 1600 	0.7108149536104295
600119长江投资	唐蕾电话: (+86) 180-0132-3861Email: tanglei91@126.com工作经历                                                                    04/2014至今 :    	中国电信集团系统集成有限责任公司 软件测试工程师1.招标测试时间:05/2016至今项目描述：通过招标测试帮助甲方找到合适的厂家做他们项目中的某些模块。项目职责：负责招标测试跟产品经理讨论并细化需	0.7083673235335991
600119长江投资	成交日期 买卖标志 成交价格 成交数量 成交金额 20160105 买入 100 897 20160108 卖出 8 200 1600 成交日期 买卖标志 成交价格 成交数量 成交金额 20160106 买入 100 1702 20160113 买入 100 1532 20160325 卖出 100 1695 20160708 卖出 100 1570 20160725 卖出 500 10700 20160802 卖出 300 6660 20160802 卖出 200 4430 20160803 卖出 20	0.7067533154378761
600119长江投资	hbase介绍阳云2011.10.27存储问题怎么持久化存储10亿行以上不断更新的数据并且保证其实时响应？HBase是什么分布式数据库，基于Google Bigtable2模型分布式、面向列、多维度、稀疏、高扩展、高性能、持久化的数据存储系统运行在Hadoop-HDFS上多副本，保证可靠性2007年开始，2008.2 成为Apache Hadoop开源项目的子项目；目前版本: 0.9HBase不是什么不是一个关系型SQL数据库！没有join操	0.6934163177898386
600119长江投资	成交日期 买卖标志 成交价格 成交数量 成交金额 20160106 买入 100 1702 20160113 买入 100 1532 20160325 卖出 100 1695 20160708 卖出 100 1570 20160725 卖出 500 10700 20160802 卖出 300 6660 20160802 卖出 200 4430 20160803 卖出 200 4672 20160908 卖出 100 2695 成交日期 买卖标志 成交价格 成交数量 成交金额 20160112 买入 100	0.6926992458915964
600119长江投资	海量数据库的设计和实现淘宝海量数据库之一：来自业务的挑战(2010-11-24 11:34:38) 作为一个电子商务企业，从一开始，数据库及其事务能力在淘宝一直扮演着十分关键的角色，淘宝积累了丰富的数据库的架构和规划等方面的经验，产生了众多优秀的DBA。 淘宝是一家迅速发展的公司。全球网站排名公司Alexa提供的数据显示，2010年4月27日，Amazon、Ebay的用户占全球互联网用户的百分比分别为3.47%和2.68%，而淘宝的用户占全球互联网用户的百分比则达到了4.1%，淘宝网日	0.6916412366881772
600119长江投资	文本自动分类介绍刘佳liujia0595@163.com2011.3.3文本自动分类：指在给定的分类体系下，根据文本的内容用计算机程序确定文本所属类别的过程函数映射过程：	A：待分类的文本集合，B：分类体系中的类别集f：映射规则是系统根据已经掌握的每类若干样本的数据信息，总结出分类的规律性而建立的判别公式和判别规则。一般采用机器学习的方法进行自动文本分类。  即:基于训练集的文本自动分类文本自动分类介绍典型的有监督的分类流程典型的自动分类系统流程定义	0.6910550172996074
600119长江投资	工作6周年5个月小记今天是中国时间8/24/2018，也就是我32岁的生日，这是一个不老也不再年轻的年纪。最近总是因为工作而郁郁寡欢，心中不快，所以决定记录总结一下，希望自己能有所释怀、转变、确立新的目标。从2012年3月31到现在，我已在微软Bing工作6年5个月。在此之前，我在百度实习9个月，在阿里巴巴实习2个月，在搜狗实习1个月。在微软北京CJK relevance组勤恳的工作2年6个月，从级别59升到61，做了1年半的DU, 1年的relevance。总体来说，老板们的风格是相关性主导基础	0.6843028789231782
600119长江投资	拉链归并算法探讨忻舟2008-8-18背景与基础知识在新产品的各个产品线中，检索作为一个必不可少的核心服务，其性能、结果相关性一直受到我们的普遍关注。检索的实现采用倒排拉链，而倒排拉链归并的效率直接影响了检索的性能。本文就拉链的归并算法展开探讨，分析各种拉链归并算法的利弊，并结合iknow的tbs升级项目讲述算法实现上的各种优化。首先简单的回顾一下拉链归并的基础知识。倒排拉链也称作拉链，是index模块对文档集合处理后的产物，每一个term都有一个拉链，记录这个term所出现的	0.6840402856961396

50query_summary	Analyzed Query represents all information derived from all classification tasks executed on the Query. QAS supports 3 basic classifications tasks: binary classification (Domain Classification), entity extraction (Query Parse), category classification (Dom	0.3877400764565044
50query_summary	Summary of 50 queries:QueryIssue categoryResolved促销策略案例分析Page NumberYes美丽说面膜Page NumberYes朝鲜金正恩腐化生活 图片Page NumberNo(L3 rule not cover this case: the second page is higher than the first page)智慧树2012全集Page NumberYes潘阳老公石磊P	0.3482807006961219
50query_summary	CRF Parser AnalysisBusiness category searchOverviewParser (phonebook)CRF ParserqueryLocation featuresCRF featuresQuery parsetoken[tag] token[tag] … token[tag]userBLUbusiness_namebusiness_categorylocationlocation_separatorbu	0.30643824109078255
50query_summary	Threshold Query Formulation Deep DiveGoal of the presentation is to communicate our approach for query formulation and get feedback on whether this aligns with overall Threshold goals.OverviewGoals & MetricsQF ModelRoadmapScenariosKey Ta	0.3018606475323771
50query_summary	Reading List for Natural Language Query ParsingThis is for improving our NL query parsing for entity/local triggering.By NL query parsing, our goal is to automatically extract the structured information from the query, normally by segmenting queries a	0.29799121256974814
50query_summary	ODP Classification: Summarizing Pages as a Topic DistributionNov 17, 2010Paul Bennett (pauben), MSR CLUESJoint work with Max Chickering & Susan Dumais© 2006 Microsoft Corporation. All rights reserved. Microsoft, Windows, Windows Vista and ot	0.296611599433729
50query_summary	Simplified Query Path SelectorSimplified query: current systemSimplified query path selectionCrf model produces a list of possible ways to place rankonly operatorQuery = “nibbana restaurant official site”nibbana restaurant rankonly:official site	0.29602064535339784
50query_summary	TermX TrainingLast saved by Gord Lueck, 8/17/2015 2:15 PMContentsTermX Training	1Overview	1Prerequisites	1Inputs	1Translation Model Generation	2TermX_GenerateTrainingData	2TermX_GenerateTM	2TermX Trim Model	3TermX_PostProcess TM	3C	0.2781291557523039
50query_summary	DU items studyJia Liu2013-05-14AgendaPublication dateMain body blockDocument qualityurl static featuresPublication dateFreshness rankingYear in title, year in url, publication dateEn-us publication date coverage is ~20%Zh-cn public	0.2675914292726714
50query_summary	Query Automotive & Vehicle Services (90056) Banking & Finance (90111) Beauty & Spa (90353) Food & Drink (90232) Healthcare (90375) Professionals & Services (90496) Real Estate (90584) Retail (90628) Sports & Recreation (90848) Travel (90881) Other Categor	0.25912058929607085

20180419 WIT AGI Turing presentation	AGI EngineAuthors & Contributors: Li Deng, Jianfeng Gao, Rangan Majumder, Mir Rosenberg, Sean YangIntroductionThis document is a set of collective thoughts around building an Artificial General Intelligence (AGI) Engine for Microsoft. Artificial gen	0.4499087539467327
20180419 WIT AGI Turing presentation	Wind Up Impact on Existing adInsight Feature Plan03/25/2015ContextTo Enable “Wind Up for Premium” as high priority, we decide to make following resource adjustmentImpact to Existing Product/Feature AreaFocus AreaProducts/FeaturesResource	0.4084543339774792
20180419 WIT AGI Turing presentation	AGI UpdateDL Representation & Applications for NLU TasksSubhojit Som(Subhsom), Chen Zhou(chzho)Xia Song (xiaso), Saurabh Tiwary (satiwary)October. 2016Agenda / UpdatesMachine Reading ComprehensionLearning Generic Representation aka Semanti	0.3960192954870618
20180419 WIT AGI Turing presentation	Tiger MigrationKefeng Deng6/15/2015Microsoft ConfidentialTiger MigrationMotivationTiger IntroductionHow do we get thereCurrent statusRemaining works6/15/2015Microsoft ConfidentialMotivationSame index serve architecture as Satori 	0.3743432043775053
20180419 WIT AGI Turing presentation	1/29 AGI ReviewAttendees: Harry Shum, Yi-Min Wang, David Ku, Steven Yao, Jianfeng Gao, Saurabh Tiwary, JJ Liu, Mir RosenbergTask Oriented Dialog AgentsJianfengShare the “Hail Caesar” slide (rule-based vs. RL dialog)Write what we discussed on Cor	0.3667016417243501
20180419 WIT AGI Turing presentation	AGI Intent EncoderGavin YingWeb Intelligence Team(Tail Ranking team)7/29/2016What is Intent EncoderGiven a text like query, question, short sentence, get a vector represent in a high dimension space. The vector should capture semantic meanin	0.34286558711937565
20180419 WIT AGI Turing presentation	Microsoft ConfidentialSeptember 14, 2016AGI EngineCore Relevance PM TeamJanuary 26thHuman and Artificial IntelligenceOur Approach to an AGI EngineSolving the AGI Engine GoalsUpgrading our Search StackAgendaLets start with a conceptual 	0.34131786724267404
20180419 WIT AGI Turing presentation	Word representationsMotivationWhy word representations?StructureWhy vectors?Distance and similarityBuild models that will automatically understand language for us.Vector space modelsVector space modelsCount based methodsDSM (distribu	0.335101086147711
20180419 WIT AGI Turing presentation	Entity Selection ModelJia Liu2017-11-08GDP Pipeline View: local data pipelineEntity TypesEntity Types:Open/CloseHead/TailNonJunk/JunkJunk TypesGhost: Local business existed beforeJunk: General name like “Lock smith”, “ATM”Move/Br	0.3112874334618596
20180419 WIT AGI Turing presentation	L4 Experiment PipelineDate: Aug 20th, 2013Author: Bangyong LiangMotivation:L4’s functionality is to merge results from multiple queries. L4 has two types of merging strategies. One is query level merger and the other one is document level merger. 	0.3103755614129958

2018.01.29 - Notes - AGI Review	TermX Deep Dive	Gord Lueck 2015.09.22ContributorsSaekoo LeeGarrett KaminagaJunfeng ZhouAsad MohuiddinKaan OzelGord LueckCiya LiaoCAL Alteration SystemsCoreCAL is the query rewriting engine for bingCustomers:  Bing Web, Ads, Local	0.35758481785990087
2018.01.29 - Notes - AGI Review	AGI UpdateDL Representation & Applications for NLU TasksSubhojit Som(Subhsom), Chen Zhou(chzho)Xia Song (xiaso), Saurabh Tiwary (satiwary)October. 2016Agenda / UpdatesMachine Reading ComprehensionLearning Generic Representation aka Semanti	0.3563253515143999
2018.01.29 - Notes - AGI Review	1/29 AGI ReviewAttendees: Harry Shum, Yi-Min Wang, David Ku, Steven Yao, Jianfeng Gao, Saurabh Tiwary, JJ Liu, Mir RosenbergTask Oriented Dialog AgentsJianfengShare the “Hail Caesar” slide (rule-based vs. RL dialog)Write what we discussed on Cor	0.35478283682248546
2018.01.29 - Notes - AGI Review	QR FY19 LRP Planning - 23/29/18Unified Concept Tagging – Key ChallengesStructural ComplexityFor ambiguous queries and multi-concept queries, how much organization is required?  How to represent this in a linear qlf?  What about inter-concept rel	0.3320603182962594
2018.01.29 - Notes - AGI Review	TermX TrainingLast saved by Gord Lueck, 8/17/2015 2:15 PMContentsTermX Training	1Overview	1Prerequisites	1Inputs	1Translation Model Generation	2TermX_GenerateTrainingData	2TermX_GenerateTM	2TermX Trim Model	3TermX_PostProcess TM	3C	0.30860834862213715
2018.01.29 - Notes - AGI Review	PA Selection StackKeng-hao Chang3/8/2017AgendaQuery (offer) understandingRetail classifierCategorizerCRFSelection algorithmsRIIRNGSRanking methodsL0, L1, L1.5, L2, Attribute-awareRetail experiencePA stack via Components*RnR	0.30755532724384754
2018.01.29 - Notes - AGI Review	Query Automotive & Vehicle Services (90056) Banking & Finance (90111) Beauty & Spa (90353) Food & Drink (90232) Healthcare (90375) Professionals & Services (90496) Real Estate (90584) Retail (90628) Sports & Recreation (90848) Travel (90881) Other Categor	0.30721839574890075
2018.01.29 - Notes - AGI Review	SVMT UpdateNovember 2016AgendaMorning (10:00-12:00)Overview – 15 minQnA:MALTA – 55 minInfoBot – 30 minLunch break (12:00-1:00)Afternoon (1:00-3:00)Query:Deep QR – 30 minRanking:ConceptX – 30 minFusion – 30 minNapa – 30 minO	0.3051390625825543
2018.01.29 - Notes - AGI Review	AGI Intent EncoderGavin YingWeb Intelligence Team(Tail Ranking team)7/29/2016What is Intent EncoderGiven a text like query, question, short sentence, get a vector represent in a high dimension space. The vector should capture semantic meanin	0.28992951413527446
2018.01.29 - Notes - AGI Review	Content Quality Progress & StatusFeb 23, 2012Yi Li, Guihong Cao, Santhosh Kodipaka, Cheng NiuDocument UnderstandingAgendaContent Quality Problem AreasNDCG vs. SBSSummarizationProblemWhat We DidBing StatusScraperXXXSegment Aut	0.28781381260503797

20170421 - Distance Model, LDS, L3 Knowledge Sharing	Distance Model, LDS, L3Knowledge SharingNikita Melnichenko, Bing Local2017-04-21Overview of PBA relevance flow in FeedsL1Keyword matchWPOL2 levelRankerTruncationCategory matchName matchLogical DistanceUI sortingGIMXIMGDM	0.6526474757236588
20170421 - Distance Model, LDS, L3 Knowledge Sharing	Distance Model Updates in LDCG V2Local Relevance and Measurement TeamAgendaDistance feature in LDCG V1Why was the switch to computing distance made?First implementation of Distance feature in LDCG V2, & improvement areasProcess followed for 	0.5493788295357254
20170421 - Distance Model, LDS, L3 Knowledge Sharing	Discover More – RestaurantsJune, 2018Daniel WeinshenkerMicrosoft ConfidentialOverview Suggests cuisines, dishes, amenities, and nearby POIs to users searching for restaurants Top 50 cities in the USA suggest the followingWell-known dishes 	0.4349639142482791
20170421 - Distance Model, LDS, L3 Knowledge Sharing	L3 Distance Model for LocalNikita Melnichenko, Bing Local2016-04-12AgendaIntroduction to the Distance problemPrevious workA new approach: experiments and designResultsFuture developmentIntroduction to the Distance problemWe say “it’s a	0.4298789905426465
20170421 - Distance Model, LDS, L3 Knowledge Sharing	Distance-Aware Local SearchZhao Zhout-zhazho@microsoft.comOutlineProject Goal and MotivationMethodologyExperimental ResultsConclusionBackgroundEntities having LatLonNew York City (40.7127,-74.0059) Facing East Restaurant (47.619905, 	0.41291303448909783
20170421 - Distance Model, LDS, L3 Knowledge Sharing	CJK RELEVANCE ALL HANDS03/06/201401Qi ASG Memo02MS Poll	03USBS MeasurementAGENDA04Win in USBSVideoEbookMemo DocWatch the VideoVideoIntroductionWho We AreOur VisionClosingDiscussion and QnA01Qi ASG Memo02	0.40551216358053377
20170421 - Distance Model, LDS, L3 Knowledge Sharing	Entity Selection ModelJia Liu2017-11-08GDP Pipeline View: local data pipelineEntity TypesEntity Types:Open/CloseHead/TailNonJunk/JunkJunk TypesGhost: Local business existed beforeJunk: General name like “Lock smith”, “ATM”Move/Br	0.39744524536553205
20170421 - Distance Model, LDS, L3 Knowledge Sharing	ML Model Scorecard Analysis8/8/2019Unexpected term search movementhttps://exp.microsoft.com/xcard/?view=4e77b420-7b77-4e41-92ac-8e84f506fb01Check correctness of scorecard metric implementationCalculate term AVG rank from raw data streamsSearch	0.39406560757763254
20170421 - Distance Model, LDS, L3 Knowledge Sharing	Mobile LT Discussion6/20/2014AgendaTop IssuesAd Product and Ad Quality UpdateSummarized Finding NDT Supply AnalysisSummarized Finding Google CompeteStatusFeatureWindows phoneIphone/AndroidUp to 2 adsShipped 5/20/2014Shipped more 	0.3853239214659895
20170421 - Distance Model, LDS, L3 Knowledge Sharing	FY18 GreenlightLocal SearchJune 14, 2017FY18 Local Search: Top GoalsInitiativeMetricFY18 GoalsTop Segments (mobile and desktop): Competitive Segment SBS (mobile and desktop)TCxSBS weak score > 5 for EN-USSegments: Hotels, Retail, Hom	0.38451449978615637

2017-11-06 AGI Review Notes - Mir	SVMT UpdateNovember 2016AgendaMorning (10:00-12:00)Overview – 15 minQnA:MALTA – 55 minInfoBot – 30 minLunch break (12:00-1:00)Afternoon (1:00-3:00)Query:Deep QR – 30 minRanking:ConceptX – 30 minFusion – 30 minNapa – 30 minO	0.39451028678515954
2017-11-06 AGI Review Notes - Mir	Microsoft ConfidentialSeptember 14, 2016AGI EngineCore Relevance PM TeamJanuary 26thHuman and Artificial IntelligenceOur Approach to an AGI EngineSolving the AGI Engine GoalsUpgrading our Search StackAgendaLets start with a conceptual 	0.3698392976635025
2017-11-06 AGI Review Notes - Mir	Microsoft ConfidentialSeptember 14, 2016DRAFTSearch and AI PM Team MeetingApril 14th 2017Our MissionWho are we?Thoughts on PMQ&AAgendaThe 5 Priorities for Artificial Intelligence and Research Bing becomes 10 billion dollar business	0.36827895345619477
2017-11-06 AGI Review Notes - Mir	The Data Skew ProblemFei Xu2/27/2018The Scheduled TalksMarch 18th Dave Maltz – OSD future network March 25th Pat – TBD April 1st Pat – TBDApril 8th Brad – Terasort in 12 minutesApril 15th Eric – The Global Scheduler April 22nd Brian – 	0.36298938828867894
2017-11-06 AGI Review Notes - Mir	Wind Up Impact on Existing adInsight Feature Plan03/25/2015ContextTo Enable “Wind Up for Premium” as high priority, we decide to make following resource adjustmentImpact to Existing Product/Feature AreaFocus AreaProducts/FeaturesResource	0.3612578591111607
2017-11-06 AGI Review Notes - Mir	Bing Ads Insight Track Weekly Review9/22/2015Primary KPIs  -- Product UsageCallout –NAKSP WoW usage increase by 223.58% on 9/14 was mainly driven by API-AdCenterAdIntelligenceService_V9 with the dev token 002234PN5W617046 whose associated accoun	0.3600122131468555
2017-11-06 AGI Review Notes - Mir	DSAT Mining & LSRBhagirath AddepalliCUV Log Based DSAT IdentificationIdentifying Google Local Answer Clicks from CUV LogsFor local queries, Google pushes users to search on MapClicking on Map results in url of type: https://www.google.com/webhp?	0.3419904624531762
2017-11-06 AGI Review Notes - Mir	Tiger MigrationKefeng Deng6/15/2015Microsoft ConfidentialTiger MigrationMotivationTiger IntroductionHow do we get thereCurrent statusRemaining works6/15/2015Microsoft ConfidentialMotivationSame index serve architecture as Satori 	0.33685849002369067
2017-11-06 AGI Review Notes - Mir	1/29 AGI ReviewAttendees: Harry Shum, Yi-Min Wang, David Ku, Steven Yao, Jianfeng Gao, Saurabh Tiwary, JJ Liu, Mir RosenbergTask Oriented Dialog AgentsJianfengShare the “Hail Caesar” slide (rule-based vs. RL dialog)Write what we discussed on Cor	0.3337187928949983
2017-11-06 AGI Review Notes - Mir	AGI UpdateDL Representation & Applications for NLU TasksSubhojit Som(Subhsom), Chen Zhou(chzho)Xia Song (xiaso), Saurabh Tiwary (satiwary)October. 2016Agenda / UpdatesMachine Reading ComprehensionLearning Generic Representation aka Semanti	0.32884702121435694

2017-04-14 Search and AI PM Team Meeting	Microsoft ConfidentialSeptember 14, 2016DRAFTSearch and AI PM Team MeetingApril 14th 2017Our MissionWho are we?Thoughts on PMQ&AAgendaThe 5 Priorities for Artificial Intelligence and Research Bing becomes 10 billion dollar business	0.6428798536604807
2017-04-14 Search and AI PM Team Meeting	FY18 GreenlightLocal SearchJune 14, 2017FY18 Local Search: Top GoalsInitiativeMetricFY18 GoalsTop Segments (mobile and desktop): Competitive Segment SBS (mobile and desktop)TCxSBS weak score > 5 for EN-USSegments: Hotels, Retail, Hom	0.5344028977604028
2017-04-14 Search and AI PM Team Meeting	Microsoft ConfidentialSeptember 14, 2016AGI EngineCore Relevance PM TeamJanuary 26thHuman and Artificial IntelligenceOur Approach to an AGI EngineSolving the AGI Engine GoalsUpgrading our Search StackAgendaLets start with a conceptual 	0.5261649060431641
2017-04-14 Search and AI PM Team Meeting	FY19 Search & AI Roadmap Review: Intelligent QnAMay 2018PM: Ali Alvi, Kaan Ozel, Ganga Venkatasubramanian, Oana NicolovDev: Xia Song, Doran ChakrabortyAgendaOverall QnA Opportunity and GoalsSemi-Structured DataMALTATuring for QnAAGI En	0.45905399626436716
2017-04-14 Search and AI PM Team Meeting	FY19 Search & AI Roadmap Review: QRMay 2018Jie Cai, Garrett Kaminaga, Jingwen Lu, Momo JengMotivation – QR Query understanding and rewrite is the first opportunity for Bing to understand users’ intents;In current production, query rewrite is a	0.4481877079253734
2017-04-14 Search and AI PM Team Meeting	TermX: the Query Rewriting Engine for BingCore Relevance PM Meeting | Shu Zheng | Jan 5th, 2016AgendaWhat is TermX? Technique DeepdiveCurrent StateFuture WorksWhat is TermX? TermX = TermExp = Term ExpansionThe query rewriting engine for 	0.4412766229765435
2017-04-14 Search and AI PM Team Meeting	LDCG V3Knowledge Transfer2017-04-14Brett Clippingdale, Sean King, Vikas Mittal, Li JiangLDCG V3 OutlineLDCG V2 vs V3: High-level comparisonLDCG V3: New distance ModelV2 vs V3 OverviewLDCG V3: GeoIntent HIT appLDCG V3: Calculate distance 	0.4406965699181914
2017-04-14 Search and AI PM Team Meeting	IQ Team RecapH1 2016FY16H1 AccomplishmentsTeamSSRxen-* Desktop SBSen-* Mobile SBSen-* Semantic SBSCore Web Relevance0.55/0.62.46/3.02.65/3.01.88/2.0Adult LeakageSpamJunkCQDCGMPCMALTABing@WorkSubstrate0.02/0.01	0.43807134365090034
2017-04-14 Search and AI PM Team Meeting	QR Team ReviewJan 2017Team IntroductionConceptXDeep QRAgendaQR Team MembersDev Manager: Ciya LiaoLeads: Garrett Kaminaga, Jingwen Lu, Saekoo Lee, Gord LueckPMs: Shyam Jayasankar, Jie CaiSTC-A Speller team: Yongen Gong and his teamWha	0.41116421024847066
2017-04-14 Search and AI PM Team Meeting	FY19 Search & AI Roadmap Review: AGI for Web RankingMay 2018Dev: Chen Zhou, Saurabh TiwaryPM: Kiki Liu, Mir RosenbergMotivation“…But often time we have more problems about the subjects we are not familiar with and therefore even the keywords	0.4011330529056293

2016_06_08_Richard_Image Indexing As Service	Bing Ads Insight Track Weekly Review9/22/2015Primary KPIs  -- Product UsageCallout –NAKSP WoW usage increase by 223.58% on 9/14 was mainly driven by API-AdCenterAdIntelligenceService_V9 with the dev token 002234PN5W617046 whose associated accoun	0.4666172538972144
2016_06_08_Richard_Image Indexing As Service	Local Category Search StudyHuanan Zhang01/03/2018OutlineStructure of PBA (Prod) rankerIntent match ranker’s role in Prod rankerIssues of intent match rankerSolutions – metastream clean upMetastream measurementPreliminary resultsPBA	0.43130688941330897
2016_06_08_Richard_Image Indexing As Service	Microsoft ConfidentialSeptember 14, 2016DRAFTSearch and AI PM Team MeetingApril 14th 2017Our MissionWho are we?Thoughts on PMQ&AAgendaThe 5 Priorities for Artificial Intelligence and Research Bing becomes 10 billion dollar business	0.4255897604711742
2016_06_08_Richard_Image Indexing As Service	Tiger MigrationKefeng Deng6/15/2015Microsoft ConfidentialTiger MigrationMotivationTiger IntroductionHow do we get thereCurrent statusRemaining works6/15/2015Microsoft ConfidentialMotivationSame index serve architecture as Satori 	0.41867026267442764
2016_06_08_Richard_Image Indexing As Service	TermX Deep Dive	Gord Lueck 2015.09.22ContributorsSaekoo LeeGarrett KaminagaJunfeng ZhouAsad MohuiddinKaan OzelGord LueckCiya LiaoCAL Alteration SystemsCoreCAL is the query rewriting engine for bingCustomers:  Bing Web, Ads, Local	0.4120436306858425
2016_06_08_Richard_Image Indexing As Service	Satori Introduction2012-09-20  yukaihAgendaOverviewMajor ModulesIngestionConflationServingGet Started in Local BoxUseful linksAppendix: Satori Local PipelineOverview - SatoriMission: build the largest, freshest, and most accurate E	0.40780768914949894
2016_06_08_Richard_Image Indexing As Service	Wind Up Impact on Existing adInsight Feature Plan03/25/2015ContextTo Enable “Wind Up for Premium” as high priority, we decide to make following resource adjustmentImpact to Existing Product/Feature AreaFocus AreaProducts/FeaturesResource	0.4077650034833355
2016_06_08_Richard_Image Indexing As Service	唐蕾电话: (+86) 180-0132-3861Email: tanglei91@126.com工作经历                                                                    04/2014至今 :    	中国电信集团系统集成有限责任公司 软件测试工程师1.招标测试时间:05/2016至今项目描述：通过招标测试帮助甲方找到合适的厂家做他们项目中的某些模块。项目职责：负责招标测试跟产品经理讨论并细化需	0.3882810259327287
2016_06_08_Richard_Image Indexing As Service	All About TermXGord Lueck 2016.09.07ContributorsSaekoo LeeGarrett KaminagaJunfeng ZhouAsad MohuiddinKaan OzelGord LueckCiya LiaoCAL Alteration SystemsCoreCAL is the query rewriting engine for bingCustomers:  Bing Web, Ads, Local,	0.3867534644698502
2016_06_08_Richard_Image Indexing As Service	Author: Tony AngellDate: 08/01/13LocalProbe Improvements for Corrections Analysis and DebuggingTable of ContentsP0 Issues	2Issue: LocalProbe is unpredictable in the amount of time it takes to return a query and how long it takes to investigate a	0.3861841616705216

20160412 - L3 Distance Model for Local	L3 Distance Model for LocalNikita Melnichenko, Bing Local2016-04-12AgendaIntroduction to the Distance problemPrevious workA new approach: experiments and designResultsFuture developmentIntroduction to the Distance problemWe say “it’s a	0.5400739291585459
20160412 - L3 Distance Model for Local	Distance Model, LDS, L3Knowledge SharingNikita Melnichenko, Bing Local2017-04-21Overview of PBA relevance flow in FeedsL1Keyword matchWPOL2 levelRankerTruncationCategory matchName matchLogical DistanceUI sortingGIMXIMGDM	0.49484952045398706
20160412 - L3 Distance Model for Local	Distance Model Updates in LDCG V2Local Relevance and Measurement TeamAgendaDistance feature in LDCG V1Why was the switch to computing distance made?First implementation of Distance feature in LDCG V2, & improvement areasProcess followed for 	0.48106853485219125
20160412 - L3 Distance Model for Local	WPO Local RelevancePing Yin2017-03-21OverviewWPO’s role in local relevance pipelineLocal Entity StampingArchitecture overviewWPO Local Relevance Models.Query: exton mall, User location: Wallingford, PAWPO RolesExtract/detect all entity	0.3933566521818077
20160412 - L3 Distance Model for Local	Entity Selection ModelJia Liu2017-11-08GDP Pipeline View: local data pipelineEntity TypesEntity Types:Open/CloseHead/TailNonJunk/JunkJunk TypesGhost: Local business existed beforeJunk: General name like “Lock smith”, “ATM”Move/Br	0.3914951459252007
20160412 - L3 Distance Model for Local	SVMT UpdateNovember 2016AgendaMorning (10:00-12:00)Overview – 15 minQnA:MALTA – 55 minInfoBot – 30 minLunch break (12:00-1:00)Afternoon (1:00-3:00)Query:Deep QR – 30 minRanking:ConceptX – 30 minFusion – 30 minNapa – 30 minO	0.3823529974762442
20160412 - L3 Distance Model for Local	The Data Skew ProblemFei Xu2/27/2018The Scheduled TalksMarch 18th Dave Maltz – OSD future network March 25th Pat – TBD April 1st Pat – TBDApril 8th Brad – Terasort in 12 minutesApril 15th Eric – The Global Scheduler April 22nd Brian – 	0.3611047298971746
20160412 - L3 Distance Model for Local	Mobile LT Discussion6/20/2014AgendaTop IssuesAd Product and Ad Quality UpdateSummarized Finding NDT Supply AnalysisSummarized Finding Google CompeteStatusFeatureWindows phoneIphone/AndroidUp to 2 adsShipped 5/20/2014Shipped more 	0.3602271754248663
20160412 - L3 Distance Model for Local	Distance-Aware Local SearchZhao Zhout-zhazho@microsoft.comOutlineProject Goal and MotivationMethodologyExperimental ResultsConclusionBackgroundEntities having LatLonNew York City (40.7127,-74.0059) Facing East Restaurant (47.619905, 	0.35582184319407406
20160412 - L3 Distance Model for Local	Discover More – RestaurantsJune, 2018Daniel WeinshenkerMicrosoft ConfidentialOverview Suggests cuisines, dishes, amenities, and nearby POIs to users searching for restaurants Top 50 cities in the USA suggest the followingWell-known dishes 	0.34912406846349364

20160216 - Introduction to XAP	Introduction to L1Xiao WuSearch Platform Tiger Team AgendaL1 goals and challengesMetrics and measurementL1 ranker and perf optimizationL1 ranking Perf optimizationDebugging tools L1 training and shippingThinking and discussionL1 	0.4253591308653104
20160216 - Introduction to XAP	AGI Intent EncoderGavin YingWeb Intelligence Team(Tail Ranking team)7/29/2016What is Intent EncoderGiven a text like query, question, short sentence, get a vector represent in a high dimension space. The vector should capture semantic meanin	0.39567013794600414
20160216 - Introduction to XAP	FY18 AGI Encoder Roadmap		Nitin Sharma, Gargi Ghosh, Saurabh TiwaryAgendaIntroductionFY18 Goals and Focus AreasFocus Area Deep DiveCustomer scenariosDetailed RoadmapAGI Encoder: MotivationGoal: One general intent encoder of source 	0.39395637757541
20160216 - Introduction to XAP	Microsoft ConfidentialSeptember 14, 2016Microsoft’s Artificial General Intelligence Effort at ASG and DLTCLi Deng, Rangan Majumder, Saurabh Tiwary, Sean Yang, Mir Rosenberg, Jianfeng GaoDefinitionsDeep learning is a class of machine learni	0.3910228718274022
20160216 - Introduction to XAP	QR FY19 LRP Planning - 23/29/18Unified Concept Tagging – Key ChallengesStructural ComplexityFor ambiguous queries and multi-concept queries, how much organization is required?  How to represent this in a linear qlf?  What about inter-concept rel	0.37755723583184525
20160216 - Introduction to XAP	成交日期 买卖标志 成交价格 成交数量 成交金额 20160106 买入 100 1702 20160113 买入 100 1532 20160325 卖出 100 1695 20160708 卖出 100 1570 20160725 卖出 500 10700 20160802 卖出 300 6660 20160802 卖出 200 4430 20160803 卖出 200 4672 20160908 卖出 100 2695 成交日期 买卖标志 成交价格 成交数量 成交金额 20160112 买入 100	0.3637735623226779
20160216 - Introduction to XAP	Satori Introduction2012-09-20  yukaihAgendaOverviewMajor ModulesIngestionConflationServingGet Started in Local BoxUseful linksAppendix: Satori Local PipelineOverview - SatoriMission: build the largest, freshest, and most accurate E	0.36348851150062217
20160216 - Introduction to XAP	Microsoft ConfidentialSeptember 14, 2016AGI EngineCore Relevance PM TeamJanuary 26thHuman and Artificial IntelligenceOur Approach to an AGI EngineSolving the AGI Engine GoalsUpgrading our Search StackAgendaLets start with a conceptual 	0.3590848713693726
20160216 - Introduction to XAP	成交日期 买卖标志 成交价格 成交数量 成交金额 20160105 买入 100 897 20160108 卖出 8 200 1600 成交日期 买卖标志 成交价格 成交数量 成交金额 20160106 买入 100 1702 20160113 买入 100 1532 20160325 卖出 100 1695 20160708 卖出 100 1570 20160725 卖出 500 10700 20160802 卖出 300 6660 20160802 卖出 200 4430 20160803 卖出 20	0.35867908964042533
20160216 - Introduction to XAP	Tiger MigrationKefeng Deng6/15/2015Microsoft ConfidentialTiger MigrationMotivationTiger IntroductionHow do we get thereCurrent statusRemaining works6/15/2015Microsoft ConfidentialMotivationSame index serve architecture as Satori 	0.3561467032374566

2016-04 Local relevance platform	WPO Local Relevance Tech TalkWPO Local Relevance TeamOverviewWPO’s role in local relevance pipelineLocal ExperienceArchitecture overviewMetricsWPO Local Relevance Model IntroductionWPO Query understanding and Location understandingWhy do	0.4482983143318326
2016-04 Local relevance platform	WPO Local RelevancePing Yin2017-03-21OverviewWPO’s role in local relevance pipelineLocal Entity StampingArchitecture overviewWPO Local Relevance Models.Query: exton mall, User location: Wallingford, PAWPO RolesExtract/detect all entity	0.3921984665889283
2016-04 Local relevance platform	BLU V3 Minghua Zhang      01/26/2016Next version of BLU Relevance Infrastructure​OutlineWhy BLU v3BLU v3 DesignCurrent StatusFuture WorkWhy BLU v3 (1)Limitations of current BLU infrastructureFeaturesCouldn’t utilize QAS feature	0.3494929035835316
2016-04 Local relevance platform	Local Search Platform PM Onboarding GuideAuthors: Dany DaherDate: 10/18/2013Architecture OverviewHow Local Search Works Local Data Platform Architecture MetricsLocal Metrics:  http://jeffke/localMetrics/Definition of QLDCG: Local Discoun	0.33379246259279327
2016-04 Local relevance platform	GoldenQuery: Past Flights v1Session v1Nov, 2013Simple Explanation of GoldenQueryQuery level Explore & ExploitExplore against techniqueMemorization basedGQ service running before speller, intercept every queryContinues E&E{Microsoft off	0.32918232902854094
2016-04 Local relevance platform	Microsoft ConfidentialSeptember 14, 2016Relevance Next and our Path to AGIAll HandsFeb 10th 2016Relevance Next and our Path to AGIRelevance OpportunitiesAGI: Project Turing Relevance PowerSubstrate RelevanceDemos! Q&AAgendaFY16	0.3223640186191784
2016-04 Local relevance platform	L3 Distance Model for LocalNikita Melnichenko, Bing Local2016-04-12AgendaIntroduction to the Distance problemPrevious workA new approach: experiments and designResultsFuture developmentIntroduction to the Distance problemWe say “it’s a	0.3207435598732207
2016-04 Local relevance platform	Whole Page RelevanceShip Meeting 08/14/2012AgendaSummary of IssuesSpecial TopicsWhole Page Relevance - IssuesTeamIssue Description StatusOwnerDue Action UpdateINTL Mon-GsheldonNo major issuesCaptions MetricsSBS – Monthly 	0.306084815604795
2016-04 Local relevance platform	Local Relevance SQR (en-us + en-ca)March 14, 2017AgendaContext & Scope:EN-US & EN-CA, Mobile and SERP relevance focusedPBA (pre-web) relevance focusedQuality measurements DSAT examplesGeneral issuesKey Segments (Restaurants, Hotels, Re	0.30507461501996025
2016-04 Local relevance platform	Distance Model, LDS, L3Knowledge SharingNikita Melnichenko, Bing Local2017-04-21Overview of PBA relevance flow in FeedsL1Keyword matchWPOL2 levelRankerTruncationCategory matchName matchLogical DistanceUI sortingGIMXIMGDM	0.29576388836135886

2016-03-11 Microsofts AGI Effort	Microsoft ConfidentialSeptember 14, 2016AGI EngineCore Relevance PM TeamJanuary 26thHuman and Artificial IntelligenceOur Approach to an AGI EngineSolving the AGI Engine GoalsUpgrading our Search StackAgendaLets start with a conceptual 	0.5525438987750886
2016-03-11 Microsofts AGI Effort	Microsoft ConfidentialSeptember 14, 2016DRAFTSearch and AI PM Team MeetingApril 14th 2017Our MissionWho are we?Thoughts on PMQ&AAgendaThe 5 Priorities for Artificial Intelligence and Research Bing becomes 10 billion dollar business	0.47832551602904066
2016-03-11 Microsofts AGI Effort	Microsoft ConfidentialSeptember 14, 2016Core Web RelevanceFY16 H2 PlanOur PrioritiesBuild a Universally Competitive Search Engine across all devicesExpand our Capabilities towards Knowledge Understanding to power Bing Next, MALTA, and great se	0.4414273906898708
2016-03-11 Microsofts AGI Effort	Microsoft ConfidentialSubstrate Day 2018 Michelle QuintonBuilding onthe Substrate:From Scenario to SolutionSubstrate PatternsStoring DataProcessing DataAuth for Data AccessBuilding a Compliant ServiceThere are many talks today and I 	0.4284742683552636
2016-03-11 Microsofts AGI Effort	Microsoft ConfidentialSeptember 14, 2016Microsoft’s Artificial General Intelligence Effort at ASG and DLTCLi Deng, Rangan Majumder, Saurabh Tiwary, Sean Yang, Mir Rosenberg, Jianfeng GaoDefinitionsDeep learning is a class of machine learni	0.40983208125770365
2016-03-11 Microsofts AGI Effort	Tiger MigrationKefeng Deng6/15/2015Microsoft ConfidentialTiger MigrationMotivationTiger IntroductionHow do we get thereCurrent statusRemaining works6/15/2015Microsoft ConfidentialMotivationSame index serve architecture as Satori 	0.40701659545199353
2016-03-11 Microsofts AGI Effort	Microsoft ConfidentialSeptember 14, 2016Relevance Next and our Path to AGIAll HandsFeb 10th 2016Relevance Next and our Path to AGIRelevance OpportunitiesAGI: Project Turing Relevance PowerSubstrate RelevanceDemos! Q&AAgendaFY16	0.39691936425477115
2016-03-11 Microsofts AGI Effort	Wind Up Impact on Existing adInsight Feature Plan03/25/2015ContextTo Enable “Wind Up for Premium” as high priority, we decide to make following resource adjustmentImpact to Existing Product/Feature AreaFocus AreaProducts/FeaturesResource	0.39274620804262667
2016-03-11 Microsofts AGI Effort	AGI UpdateDL Representation & Applications for NLU TasksSubhojit Som(Subhsom), Chen Zhou(chzho)Xia Song (xiaso), Saurabh Tiwary (satiwary)October. 2016Agenda / UpdatesMachine Reading ComprehensionLearning Generic Representation aka Semanti	0.36868588946057557
2016-03-11 Microsofts AGI Effort	After Action Report TellMeService, Shredder, AugmentationService, Enrichment, UCIService (Insights), Entity Service<<insert Service Name>>	 [Technology /Service Name]Disaster Recovery Plan (DRP)	 						Office Group Name : After Action Report 	0.3587283461501144

2016-02-08 Relevance Next and AGI - R&I Offsite	Microsoft ConfidentialSeptember 14, 2016AGI EngineCore Relevance PM TeamJanuary 26thHuman and Artificial IntelligenceOur Approach to an AGI EngineSolving the AGI Engine GoalsUpgrading our Search StackAgendaLets start with a conceptual 	0.4687709951566708
2016-02-08 Relevance Next and AGI - R&I Offsite	Microsoft ConfidentialSeptember 14, 2016Relevance Next and our Path to AGIAll HandsFeb 10th 2016Relevance Next and our Path to AGIRelevance OpportunitiesAGI: Project Turing Relevance PowerSubstrate RelevanceDemos! Q&AAgendaFY16	0.4622819291355996
2016-02-08 Relevance Next and AGI - R&I Offsite	SVMT UpdateNovember 2016AgendaMorning (10:00-12:00)Overview – 15 minQnA:MALTA – 55 minInfoBot – 30 minLunch break (12:00-1:00)Afternoon (1:00-3:00)Query:Deep QR – 30 minRanking:ConceptX – 30 minFusion – 30 minNapa – 30 minO	0.44896799126606796
2016-02-08 Relevance Next and AGI - R&I Offsite	PBAVnext and migrationFrank ZhangBenefit of vnextIt will reflect five years’ worth of local search relevance insights and lessons learned, including the relevance tuning principles we have discovered over the years.It will make it easier to suppor	0.43587343287377106
2016-02-08 Relevance Next and AGI - R&I Offsite	TermX Deep Dive	Gord Lueck 2015.09.22ContributorsSaekoo LeeGarrett KaminagaJunfeng ZhouAsad MohuiddinKaan OzelGord LueckCiya LiaoCAL Alteration SystemsCoreCAL is the query rewriting engine for bingCustomers:  Bing Web, Ads, Local	0.4339355134903448
2016-02-08 Relevance Next and AGI - R&I Offsite	Whole Page RelevanceShip Meeting 08/14/2012AgendaSummary of IssuesSpecial TopicsWhole Page Relevance - IssuesTeamIssue Description StatusOwnerDue Action UpdateINTL Mon-GsheldonNo major issuesCaptions MetricsSBS – Monthly 	0.426694886295004
2016-02-08 Relevance Next and AGI - R&I Offsite	Microsoft ConfidentialSeptember 14, 2016DRAFTSearch and AI PM Team MeetingApril 14th 2017Our MissionWho are we?Thoughts on PMQ&AAgendaThe 5 Priorities for Artificial Intelligence and Research Bing becomes 10 billion dollar business	0.42489539901112117
2016-02-08 Relevance Next and AGI - R&I Offsite	Microsoft ConfidentialSeptember 14, 2016Core Web RelevanceFY16 H2 PlanOur PrioritiesBuild a Universally Competitive Search Engine across all devicesExpand our Capabilities towards Knowledge Understanding to power Bing Next, MALTA, and great se	0.4206234121333562
2016-02-08 Relevance Next and AGI - R&I Offsite	唐蕾电话: (+86) 180-0132-3861Email: tanglei91@126.com工作经历                                                                    04/2014至今 :    	中国电信集团系统集成有限责任公司 软件测试工程师1.招标测试时间:05/2016至今项目描述：通过招标测试帮助甲方找到合适的厂家做他们项目中的某些模块。项目职责：负责招标测试跟产品经理讨论并细化需	0.4187456859025166
2016-02-08 Relevance Next and AGI - R&I Offsite	Microsoft ConfidentialSeptember 14, 2016Relevance Next and Artificial IntelligenceRelevance and Intent OffsiteFebruary 8thOur PrioritiesExpand our Capabilities towards a full fledged AGI Engine, with focus on Knowledge, NL/Semantic Understandi	0.40882466794867606

2016-01-26 AGI Engine	Microsoft ConfidentialSeptember 14, 2016AGI EngineCore Relevance PM TeamJanuary 26thHuman and Artificial IntelligenceOur Approach to an AGI EngineSolving the AGI Engine GoalsUpgrading our Search StackAgendaLets start with a conceptual 	0.4071261519504609
2016-01-26 AGI Engine	AGI EngineAuthors & Contributors: Li Deng, Jianfeng Gao, Rangan Majumder, Mir Rosenberg, Sean YangIntroductionThis document is a set of collective thoughts around building an Artificial General Intelligence (AGI) Engine for Microsoft. Artificial gen	0.3843866412084836
2016-01-26 AGI Engine	FY18 AGI Encoder Roadmap		Nitin Sharma, Gargi Ghosh, Saurabh TiwaryAgendaIntroductionFY18 Goals and Focus AreasFocus Area Deep DiveCustomer scenariosDetailed RoadmapAGI Encoder: MotivationGoal: One general intent encoder of source 	0.37403365608050837
2016-01-26 AGI Engine	Online Click Labels for CAL Ranker:End – To End:aether://experiments/31148112-679c-476c-91d0-bb3ebbef81c2Continuous trained module continuously trains trees using HRS and then the ranker.OFE Ranker Training Pipeline:aether://experiments/01dbe0	0.356280560662857
2016-01-26 AGI Engine	Satori Introduction2012-09-20  yukaihAgendaOverviewMajor ModulesIngestionConflationServingGet Started in Local BoxUseful linksAppendix: Satori Local PipelineOverview - SatoriMission: build the largest, freshest, and most accurate E	0.3355332244636769
2016-01-26 AGI Engine	AGI Intent EncoderGavin YingWeb Intelligence Team(Tail Ranking team)7/29/2016What is Intent EncoderGiven a text like query, question, short sentence, get a vector represent in a high dimension space. The vector should capture semantic meanin	0.3313553654438884
2016-01-26 AGI Engine	Query Automotive & Vehicle Services (90056) Banking & Finance (90111) Beauty & Spa (90353) Food & Drink (90232) Healthcare (90375) Professionals & Services (90496) Real Estate (90584) Retail (90628) Sports & Recreation (90848) Travel (90881) Other Categor	0.3275471471957561
2016-01-26 AGI Engine	1/29 AGI ReviewAttendees: Harry Shum, Yi-Min Wang, David Ku, Steven Yao, Jianfeng Gao, Saurabh Tiwary, JJ Liu, Mir RosenbergTask Oriented Dialog AgentsJianfengShare the “Hail Caesar” slide (rule-based vs. RL dialog)Write what we discussed on Cor	0.3238816851553447
2016-01-26 AGI Engine	Speller Related Issues & SolutionsMing Wu2014-01-08Speller Related Issues – in nativePBA reads spell corrected query from Speller kif responseAssumes offsets are on raw query, which is not the caseE.g. {   piza hut} -> {pizzaiza hut}Proposed	0.32355878619615636
2016-01-26 AGI Engine	Tiger MigrationKefeng Deng6/15/2015Microsoft ConfidentialTiger MigrationMotivationTiger IntroductionHow do we get thereCurrent statusRemaining works6/15/2015Microsoft ConfidentialMotivationSame index serve architecture as Satori 	0.305921274101153

2016-01-19 AGI Engine	AGI EngineAuthors & Contributors: Li Deng, Jianfeng Gao, Rangan Majumder, Mir Rosenberg, Sean YangIntroductionThis document is a set of collective thoughts around building an Artificial General Intelligence (AGI) Engine for Microsoft. Artificial gen	0.41241071701804943
2016-01-19 AGI Engine	Microsoft ConfidentialSeptember 14, 2016AGI EngineCore Relevance PM TeamJanuary 26thHuman and Artificial IntelligenceOur Approach to an AGI EngineSolving the AGI Engine GoalsUpgrading our Search StackAgendaLets start with a conceptual 	0.41003820142808806
2016-01-19 AGI Engine	AGI Intent EncoderGavin YingWeb Intelligence Team(Tail Ranking team)7/29/2016What is Intent EncoderGiven a text like query, question, short sentence, get a vector represent in a high dimension space. The vector should capture semantic meanin	0.35089177439255476
2016-01-19 AGI Engine	Tiger MigrationKefeng Deng6/15/2015Microsoft ConfidentialTiger MigrationMotivationTiger IntroductionHow do we get thereCurrent statusRemaining works6/15/2015Microsoft ConfidentialMotivationSame index serve architecture as Satori 	0.3363813130388698
2016-01-19 AGI Engine	Microsoft ConfidentialSeptember 14, 2016DRAFTSearch and AI PM Team MeetingApril 14th 2017Our MissionWho are we?Thoughts on PMQ&AAgendaThe 5 Priorities for Artificial Intelligence and Research Bing becomes 10 billion dollar business	0.3292218482439134
2016-01-19 AGI Engine	Online Click Labels for CAL Ranker:End – To End:aether://experiments/31148112-679c-476c-91d0-bb3ebbef81c2Continuous trained module continuously trains trees using HRS and then the ranker.OFE Ranker Training Pipeline:aether://experiments/01dbe0	0.31485546471244164
2016-01-19 AGI Engine	Bing Ads Insight Track Weekly Review9/22/2015Primary KPIs  -- Product UsageCallout –NAKSP WoW usage increase by 223.58% on 9/14 was mainly driven by API-AdCenterAdIntelligenceService_V9 with the dev token 002234PN5W617046 whose associated accoun	0.3131331583365802
2016-01-19 AGI Engine	Satori Introduction2012-09-20  yukaihAgendaOverviewMajor ModulesIngestionConflationServingGet Started in Local BoxUseful linksAppendix: Satori Local PipelineOverview - SatoriMission: build the largest, freshest, and most accurate E	0.3097944750620916
2016-01-19 AGI Engine	1/29 AGI ReviewAttendees: Harry Shum, Yi-Min Wang, David Ku, Steven Yao, Jianfeng Gao, Saurabh Tiwary, JJ Liu, Mir RosenbergTask Oriented Dialog AgentsJianfengShare the “Hail Caesar” slide (rule-based vs. RL dialog)Write what we discussed on Cor	0.28121328218864994
2016-01-19 AGI Engine	FY18 AGI Encoder Roadmap		Nitin Sharma, Gargi Ghosh, Saurabh TiwaryAgendaIntroductionFY18 Goals and Focus AreasFocus Area Deep DiveCustomer scenariosDetailed RoadmapAGI Encoder: MotivationGoal: One general intent encoder of source 	0.27271754302377926

20151109-AdInsight	PO Box 91059Seattle, WA 98111-9159	VISION 	Member Claim Form 	for Microsoft  This form is to be used for Vision claims (routine exam and hardware) where you incurred expenses from a provider who did not bill the plan directly.For Medical or De	0.30551467313915265
20151109-AdInsight	Wind Up Impact on Existing adInsight Feature Plan03/25/2015ContextTo Enable “Wind Up for Premium” as high priority, we decide to make following resource adjustmentImpact to Existing Product/Feature AreaFocus AreaProducts/FeaturesResource	0.26328585034135094
20151109-AdInsight	BLU V3 Minghua Zhang      01/26/2016Next version of BLU Relevance Infrastructure​OutlineWhy BLU v3BLU v3 DesignCurrent StatusFuture WorkWhy BLU v3 (1)Limitations of current BLU infrastructureFeaturesCouldn’t utilize QAS feature	0.22916067445465235
20151109-AdInsight	成交日期 买卖标志 成交价格 成交数量 成交金额 20160105 买入 100 897 20160108 卖出 8 200 1600 成交日期 买卖标志 成交价格 成交数量 成交金额 20160106 买入 100 1702 20160113 买入 100 1532 20160325 卖出 100 1695 20160708 卖出 100 1570 20160725 卖出 500 10700 20160802 卖出 300 6660 20160802 卖出 200 4430 20160803 卖出 20	0.21935663953843682
20151109-AdInsight	成交日期 买卖标志 成交价格 成交数量 成交金额 2016年亏319 2015及2016年已完结 20160105 买入 100 897 20160108 卖出 8 200 1600 20150615 买入 100 1889 20150615 买入 100 1840 20150624 卖出 100 1585 20150720 买入 100 1073 20150721 买入 100 1098 20150721 买入 100 1086 20150723 买入 100 1110 20150818 卖出 500 	0.21918782652373217
20151109-AdInsight	GoldenQuery: Past Flights v1Session v1Nov, 2013Simple Explanation of GoldenQueryQuery level Explore & ExploitExplore against techniqueMemorization basedGQ service running before speller, intercept every queryContinues E&E{Microsoft off	0.20914575482322637
20151109-AdInsight	唐蕾电话: (+86) 180-0132-3861Email: tanglei91@126.com工作经历                                                                    04/2014至今 :    	中国电信集团系统集成有限责任公司 软件测试工程师1.招标测试时间:05/2016至今项目描述：通过招标测试帮助甲方找到合适的厂家做他们项目中的某些模块。项目职责：负责招标测试跟产品经理讨论并细化需	0.20845851828036616
20151109-AdInsight	OPG- Business Continuity PlanTellMeService, Shredder, AugmentationService, Enrichment, UCIService (Insights), Entity ServiceDocument Revision HistoryDateAuthorChange NotesLeader Sign off4/30/2018alyanInitial document5/10/2019alyanU	0.20608896842948604
20151109-AdInsight	Query Automotive & Vehicle Services (90056) Banking & Finance (90111) Beauty & Spa (90353) Food & Drink (90232) Healthcare (90375) Professionals & Services (90496) Real Estate (90584) Retail (90628) Sports & Recreation (90848) Travel (90881) Other Categor	0.2028334985470119
20151109-AdInsight	成交日期 买卖标志 成交价格 成交数量 成交金额 20160106 买入 100 1702 20160113 买入 100 1532 20160325 卖出 100 1695 20160708 卖出 100 1570 20160725 卖出 500 10700 20160802 卖出 300 6660 20160802 卖出 200 4430 20160803 卖出 200 4672 20160908 卖出 100 2695 成交日期 买卖标志 成交价格 成交数量 成交金额 20160112 买入 100	0.19863181281870776

20150922-AdInsight	唐蕾电话: (+86) 180-0132-3861Email: tanglei91@126.com工作经历                                                                    04/2014至今 :    	中国电信集团系统集成有限责任公司 软件测试工程师1.招标测试时间:05/2016至今项目描述：通过招标测试帮助甲方找到合适的厂家做他们项目中的某些模块。项目职责：负责招标测试跟产品经理讨论并细化需	0.2535289041268557
20150922-AdInsight	Entity Selection ModelJia Liu2017-11-08GDP Pipeline View: local data pipelineEntity TypesEntity Types:Open/CloseHead/TailNonJunk/JunkJunk TypesGhost: Local business existed beforeJunk: General name like “Lock smith”, “ATM”Move/Br	0.2356424513638373
20150922-AdInsight	成交日期 买卖标志 成交价格 成交数量 成交金额 2016年亏319 2015及2016年已完结 20160105 买入 100 897 20160108 卖出 8 200 1600 20150615 买入 100 1889 20150615 买入 100 1840 20150624 卖出 100 1585 20150720 买入 100 1073 20150721 买入 100 1098 20150721 买入 100 1086 20150723 买入 100 1110 20150818 卖出 500 	0.23497782291836333
20150922-AdInsight	SVMT UpdateNovember 2016AgendaMorning (10:00-12:00)Overview – 15 minQnA:MALTA – 55 minInfoBot – 30 minLunch break (12:00-1:00)Afternoon (1:00-3:00)Query:Deep QR – 30 minRanking:ConceptX – 30 minFusion – 30 minNapa – 30 minO	0.23128734650977711
20150922-AdInsight	成交日期 买卖标志 成交价格 成交数量 成交金额 20160105 买入 100 897 20160108 卖出 8 200 1600 成交日期 买卖标志 成交价格 成交数量 成交金额 20160106 买入 100 1702 20160113 买入 100 1532 20160325 卖出 100 1695 20160708 卖出 100 1570 20160725 卖出 500 10700 20160802 卖出 300 6660 20160802 卖出 200 4430 20160803 卖出 20	0.22913161112437933
20150922-AdInsight	成交日期 买卖标志 成交价格 成交数量 成交金额 20160106 买入 100 1702 20160113 买入 100 1532 20160325 卖出 100 1695 20160708 卖出 100 1570 20160725 卖出 500 10700 20160802 卖出 300 6660 20160802 卖出 200 4430 20160803 卖出 200 4672 20160908 卖出 100 2695 成交日期 买卖标志 成交价格 成交数量 成交金额 20160112 买入 100	0.22066273119660768
20150922-AdInsight	PA Selection StackKeng-hao Chang3/8/2017AgendaQuery (offer) understandingRetail classifierCategorizerCRFSelection algorithmsRIIRNGSRanking methodsL0, L1, L1.5, L2, Attribute-awareRetail experiencePA stack via Components*RnR	0.21996335627771024
20150922-AdInsight	LDCG V3Knowledge Transfer2017-04-14Brett Clippingdale, Sean King, Vikas Mittal, Li JiangLDCG V3 OutlineLDCG V2 vs V3: High-level comparisonLDCG V3: New distance ModelV2 vs V3 OverviewLDCG V3: GeoIntent HIT appLDCG V3: Calculate distance 	0.21751415013744083
20150922-AdInsight	成交日期 买卖标志 成交价格 成交数量 成交金额 20160105 买入 100 897 20160108 卖出 8 200 1600 成交日期 买卖标志 成交价格 成交数量 成交金额 20160106 买入 100 1702 成交日期 买卖标志 成交价格 成交数量 成交金额 20160105 买入 100 897 20160108 卖出 8 200 1600 	0.2149582583928256
20150922-AdInsight	DSAT Mining & LSRBhagirath AddepalliCUV Log Based DSAT IdentificationIdentifying Google Local Answer Clicks from CUV LogsFor local queries, Google pushes users to search on MapClicking on Map results in url of type: https://www.google.com/webhp?	0.21393666392136776

20150907-AdInsight	唐蕾电话: (+86) 180-0132-3861Email: tanglei91@126.com工作经历                                                                    04/2014至今 :    	中国电信集团系统集成有限责任公司 软件测试工程师1.招标测试时间:05/2016至今项目描述：通过招标测试帮助甲方找到合适的厂家做他们项目中的某些模块。项目职责：负责招标测试跟产品经理讨论并细化需	0.30954698465087244
20150907-AdInsight	成交日期 买卖标志 成交价格 成交数量 成交金额 2016年亏319 2015及2016年已完结 20160105 买入 100 897 20160108 卖出 8 200 1600 20150615 买入 100 1889 20150615 买入 100 1840 20150624 卖出 100 1585 20150720 买入 100 1073 20150721 买入 100 1098 20150721 买入 100 1086 20150723 买入 100 1110 20150818 卖出 500 	0.29201373933462205
20150907-AdInsight	Query Simplification Deep DiveJON Fu12/11/2017AgendaQuery Simplification Motivation and TheoryQuery Simplification for WebQuery Simplification for Cortana 3ARecent Progress in Query Simplification WorkReferencesIntroductionMotiva	0.2908021576620242
20150907-AdInsight	成交日期 买卖标志 成交价格 成交数量 成交金额 20160105 买入 100 897 20160108 卖出 8 200 1600 成交日期 买卖标志 成交价格 成交数量 成交金额 20160106 买入 100 1702 20160113 买入 100 1532 20160325 卖出 100 1695 20160708 卖出 100 1570 20160725 卖出 500 10700 20160802 卖出 300 6660 20160802 卖出 200 4430 20160803 卖出 20	0.2821020721599984
20150907-AdInsight	成交日期 买卖标志 成交价格 成交数量 成交金额 20160106 买入 100 1702 20160113 买入 100 1532 20160325 卖出 100 1695 20160708 卖出 100 1570 20160725 卖出 500 10700 20160802 卖出 300 6660 20160802 卖出 200 4430 20160803 卖出 200 4672 20160908 卖出 100 2695 成交日期 买卖标志 成交价格 成交数量 成交金额 20160112 买入 100	0.2765430053871483
20150907-AdInsight	SVMT UpdateNovember 2016AgendaMorning (10:00-12:00)Overview – 15 minQnA:MALTA – 55 minInfoBot – 30 minLunch break (12:00-1:00)Afternoon (1:00-3:00)Query:Deep QR – 30 minRanking:ConceptX – 30 minFusion – 30 minNapa – 30 minO	0.273829185787719
20150907-AdInsight	成交日期 买卖标志 成交价格 成交数量 成交金额 20160105 买入 100 897 20160108 卖出 8 200 1600 成交日期 买卖标志 成交价格 成交数量 成交金额 20160106 买入 100 1702 成交日期 买卖标志 成交价格 成交数量 成交金额 20160105 买入 100 897 20160108 卖出 8 200 1600 	0.2715403662822787
20150907-AdInsight	Hadoop介绍阳云2011.03主要内容Hadoop应用背景Hadoop介绍Hdfs的介绍Mapred的介绍HiveHbase开心网hadoop使用现状背景解决单机无法完成的大存储(>1TB)和大规模计算基于RDBMS的存储和计算瓶颈扩展差容错差 可以开发自己的分布式系统开发成本高通用性差mpi？一个消息传递库利用mpi开发成本依旧很高无容错Hadoop简介Google的GFS，MapReduce	0.26671302011967063
20150907-AdInsight	GoldenQuery: Past Flights v1Session v1Nov, 2013Simple Explanation of GoldenQueryQuery level Explore & ExploitExplore against techniqueMemorization basedGQ service running before speller, intercept every queryContinues E&E{Microsoft off	0.25604932896702426
20150907-AdInsight	Wrapstar rating signalsfor zh-cn documentsJia LiuWrapstar rating signals for rankingWrapstar Taobao ratingWrapstar Tmall ratingWrapstar Qna ratingWrapstar Book ratingWrapstar Video ratingDsats examplesTaobao examplesQuery=“蓝色休闲裤	淘宝”	0.25503102973756087

20150325-AdInsight - Wind Up Impact	Wind Up Impact on Existing adInsight Feature Plan03/25/2015ContextTo Enable “Wind Up for Premium” as high priority, we decide to make following resource adjustmentImpact to Existing Product/Feature AreaFocus AreaProducts/FeaturesResource	0.5309285979653916
20150325-AdInsight - Wind Up Impact	SVMT UpdateNovember 2016AgendaMorning (10:00-12:00)Overview – 15 minQnA:MALTA – 55 minInfoBot – 30 minLunch break (12:00-1:00)Afternoon (1:00-3:00)Query:Deep QR – 30 minRanking:ConceptX – 30 minFusion – 30 minNapa – 30 minO	0.4096689119089227
20150325-AdInsight - Wind Up Impact	Mobile LT Discussion6/20/2014AgendaTop IssuesAd Product and Ad Quality UpdateSummarized Finding NDT Supply AnalysisSummarized Finding Google CompeteStatusFeatureWindows phoneIphone/AndroidUp to 2 adsShipped 5/20/2014Shipped more 	0.3401067177281953
20150325-AdInsight - Wind Up Impact	LDCG V3Knowledge Transfer2017-04-14Brett Clippingdale, Sean King, Vikas Mittal, Li JiangLDCG V3 OutlineLDCG V2 vs V3: High-level comparisonLDCG V3: New distance ModelV2 vs V3 OverviewLDCG V3: GeoIntent HIT appLDCG V3: Calculate distance 	0.32822303627261756
20150325-AdInsight - Wind Up Impact	Satori Introduction2012-09-20  yukaihAgendaOverviewMajor ModulesIngestionConflationServingGet Started in Local BoxUseful linksAppendix: Satori Local PipelineOverview - SatoriMission: build the largest, freshest, and most accurate E	0.302685409549697
20150325-AdInsight - Wind Up Impact	Bing Ads Insight Track Weekly Review9/22/2015Primary KPIs  -- Product UsageCallout –NAKSP WoW usage increase by 223.58% on 9/14 was mainly driven by API-AdCenterAdIntelligenceService_V9 with the dev token 002234PN5W617046 whose associated accoun	0.30145385356152904
20150325-AdInsight - Wind Up Impact	GoldenQuery: Past Flights v1Session v1Nov, 2013Simple Explanation of GoldenQueryQuery level Explore & ExploitExplore against techniqueMemorization basedGQ service running before speller, intercept every queryContinues E&E{Microsoft off	0.2935385027294693
20150325-AdInsight - Wind Up Impact	BLU V3 Minghua Zhang      01/26/2016Next version of BLU Relevance Infrastructure​OutlineWhy BLU v3BLU v3 DesignCurrent StatusFuture WorkWhy BLU v3 (1)Limitations of current BLU infrastructureFeaturesCouldn’t utilize QAS feature	0.29036822769806375
20150325-AdInsight - Wind Up Impact	Multi-Query Issue and QR/Ranking Joint Optimization Bhuvan MiddhaJonas BarklundYinzhe YuYuan Wang6/26/2012AgendaPresentation TopicTime/PresenterIntroduction/QR/Ranking for Joint Optimization3:05 pm – 3:30 pm [Bhuvan/Jonas]Joint Opt	0.2899477314019719
20150325-AdInsight - Wind Up Impact	Metrics Pipeline & ToolsJia Liu / Xiaohui Sun / Alex SergeevASG Data Mining TeamDemo link: http://dmsql05/MetricsDefinitionTool/MetricsDefinition.aspx?DataSet=BFT&MetricName=HasCortanaChitChatsTopicsBing Live Metrics PipelineUsage and Perf	0.2892005839590811

20150310 - Successful Feeds Query Debugging	Successful Feeds Query DebuggingNikita Melnichenko, 2015-03-10Feeds query debugging overviewWhen to use:Checking a new rankerChecking new augmentation before running a scrapeComparing several rankersUnderstanding feature contributionDebugg	0.6658370735363665
20150310 - Successful Feeds Query Debugging	PBA Dependency and DebugMing Wu2014-01-28PBA DependenciesLocation Understanding (LES/BLU)Location info (explicit/implicit) – fulfill detailed location infoProvide location related features to phonebook CRFXapQuServiceAnswer (QAS)For most c	0.5346231478378775
20150310 - Successful Feeds Query Debugging	query分类—分享                     刘佳2011.6.8web query classification(query分类):	将web search query根据它的主题，分派到1个或者多个预先定义的分类中。web search query的特征：有噪声：拼写错误等长度很短：信息量少，特征少表意含糊：query可能包含多个含义,属于多个分类含义会随时间演变目标分类的特征：目标分类定义缺少语义注解一级或者多级分类分类数目：几	0.5146535429829315
20150310 - Successful Feeds Query Debugging	IQ Team RecapH1 2016FY16H1 AccomplishmentsTeamSSRxen-* Desktop SBSen-* Mobile SBSen-* Semantic SBSCore Web Relevance0.55/0.62.46/3.02.65/3.01.88/2.0Adult LeakageSpamJunkCQDCGMPCMALTABing@WorkSubstrate0.02/0.01	0.4685051648843711
20150310 - Successful Feeds Query Debugging	客户价值模型分享和讨论WHY/WHAT/HOWECom ASEA  ——  Advertisement Search Analysis2010-12-29为什么要做客户模型客户价值度模型客户关注点模型客户忠诚度模型……常用的客户价值模型RFM模型R(Recency)表示客户最近一次购买的时间有多远；F(Frequency)表示客户在最近一段时间内购买的次数；M (Monetary)表示最近一段时间内购买的金额2维RFM（消除购买次数与购买额之间的多重	0.46698924003491815
20150310 - Successful Feeds Query Debugging	NTCG DebuggingSteven Zittrower01/30/2015AgendaNTCGNTCG DashboardOverview of BLU Architecture (Address Specific)Address Debugging in QATNTCGNTCG (Normalized Total Cumulative Gain) is a composite metric that measures address query releva	0.46339562720828775
20150310 - Successful Feeds Query Debugging	成交日期 买卖标志 成交价格 成交数量 成交金额 20160105 买入 100 897 20160108 卖出 8 200 1600 成交日期 买卖标志 成交价格 成交数量 成交金额 20160106 买入 100 1702 20160113 买入 100 1532 20160325 卖出 100 1695 20160708 卖出 100 1570 20160725 卖出 500 10700 20160802 卖出 300 6660 20160802 卖出 200 4430 20160803 卖出 20	0.4620202448558937
20150310 - Successful Feeds Query Debugging	成交日期 买卖标志 成交价格 成交数量 成交金额 2016年亏319 2015及2016年已完结 20160105 买入 100 897 20160108 卖出 8 200 1600 20150615 买入 100 1889 20150615 买入 100 1840 20150624 卖出 100 1585 20150720 买入 100 1073 20150721 买入 100 1098 20150721 买入 100 1086 20150723 买入 100 1110 20150818 卖出 500 	0.4556607470125885
20150310 - Successful Feeds Query Debugging	Summary of 50 queries:QueryIssue categoryResolved促销策略案例分析Page NumberYes美丽说面膜Page NumberYes朝鲜金正恩腐化生活 图片Page NumberNo(L3 rule not cover this case: the second page is higher than the first page)智慧树2012全集Page NumberYes潘阳老公石磊P	0.45199856899861524
20150310 - Successful Feeds Query Debugging	成交日期 买卖标志 成交价格 成交数量 成交金额 20160105 买入 100 897 20160108 卖出 8 200 1600 成交日期 买卖标志 成交价格 成交数量 成交金额 20160106 买入 100 1702 成交日期 买卖标志 成交价格 成交数量 成交金额 20160105 买入 100 897 20160108 卖出 8 200 1600 	0.44995127574661714

2015-12-17 Core Web Relevance FY16H2 review	Core Web RelevanceFY16 H2 PlanCore Web RelevanceFY16 H2 PlanCore Web RelevanceFY16 H2 PlanCore Web RelevanceFY16 H2 Plan	0.4972823372593426
2015-12-17 Core Web Relevance FY16H2 review	Local Relevance SQR (en-us + en-ca)March 14, 2017AgendaContext & Scope:EN-US & EN-CA, Mobile and SERP relevance focusedPBA (pre-web) relevance focusedQuality measurements DSAT examplesGeneral issuesKey Segments (Restaurants, Hotels, Re	0.3853845709674487
2015-12-17 Core Web Relevance FY16H2 review	Bing Ads Insight Track Weekly Review9/22/2015Primary KPIs  -- Product UsageCallout –NAKSP WoW usage increase by 223.58% on 9/14 was mainly driven by API-AdCenterAdIntelligenceService_V9 with the dev token 002234PN5W617046 whose associated accoun	0.3675045937183789
2015-12-17 Core Web Relevance FY16H2 review	Microsoft ConfidentialSeptember 14, 2016AGI EngineCore Relevance PM TeamJanuary 26thHuman and Artificial IntelligenceOur Approach to an AGI EngineSolving the AGI Engine GoalsUpgrading our Search StackAgendaLets start with a conceptual 	0.35947181330924305
2015-12-17 Core Web Relevance FY16H2 review	QR FY19 LRP Planning - 23/29/18Unified Concept Tagging – Key ChallengesStructural ComplexityFor ambiguous queries and multi-concept queries, how much organization is required?  How to represent this in a linear qlf?  What about inter-concept rel	0.35348776290153555
2015-12-17 Core Web Relevance FY16H2 review	Microsoft ConfidentialSeptember 14, 2016Core Web RelevanceFY16 H2 PlanOur PrioritiesBuild a Universally Competitive Search Engine across all devicesExpand our Capabilities towards Knowledge Understanding to power Bing Next, MALTA, and great se	0.3461098338687598
2015-12-17 Core Web Relevance FY16H2 review	SmartRelax training and evaluation from 15%/15% flightForay scorecard: 15%+15% datagatheringUser-triggered scorecardSSRx gain of 0.12%, for 3+4 word on vs. 3+4 word off. (NOT vs. prod.)Gain is 36% from SSR, 11% from TTS, 52% from TSRSSRx gains s	0.34550014933264633
2015-12-17 Core Web Relevance FY16H2 review	WPO Local RelevancePing Yin2017-03-21OverviewWPO’s role in local relevance pipelineLocal Entity StampingArchitecture overviewWPO Local Relevance Models.Query: exton mall, User location: Wallingford, PAWPO RolesExtract/detect all entity	0.34337341205643745
2015-12-17 Core Web Relevance FY16H2 review	Distance Model, LDS, L3Knowledge SharingNikita Melnichenko, Bing Local2017-04-21Overview of PBA relevance flow in FeedsL1Keyword matchWPOL2 levelRankerTruncationCategory matchName matchLogical DistanceUI sortingGIMXIMGDM	0.3402956820116008
2015-12-17 Core Web Relevance FY16H2 review	Relevance Debug InfrastructureProblemFrequent  daily metric fluctuationRelevance gain negated by regressions from Sep to Oct 2013Painful to investigateChallengeLocal stack is complex with lots of componentsVarious relevance events mixed toge	0.33272335946339093

20140805 Deep Dive - ProjectN	Bing GC Deep DiveBingGCI 9/26/2014Introduction – Pavel, 2minsProject overview – Wei, 6minsBing GC XAP workflow – John, 10minsBing GC data pipeline and data ingestion – Florin, 7minsBing GC Offline relevance platform – Jian, 8minsSingle-poi	0.5264672087194747
20140805 Deep Dive - ProjectN	Project-N DeepDiveAbstractSimilarity issue has been one of the biggest problems of zh-CN relevance for years but not well got solved. In this document, we will focus on one of the main problem of similarity - entity/phrase mismatch issue in query/doc 	0.4699695265993642
20140805 Deep Dive - ProjectN	Deep Dive: Query Generic Entity Extraction (GEE)Zhen Liao04/22/2016OutlineOverview of GEEFAQ for GEEArchitecture and ModelingRecent breakthrough via Deep LearningLessons we’ve learnedGeneric Entity Extraction for Queries: What is the g	0.4423704774308149
20140805 Deep Dive - ProjectN	TermX Deep Dive	Gord Lueck 2015.09.22ContributorsSaekoo LeeGarrett KaminagaJunfeng ZhouAsad MohuiddinKaan OzelGord LueckCiya LiaoCAL Alteration SystemsCoreCAL is the query rewriting engine for bingCustomers:  Bing Web, Ads, Local	0.4262365134582982
20140805 Deep Dive - ProjectN	Query Simplification Deep DiveJON Fu12/11/2017AgendaQuery Simplification Motivation and TheoryQuery Simplification for WebQuery Simplification for Cortana 3ARecent Progress in Query Simplification WorkReferencesIntroductionMotiva	0.4204856240751591
20140805 Deep Dive - ProjectN	PBA Dependency and DebugMing Wu2014-01-28PBA DependenciesLocation Understanding (LES/BLU)Location info (explicit/implicit) – fulfill detailed location infoProvide location related features to phonebook CRFXapQuServiceAnswer (QAS)For most c	0.4192742004979378
20140805 Deep Dive - ProjectN	Discover More – RestaurantsJune, 2018Daniel WeinshenkerMicrosoft ConfidentialOverview Suggests cuisines, dishes, amenities, and nearby POIs to users searching for restaurants Top 50 cities in the USA suggest the followingWell-known dishes 	0.4097729382290283
20140805 Deep Dive - ProjectN	Mobile LT Discussion6/20/2014AgendaTop IssuesAd Product and Ad Quality UpdateSummarized Finding NDT Supply AnalysisSummarized Finding Google CompeteStatusFeatureWindows phoneIphone/AndroidUp to 2 adsShipped 5/20/2014Shipped more 	0.4043431875435535
20140805 Deep Dive - ProjectN	Deep Dive on Statistical Simplification Model for Hard QueriesBin Zhang (intern, University of Washington)Xiaolong Li, Ye-Yi Wang (Bing)Xiaodong He (MSR)9/11/2012OutlineHard query backgroundDeletion modelsTraining dataOnline experiment	0.39594708310253207
20140805 Deep Dive - ProjectN	Query Automotive & Vehicle Services (90056) Banking & Finance (90111) Beauty & Spa (90353) Food & Drink (90232) Healthcare (90375) Professionals & Services (90496) Real Estate (90584) Retail (90628) Sports & Recreation (90848) Travel (90881) Other Categor	0.39541247234626786

20140603 DeepDive-Title Match	L2 General Title MatchJia Liu2/25/2014N-Gram Table6B Documents TitleN-Gram is continually builtTitle: A B C D3-Gram: A B C, B C D1-Gram to 10-Gram, N is in [1…10]Format: N-gram \t Len \t FrequencyTable Guid:3ce6e18c-ad7e-47e0-94ec-dfd6	0.4982693552520554
20140603 DeepDive-Title Match	Deep Learning: The Path ForwardTuring/AGI/WITSaurabh TiwaryGoalsStrategyDL first everywhereScaleAGI-fying building blocksNew ScenarioLight up T@W & Unified QUDL-firstWe have been hedging our effortsLet’s do (a little bit of) everyt	0.41716409728617176
20140603 DeepDive-Title Match	Successful Feeds Query DebuggingNikita Melnichenko, 2015-03-10Feeds query debugging overviewWhen to use:Checking a new rankerChecking new augmentation before running a scrapeComparing several rankersUnderstanding feature contributionDebugg	0.39891559022074236
20140603 DeepDive-Title Match	PBA Dependency and DebugMing Wu2014-01-28PBA DependenciesLocation Understanding (LES/BLU)Location info (explicit/implicit) – fulfill detailed location infoProvide location related features to phonebook CRFXapQuServiceAnswer (QAS)For most c	0.37813840480864114
20140603 DeepDive-Title Match	Query Automotive & Vehicle Services (90056) Banking & Finance (90111) Beauty & Spa (90353) Food & Drink (90232) Healthcare (90375) Professionals & Services (90496) Real Estate (90584) Retail (90628) Sports & Recreation (90848) Travel (90881) Other Categor	0.37808337038326223
20140603 DeepDive-Title Match	Speller Related Issues & SolutionsMing Wu2014-01-08Speller Related Issues – in nativePBA reads spell corrected query from Speller kif responseAssumes offsets are on raw query, which is not the caseE.g. {   piza hut} -> {pizzaiza hut}Proposed	0.37780707762294446
20140603 DeepDive-Title Match	Bing Local Search				PBA QU Post-processing in QAS Dev ownerMing WuBuddy dev(s)PM ownerContributorsFeature areaPBA Query ProcessingMilestoneAluminumTable of contents1	Overview	22	Goals/Non Goals	23	Risks/Open Issues	24	Desi	0.3532903080329091
20140603 DeepDive-Title Match	CJK RELEVANCE ALL HANDS03/06/201401Qi ASG Memo02MS Poll	03USBS MeasurementAGENDA04Win in USBSVideoEbookMemo DocWatch the VideoVideoIntroductionWho We AreOur VisionClosingDiscussion and QnA01Qi ASG Memo02	0.33588626084608986
20140603 DeepDive-Title Match	TermX Deep Dive	Gord Lueck 2015.09.22ContributorsSaekoo LeeGarrett KaminagaJunfeng ZhouAsad MohuiddinKaan OzelGord LueckCiya LiaoCAL Alteration SystemsCoreCAL is the query rewriting engine for bingCustomers:  Bing Web, Ads, Local	0.3293112634002134
20140603 DeepDive-Title Match	query分类—分享                     刘佳2011.6.8web query classification(query分类):	将web search query根据它的主题，分派到1个或者多个预先定义的分类中。web search query的特征：有噪声：拼写错误等长度很短：信息量少，特征少表意含糊：query可能包含多个含义,属于多个分类含义会随时间演变目标分类的特征：目标分类定义缺少语义注解一级或者多级分类分类数目：几	0.32823313209860566

20140306 CJK Relevance All Hands	CJK RELEVANCE ALL HANDS03/06/201401Qi ASG Memo02MS Poll	03USBS MeasurementAGENDA04Win in USBSVideoEbookMemo DocWatch the VideoVideoIntroductionWho We AreOur VisionClosingDiscussion and QnA01Qi ASG Memo02	0.6352325280824166
20140306 CJK Relevance All Hands	LDCG V3Knowledge Transfer2017-04-14Brett Clippingdale, Sean King, Vikas Mittal, Li JiangLDCG V3 OutlineLDCG V2 vs V3: High-level comparisonLDCG V3: New distance ModelV2 vs V3 OverviewLDCG V3: GeoIntent HIT appLDCG V3: Calculate distance 	0.4832758109616905
20140306 CJK Relevance All Hands	BLU V3 Minghua Zhang      01/26/2016Next version of BLU Relevance Infrastructure​OutlineWhy BLU v3BLU v3 DesignCurrent StatusFuture WorkWhy BLU v3 (1)Limitations of current BLU infrastructureFeaturesCouldn’t utilize QAS feature	0.48270820276199594
20140306 CJK Relevance All Hands	Satori Introduction2012-09-20  yukaihAgendaOverviewMajor ModulesIngestionConflationServingGet Started in Local BoxUseful linksAppendix: Satori Local PipelineOverview - SatoriMission: build the largest, freshest, and most accurate E	0.47227178454515395
20140306 CJK Relevance All Hands	NTCG DebuggingSteven Zittrower01/30/2015AgendaNTCGNTCG DashboardOverview of BLU Architecture (Address Specific)Address Debugging in QATNTCGNTCG (Normalized Total Cumulative Gain) is a composite metric that measures address query releva	0.4572940616628757
20140306 CJK Relevance All Hands	Microsoft ConfidentialSeptember 14, 2016Core Web RelevanceFY16 H2 PlanOur PrioritiesBuild a Universally Competitive Search Engine across all devicesExpand our Capabilities towards Knowledge Understanding to power Bing Next, MALTA, and great se	0.45604381953735407
20140306 CJK Relevance All Hands	Speller Related Issues & SolutionsMing Wu2014-01-08Speller Related Issues – in nativePBA reads spell corrected query from Speller kif responseAssumes offsets are on raw query, which is not the caseE.g. {   piza hut} -> {pizzaiza hut}Proposed	0.456034709678301
20140306 CJK Relevance All Hands	Microsoft ConfidentialSeptember 14, 2016AGI EngineCore Relevance PM TeamJanuary 26thHuman and Artificial IntelligenceOur Approach to an AGI EngineSolving the AGI Engine GoalsUpgrading our Search StackAgendaLets start with a conceptual 	0.451059967794072
20140306 CJK Relevance All Hands	Microsoft ConfidentialSeptember 14, 2016Relevance Next and our Path to AGIAll HandsFeb 10th 2016Relevance Next and our Path to AGIRelevance OpportunitiesAGI: Project Turing Relevance PowerSubstrate RelevanceDemos! Q&AAgendaFY16	0.4504368836102753
20140306 CJK Relevance All Hands	Introduction to L1Xiao WuSearch Platform Tiger Team AgendaL1 goals and challengesMetrics and measurementL1 ranker and perf optimizationL1 ranking Perf optimizationDebugging tools L1 training and shippingThinking and discussionL1 	0.44751135313012946

1706_02_Restaurants_POIQueries	Restaurant segment metrics collectionObjectiveTo understand user behavior/engagement on Restaurant answers.Why this is important? The metrics will help us understand:The comparisons between different answersWhat is important to our users and w	0.3984228186163508
1706_02_Restaurants_POIQueries	Query Automotive & Vehicle Services (90056) Banking & Finance (90111) Beauty & Spa (90353) Food & Drink (90232) Healthcare (90375) Professionals & Services (90496) Real Estate (90584) Retail (90628) Sports & Recreation (90848) Travel (90881) Other Categor	0.37565214909500505
1706_02_Restaurants_POIQueries	唐蕾电话: (+86) 180-0132-3861Email: tanglei91@126.com工作经历                                                                    04/2014至今 :    	中国电信集团系统集成有限责任公司 软件测试工程师1.招标测试时间:05/2016至今项目描述：通过招标测试帮助甲方找到合适的厂家做他们项目中的某些模块。项目职责：负责招标测试跟产品经理讨论并细化需	0.37083096160601253
1706_02_Restaurants_POIQueries	Jia Liu2013-08-05DU Pipeline Sodium Achievements And Magnesium Plans For CJK　　OutlineSodium AchievementsMagnesium PlanMagnesium Work ItemsSodium Work ItemsAppendixSodium AchievementsWrapstar rating signalsTaobao, tmall; qna; novel; v	0.3680278543576342
1706_02_Restaurants_POIQueries	Discover More – RestaurantsJune, 2018Daniel WeinshenkerMicrosoft ConfidentialOverview Suggests cuisines, dishes, amenities, and nearby POIs to users searching for restaurants Top 50 cities in the USA suggest the followingWell-known dishes 	0.36623988148783254
1706_02_Restaurants_POIQueries	Distance Model Updates in LDCG V2Local Relevance and Measurement TeamAgendaDistance feature in LDCG V1Why was the switch to computing distance made?First implementation of Distance feature in LDCG V2, & improvement areasProcess followed for 	0.35736933426494344
1706_02_Restaurants_POIQueries	CJK RELEVANCE ALL HANDS03/06/201401Qi ASG Memo02MS Poll	03USBS MeasurementAGENDA04Win in USBSVideoEbookMemo DocWatch the VideoVideoIntroductionWho We AreOur VisionClosingDiscussion and QnA01Qi ASG Memo02	0.35431718037511833
1706_02_Restaurants_POIQueries	Summary of 50 queries:QueryIssue categoryResolved促销策略案例分析Page NumberYes美丽说面膜Page NumberYes朝鲜金正恩腐化生活 图片Page NumberNo(L3 rule not cover this case: the second page is higher than the first page)智慧树2012全集Page NumberYes潘阳老公石磊P	0.3460068204109932
1706_02_Restaurants_POIQueries	Adaboost算法总结Adaboost原理AdaBoost是英文"Adaptive Boosting"（自适应增强）的缩写，由Yoav Freund和Robert Schapire在1995年提出。AdaBoost 是一种迭代算法，其核心思想是针对同一个训练集训练不同的分类器，即弱分类器，然后把这些弱分类器集合起来，构造一个更强的最终分类器。算法本身是改变数据分布实现的，它根据每次训练集之中的每个样本的分类是否正确，以及上次的总体分类的准确率，来确定每个样本的权值。将修改权值的新数据送给下层分类	0.3319308962135191
1706_02_Restaurants_POIQueries	Introduction toas measurement platformOlli-Pekka TossavainenMSQ TeamSunnyvaleContentsOverviewAres AssetsData Web Store (DWS)Single HitApp core relevance exampleWhat is ARESFrom their web site:What’s been built on ARESMap Search	0.3225730007671763

1706-02-Restaurants_Queries_LocationInfo	Query Latitude Longitude QueryId Prod_PLDCG@3 Restcat_PLDCG@3 G_PLDCG@3 Delta ResultQuality Dolphin CRF PhonebookQuLocation LocalPivotEntity TLA Built? Result Returned? Result Good? Comment Restaurants in times square 00f0d1ee-9688-5b09-bcea-a5e860fead14 	0.42793526130797593
1706-02-Restaurants_Queries_LocationInfo	Query Automotive & Vehicle Services (90056) Banking & Finance (90111) Beauty & Spa (90353) Food & Drink (90232) Healthcare (90375) Professionals & Services (90496) Real Estate (90584) Retail (90628) Sports & Recreation (90848) Travel (90881) Other Categor	0.42723896357539654
1706-02-Restaurants_Queries_LocationInfo	Distance Model Updates in LDCG V2Local Relevance and Measurement TeamAgendaDistance feature in LDCG V1Why was the switch to computing distance made?First implementation of Distance feature in LDCG V2, & improvement areasProcess followed for 	0.3882540003600922
1706-02-Restaurants_Queries_LocationInfo	Jia Liu2013-08-05DU Pipeline Sodium Achievements And Magnesium Plans For CJK　　OutlineSodium AchievementsMagnesium PlanMagnesium Work ItemsSodium Work ItemsAppendixSodium AchievementsWrapstar rating signalsTaobao, tmall; qna; novel; v	0.37993628000491764
1706-02-Restaurants_Queries_LocationInfo	Discover More – RestaurantsJune, 2018Daniel WeinshenkerMicrosoft ConfidentialOverview Suggests cuisines, dishes, amenities, and nearby POIs to users searching for restaurants Top 50 cities in the USA suggest the followingWell-known dishes 	0.3678607838158715
1706-02-Restaurants_Queries_LocationInfo	DU items studyJia Liu2013-05-14AgendaPublication dateMain body blockDocument qualityurl static featuresPublication dateFreshness rankingYear in title, year in url, publication dateEn-us publication date coverage is ~20%Zh-cn public	0.36225738064346424
1706-02-Restaurants_Queries_LocationInfo	Restaurant segment metrics collectionObjectiveTo understand user behavior/engagement on Restaurant answers.Why this is important? The metrics will help us understand:The comparisons between different answersWhat is important to our users and w	0.3607341309634484
1706-02-Restaurants_Queries_LocationInfo	CJK RELEVANCE ALL HANDS03/06/201401Qi ASG Memo02MS Poll	03USBS MeasurementAGENDA04Win in USBSVideoEbookMemo DocWatch the VideoVideoIntroductionWho We AreOur VisionClosingDiscussion and QnA01Qi ASG Memo02	0.36017332671316515
1706-02-Restaurants_Queries_LocationInfo	Machine Learning Categorization & Popularity2012-08-30 | Nicolas NicolovGoalsShow how categorization and popularity systems work.Introduce important ML concepts.Illustrate ML techniques through examples.(aiming to be self-contained)Categoriz	0.34288967863839903
1706-02-Restaurants_Queries_LocationInfo	Introduction toas measurement platformOlli-Pekka TossavainenMSQ TeamSunnyvaleContentsOverviewAres AssetsData Web Store (DWS)Single HitApp core relevance exampleWhat is ARESFrom their web site:What’s been built on ARESMap Search	0.3428049325039737

1706-02-Restaurants_2018-05-30	Query Automotive & Vehicle Services (90056) Banking & Finance (90111) Beauty & Spa (90353) Food & Drink (90232) Healthcare (90375) Professionals & Services (90496) Real Estate (90584) Retail (90628) Sports & Recreation (90848) Travel (90881) Other Categor	0.39074813662300556
1706-02-Restaurants_2018-05-30	唐蕾电话: (+86) 180-0132-3861Email: tanglei91@126.com工作经历                                                                    04/2014至今 :    	中国电信集团系统集成有限责任公司 软件测试工程师1.招标测试时间:05/2016至今项目描述：通过招标测试帮助甲方找到合适的厂家做他们项目中的某些模块。项目职责：负责招标测试跟产品经理讨论并细化需	0.3638372893648707
1706-02-Restaurants_2018-05-30	Distance Model Updates in LDCG V2Local Relevance and Measurement TeamAgendaDistance feature in LDCG V1Why was the switch to computing distance made?First implementation of Distance feature in LDCG V2, & improvement areasProcess followed for 	0.3448211455804301
1706-02-Restaurants_2018-05-30	CJK RELEVANCE ALL HANDS03/06/201401Qi ASG Memo02MS Poll	03USBS MeasurementAGENDA04Win in USBSVideoEbookMemo DocWatch the VideoVideoIntroductionWho We AreOur VisionClosingDiscussion and QnA01Qi ASG Memo02	0.3295150127154117
1706-02-Restaurants_2018-05-30	TermX Deep Dive	Gord Lueck 2015.09.22ContributorsSaekoo LeeGarrett KaminagaJunfeng ZhouAsad MohuiddinKaan OzelGord LueckCiya LiaoCAL Alteration SystemsCoreCAL is the query rewriting engine for bingCustomers:  Bing Web, Ads, Local	0.3284156400178333
1706-02-Restaurants_2018-05-30	Jia Liu2013-08-05DU Pipeline Sodium Achievements And Magnesium Plans For CJK　　OutlineSodium AchievementsMagnesium PlanMagnesium Work ItemsSodium Work ItemsAppendixSodium AchievementsWrapstar rating signalsTaobao, tmall; qna; novel; v	0.3244213224789962
1706-02-Restaurants_2018-05-30	Distance Model, LDS, L3Knowledge SharingNikita Melnichenko, Bing Local2017-04-21Overview of PBA relevance flow in FeedsL1Keyword matchWPOL2 levelRankerTruncationCategory matchName matchLogical DistanceUI sortingGIMXIMGDM	0.31319698813496005
1706-02-Restaurants_2018-05-30	Bing Ads Insight Track Weekly Review9/22/2015Primary KPIs  -- Product UsageCallout –NAKSP WoW usage increase by 223.58% on 9/14 was mainly driven by API-AdCenterAdIntelligenceService_V9 with the dev token 002234PN5W617046 whose associated accoun	0.3127614291789169
1706-02-Restaurants_2018-05-30	Discover More – RestaurantsJune, 2018Daniel WeinshenkerMicrosoft ConfidentialOverview Suggests cuisines, dishes, amenities, and nearby POIs to users searching for restaurants Top 50 cities in the USA suggest the followingWell-known dishes 	0.2964011518733071
1706-02-Restaurants_2018-05-30	BLU V3 Minghua Zhang      01/26/2016Next version of BLU Relevance Infrastructure​OutlineWhy BLU v3BLU v3 DesignCurrent StatusFuture WorkWhy BLU v3 (1)Limitations of current BLU infrastructureFeaturesCouldn’t utilize QAS feature	0.2947507044936622

1511Queries-4	唐蕾电话: (+86) 180-0132-3861Email: tanglei91@126.com工作经历                                                                    04/2014至今 :    	中国电信集团系统集成有限责任公司 软件测试工程师1.招标测试时间:05/2016至今项目描述：通过招标测试帮助甲方找到合适的厂家做他们项目中的某些模块。项目职责：负责招标测试跟产品经理讨论并细化需	0.39340114074914495
1511Queries-4	成交日期 买卖标志 成交价格 成交数量 成交金额 20160105 买入 100 897 20160108 卖出 8 200 1600 成交日期 买卖标志 成交价格 成交数量 成交金额 20160106 买入 100 1702 20160113 买入 100 1532 20160325 卖出 100 1695 20160708 卖出 100 1570 20160725 卖出 500 10700 20160802 卖出 300 6660 20160802 卖出 200 4430 20160803 卖出 20	0.379893071937751
1511Queries-4	成交日期 买卖标志 成交价格 成交数量 成交金额 2016年亏319 2015及2016年已完结 20160105 买入 100 897 20160108 卖出 8 200 1600 20150615 买入 100 1889 20150615 买入 100 1840 20150624 卖出 100 1585 20150720 买入 100 1073 20150721 买入 100 1098 20150721 买入 100 1086 20150723 买入 100 1110 20150818 卖出 500 	0.3695301172611735
1511Queries-4	成交日期 买卖标志 成交价格 成交数量 成交金额 20160106 买入 100 1702 20160113 买入 100 1532 20160325 卖出 100 1695 20160708 卖出 100 1570 20160725 卖出 500 10700 20160802 卖出 300 6660 20160802 卖出 200 4430 20160803 卖出 200 4672 20160908 卖出 100 2695 成交日期 买卖标志 成交价格 成交数量 成交金额 20160112 买入 100	0.36907558051114703
1511Queries-4	成交日期 买卖标志 成交价格 成交数量 成交金额 20160105 买入 100 897 20160108 卖出 8 200 1600 成交日期 买卖标志 成交价格 成交数量 成交金额 20160106 买入 100 1702 成交日期 买卖标志 成交价格 成交数量 成交金额 20160105 买入 100 897 20160108 卖出 8 200 1600 	0.34531564956306054
1511Queries-4	Author: Tony AngellDate: 08/01/13LocalProbe Improvements for Corrections Analysis and DebuggingTable of ContentsP0 Issues	2Issue: LocalProbe is unpredictable in the amount of time it takes to return a query and how long it takes to investigate a	0.3387161471463379
1511Queries-4	贴吧大数据存储luhongbo@baidu.com2011-8-7/31目录概述和现状设计原则pbFrs负载均衡发展方向2011-8-7/31贴吧数据概述2011-8-7/31贴吧存储现状按照功能做模块水平拆分各模块均为数据单机模式镜像抗压力2011-8-7/31设计要求和原则性能（更新、浏览）访问模式决定设计最优化内存使用有效利用磁盘特性硬盘？Flash？顺序io还是随机读写？区别对待高峰期和	0.3358402021980115
1511Queries-4	Pthreads mutex vs Pthreads spinlock 锁机制(lock) 是多线程编程中最常用的同步机制,用来对多线程间共享的临界区(Critical Section) 进行保护。Pthreads提供了多种锁机制,常见的有：1) Mutex（互斥量）：pthread_mutex_***2) Spin lock（自旋锁）：pthread_spin_***3) Condition Variable（条件变量）：pthread_con_***4) Read/Write 	0.3344333704445459
1511Queries-4	 阿里浏览器DNS解析加速布可2010.12.31AgendaDNS解析过程DNS协议阿里浏览器DNS解析加速浏览器查找域名的IPtaobao.com浏览器缓存(2-30min)系统缓存(DNS client resolver cache)Local DNS递归查询->dns1.禁用IE的dns缓存：Start Registry Editor. Locate and click the following key in the reg	0.3333792760542653
1511Queries-4	query分类—分享                     刘佳2011.6.8web query classification(query分类):	将web search query根据它的主题，分派到1个或者多个预先定义的分类中。web search query的特征：有噪声：拼写错误等长度很短：信息量少，特征少表意含糊：query可能包含多个含义,属于多个分类含义会随时间演变目标分类的特征：目标分类定义缺少语义注解一级或者多级分类分类数目：几	0.3310640707351353

100k_Compete_Report_Bing_Google_iPhone_Mobile_Modified	Mobile 100k Compete Data analysis with G - Simulation Report6/6/2014Mobile Simulation AnalysisThis analysis compares Google and Bing on iOS for 3 querysets.REPORTS GENERATED FOR **: Overall Metrics Coverage (WP, ML and Bot)IY (WP, ML and Bot	0.6140417068237463
100k_Compete_Report_Bing_Google_iPhone_Mobile_Modified	Google Mobile vs Desktop RankDiff StudyNov 2017GoalsUnderstand what Google does differently on Mobile, if anythingDrive product ideas & shape ranking improvements on MobileUnderstand any possible impact to Algo scrapes & metricsDrive scrapin	0.49577252753414236
100k_Compete_Report_Bing_Google_iPhone_Mobile_Modified	Bing Ads Insight Track Weekly Review9/22/2015Primary KPIs  -- Product UsageCallout –NAKSP WoW usage increase by 223.58% on 9/14 was mainly driven by API-AdCenterAdIntelligenceService_V9 with the dev token 002234PN5W617046 whose associated accoun	0.4235260925169137
100k_Compete_Report_Bing_Google_iPhone_Mobile_Modified	FY19 Search & AI Roadmap Review: QRMay 2018Jie Cai, Garrett Kaminaga, Jingwen Lu, Momo JengMotivation – QR Query understanding and rewrite is the first opportunity for Bing to understand users’ intents;In current production, query rewrite is a	0.40707207889800273
100k_Compete_Report_Bing_Google_iPhone_Mobile_Modified	FY19 Search & AI Roadmap Review: AGI for Web RankingMay 2018Dev: Chen Zhou, Saurabh TiwaryPM: Kiki Liu, Mir RosenbergMotivation“…But often time we have more problems about the subjects we are not familiar with and therefore even the keywords	0.4069570007190693
100k_Compete_Report_Bing_Google_iPhone_Mobile_Modified	ML Model Scorecard Analysis8/8/2019Unexpected term search movementhttps://exp.microsoft.com/xcard/?view=4e77b420-7b77-4e41-92ac-8e84f506fb01Check correctness of scorecard metric implementationCalculate term AVG rank from raw data streamsSearch	0.40576435855459814
100k_Compete_Report_Bing_Google_iPhone_Mobile_Modified	FY19 Search & AI Roadmap Review: Intelligent QnAMay 2018PM: Ali Alvi, Kaan Ozel, Ganga Venkatasubramanian, Oana NicolovDev: Xia Song, Doran ChakrabortyAgendaOverall QnA Opportunity and GoalsSemi-Structured DataMALTATuring for QnAAGI En	0.39234311663099025
100k_Compete_Report_Bing_Google_iPhone_Mobile_Modified	Handbook of MLGProcessor AEther ModulesContents1.	Introduction	72.	MLGProcessor Modules	82.1.	Common Module Parameters	8Inputs	8Outputs	8Parameters	92.2.	BodySurfaceStream	9Inputs	9Outputs	92.3.	BoundaryView	9Examples	102.4.	Char	0.37975077888462483
100k_Compete_Report_Bing_Google_iPhone_Mobile_Modified	Introduction to dynamic ranking Xiao WuOutlinesIntroductionRelevance MeasurementDynamic rankingRanking FeaturesRanking DataRanking modelsRelevance ExperiementIntroductionWhat is dynamic rankingRanking based on query dependent featu	0.3741194135784187
100k_Compete_Report_Bing_Google_iPhone_Mobile_Modified	Google-Bing Entity MatchingIn 75,563 Google scrape entities those with a non-empty name are 12,507: Mapped to Bing entities: 𝟖𝟒.𝟖𝟗% (=(10,162+455)/12,507). Missing data.Among entities in            and            1.07%(=83+51) have Lat/Lon	0.3601289387516431

031371	LDCG V3Knowledge Transfer2017-04-14Brett Clippingdale, Sean King, Vikas Mittal, Li JiangLDCG V3 OutlineLDCG V2 vs V3: High-level comparisonLDCG V3: New distance ModelV2 vs V3 OverviewLDCG V3: GeoIntent HIT appLDCG V3: Calculate distance 	0.33651060579840814
031371	Online Click Labels for CAL Ranker:End – To End:aether://experiments/31148112-679c-476c-91d0-bb3ebbef81c2Continuous trained module continuously trains trees using HRS and then the ranker.OFE Ranker Training Pipeline:aether://experiments/01dbe0	0.31754193541604075
031371	BLU V3 Minghua Zhang      01/26/2016Next version of BLU Relevance Infrastructure​OutlineWhy BLU v3BLU v3 DesignCurrent StatusFuture WorkWhy BLU v3 (1)Limitations of current BLU infrastructureFeaturesCouldn’t utilize QAS feature	0.3082335469330437
031371	空检索优化：背景：空检索请求耗时分析：统计7.21的所有空检索耗时：(71551个)      1 10144.000000      2 bs:4767252.000000       ----->66.63ms      3 390.000000      4 统计：2818865.000000   ----->39.4ms      5 1187696.000000      6 1588991.000000          7 7554473.000000	0.30705167896934815
031371	唐蕾电话: (+86) 180-0132-3861Email: tanglei91@126.com工作经历                                                                    04/2014至今 :    	中国电信集团系统集成有限责任公司 软件测试工程师1.招标测试时间:05/2016至今项目描述：通过招标测试帮助甲方找到合适的厂家做他们项目中的某些模块。项目职责：负责招标测试跟产品经理讨论并细化需	0.29598740594387934
031371	CJK RELEVANCE ALL HANDS03/06/201401Qi ASG Memo02MS Poll	03USBS MeasurementAGENDA04Win in USBSVideoEbookMemo DocWatch the VideoVideoIntroductionWho We AreOur VisionClosingDiscussion and QnA01Qi ASG Memo02	0.29569588319371015
031371	成交日期 买卖标志 成交价格 成交数量 成交金额 20160106 买入 100 1702 20160113 买入 100 1532 20160325 卖出 100 1695 20160708 卖出 100 1570 20160725 卖出 500 10700 20160802 卖出 300 6660 20160802 卖出 200 4430 20160803 卖出 200 4672 20160908 卖出 100 2695 成交日期 买卖标志 成交价格 成交数量 成交金额 20160112 买入 100	0.2919486905657177
031371	成交日期 买卖标志 成交价格 成交数量 成交金额 20160105 买入 100 897 20160108 卖出 8 200 1600 成交日期 买卖标志 成交价格 成交数量 成交金额 20160106 买入 100 1702 20160113 买入 100 1532 20160325 卖出 100 1695 20160708 卖出 100 1570 20160725 卖出 500 10700 20160802 卖出 300 6660 20160802 卖出 200 4430 20160803 卖出 20	0.2891570262712361
031371	PO Box 91059Seattle, WA 98111-9159	VISION 	Member Claim Form 	for Microsoft  This form is to be used for Vision claims (routine exam and hardware) where you incurred expenses from a provider who did not bill the plan directly.For Medical or De	0.2842777212575921
031371	成交日期 买卖标志 成交价格 成交数量 成交金额 20160105 买入 100 897 20160108 卖出 8 200 1600 成交日期 买卖标志 成交价格 成交数量 成交金额 20160106 买入 100 1702 成交日期 买卖标志 成交价格 成交数量 成交金额 20160105 买入 100 897 20160108 卖出 8 200 1600 	0.27221640466595076

000620新华联	空检索优化：背景：空检索请求耗时分析：统计7.21的所有空检索耗时：(71551个)      1 10144.000000      2 bs:4767252.000000       ----->66.63ms      3 390.000000      4 统计：2818865.000000   ----->39.4ms      5 1187696.000000      6 1588991.000000          7 7554473.000000	0.7544741672685595
000620新华联	成交日期 买卖标志 成交价格 成交数量 成交金额 20160105 买入 100 897 20160108 卖出 8 200 1600 成交日期 买卖标志 成交价格 成交数量 成交金额 20160106 买入 100 1702 成交日期 买卖标志 成交价格 成交数量 成交金额 20160105 买入 100 897 20160108 卖出 8 200 1600 	0.6728716278208118
000620新华联	成交日期 买卖标志 成交价格 成交数量 成交金额 20160105 买入 100 897 20160108 卖出 8 200 1600 成交日期 买卖标志 成交价格 成交数量 成交金额 20160106 买入 100 1702 20160113 买入 100 1532 20160325 卖出 100 1695 20160708 卖出 100 1570 20160725 卖出 500 10700 20160802 卖出 300 6660 20160802 卖出 200 4430 20160803 卖出 20	0.6628630811895584
000620新华联	海量数据库的设计和实现淘宝海量数据库之一：来自业务的挑战(2010-11-24 11:34:38) 作为一个电子商务企业，从一开始，数据库及其事务能力在淘宝一直扮演着十分关键的角色，淘宝积累了丰富的数据库的架构和规划等方面的经验，产生了众多优秀的DBA。 淘宝是一家迅速发展的公司。全球网站排名公司Alexa提供的数据显示，2010年4月27日，Amazon、Ebay的用户占全球互联网用户的百分比分别为3.47%和2.68%，而淘宝的用户占全球互联网用户的百分比则达到了4.1%，淘宝网日	0.6570306149531145
000620新华联	成交日期 买卖标志 成交价格 成交数量 成交金额 20160106 买入 100 1702 20160113 买入 100 1532 20160325 卖出 100 1695 20160708 卖出 100 1570 20160725 卖出 500 10700 20160802 卖出 300 6660 20160802 卖出 200 4430 20160803 卖出 200 4672 20160908 卖出 100 2695 成交日期 买卖标志 成交价格 成交数量 成交金额 20160112 买入 100	0.6538936322407777
000620新华联	成交日期 买卖标志 成交价格 成交数量 成交金额 2016年亏319 2015及2016年已完结 20160105 买入 100 897 20160108 卖出 8 200 1600 20150615 买入 100 1889 20150615 买入 100 1840 20150624 卖出 100 1585 20150720 买入 100 1073 20150721 买入 100 1098 20150721 买入 100 1086 20150723 买入 100 1110 20150818 卖出 500 	0.6495027414303852
000620新华联	Query语义重要度标准Query语义重要度标准目录1.	标注整体介绍	22.	标注方法介绍	22.1.	分析Query中term的依存关系	22.2.	标注各依存关系的重要度	32.3.	融合规则	32.3.1.	典型标注方法介绍	32.3.2.	特殊情况处理	42.3.3.	无损词	53.	各依存类型介绍与典型范例（双term）	63.1.	需求关系	63.2.	属性关系	73.3.	限定关系	93.4.	施事关系	103.5.	受事关系	0.648239571212252
000620新华联	工作6周年5个月小记今天是中国时间8/24/2018，也就是我32岁的生日，这是一个不老也不再年轻的年纪。最近总是因为工作而郁郁寡欢，心中不快，所以决定记录总结一下，希望自己能有所释怀、转变、确立新的目标。从2012年3月31到现在，我已在微软Bing工作6年5个月。在此之前，我在百度实习9个月，在阿里巴巴实习2个月，在搜狗实习1个月。在微软北京CJK relevance组勤恳的工作2年6个月，从级别59升到61，做了1年半的DU, 1年的relevance。总体来说，老板们的风格是相关性主导基础	0.6482170432165753
000620新华联	贝叶斯分类模型：基础知识：假设	X：是数据元组，由n个属性描述；	H：是某种假设，如数据元组属于某特定类C	P(H|X)：表示给定X的属性描述，找出元组X属于类C的概率举例：X：一位35岁的顾客，收入为4w美元；H：顾客将购买计算机P(H|X)：在X的条件下，H的后验概率。当我们知道顾客的年龄和收入时，顾客X将购买计算机的概率。P(H)：H的先验概率。任意给定顾客将购买计算机的概率，独立与X。P(X|H)：在条件H下，X的后验概率。已知顾客购买了计算机，顾客是一位3	0.6456773500180534
000620新华联	神经网络原理及应用介绍Anti RD：王伟琼、张爱华主要内容特点及应用场景神经网络原理我们的经验和教训多线程训练下一步的工作应用场景分类预测时间允许的场合使用并行化等方法加速测试过程很快，且可以方便的使用hadoop平台环境比较固定的场合数据的统计特性变化不大需要定量预测的场合给出未知数据的定量预测神经网络特点优点对噪音数据有较好的适应能力对未知数据具有较好的预测分类能力拟合各种函数得出定量值缺点学习时间较长	0.6454703293526733
